{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f27ae675",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6227ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d840881",
   "metadata": {},
   "source": [
    "## Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c24af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for displaying ROC curves of multiple classifiers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_connected_points(results_list, results_original_roc, name=\"All Classifiers\"):\n",
    "    \"\"\"\n",
    "    Creates a plot showing the performance of all classifiers as points,\n",
    "    and connects them with a line, sorted by FPR.\n",
    "\n",
    "    Args:\n",
    "        results_list: A list of dictionaries, where each dict contains 'fpr', 'tpr'.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    # Convert results to a pandas DataFrame for easy sorting\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Sort the models by their False Positive Rate to create a left-to-right line\n",
    "    df_sorted = df.sort_values(by='fpr').reset_index(drop=True)\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot all the individual model points as a scatter plot\n",
    "    # This helps see the actual performance of each model\n",
    "    plt.scatter(df_sorted['fpr'], df_sorted['tpr'], c='black', marker='o', \n",
    "                alpha=0.6, s=100, zorder=3) # zorder=3 puts dots on top\n",
    "\n",
    "    # Plot the line connecting the points\n",
    "    plt.plot(df_sorted['fpr'], df_sorted['tpr'], color='red', lw=1.5,\n",
    "             alpha=0.8, label=f'{name} (AUC = {auc(df_sorted[\"fpr\"], df_sorted[\"tpr\"]):.2f})')\n",
    "    \n",
    "    #plot the original ROC curve\n",
    "    plt.plot(results_original_roc[\"fpr\"], results_original_roc[\"tpr\"], color='blue', \n",
    "             label=f'{results_original_roc[\"name\"]} (AUC = {results_original_roc[\"auc\"]:.2f})')\n",
    "\n",
    "    # Plot the \"no-skill\" line for reference\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Performance Path of All Trained Classifiers')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23b1ea",
   "metadata": {},
   "source": [
    "## Best ROC envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e350c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def get_best_roc_envelope(results_list, results_original_roc=None):\n",
    "    \"\"\"\n",
    "    Constructs the upper envelope of multiple ROC curves to find the best\n",
    "    possible operating points from a collection of classifiers.\n",
    "\n",
    "    This function is guaranteed to produce a list of points that starts at\n",
    "    (FPR=0, TPR=0) and ends at (FPR=1, TPR=1), making it suitable for direct\n",
    "    plotting and AUC calculation.\n",
    "\n",
    "    Args:\n",
    "        results_list (list): A list of dictionaries. Each dictionary must\n",
    "                             contain a 'model' name and the full ROC results\n",
    "                             under the 'full_roc' key.\n",
    "        results_original_roc (dict, optional): A dictionary containing the\n",
    "                                               ROC results of a baseline model,\n",
    "                                               which will also be included in\n",
    "                                               the comparison. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of dictionaries representing the optimal ROC\n",
    "              envelope. Each dictionary includes 'model', 'fpr', 'tpr',\n",
    "              and 'threshold'.\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "\n",
    "    # Step 1: Gather all ROC points from all provided models\n",
    "    all_results = results_list[:]\n",
    "    if results_original_roc:\n",
    "        all_results.append({\n",
    "            'model': 'original_baseline',\n",
    "            'full_roc': results_original_roc\n",
    "        })\n",
    "\n",
    "    for result in all_results:\n",
    "        model_name = result.get('model', 'Unknown Model')\n",
    "        roc = result.get('full_roc')\n",
    "        if not roc: continue\n",
    "\n",
    "        fprs = roc.get('fpr', [])\n",
    "        tprs = roc.get('tpr', [])\n",
    "        thresholds = roc.get('thresholds', [])\n",
    "\n",
    "        for i in range(len(fprs)):\n",
    "            threshold = thresholds[i] if i < len(thresholds) else thresholds[-1]\n",
    "            all_points.append({\n",
    "                'model': model_name, 'fpr': fprs[i],\n",
    "                'tpr': tprs[i], 'threshold': threshold\n",
    "            })\n",
    "\n",
    "    # Handle case with no data by returning a default diagonal line\n",
    "    if not all_points:\n",
    "        return [\n",
    "            {'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf},\n",
    "            {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}\n",
    "        ]\n",
    "\n",
    "    # Step 2: Sort all points by FPR (asc), then by TPR (desc)\n",
    "    all_points.sort(key=lambda p: (p['fpr'], -p['tpr']))\n",
    "\n",
    "    # Step 3: Build the core ROC envelope\n",
    "    best_roc_envelope = []\n",
    "    max_tpr_so_far = -1.0\n",
    "    for point in all_points:\n",
    "        # Add a point only if it has a strictly higher TPR\n",
    "        if point['tpr'] > max_tpr_so_far:\n",
    "            # To prevent adding multiple points at the same FPR, check if the last point\n",
    "            # has the same FPR and replace it if so (since this one has a higher TPR)\n",
    "            if best_roc_envelope and best_roc_envelope[-1]['fpr'] == point['fpr']:\n",
    "                best_roc_envelope[-1] = point\n",
    "            else:\n",
    "                best_roc_envelope.append(point)\n",
    "            max_tpr_so_far = point['tpr']\n",
    "    \n",
    "    # Step 4: Manually add extremities if they are missing\n",
    "    \n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not best_roc_envelope or best_roc_envelope[0]['fpr'] > 0.0:\n",
    "        best_roc_envelope.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if best_roc_envelope[-1]['fpr'] < 1.0 or best_roc_envelope[-1]['tpr'] < 1.0:\n",
    "        best_roc_envelope.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return best_roc_envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b781e9",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c3deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_data(dataset):\n",
    "    if dataset == \"data1\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [0, 2], [2, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "    elif dataset == \"data2\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [1, 2], [1, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    elif dataset == \"pneumoniaMNIST\":\n",
    "        import medmnist\n",
    "        print(medmnist.__version__)\n",
    "        # read in the PneumoniaMNIST dataset\n",
    "        from medmnist import PneumoniaMNIST\n",
    "        train_data = PneumoniaMNIST(split='train', download=True, size=224)\n",
    "        test_data = PneumoniaMNIST(split='test', download=True, size=224)\n",
    "        val_data = PneumoniaMNIST(split='val', download=True, size=224)\n",
    "        # print the dataset info\n",
    "        print(f\"Number of training samples: {len(train_data)}\")\n",
    "        print(f\"Number of test samples: {len(test_data)}\")\n",
    "        print(f\"Number of validation samples: {len(val_data)}\")\n",
    "\n",
    "    return train_data, test_data, val_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59034e",
   "metadata": {},
   "source": [
    "## Data1: NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74133e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a060ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 4\n",
    "K_FOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a702675",
   "metadata": {},
   "source": [
    "### Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3760e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "\n",
    "# A simple classifier head\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_features=2, hidden_units=32, num_classes=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_features (int): Number of input features (2 for your data)\n",
    "            hidden_units (int): Number of neurons in the hidden layer\n",
    "            num_classes (int): Number of output classes (1 for binary)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            # --- Hidden Layer 1 ---\n",
    "            # Takes 2 features in, outputs a hidden representation of size 32\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(),  # <-- The crucial non-linear activation function\n",
    "\n",
    "            # --- Output Layer ---\n",
    "            # Takes the 16-unit hidden representation, outputs 1 logit\n",
    "            nn.Linear(in_features=hidden_units, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "\n",
    "# A new LightningModule just for training the classifier\n",
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_features=512, hidden_units=32, num_classes=1, learning_rate=1e-4, pos_weight=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = SimpleClassifier(\n",
    "            input_features=self.hparams.input_features,\n",
    "            hidden_units=self.hparams.hidden_units,\n",
    "            num_classes=self.hparams.num_classes\n",
    "        )\n",
    "\n",
    "        self.current_test_threshold = 0.5  # Default threshold for binary classification\n",
    "\n",
    "        # This ensures the model's structure is correct upon initialization\n",
    "        if self.hparams.pos_weight is not None:\n",
    "            self.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(self.hparams.pos_weight))\n",
    "        else:\n",
    "            self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        \n",
    "        \n",
    "        # --- METRICS ---\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_auc = torchmetrics.AUROC(task=\"binary\")\n",
    "        \n",
    "        # This list will store outputs from each test step\n",
    "        self.test_step_outputs = []\n",
    "        # This dictionary will hold the final results\n",
    "        self.last_test_results = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self(features)\n",
    "        \n",
    "        # For the loss function, labels need to be reshaped to match outputs\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "        \n",
    "        # For metrics, squeeze predictions to match labels' shape\n",
    "        self.train_accuracy(outputs.squeeze(), labels.int())\n",
    "        \n",
    "        self.log('classifier_train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('classifier_train_acc', self.train_accuracy, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        features, labels = batch\n",
    "        outputs = self.model(features)\n",
    "        loss = self.criterion(outputs, labels.float().view(-1, 1))\n",
    "\n",
    "        # Append predictions and labels to our list for aggregation\n",
    "        self.test_step_outputs.append({\"preds\": outputs.detach(), \"labels\": labels.detach()})\n",
    "        \n",
    "        self.log('test_loss', loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        if not self.test_step_outputs:\n",
    "            return # Avoid errors if test loop was empty\n",
    "\n",
    "        # Concatenate all predictions and labels\n",
    "        all_preds = torch.cat([x['preds'] for x in self.test_step_outputs])\n",
    "        all_labels = torch.cat([x['labels'] for x in self.test_step_outputs])\n",
    "\n",
    "        # --- FIX: Squeeze BOTH predictions and labels to ensure they match ---\n",
    "        squeezed_preds = all_preds.squeeze()\n",
    "        all_probs = torch.sigmoid(squeezed_preds)\n",
    "        # The labels tensor might also be [N, 1], so we squeeze it as well.\n",
    "        int_labels = all_labels.squeeze().int()\n",
    "\n",
    "        # Calculate final scalar metrics\n",
    "        test_acc = self.test_accuracy(squeezed_preds, int_labels)\n",
    "        test_auc_val = self.test_auc(squeezed_preds, int_labels)\n",
    "\n",
    "\n",
    "        # Get the confusion matrix stats at the default 0.0 logit threshold\n",
    "        tp, fp, tn, fn, _ = torchmetrics.functional.stat_scores(\n",
    "            all_probs, int_labels, task=\"binary\", threshold=self.current_test_threshold\n",
    "        ) \n",
    "        \n",
    "        # Calculate TPR and FPR from these raw scores\n",
    "        epsilon = 1e-6\n",
    "        tpr_at_0 = tp / (tp + fn + epsilon)\n",
    "        fpr_at_0 = fp / (fp + tn + epsilon)\n",
    "\n",
    "        # Calculate data for the full ROC Curve\n",
    "        fpr_full, tpr_full, thresholds_full = torchmetrics.functional.roc(\n",
    "            torch.sigmoid(squeezed_preds),\n",
    "            int_labels,\n",
    "            task=\"binary\"\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"\\n--- Final Classifier Test Metrics ---\")\n",
    "        print(f\"Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"AUC: {test_auc_val:.4f}\")\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        \n",
    "        self.last_test_results = {\n",
    "            \"w\": self.hparams.get('w'),\n",
    "            \"fpr\": fpr_at_0.cpu().numpy(),\n",
    "            \"tpr\": tpr_at_0.cpu().numpy(),\n",
    "            \"threshold\": self.current_test_threshold,\n",
    "            \"auc\": test_auc_val.cpu().numpy(),\n",
    "            \"accuracy\": test_acc.cpu().numpy(),\n",
    "            \"full_roc\": {\n",
    "                \"fpr\": fpr_full.cpu().numpy(),\n",
    "                \"tpr\": tpr_full.cpu().numpy(),\n",
    "                \"thresholds\": thresholds_full.cpu().numpy()\n",
    "            }\n",
    "        }\n",
    "        self.test_step_outputs.clear()\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ea652",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f28dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1000, 2), (1000,)\n",
      "Test data shape: (600, 2), (600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train_data, test_data, val_data = generate_data(\"data2\")\n",
    "\n",
    "\n",
    "train_data_tensor = data.TensorDataset(torch.tensor(train_data[:, :-1], dtype=torch.float32),\n",
    "                                        torch.tensor(train_data[:, -1], dtype=torch.float32))\n",
    "train_loader = data.DataLoader(train_data_tensor, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) #over-write later for k-fold cross-validation\n",
    "test_data_tensor = data.TensorDataset(torch.tensor(test_data[:, :-1], dtype=torch.float32),\n",
    "                                       torch.tensor(test_data[:, -1], dtype=torch.float32))\n",
    "test_loader = data.DataLoader(test_data_tensor, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# initialize fold\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065beae",
   "metadata": {},
   "source": [
    "### Regular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261a6f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training for 1 epochs on train_loader ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4664d3b57fbd49708e95da054c837cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v16.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v16.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model from Phase 1 saved to: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v16.ckpt\n",
      "\n",
      "--- Testing model from Phase 1 checkpoint: /home/katzkid/Documents/RoC_Analysis/checkpoints/simple-clf-epoch=00-v16.ckpt ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781ca11050f24d85a3236d51ebe3b780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5700\n",
      "AUC: 0.6139\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6873143315315247\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "--- Manually Calculating Metrics on Test Set ---\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "[[176 124]\n",
      " [135 165]]\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.57      0.59      0.58       300\n",
      "     Class 1       0.57      0.55      0.56       300\n",
      "\n",
      "    accuracy                           0.57       600\n",
      "   macro avg       0.57      0.57      0.57       600\n",
      "weighted avg       0.57      0.57      0.57       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Instantiate the LightningModule\n",
    "model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    "\n",
    "checkpoint_callback_full_model = ModelCheckpoint(\n",
    "    monitor='classifier_train_acc',  # Monitor training accuracy\n",
    "    every_n_epochs=1,                # Save model every epoch\n",
    "    dirpath='checkpoints/',\n",
    "    filename='simple-clf-{epoch:02d}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "train_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',                 # Use GPUs\n",
    "    devices=1,                         # Number of GPUs to use\n",
    "    #strategy='ddp_notebook',                    # DistributedDataParallel strategy (best for multi-GPU)\n",
    "    max_epochs=NUM_EPOCHS,              # Total number of epochs\n",
    "    callbacks=[checkpoint_callback_full_model, progress_bar],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-train\"),\n",
    ")\n",
    "\n",
    "test_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=1,  # Use only one GPU\n",
    "    logger = pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple-clf-test\"),\n",
    "    # Add the callback here so the Trainer can find the 'best' path\n",
    "    callbacks=[checkpoint_callback_full_model],\n",
    "    precision='16-mixed'  # Use mixed precision for testing\n",
    ")\n",
    "\n",
    "# --- Phase 1 Training ---\n",
    "print(f\"--- Starting Training for {NUM_EPOCHS} epochs on train_loader ---\")\n",
    "train_trainer_1.fit(model, train_dataloaders=train_loader)\n",
    "\n",
    "# CRITICAL: Save the path to the best model from this phase\n",
    "path_after_phase1 = checkpoint_callback_full_model.best_model_path\n",
    "print(f\"Best model from Phase 1 saved to: {path_after_phase1}\")\n",
    "\n",
    "# --- Test 1: Evaluate the model from after Phase 1 ---\n",
    "print(f\"\\n--- Testing model from Phase 1 checkpoint: {path_after_phase1} ---\")\n",
    "model.current_test_title = \"ROC Curve after training on DataLoader 1\"\n",
    "model = LitClassifier.load_from_checkpoint(path_after_phase1)  # Load the model from Phase 1\n",
    "model.eval().to('cuda:0')  # Ensure the model is in evaluation mode and on GPU\n",
    "test_trainer_1.test(model, dataloaders=test_loader, ckpt_path=path_after_phase1)\n",
    "results_phase1 = model.last_test_results.copy()\n",
    "results_original_roc = {\"fpr\": results_phase1[\"full_roc\"][\"fpr\"], \"tpr\": results_phase1[\"full_roc\"][\"tpr\"], \"thresholds\": results_phase1[\"full_roc\"][\"thresholds\"], \"name\": \"Original NN data1\", \"auc\": results_phase1[\"auc\"], \"model\": model}\n",
    "\n",
    "# Metrics\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval() # Set to evaluation mode\n",
    "\n",
    "final_predictions = [] # This will store binary predictions (0s or 1s)\n",
    "true_labels = []\n",
    "\n",
    "print(\"\\n--- Manually Calculating Metrics on Test Set ---\")\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Move input data to the same device as the model\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # 1. Get the raw model output (logits) and convert to probabilities\n",
    "        outputs = torch.sigmoid(model(inputs))\n",
    "\n",
    "        # 2. Convert probabilities to binary class predictions (0 or 1) using a 0.5 threshold\n",
    "        preds = (outputs > 0.5).int()\n",
    "\n",
    "        final_predictions.extend(preds.cpu().numpy().flatten())\n",
    "        true_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "# Ensure they are numpy arrays for sklearn\n",
    "true_labels = np.array(true_labels)\n",
    "final_predictions = np.array(final_predictions)\n",
    "\n",
    "# Now, calculate metrics using the correct binary predictions\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "cm = confusion_matrix(true_labels, final_predictions)\n",
    "print(cm)\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "report = classification_report(true_labels, final_predictions, target_names=['Class 0', 'Class 1'], zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c2d0a",
   "metadata": {},
   "source": [
    "### Undersampling ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226e70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# --- This block generates the list of ratios for your experiment ---\n",
    "\n",
    "# 1. Get original class counts from your train_dataset\n",
    "def generate_ratios(train_data):\n",
    "   \n",
    "    try:\n",
    "        original_labels = np.array(train_data.targets).flatten()\n",
    "    except AttributeError:\n",
    "        original_labels = train_data[:, -1]\n",
    "\n",
    "    original_counts = Counter(original_labels)\n",
    "    num_pos_original = original_counts.get(1, 0)  \n",
    "    num_neg_original = original_counts.get(0, 0)  \n",
    "    print(f\"Original class counts: {num_pos_original} positives, {num_neg_original} negatives\")\n",
    "\n",
    "    # The pivot point for your function's logic\n",
    "    orig_sample_ratio = num_pos_original / num_neg_original \n",
    "\n",
    "    # 2. Define how many steps for each regime\n",
    "    N_POINTS_PER_REGIME = 25  # You can change this\n",
    "\n",
    "    # 3. Generate ratios for Regime 1 (from near 0 up to the pivot)\n",
    "    # This will test scenarios from extreme negative-class dominance up to the original balance.\n",
    "    print(f\"Generating ratios for Regime 1 (target ratio < {orig_sample_ratio})...\")\n",
    "    ratios_regime1 = np.geomspace(\n",
    "        start=1/num_neg_original,                      # A small starting ratio (e.g., 1 positive for every 10 negatives)\n",
    "        stop=orig_sample_ratio,         # Go up to the original ratio\n",
    "        num=N_POINTS_PER_REGIME,\n",
    "        endpoint=False                  # Exclude the pivot itself to avoid the 'else' block\n",
    "    )\n",
    "\n",
    "    # 4. Generate ratios for Regime 2 (from the pivot up to 3494)\n",
    "    # This will test scenarios from the original balance up to extreme positive-class dominance.\n",
    "    print(f\"Generating ratios for Regime 2 (target ratio > {orig_sample_ratio})...\")\n",
    "    ratios_regime2 = np.geomspace(\n",
    "        start=orig_sample_ratio, # Start just above the pivot\n",
    "        stop=num_pos_original,                      # Your specified upper limit\n",
    "        num=N_POINTS_PER_REGIME\n",
    "    )\n",
    "\n",
    "    # 5. Combine, sort, and create the final list for the loop\n",
    "    #    We also add the original ratio to ensure we have a baseline run.\n",
    "    all_ratios = sorted(list(np.concatenate([ratios_regime1, ratios_regime2, [orig_sample_ratio]])))\n",
    "\n",
    "    print(f\"\\nGenerated {len(all_ratios)} unique sample ratios to test.\")\n",
    "    print(\"First few ratios:\", np.round(all_ratios[:5], 3))\n",
    "    print(\"Last few ratios:\", np.round(all_ratios[-5:], 2))\n",
    "    return all_ratios, num_neg_original, num_pos_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfd1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def undersample_dataset(train_dataset, sample_ratio):\n",
    "\n",
    "    \n",
    "    \n",
    "    # Get the labels from the dataset (0 for normal, 1 for pneumonia)\n",
    "    try:\n",
    "        labels = np.array(train_dataset.targets).flatten()\n",
    "    except AttributeError:\n",
    "        labels = train_dataset[:, -1]\n",
    "\n",
    "    # Find the indices for the positive (pneumonia) and negative (normal) classes\n",
    "    positive_indices = np.where(labels == 1)[0]\n",
    "    negative_indices = np.where(labels == 0)[0]\n",
    "    num_orig_positive = len(positive_indices)\n",
    "    num_orig_negative = len(negative_indices)\n",
    "\n",
    "    orig_sample_ratio = num_orig_positive / num_orig_negative\n",
    "    print(f\"Original sample ratio (positive:negative): {orig_sample_ratio:.2f}\")\n",
    "\n",
    "    #based on sample ratio find the number of positive or negative samples\n",
    "    if sample_ratio>orig_sample_ratio:\n",
    "        neg_samples = int(num_orig_positive / sample_ratio)\n",
    "        pos_samples = num_orig_positive\n",
    "        sampled_negative_indices = np.random.choice(negative_indices, neg_samples, replace=False)\n",
    "        final_indices = np.concatenate([sampled_negative_indices, positive_indices])\n",
    "    elif sample_ratio<orig_sample_ratio:\n",
    "        pos_samples = int(sample_ratio * num_orig_negative)\n",
    "        neg_samples = num_orig_negative\n",
    "        sampled_positive_indices = np.random.choice(positive_indices, pos_samples, replace=False)\n",
    "        final_indices = np.concatenate([sampled_positive_indices, negative_indices])\n",
    "    else:\n",
    "        pos_samples = num_orig_positive\n",
    "        neg_samples = num_orig_negative\n",
    "        final_indices = np.concatenate([positive_indices, negative_indices])\n",
    "        \n",
    "    # Shuffle the final indices to mix positive and negative samples\n",
    "    np.random.shuffle(final_indices)\n",
    "\n",
    "    # Create a subset of the original dataset with the sampled indices\n",
    "    return train_dataset[final_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d1bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 1/4 ---\n",
      "Original class counts: 378 positives, 372 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 1.0161290322580645)...\n",
      "Generating ratios for Regime 2 (target ratio > 1.0161290322580645)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.005 0.007]\n",
      "Last few ratios: [140.95 180.37 230.82 295.38 378.  ]\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8651a8c077442fa820a1a01f64af5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v17.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v17.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v17.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_1/best-model-fold1-epoch=00-v17.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f08f12f2787475a91343de144439189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2749\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7430925369262695\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7876aa8e5b249cfa3f43317e0f6e85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b45f838e94409f979ca69b7dc3af4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2650\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7615585923194885\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346dfe6b4d5340f8a0c4ddc26a669894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ca2097f0ff4d7e8a7280c770a47291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2588\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7825551629066467\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca933515bf11493b9a3c171f5cd2f27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5cf57d7e0944daa39f0b91d1741946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2555\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8064152002334595\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ca94d2710e409ea9786878cc1233bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f49b31a25447339af593ad245e8584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2521\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8328529596328735\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5d23d2814c41bf8cf6b5f396a780b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a863760802449198b5cfcbacd891ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2507\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8618545532226562\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8fb961a91a445e889d7cc61acd4a94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad2eda153fb461f833579b4d7e3351b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2515\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8924035429954529\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748a2315395242c59e78ac94d9e7fb50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eca0310be8e46538e65e6b0baaaea07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2528\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9256980419158936\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54ddfa409af4c92a28a49dadc8e9b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b2cdec787d4a558f95503c2ef186f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2519\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9628835320472717\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e6ced787fd4b418b9af4424192a902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db49f91e5a5d4939aed19beba8fbffc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2562\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9974338412284851\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435539a65ab14057972fbd46dff959cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81bd805e1e949e5a9b2f6e1f1a361f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2589\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.035998821258545\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (6) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27075c38255e45cda10b2abb551af363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6059b985ab240f89271e83ed0d8d516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2629\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0825011730194092\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55457bdae6140cb9c3e3a6d6e514cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79525d837f0d45ca8c0bf78160c48bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2697\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.124325156211853\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd561cc9a2844c09691b1e69e5e7a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4635c6daf61c4b57b9ff7d4b0f92f64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2776\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1641403436660767\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db8ed999d954b90b1aebb21d2d09b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046e6c7cf1054751bf0402f3c8c73b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2840\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1971818208694458\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554f969004ef43ba96fd38e8d3b89eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a600defe31df4b36929f6ae550ac6b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2892\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.2099231481552124\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f441f7dac71c4468a955c957d82de775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba37e14b69774a0a85691f07390190fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2926\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.217329740524292\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50be631c85e44113b34b20e8eff063aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b2c8a5a5744b2dabff9eb3d7c055d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.2983\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1876742839813232\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2170ea4ff14749a3bbcec093ac672826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4965d9784b1c4c719ca537ee9813182e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3028\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1474117040634155\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (7) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350adb15dea6442dad369a1c994b7282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60e69e07b0f415ab24836073b8e018e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3051\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.096774697303772\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3ec74440ae64997a07327efdb83f244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b66d6ac662e452eac6ae92b3bf59faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3112\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0390164852142334\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7b2a21cbcd43e8a4cc2f602f3770fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04aadd17dc924266bed00d9fd9f64457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3205\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.971116840839386\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938ac031b5be478580d03a27da904d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d76c64dae349858baeb31b42183400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3326\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9068917632102966\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f66b79f08b444ca46533c03bbc3b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97047ad58ab44f8a52e2cfedfceda56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.3665\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8400854468345642\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2134129b7fdd4123a8ce1319105fa85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516e774e39ad4f3b9d464f7bf4d357e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.4746\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7751419544219971\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (11) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ffc1d7abc54021afbfea3f1f0eb651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed95b4c949a149d99781ac0bda26007c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.6333\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7172993421554565\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb5264a59b647e4814179eab2c830fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a0c85d538548fd8613dc9a91b24365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5120\n",
      "AUC: 0.7233\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6729666590690613\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5654028d1c834cc3b2213babb583cca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acafd3d962d442c5aa62b11bbf357cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7240\n",
      "AUC: 0.7833\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6423667073249817\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65767d711c9844979d30a2cb156300de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6755b990e443cba60f33f72a50083e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8201\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6226012110710144\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a9d789bdc848ee8c71b173df895ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6663c51ecbbf41d3bf4fe2bccdb0aabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8355\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6109229326248169\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f06f0cd11174b38819bf770adec2a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b435e1d43634495bdff412e53145d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.8450\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6045517325401306\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b6d602c53d4e2fba90553456405cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1009012dec1344f9958c25a07433d7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6680\n",
      "AUC: 0.8488\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6026245355606079\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803552cc444c4a7292018ee5666e24c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1753edb8a4374d528717644ccf48a59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6760\n",
      "AUC: 0.8508\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6044471263885498\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fc6481c93f49fa88e8a6371954dab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30752c0e91e24dd89ede49066053afa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6600\n",
      "AUC: 0.8524\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.608582615852356\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681fc9d4a08044e3af7174a276a10f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57b9142ef7b4d61855e8418c96253e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.8534\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6152670979499817\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e638f22574411fb335e44cf85400a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54e3b070f8b4e1aaad026edb41b4f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.8535\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6237248778343201\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0d3c4d031c477f97f9fb19758a1a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7383c7ded14877bb64cd6abb0e942d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.8536\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6347448229789734\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96788cba0cdc4f4b88e3269b737e1443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f04bb993854157aa4bcf8200e06e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.8543\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6476730704307556\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1514e39954df4e59a423e41dbc589368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef640db71694048a1dd22077f83176e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6120\n",
      "AUC: 0.8543\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6625935435295105\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503e77ab8da94398b6452bc55e508b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20352976d79446299d9c5a47e29374f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6040\n",
      "AUC: 0.8534\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6796949505805969\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53ad50e746346aab3a4e639ca936820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8170a15c497a4db095746fab8e8b0e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5840\n",
      "AUC: 0.8524\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.699102520942688\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9d46346b574e5eaa9de04c8986be32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341dcd13890f4c1b89e41807317896b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5800\n",
      "AUC: 0.8522\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7209584712982178\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb97bda9bab48de98f6eee6ec867001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529dc6b3f64447e78c6389eda6e425e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5760\n",
      "AUC: 0.8515\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7438458800315857\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684e4e86087d4d95a8a3e36119db737c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2332cd88de441eaa3e8ed40e00411ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5760\n",
      "AUC: 0.8506\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7646210789680481\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad350b730f434d0d829aaeb41f57dd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc818067351e4c8ca0b6ddcc83685a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5680\n",
      "AUC: 0.8501\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7862520813941956\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60476bf0c42042b2990de4387c889c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10920b6056ca40dbb46da791ba1d7326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5640\n",
      "AUC: 0.8494\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8097356557846069\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66445803884048dab00729f05770582e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d51e72c7174d22a7282c9a9990a156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5480\n",
      "AUC: 0.8488\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8344933986663818\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9803d9c4e0e47f695258bc982c010df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49e7880813541fc964f0e3b66d16d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.8482\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8601152300834656\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215c351ddd9d499090342b9164b7b8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af45ee7bfd8f455196032bc407a55d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5400\n",
      "AUC: 0.8470\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8871428966522217\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d349c774d742559200f89b92ecb80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_1/best-model-fold1-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4984bdef87c451597d45c44d1c487f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.8462\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9159224629402161\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af15b9fb5fe44e08f54151aa21af429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v5.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v5.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 1 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v5.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_1/best-model-fold1-epoch=00-v5.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 1 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab199d9fec104460b3be18d73193e815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5200\n",
      "AUC: 0.8460\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9458543658256531\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 2/4 ---\n",
      "Original class counts: 368 positives, 382 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 0.9633507853403142)...\n",
      "Generating ratios for Regime 2 (target ratio > 0.9633507853403142)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.005 0.007]\n",
      "Last few ratios: [136.62 175.02 224.22 287.25 368.  ]\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e875e248ff476f847c0036683de198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "034d3c9a2db345deaa7b33c2b4da0783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2047\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8057905435562134\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad345d1f10704c4d82ff1728820b5ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75de9fc057864514a98384661120ca71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1962\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8295233845710754\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303789f1a2b3474da39e7d08c13bdaa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681ef8e84273483396ea44f3b04d4118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1914\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8549324870109558\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e7aa57c77149fda89c1b00db007b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d47d36a06f04f58bbfa7918a848114d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1872\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8884616494178772\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12be8411c1d240b29ed0d204d3d25940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e78b75b88a4bdf8be764530f19ed03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1839\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9241988062858582\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f75d4e1433840c68023dcbc9c82c606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab98ebc8897f4ea4b92fa5dac78f8c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1821\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9616643190383911\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee37f76b6bb49448fe4663b400de23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a7dd2ac0cb4282aa1a073aff2dffb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1814\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0013171434402466\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db7e88fe6bb4dc5ae132420c55c4030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7e603432394d7b87f56c12fb4a70e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1800\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0433589220046997\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e55b25b532478cbf953344777b7692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6ac84739844bd6b61d377cf9ab40af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4720\n",
      "AUC: 0.1798\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0865001678466797\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c486c0f28e148888d11a9af778909e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf2f74f61f140d48bb08efd27bb6a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1792\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1352816820144653\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24fcc318e66410e99eec1f850886d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6190f50fd174078bc5a456535756af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1830\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1753184795379639\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf066291fd44f5c948af41e38dfb757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180465d4f25d44cc80c5bffed0433e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1850\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.2204902172088623\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5eec7d97c1b40cdab6281d3408b282b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022b38386bc24b27abf2c7205ff85ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.1916\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.251210331916809\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711511917cd749cc982a8718d091c786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93783676c153456a91843891c982ef18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2004\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.2826486825942993\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f424fce172974cfdaaad36b255d64a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e6a7b42a3245fa9741f445347ed915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2050\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.3060619831085205\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd9aba05ef64f40aff58266edde11b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc07df5b9d540418a60fa441848ecca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2124\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.3226732015609741\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8ccc6350e04db784ab57fa7b70e722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e1d1fcae7a44c586298bddb21aba51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2174\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.3138558864593506\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced8991f89964197b12a170ff51680db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dcf08002014ae2aba5ba84c34427a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2220\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.2791740894317627\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2649709724c44eab922051bbece58eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578ac32ee1d54e85928844ed20e8dee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2366\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.230324149131775\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed809f5658e423983cd83d48fb21a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1605442a8bb3416ba0357c17f64a3631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2515\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1709167957305908\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e8916cc8594f2ca3d40aba4ca8e2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a1c1ef8ef349dba20476d1f748a284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.2743\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1189407110214233\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4365e002f9774a0c897baa726c579aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb269bfe6e240fbacbc395988c5906b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.3223\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.054006814956665\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2cdd03681b4480b6af3cd68498785a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3decf09135a84a6995fe3170cbc6d38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.4028\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9864169359207153\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d206f5a2c448e589645630df11c31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf8b3cdb1a242e2bc80f06737b251fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.5412\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9161723852157593\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34213cf8d7d940f8b92feda4f75356c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2449b7408a18407bb44790a6be26d3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.6817\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8460894227027893\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748912e1c8d4449fb62ddab85dd94517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86d1168a9bd45d899e87cf0c8246489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.7652\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7768157720565796\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3bafe0e77545879141ad56f39c3a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29b658e7b40468d899eaf8833adee9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.8060\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7170367240905762\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b441986397847128146fc58ab622b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14dcb476a084aff872e6966688b9c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4720\n",
      "AUC: 0.8304\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6700695157051086\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf89e420fc940c59f8749dd24700d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2584157de148db8c1a2dcba6b05d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6280\n",
      "AUC: 0.8439\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6334453225135803\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f03b4a395844a85973ccb3862ca0ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addff7b7411342b8ab41dc382e948fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.8496\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6061335206031799\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e71ce8e979a4e209e616dd5a0acacc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78201ef5de134b1f9ca3db7a071835da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7080\n",
      "AUC: 0.8520\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5864254236221313\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a537f69b85441a9a77d03a055623b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229d5a3f369d40789ac3feb7daafab8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8556\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5699397921562195\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea514adc9184496180e1dc165cf9d54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4dd23ac6e3f4f15812103290c76d096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7520\n",
      "AUC: 0.8569\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5566287040710449\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305b92e3ccc14da1b385154637ce7021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cc0f397fdc4318859cc0257542a8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7600\n",
      "AUC: 0.8583\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.548261284828186\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe4ef2a240941848636808a161ce396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e1820dcee249df91e99605fd361870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7320\n",
      "AUC: 0.8576\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5422207117080688\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39683b16dfad468d9cb6bfd62768a465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610c4d4ce3954c77a8700561cecff233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8574\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5387017726898193\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d22aeb410cb4922900bf1529647979e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c62c06b18884fffae6e3e4ac0317d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8568\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5371223092079163\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6a8f79cddd4df190b385fc9e0060b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400a097880c144218f5270845fac3ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7160\n",
      "AUC: 0.8577\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5379713177680969\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4429a78b0888460f952877799554fb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a001bc84397044f99b1770b34a95f7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7080\n",
      "AUC: 0.8569\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5412276387214661\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870321974bc043e0b51ea5a639e7ddef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c876db6e824e4f1ea6db44875b1b172f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7040\n",
      "AUC: 0.8562\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.545985758304596\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a7c3f382004780afae8a8e7098404a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee346854d4e4b3483ea7a270d3e41fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.8549\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5522181987762451\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b03c04c4c84d789099ab09f02ebcf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac247fe639f4b50acaa8e08c49185ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6960\n",
      "AUC: 0.8544\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5601263642311096\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9755d7e01ca542368d75633b70529faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4976dca36a9f4678a79f39b9721754ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.8540\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5700172781944275\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b307e11abe4056848f81d46e2bc928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf2f758f1a2432db6adb913be5255ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.8532\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5800992250442505\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873aaa998498459ba0d700fd3c3ad904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb33f726d24416595b431b57b49c75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6800\n",
      "AUC: 0.8528\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5916373133659363\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa6b90511284d968cfd89f26725c00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ad4e22da764410a92ad9acb601bef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.8523\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6053287386894226\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3435c30cf3dd49d8863476665c63865f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7161076970404231b035b421932e062c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.8516\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6207806468009949\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a08f72440ac41d88442dc2136a4fb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f407d7074bf749308c7cb44078c508b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6640\n",
      "AUC: 0.8507\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6376273036003113\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35d8f4bdc65491fb08f14bf5bf684fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d55a2f9e01f4697a66aa7ede199841b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6600\n",
      "AUC: 0.8503\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6549413800239563\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77199bc3b424866bb8de1c138270bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_2/best-model-fold2-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d485ea26164dd4974c481aa6f9a4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6480\n",
      "AUC: 0.8497\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.674176037311554\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c587451b2e491f82521bc13ea5bf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v5.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v5.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 2 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v5.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_2/best-model-fold2-epoch=00-v5.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 2 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669e8a81875d4f518142c2342a8208f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6440\n",
      "AUC: 0.8491\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6940557360649109\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "--- Starting Fold 3/4 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class counts: 370 positives, 380 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 0.9736842105263158)...\n",
      "Generating ratios for Regime 2 (target ratio > 0.9736842105263158)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.005 0.007]\n",
      "Last few ratios: [137.48 176.09 225.54 288.88 370.  ]\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b72257d682b4691b66d114b24f67e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7292298a946460cb4374f589a0a105c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5160\n",
      "AUC: 0.5334\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7172581553459167\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3920a0360b42109b1617aedc36c77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b09c1aeabf7454599cc41741589604f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4840\n",
      "AUC: 0.5027\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7156358361244202\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a743f94afcb492e84f192f8b7d2d050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798d60e314f7483aa90294aa4499cf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4440\n",
      "AUC: 0.4682\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7162420749664307\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4050a73acde4821895b8bbc3d8474e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2cf9ff281240af86d0b4148eaee384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4120\n",
      "AUC: 0.4339\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7189261317253113\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036b318acd0f47fd8fc07c0bd282a57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b818d7b237914d55bbfe649b2eb3a88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.3960\n",
      "AUC: 0.4066\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7237836718559265\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e513d91fe44dd0906ae2949bcf3a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca8ca17019c4eb7aa2f598ee7d43ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4160\n",
      "AUC: 0.3851\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7308009266853333\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111f78708d69450386ddf95c820748cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4294c72d659345efae13c7f6108ae1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4640\n",
      "AUC: 0.3614\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7414585947990417\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9bebae83174162a042528a595f177e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4541bd7e8d4ad98cc7bdac4ff95f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4560\n",
      "AUC: 0.3344\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.754833996295929\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3a2599d6b849fcac4330c7d0b94e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e683e93e1a4fa4889c69107799e410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4840\n",
      "AUC: 0.3127\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7673903703689575\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9ab4aaa14d44e487fb926a21578cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee43afb08ce3439484bb25a92bb58c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2822\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7832854986190796\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760d4b79c72146e9ba071a9f441c7969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27143c4afdc54cfeba931846899e2847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2390\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7989940047264099\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be12065485b14dee9f4fde0a515176bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45258d5fc374cdd9dad7687b670cabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2008\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8181977868080139\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1a245a0c6c417f91f1a0200e5e5887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98114c912a304ed6926f651a34a4b097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1819\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8347432017326355\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6206458f0b24311943019d023d4aee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c065bfd5e7ed4e02be1548698947a9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1699\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8555095195770264\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e8472878144f9fb9515fa95fe390e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5452788c66ef4dcdafdb68292f898511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1674\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8722931146621704\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f38ab4e48854aecb09c8ebc086c4464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c942d30620a43c39b8ef001d3a361cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1661\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8982598781585693\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de5dacf2732496abfa9ee24aa380c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827c1f873b524c82a0c62d888c45d0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.1813\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9128673076629639\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7e585d770e4a2f8716cc7426f0773f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269e2552a3b54aeda3ac8b2c9c88e309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2010\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9194435477256775\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4043f55179404e249a0ecfc4b44d6061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525580bd467a4894816989425b5f2681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2503\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9127093553543091\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd42f1f6bbc841bd8ebaad8a444ce167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af5f2f27bc546d48836edd8b4a71a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.2908\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9123475551605225\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9511985b376348c4b019d7daa4bbc7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e938dd5dac5b4775a3d55a8d6317de2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.3544\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8846752643585205\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9921daab7ca2480eb355df6b959f38cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8179b08768c44450aee6c88f06631f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.4380\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.843661367893219\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80d52c4327d45f5af8c9ea054a05eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a18239bbee4bae86b9a31b98d9d5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.5260\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8055543303489685\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0c96cdfc1c41ac89015ae59694d5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b3bf712eda4fd792ee0d3c78f8ab30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.6205\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7596288323402405\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512f5cb834624ad5866908837149dd97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1741e5b856c94795ad4695ff00c9997c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.6984\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7156115770339966\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feac2a4b7b6444b2bc4ac69b465a6880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e621449edf4a058b482763d0844884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4800\n",
      "AUC: 0.7656\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6716550588607788\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84445c1c4b5047488d248ac8fee5168c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e3d77e2508428ab1550238e37a57da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.8019\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6362646818161011\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3c9ae318c54d4da5804e796268caf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdec98a72b87466bb159bdbcfe0c054d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7680\n",
      "AUC: 0.8170\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6086018681526184\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9757ed345d4680bbab7eddea217c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eeb2fbad3a548e793954680d009b55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8256\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5891926288604736\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15bba4c2dc79436c9ad7a0e392bf4891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2587a8ceac4e40d8831d4057872e5549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8279\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5766652226448059\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d4c2a28fa24daa8868653ff6a037f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b18a7641794d9989fdfabfbd309197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8281\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5697757005691528\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f62476bf8b44fd0b4fd15b4dbf8c69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7e46cf72e448858d0bdb8f23faaeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7200\n",
      "AUC: 0.8257\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5659310221672058\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55bca5fc3bd422a8676d1884b815d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8940b435c9cd4bc3a690c2cf20c81011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8262\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5655063390731812\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28691c0af037420fb06700ee6f8fba11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc5eb04361b4283bfe8df65bb8c5a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8245\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.567673921585083\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cd459f444942499e405bbc56d27f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293f9a30ab004e1baf4a0d115926a81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7080\n",
      "AUC: 0.8233\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5720875263214111\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443d97aebbfa4d8ea3ed5b547c279c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6f54bc7ad2437d966f733f19060354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.8205\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5798749923706055\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9df84048a3c4d5d8fe2ebc8cef91bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8831a8ef5834423090dcdd901510f0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7000\n",
      "AUC: 0.8189\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5902303457260132\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7705823c684379bbc0a51ad9eb908e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214970d4771545689020ddcd345341ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6960\n",
      "AUC: 0.8171\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6023295521736145\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa4f14e6f704f64884eec90f0d3948e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ae66e6941547639db1bb0c26f6dba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.8148\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6179484724998474\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63dea7d92afb4aa9ac5ff4b7acb31719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc02be54529044efb4e90b80cd9c1a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.8132\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6346496343612671\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7363a498b23d424b8f6e0f52578c2bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183588b463e54de8a390ddc8827ad4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6920\n",
      "AUC: 0.8117\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6513602137565613\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5287c41d5d4e1eaeebfad2aed8e67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480f833e10ba4fddad4c5dd9589711e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.8096\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6702102422714233\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3187a5753df84874b9b1b93fe750e14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c28bac6b28c45d8a3a34f7f7bc0798e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.8080\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6888540983200073\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6b8b2a51034ba19b7b32d4439a4c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0796956e581346a589dd07ec881a0dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6760\n",
      "AUC: 0.8071\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7112359404563904\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b894ae81fb45b6b373c57a8a62cd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633df12d1a184d9894aafab1d1333f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6680\n",
      "AUC: 0.8061\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7347466945648193\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d755f6499b54fdabb4d189b038a742b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f837ad0afd14d89a6df598d6795f501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6600\n",
      "AUC: 0.8045\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7606726884841919\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d11f8cde4942949896cf1172bd1d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b669f2a05d84aa9b2451ce5569a5860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6600\n",
      "AUC: 0.8029\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7867240309715271\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8595aca8b98743f3bbbeac0c619b25aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b24b181a4d44d51971c4cd8a4cb27c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6520\n",
      "AUC: 0.8023\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.813260555267334\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1be8e270b55411d87e71905ffa14a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4612685f9e40487989d19c255f16e29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6480\n",
      "AUC: 0.8012\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8431553244590759\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1088f8e3e64b20aff065d3cdfb037c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_3/best-model-fold3-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54b02fcad83471c863f93ccfd30410a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6400\n",
      "AUC: 0.8008\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8747382760047913\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 0.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0316f4b8be6e46f98ab89e1771e725e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v5.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v5.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 3 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v5.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_3/best-model-fold3-epoch=00-v5.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 3 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6975ef6fc54da1a38733e4fca9e608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6360\n",
      "AUC: 0.7994\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9067208766937256\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 4/4 ---\n",
      "Original class counts: 384 positives, 366 negatives\n",
      "Generating ratios for Regime 1 (target ratio < 1.0491803278688525)...\n",
      "Generating ratios for Regime 2 (target ratio > 1.0491803278688525)...\n",
      "\n",
      "Generated 51 unique sample ratios to test.\n",
      "First few ratios: [0.003 0.003 0.004 0.006 0.007]\n",
      "Last few ratios: [143.58 183.61 234.81 300.28 384.  ]\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25117be91fbf432dbbc2189682bdcc34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 1 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_1/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 1 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928c0f9a49554a929ef7ddf8b21efa35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4680\n",
      "AUC: 0.5574\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6888123750686646\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20eae18c25549d293cdb4dd72b9f109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 2 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_2/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 2 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8737410fb4cc49929eb37e121039349b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.4520\n",
      "AUC: 0.4346\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.696405291557312\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7acaea9a3144a98c63d14ebb9bc50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 3 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_3/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 3 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9400eae789474a2f9de0763d8d45d18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5080\n",
      "AUC: 0.3717\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7074582576751709\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca44a81f10c4538898f968b0802bb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 4 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_4/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 4 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83907b8be00c43b694c338864ff089bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5000\n",
      "AUC: 0.3299\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7218055129051208\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad692a203afc43b0ac0cc5f8483c0743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 5 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_5/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1930a371ab6c49ffb65fc623caac6de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5240\n",
      "AUC: 0.3083\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7394762635231018\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75b1e02af164f829fcb33532690dedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 6 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_6/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 6 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b0d50054f84bbbb29bfb352490959d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2986\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7602344751358032\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578aff0759a44c12a320c54ac5f50be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 7 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_7/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 7 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0067ac39bb445db53e12b1bb0016f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2916\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7840190529823303\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961f439ea49446e09b3ebc452848c5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 8 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_8/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 8 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a5d7b25a224393a7a6fd237a95230e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2878\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8103085160255432\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c09aa62a7444da93780e84d89bd807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 9 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_9/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 9 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031240e98e104f9eb9f7388e87089fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2854\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8392935991287231\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddc93b574c64ebdbd3b227407f4c5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 10 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_10/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 10 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f939c4bc2ba949db959f07f7d437e1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2859\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            0.868845522403717\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87d1720a2e04c16a0a69c051ea9ecc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 11 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_11/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 11 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57aaa78a29564babbd65763883b9735a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2858\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9015440940856934\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699c63479b32435097aca2d7a58ac57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 12 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_12/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 12 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45a179de047433cb38c7789eac0d232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2854\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9351975321769714\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cd97300ac946b28dc257ff8821035a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 13 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_13/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 13 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ab62cc893644ad865b8632b4363a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2888\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9671075940132141\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7027872522f8444fae73127fc6d751f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 14 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_14/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 14 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651fe95586ff4eb8a92bb061604d08ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2905\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0049251317977905\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c14d87a0044ae3a156e28c02ec9e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 15 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_15/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 15 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a271bb5de0a1441f87bb64bd5a9e623c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2953\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0406962633132935\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9d398222134318b970b48af9c14415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 16 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_16/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 16 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c9c896787949788772e84a01665db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.2983\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0640822649002075\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ceb00b454fa4accac127e283a91dc26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 17 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_17/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 17 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8ff24dbadd4580a87dd22cca3aabea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3039\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.063159704208374\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25baa1def5ca48ee8dc38b05d7a9751c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 18 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_18/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 18 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54664e3379714ed489898bdce7198442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3070\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.031141996383667\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503f99c6d58d4aa9b08659b87a1d4cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 19 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_19/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 19 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ff2d7331524441a8b2fceead1fb763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3122\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9950731992721558\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2cb279fb409452a936e84215e89bc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 20 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_20/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 20 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c72fece1574cf0aac3883f7ce24467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3182\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9461104869842529\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53c3065e49344da9897b622e94465c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 21 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_21/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 21 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d9b719a8074bd2a69ce2d1a1800777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3316\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8954601883888245\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442c35f0e3364322ac8d5b30cd59bd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 22 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_22/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 22 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b0b8b0908947efb45be261ee49ad38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.3746\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8478026390075684\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691f4394a7754cc2b8515fd1194ea895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 23 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_23/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 23 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f749e1e759439f96393d9e8e4615ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.4425\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7953307032585144\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00948c38fc694d84af75f48ba5b03c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 24 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_24/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 24 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3983f8ef5e845c1be2abb83e8d7bc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5360\n",
      "AUC: 0.5314\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7380992770195007\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbd3a4a2fba4a219acdc8b3a908c995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 25 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_25/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 25 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f5e0e93c0e41fb8db2663ce6eb2793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5520\n",
      "AUC: 0.5909\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6871799230575562\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9a4e95b4b54d8a84a818f21acc90c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 26 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_26/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 26 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f18d9b7e9d1450f8e980166ae569bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.7141\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6412854194641113\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05293cd2d59e4c78825c70ca6759254f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 27 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_27/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 27 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35b0d1130344ab4b1ba1202b3c75fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7400\n",
      "AUC: 0.8303\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6087271571159363\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c040d42bc51b48e8a2e958cfbf768e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 28 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_28/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 28 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddeb2b6d22d3489f985a423f982a54c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7360\n",
      "AUC: 0.8652\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5897067189216614\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef89092422fa43eda1f249cc597d5625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 29 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_29/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 29 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd94755e068c4bd8b4c6374ce908f331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7280\n",
      "AUC: 0.8726\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5818029642105103\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f3fbd2f9b3447b8e8b7ade8e393b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 30 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_30/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 30 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083c81149f6b499695f36c2fed033233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.7120\n",
      "AUC: 0.8732\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5822691321372986\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e8069f3f8445a7b7e47b917478af0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 31 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_31/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 31 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170031458617493bb5907551b986fedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6880\n",
      "AUC: 0.8705\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.5905090570449829\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4a01d1b0d5452e9f0a4ae5f14d2780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 32 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_32/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 32 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c367af01644085998f568b07f8d474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6840\n",
      "AUC: 0.8673\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6023442149162292\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5bac2c6746244eaa8f2a91af9263ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 33 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_33/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 33 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab56177432846d9a55a732c38b5ea72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6760\n",
      "AUC: 0.8638\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6229070425033569\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d314fa278241446dabf257dc62a57750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 34 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_34/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 34 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef107120b75419885169abe99415520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6560\n",
      "AUC: 0.8597\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6474140882492065\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178343b5844b41f9abbc879f0cd96908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 35 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_35/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 35 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c801760bee4d189f354ccc2b1d8173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6320\n",
      "AUC: 0.8563\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.6718589067459106\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fff929a24e4eb19e6f02c808c78550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 36 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_36/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 36 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a05852f2ef47ed88d9923bfb72734c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.8526\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7012943029403687\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cc8ea117944d17aa7b552dc7abb14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 37 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_37/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 37 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e839a1ae004497b8f8564ae1947d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6160\n",
      "AUC: 0.8485\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7359826564788818\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091bedb746814b43a3585543c36221b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 38 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_38/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 38 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e80a09f564f4228b0368f3b51bb0d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.8454\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.7746216058731079\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f4741f7f7548089a2a91c1329f5092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 39 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_39/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 39 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b62aea093c0a4be6ab39199c53dd84fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.8429\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8151555061340332\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b901fdfc4d4dc78c7457a07b908a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 40 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_40/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 40 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b485609887e42c3b333ab90c4cc904c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6080\n",
      "AUC: 0.8390\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.8576806783676147\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40e76525be14a4a9836f641cd9c3091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 41 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_41/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 41 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b95e822b41d42e8b5eb14c6bf0586a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.6000\n",
      "AUC: 0.8360\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9037207961082458\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c860920977504926a5dcbb6d916055fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 42 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_42/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 42 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16457293a7874e8daa4b9040368437d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5920\n",
      "AUC: 0.8333\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.9530518651008606\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9a5f66320c4044992536e0b4891cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 43 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_43/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 43 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b318eb69fb4952bd7433f6d6faedd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5800\n",
      "AUC: 0.8311\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.0034219026565552\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89ed6f7e356460d91892936068ab6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 44 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_44/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 44 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52dc4dabdc06451eb42d382834971047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5760\n",
      "AUC: 0.8293\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.056376576423645\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46240c533d64369b1e251bcb87b5c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 45 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_45/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 45 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba891f9dc7947859642f5ac9b7180d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5720\n",
      "AUC: 0.8273\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1121327877044678\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190ece18e90e45cbb0486b47dde647b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 46 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_46/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 46 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb241a14a5a4bc9b9636325aff68223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5600\n",
      "AUC: 0.8249\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.1716508865356445\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbd8fff1d434c7ca732a40f5f3181cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 47 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_47/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 47 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07f2af3aa764c289d35ef4fc4926dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5480\n",
      "AUC: 0.8225\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.2298377752304077\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0459037c59ad4aef8506f0bcc76342b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 48 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_48/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 48 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03810e24c3f4549bc255c4452f20fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5280\n",
      "AUC: 0.8195\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.2937079668045044\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce46f43cd08c455b92cca38baf2cbb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 49 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_49/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 49 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1de361a31046c8987d21393512606b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5280\n",
      "AUC: 0.8171\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.3589792251586914\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fe8d66c01d47388433e8a89c4b6032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v14.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v14.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 50 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v14.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_50/fold_4/best-model-fold4-epoch=00-v14.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 50 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38b24d8a1d34262b8a2325bc5cff9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5280\n",
      "AUC: 0.8147\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           1.4267653226852417\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/katzkid/miniforge3/envs/MLlabs/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name           | Type              | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | model          | SimpleClassifier  | 129    | train\n",
      "1 | criterion      | BCEWithLogitsLoss | 0      | train\n",
      "2 | train_accuracy | BinaryAccuracy    | 0      | train\n",
      "3 | test_accuracy  | BinaryAccuracy    | 0      | train\n",
      "4 | test_auc       | BinaryAUROC       | 0      | train\n",
      "-------------------------------------------------------------\n",
      "129       Trainable params\n",
      "0         Non-trainable params\n",
      "129       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "9         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample ratio (positive:negative): 1.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a14c399e2448fe82bee2453218c648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Restoring states from the checkpoint path at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v5.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Loaded model weights from the checkpoint at /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v5.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fold 4 Stage 51 complete. Best model path: /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v5.ckpt ---\n",
      "Loading best weights from /home/katzkid/Documents/RoC_Analysis/checkpoints/stage_51/fold_4/best-model-fold4-epoch=00-v5.ckpt to continue...\n",
      "\n",
      "--- Testing model after Fold 4 Stage 51 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92cd980d5ece43fea376fb10450cb9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Classifier Test Metrics ---\n",
      "Accuracy: 0.5240\n",
      "AUC: 0.8149\n",
      "-------------------------------------\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            1.485900640487671\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "#store the weighted classifiers of all the folds\n",
    "list_folds_weighted_clfs = []  # List to store classifiers from all folds\n",
    "#store the best classfiers of all the folds\n",
    "list_folds_best_models = []  # List to store best models from all folds\n",
    "\n",
    "# Dictionary to store the history of each fold\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "# 3. K-fold cross-validation loop\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data_tensor)):\n",
    "    list_weighted_clfs = [] # List to store the models trained at each stage\n",
    "    best_clfs = [] # List to store the best models from each stage\n",
    "    best_model_paths = [] # List to store the path of the best model from each stage\n",
    "    print(f\"--- Starting Fold {fold + 1}/{K_FOLDS} ---\")\n",
    "    # 1. Instantiate the LightningModule\n",
    "    model = LitClassifier(input_features=2, hidden_units=32, learning_rate=LEARNING_RATE)\n",
    " \n",
    "    # --- Create datasets and dataloaders for the current fold ---\n",
    "    # FIX 2: Get the fold-specific data by indexing the underlying tensors of the TensorDataset\n",
    "    fold_train_features, fold_train_labels = train_data_tensor.tensors[0][train_ids], train_data_tensor.tensors[1][train_ids]\n",
    "    fold_val_features, fold_val_labels = train_data_tensor.tensors[0][val_ids], train_data_tensor.tensors[1][val_ids]\n",
    "\n",
    "    # Create the validation loader for this fold\n",
    "    fold_val_dataset = data.TensorDataset(fold_val_features, fold_val_labels)\n",
    "    fold_loader = data.DataLoader(fold_val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "    # Create a temporary dataset for the generate_ratios function\n",
    "    temp_train_dataset_for_ratios = np.c_[fold_train_features, fold_train_labels]\n",
    "    all_ratios, Class0_initial, Class1_initial = generate_ratios(train_data=temp_train_dataset_for_ratios)\n",
    "\n",
    "\n",
    "    for i, sample_ratio in enumerate(all_ratios):\n",
    "        undersampled_fold_train_data = undersample_dataset(temp_train_dataset_for_ratios, sample_ratio=sample_ratio)\n",
    "        # Create a new TensorDataset for the undersampled data\n",
    "        fold_train_dataset = data.TensorDataset(\n",
    "            torch.tensor(undersampled_fold_train_data[:, :-1], dtype=torch.float32),\n",
    "            torch.tensor(undersampled_fold_train_data[:, -1], dtype=torch.float32)\n",
    "        )\n",
    "        # Create a DataLoader for the undersampled training data\n",
    "        fold_train_loader = data.DataLoader(\n",
    "            fold_train_dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=True,  # Shuffle the training data\n",
    "            num_workers=NUM_WORKERS,\n",
    "            drop_last=True  # Drop the last incomplete batch if it exists\n",
    "        )\n",
    "        \n",
    "        \n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            every_n_epochs=1,                # Save model every epoch\n",
    "            dirpath=f'checkpoints/stage_{i+1}/fold_{fold+1}/',\n",
    "            filename=f'best-model-fold{fold+1}-{{epoch:02d}}',\n",
    "            save_top_k=1,\n",
    "            mode='max',\n",
    "        )\n",
    "        \n",
    "        # 3. Instantiate a NEW Trainer for this specific stage\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}_fold_{fold+1}_ratio_{sample_ratio}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "        \n",
    "        # 4. Train the model. It will start with weights from the previous stage.\n",
    "        trainer.fit(model, train_dataloaders=fold_train_loader)\n",
    "        \n",
    "        # 5. Get the path to the best model from THIS stage and store it\n",
    "        if checkpoint_callback.best_model_path:\n",
    "            best_path_this_stage = checkpoint_callback.best_model_path\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. Best model path: {best_path_this_stage} ---\")\n",
    "            best_model_paths.append(best_path_this_stage)\n",
    "            \n",
    "            # 6. CRITICAL: Load the best weights back into the model object\n",
    "            # This ensures we carry forward the BEST model to the next stage, not the last.\n",
    "            print(f\"Loading best weights from {best_path_this_stage} to continue...\")\n",
    "            model = LitClassifier.load_from_checkpoint(best_path_this_stage, strict=False)  # Use strict=False to ignore missing keys if any\n",
    "        else:\n",
    "            print(f\"--- Fold {fold+1} Stage {i+1} complete. No checkpoint was saved. ---\")\n",
    "            # If no checkpoint was saved, the model object will just have the weights from the last epoch.\n",
    "\n",
    "        # 7. Test the model after each stage\n",
    "        print(f\"\\n--- Testing model after Fold {fold+1} Stage {i+1} ---\")\n",
    "        trainer.test(model, dataloaders=fold_loader, ckpt_path=best_path_this_stage)\n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "        best_clfs = get_best_roc_envelope(list_weighted_clfs, results_original_roc)\n",
    "    list_folds_weighted_clfs.append(list_weighted_clfs)\n",
    "    list_folds_best_models.append(best_clfs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fd2a468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to pickle/NN_data2_undersampling.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_models': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.4918033),\n",
       "    'threshold': np.float16(0.5293)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0078125),\n",
       "    'tpr': np.float32(0.5081967),\n",
       "    'threshold': np.float16(0.525)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.015625),\n",
       "    'tpr': np.float32(0.5163934),\n",
       "    'threshold': np.float16(0.4788)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0390625),\n",
       "    'tpr': np.float32(0.52459013),\n",
       "    'threshold': np.float16(0.5195)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.046875),\n",
       "    'tpr': np.float32(0.5327869),\n",
       "    'threshold': np.float16(0.5176)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0546875),\n",
       "    'tpr': np.float32(0.5409836),\n",
       "    'threshold': np.float16(0.517)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0625),\n",
       "    'tpr': np.float32(0.55737704),\n",
       "    'threshold': np.float16(0.5566)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09375),\n",
       "    'tpr': np.float32(0.57377046),\n",
       "    'threshold': np.float16(0.4666)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1328125),\n",
       "    'tpr': np.float32(0.59016395),\n",
       "    'threshold': np.float16(0.4614)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.140625),\n",
       "    'tpr': np.float32(0.60655737),\n",
       "    'threshold': np.float16(0.4602)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15625),\n",
       "    'tpr': np.float32(0.63114756),\n",
       "    'threshold': np.float16(0.7197)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.171875),\n",
       "    'tpr': np.float32(0.6639344),\n",
       "    'threshold': np.float16(0.692)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1875),\n",
       "    'tpr': np.float32(0.6803279),\n",
       "    'threshold': np.float16(0.87)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1953125),\n",
       "    'tpr': np.float32(0.6885246),\n",
       "    'threshold': np.float16(0.8984)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.203125),\n",
       "    'tpr': np.float32(0.704918),\n",
       "    'threshold': np.float16(0.657)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2109375),\n",
       "    'tpr': np.float32(0.72131145),\n",
       "    'threshold': np.float16(0.701)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.21875),\n",
       "    'tpr': np.float32(0.7295082),\n",
       "    'threshold': np.float16(0.836)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2265625),\n",
       "    'tpr': np.float32(0.74590164),\n",
       "    'threshold': np.float16(0.8)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.234375),\n",
       "    'tpr': np.float32(0.7704918),\n",
       "    'threshold': np.float16(0.7163)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.25),\n",
       "    'tpr': np.float32(0.77868855),\n",
       "    'threshold': np.float16(0.777)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2578125),\n",
       "    'tpr': np.float32(0.78688526),\n",
       "    'threshold': np.float16(0.756)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2734375),\n",
       "    'tpr': np.float32(0.8114754),\n",
       "    'threshold': np.float16(0.791)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.28125),\n",
       "    'tpr': np.float32(0.8196721),\n",
       "    'threshold': np.float16(0.79)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2890625),\n",
       "    'tpr': np.float32(0.8278689),\n",
       "    'threshold': np.float16(0.771)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3046875),\n",
       "    'tpr': np.float32(0.8360656),\n",
       "    'threshold': np.float16(0.8477)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.328125),\n",
       "    'tpr': np.float32(0.86885244),\n",
       "    'threshold': np.float16(0.883)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3515625),\n",
       "    'tpr': np.float32(0.8770492),\n",
       "    'threshold': np.float16(0.8965)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.359375),\n",
       "    'tpr': np.float32(0.8852459),\n",
       "    'threshold': np.float16(0.713)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3828125),\n",
       "    'tpr': np.float32(0.89344263),\n",
       "    'threshold': np.float16(0.686)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.390625),\n",
       "    'tpr': np.float32(0.90163934),\n",
       "    'threshold': np.float16(0.6836)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.40625),\n",
       "    'tpr': np.float32(0.91803277),\n",
       "    'threshold': np.float16(0.604)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4140625),\n",
       "    'tpr': np.float32(0.92622954),\n",
       "    'threshold': np.float16(0.6284)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4375),\n",
       "    'tpr': np.float32(0.93442625),\n",
       "    'threshold': np.float16(0.621)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4453125),\n",
       "    'tpr': np.float32(0.9590164),\n",
       "    'threshold': np.float16(0.8564)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.453125),\n",
       "    'tpr': np.float32(0.9672131),\n",
       "    'threshold': np.float16(0.8066)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4609375),\n",
       "    'tpr': np.float32(0.9836066),\n",
       "    'threshold': np.float16(0.817)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4921875),\n",
       "    'tpr': np.float32(0.9918033),\n",
       "    'threshold': np.float16(0.7656)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.6015625),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.588)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.43939394),\n",
       "    'threshold': np.float16(0.666)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.008474576),\n",
       "    'tpr': np.float32(0.47727272),\n",
       "    'threshold': np.float16(0.4397)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025423728),\n",
       "    'tpr': np.float32(0.50757575),\n",
       "    'threshold': np.float16(0.521)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.042372882),\n",
       "    'tpr': np.float32(0.5151515),\n",
       "    'threshold': np.float16(0.5503)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.050847456),\n",
       "    'tpr': np.float32(0.530303),\n",
       "    'threshold': np.float16(0.577)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06779661),\n",
       "    'tpr': np.float32(0.54545456),\n",
       "    'threshold': np.float16(0.604)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.084745765),\n",
       "    'tpr': np.float32(0.5530303),\n",
       "    'threshold': np.float16(0.5435)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09322034),\n",
       "    'tpr': np.float32(0.56060606),\n",
       "    'threshold': np.float16(0.5073)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.10169491),\n",
       "    'tpr': np.float32(0.59090906),\n",
       "    'threshold': np.float16(0.4695)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.118644066),\n",
       "    'tpr': np.float32(0.6060606),\n",
       "    'threshold': np.float16(0.4666)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.12711865),\n",
       "    'tpr': np.float32(0.6136364),\n",
       "    'threshold': np.float16(0.4333)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.13559322),\n",
       "    'tpr': np.float32(0.6287879),\n",
       "    'threshold': np.float16(0.43)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1440678),\n",
       "    'tpr': np.float32(0.6363636),\n",
       "    'threshold': np.float16(0.4897)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15254237),\n",
       "    'tpr': np.float32(0.6439394),\n",
       "    'threshold': np.float16(0.488)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.16101696),\n",
       "    'tpr': np.float32(0.65909094),\n",
       "    'threshold': np.float16(0.4243)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.16949153),\n",
       "    'tpr': np.float32(0.6666667),\n",
       "    'threshold': np.float16(0.4236)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1779661),\n",
       "    'tpr': np.float32(0.6818182),\n",
       "    'threshold': np.float16(0.4224)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.18644068),\n",
       "    'tpr': np.float32(0.68939394),\n",
       "    'threshold': np.float16(0.4219)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.19491525),\n",
       "    'tpr': np.float32(0.6969697),\n",
       "    'threshold': np.float16(0.56)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.21186441),\n",
       "    'tpr': np.float32(0.7121212),\n",
       "    'threshold': np.float16(0.4458)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.22033899),\n",
       "    'tpr': np.float32(0.72727275),\n",
       "    'threshold': np.float16(0.385)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.23728813),\n",
       "    'tpr': np.float32(0.75),\n",
       "    'threshold': np.float16(0.501)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2457627),\n",
       "    'tpr': np.float32(0.75757575),\n",
       "    'threshold': np.float16(0.47)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.26271185),\n",
       "    'tpr': np.float32(0.780303),\n",
       "    'threshold': np.float16(0.8184)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.27118644),\n",
       "    'tpr': np.float32(0.79545456),\n",
       "    'threshold': np.float16(0.6836)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.27966103),\n",
       "    'tpr': np.float32(0.8181818),\n",
       "    'threshold': np.float16(0.6978)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29661018),\n",
       "    'tpr': np.float32(0.8333333),\n",
       "    'threshold': np.float16(0.64)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.30508474),\n",
       "    'tpr': np.float32(0.84090906),\n",
       "    'threshold': np.float16(0.764)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.31355932),\n",
       "    'tpr': np.float32(0.8484849),\n",
       "    'threshold': np.float16(0.729)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3220339),\n",
       "    'tpr': np.float32(0.8787879),\n",
       "    'threshold': np.float16(0.768)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3559322),\n",
       "    'tpr': np.float32(0.8863636),\n",
       "    'threshold': np.float16(0.805)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3983051),\n",
       "    'tpr': np.float32(0.8939394),\n",
       "    'threshold': np.float16(0.5503)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.40677965),\n",
       "    'tpr': np.float32(0.9166667),\n",
       "    'threshold': np.float16(0.4514)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41525424),\n",
       "    'tpr': np.float32(0.92424244),\n",
       "    'threshold': np.float16(0.4778)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.42372882),\n",
       "    'tpr': np.float32(0.9318182),\n",
       "    'threshold': np.float16(0.451)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.44067797),\n",
       "    'tpr': np.float32(0.9469697),\n",
       "    'threshold': np.float16(0.475)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.44915253),\n",
       "    'tpr': np.float32(0.95454544),\n",
       "    'threshold': np.float16(0.514)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4915254),\n",
       "    'tpr': np.float32(0.9621212),\n",
       "    'threshold': np.float16(0.5283)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5084746),\n",
       "    'tpr': np.float32(0.969697),\n",
       "    'threshold': np.float16(0.5996)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5677966),\n",
       "    'tpr': np.float32(0.97727275),\n",
       "    'threshold': np.float16(0.567)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5762712),\n",
       "    'tpr': np.float32(0.99242425),\n",
       "    'threshold': np.float16(0.5317)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.6694915),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.3667)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.17333333),\n",
       "    'threshold': np.float16(0.5273)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.0033333334),\n",
       "    'tpr': np.float32(0.19),\n",
       "    'threshold': np.float16(0.5264)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.006666667),\n",
       "    'tpr': np.float32(0.20333333),\n",
       "    'threshold': np.float16(0.525)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.01),\n",
       "    'tpr': np.float32(0.23333333),\n",
       "    'threshold': np.float16(0.524)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.013333334),\n",
       "    'tpr': np.float32(0.27333334),\n",
       "    'threshold': np.float16(0.521)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.016666668),\n",
       "    'tpr': np.float32(0.28333333),\n",
       "    'threshold': np.float16(0.5205)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.02),\n",
       "    'tpr': np.float32(0.28666666),\n",
       "    'threshold': np.float16(0.52)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.025),\n",
       "    'tpr': np.float32(0.2923077),\n",
       "    'threshold': np.float16(0.7617)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float32(0.026666667),\n",
       "    'tpr': np.float32(0.29333332),\n",
       "    'threshold': np.float16(0.5195)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.033333335),\n",
       "    'tpr': np.float32(0.3846154),\n",
       "    'threshold': np.float16(0.6255)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05),\n",
       "    'tpr': np.float32(0.4076923),\n",
       "    'threshold': np.float16(0.4927)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.058333334),\n",
       "    'tpr': np.float32(0.43076923),\n",
       "    'threshold': np.float16(0.647)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06666667),\n",
       "    'tpr': np.float32(0.43846154),\n",
       "    'threshold': np.float16(0.4915)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.075),\n",
       "    'tpr': np.float32(0.44615385),\n",
       "    'threshold': np.float16(0.614)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.083333336),\n",
       "    'tpr': np.float32(0.46153846),\n",
       "    'threshold': np.float16(0.611)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.09166667),\n",
       "    'tpr': np.float32(0.4923077),\n",
       "    'threshold': np.float16(0.6987)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.108333334),\n",
       "    'tpr': np.float32(0.5307692),\n",
       "    'threshold': np.float16(0.5264)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.11666667),\n",
       "    'tpr': np.float32(0.54615384),\n",
       "    'threshold': np.float16(0.525)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.125),\n",
       "    'tpr': np.float32(0.5538462),\n",
       "    'threshold': np.float16(0.524)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.13333334),\n",
       "    'tpr': np.float32(0.5769231),\n",
       "    'threshold': np.float16(0.5615)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.14166667),\n",
       "    'tpr': np.float32(0.5923077),\n",
       "    'threshold': np.float16(0.5566)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15),\n",
       "    'tpr': np.float32(0.64615387),\n",
       "    'threshold': np.float16(0.586)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15833333),\n",
       "    'tpr': np.float32(0.6615385),\n",
       "    'threshold': np.float16(0.5503)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.16666667),\n",
       "    'tpr': np.float32(0.6846154),\n",
       "    'threshold': np.float16(0.5474)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.18333334),\n",
       "    'tpr': np.float32(0.7),\n",
       "    'threshold': np.float16(0.5054)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.19166666),\n",
       "    'tpr': np.float32(0.7307692),\n",
       "    'threshold': np.float16(0.5015)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.23333333),\n",
       "    'tpr': np.float32(0.74615383),\n",
       "    'threshold': np.float16(0.4534)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.24166666),\n",
       "    'tpr': np.float32(0.75384617),\n",
       "    'threshold': np.float16(0.4902)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.25),\n",
       "    'tpr': np.float32(0.8),\n",
       "    'threshold': np.float16(0.52)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.275),\n",
       "    'tpr': np.float32(0.8076923),\n",
       "    'threshold': np.float16(0.515)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.28333333),\n",
       "    'tpr': np.float32(0.8153846),\n",
       "    'threshold': np.float16(0.548)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29166666),\n",
       "    'tpr': np.float32(0.8230769),\n",
       "    'threshold': np.float16(0.5435)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3),\n",
       "    'tpr': np.float32(0.83076924),\n",
       "    'threshold': np.float16(0.5415)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.30833334),\n",
       "    'tpr': np.float32(0.8384615),\n",
       "    'threshold': np.float16(0.5386)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.325),\n",
       "    'tpr': np.float32(0.84615386),\n",
       "    'threshold': np.float16(0.5703)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.35833332),\n",
       "    'tpr': np.float32(0.85384613),\n",
       "    'threshold': np.float16(0.5605)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.38333333),\n",
       "    'tpr': np.float32(0.86153847),\n",
       "    'threshold': np.float16(0.6514)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.39166668),\n",
       "    'tpr': np.float32(0.8923077),\n",
       "    'threshold': np.float16(0.7637)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4),\n",
       "    'tpr': np.float32(0.9076923),\n",
       "    'threshold': np.float16(0.632)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.40833333),\n",
       "    'tpr': np.float32(0.9307692),\n",
       "    'threshold': np.float16(0.879)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41666666),\n",
       "    'tpr': np.float32(0.95384616),\n",
       "    'threshold': np.float16(0.8843)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.425),\n",
       "    'tpr': np.float32(0.96153843),\n",
       "    'threshold': np.float16(0.8813)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.45833334),\n",
       "    'tpr': np.float32(0.9846154),\n",
       "    'threshold': np.float16(0.753)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5083333),\n",
       "    'tpr': np.float32(0.99230766),\n",
       "    'threshold': np.float16(0.796)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.56666666),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.7104)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.0),\n",
       "    'tpr': np.float32(0.47413793),\n",
       "    'threshold': np.float16(0.539)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.014925373),\n",
       "    'tpr': np.float32(0.49137932),\n",
       "    'threshold': np.float16(0.5327)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.02238806),\n",
       "    'tpr': np.float32(0.5086207),\n",
       "    'threshold': np.float16(0.5986)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.029850746),\n",
       "    'tpr': np.float32(0.51724136),\n",
       "    'threshold': np.float16(0.5303)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.04477612),\n",
       "    'tpr': np.float32(0.5258621),\n",
       "    'threshold': np.float16(0.594)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.052238807),\n",
       "    'tpr': np.float32(0.5344828),\n",
       "    'threshold': np.float16(0.5264)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.05970149),\n",
       "    'tpr': np.float32(0.5689655),\n",
       "    'threshold': np.float16(0.5864)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.06716418),\n",
       "    'tpr': np.float32(0.57758623),\n",
       "    'threshold': np.float16(0.5225)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.08208955),\n",
       "    'tpr': np.float32(0.5862069),\n",
       "    'threshold': np.float16(0.585)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.104477614),\n",
       "    'tpr': np.float32(0.6034483),\n",
       "    'threshold': np.float16(0.5215)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.1119403),\n",
       "    'tpr': np.float32(0.61206895),\n",
       "    'threshold': np.float16(0.521)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.11940298),\n",
       "    'tpr': np.float32(0.62931037),\n",
       "    'threshold': np.float16(0.52)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.12686567),\n",
       "    'tpr': np.float32(0.63793105),\n",
       "    'threshold': np.float16(0.5195)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.13432837),\n",
       "    'tpr': np.float32(0.6465517),\n",
       "    'threshold': np.float16(0.519)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.14179105),\n",
       "    'tpr': np.float32(0.6637931),\n",
       "    'threshold': np.float16(0.5747)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.15671642),\n",
       "    'tpr': np.float32(0.6810345),\n",
       "    'threshold': np.float16(0.623)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.17910448),\n",
       "    'tpr': np.float32(0.6896552),\n",
       "    'threshold': np.float16(0.5137)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.18656716),\n",
       "    'tpr': np.float32(0.70689654),\n",
       "    'threshold': np.float16(0.6167)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.19402985),\n",
       "    'tpr': np.float32(0.7241379),\n",
       "    'threshold': np.float16(0.615)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.21641791),\n",
       "    'tpr': np.float32(0.73275864),\n",
       "    'threshold': np.float16(0.698)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2238806),\n",
       "    'tpr': np.float32(0.75),\n",
       "    'threshold': np.float16(0.611)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.23134328),\n",
       "    'tpr': np.float32(0.7586207),\n",
       "    'threshold': np.float16(0.695)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.24626866),\n",
       "    'tpr': np.float32(0.76724136),\n",
       "    'threshold': np.float16(0.6553)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.2835821),\n",
       "    'tpr': np.float32(0.7758621),\n",
       "    'threshold': np.float16(0.5537)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29104477),\n",
       "    'tpr': np.float32(0.8189655),\n",
       "    'threshold': np.float16(0.6367)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.29850745),\n",
       "    'tpr': np.float32(0.82758623),\n",
       "    'threshold': np.float16(0.636)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.30597016),\n",
       "    'tpr': np.float32(0.87068963),\n",
       "    'threshold': np.float16(0.708)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.32089552),\n",
       "    'tpr': np.float32(0.8965517),\n",
       "    'threshold': np.float16(0.662)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.33582088),\n",
       "    'tpr': np.float32(0.9137931),\n",
       "    'threshold': np.float16(0.5747)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.35820895),\n",
       "    'tpr': np.float32(0.92241377),\n",
       "    'threshold': np.float16(0.606)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.3955224),\n",
       "    'tpr': np.float32(0.9396552),\n",
       "    'threshold': np.float16(0.6943)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.40298507),\n",
       "    'tpr': np.float32(0.95689654),\n",
       "    'threshold': np.float16(0.788)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.41044775),\n",
       "    'tpr': np.float32(0.9655172),\n",
       "    'threshold': np.float16(0.8535)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.42537314),\n",
       "    'tpr': np.float32(0.98275864),\n",
       "    'threshold': np.float16(0.7515)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.4477612),\n",
       "    'tpr': np.float32(0.9913793),\n",
       "    'threshold': np.float16(0.7715)},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': np.float32(0.5),\n",
       "    'tpr': np.float32(1.0),\n",
       "    'threshold': np.float16(0.858)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}]],\n",
       " 'weighted_clfs': [[{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.078125 , 0.09375  , 0.1015625,\n",
       "            0.109375 , 0.1328125, 0.1484375, 0.15625  , 0.1796875, 0.203125 ,\n",
       "            0.21875  , 0.25     , 0.2578125, 0.265625 , 0.28125  , 0.2890625,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5      , 0.5078125, 0.5078125, 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6640625,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.703125 , 0.703125 , 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.75     , 0.7578125, 0.7578125, 0.765625 ,\n",
       "            0.765625 , 0.765625 , 0.765625 , 0.765625 , 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.7734375, 0.78125  , 0.796875 , 0.796875 ,\n",
       "            0.796875 , 0.8046875, 0.8046875, 0.8046875, 0.8125   , 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.84375  , 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.8671875,\n",
       "            0.875    , 0.8828125, 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.04098361, 0.04918033,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.19672132, 0.19672132, 0.20491803, 0.21311475, 0.21311475,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.27868852, 0.29508197,\n",
       "            0.30327868, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.352459  , 0.352459  ,\n",
       "            0.37704918, 0.37704918, 0.39344263, 0.39344263, 0.40983605,\n",
       "            0.4180328 , 0.4180328 , 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.45081967, 0.45081967, 0.45901638, 0.46721312, 0.48360655,\n",
       "            0.4918033 , 0.5163934 , 0.52459013, 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.6639344 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8032787 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4875, 0.4863, 0.4856, 0.4849, 0.4844, 0.4836, 0.4834,\n",
       "            0.483 , 0.4824, 0.4812, 0.4807, 0.48  , 0.4795, 0.4792, 0.479 ,\n",
       "            0.4788, 0.4785, 0.4783, 0.478 , 0.4778, 0.4775, 0.477 , 0.4768,\n",
       "            0.4766, 0.4763, 0.4756, 0.4753, 0.4744, 0.4731, 0.473 , 0.4724,\n",
       "            0.4722, 0.4714, 0.4712, 0.4646, 0.4644, 0.464 , 0.4639, 0.462 ,\n",
       "            0.4617, 0.4612, 0.4604, 0.4597, 0.4578, 0.4573, 0.455 , 0.4526,\n",
       "            0.451 , 0.4507, 0.45  , 0.4495, 0.449 , 0.4473, 0.4456, 0.445 ,\n",
       "            0.4448, 0.444 , 0.4414, 0.4404, 0.44  , 0.4395, 0.4382, 0.438 ,\n",
       "            0.437 , 0.4358, 0.4333, 0.4329, 0.4326, 0.4321, 0.432 , 0.4302,\n",
       "            0.4292, 0.4287, 0.4277, 0.4268, 0.4265, 0.4263, 0.426 , 0.4243,\n",
       "            0.4236, 0.4226, 0.4219, 0.4214, 0.4211, 0.421 , 0.4207, 0.4204,\n",
       "            0.4194, 0.4192, 0.4185, 0.418 , 0.4167, 0.4165, 0.415 , 0.4146,\n",
       "            0.414 , 0.4138, 0.4126, 0.4119, 0.411 , 0.4104, 0.4097, 0.4082,\n",
       "            0.408 , 0.4075, 0.4062, 0.406 , 0.4058, 0.4055, 0.4048, 0.4043,\n",
       "            0.404 , 0.4036, 0.4033, 0.4026, 0.402 , 0.4016, 0.401 , 0.4004,\n",
       "            0.3997, 0.3992, 0.399 , 0.3987, 0.3984, 0.3965, 0.3958, 0.3955,\n",
       "            0.3953, 0.3948, 0.3943, 0.3936, 0.3933, 0.3926, 0.3916, 0.3909,\n",
       "            0.3906, 0.3887, 0.3877, 0.3872, 0.3865, 0.3855, 0.384 , 0.3835,\n",
       "            0.383 , 0.3818, 0.3813, 0.3804, 0.3796, 0.3794, 0.3787, 0.3774,\n",
       "            0.3767, 0.3765, 0.375 , 0.3745, 0.3735, 0.373 , 0.3713, 0.3708,\n",
       "            0.3691, 0.369 , 0.368 , 0.3665, 0.3647, 0.3635, 0.363 , 0.3625,\n",
       "            0.3616, 0.3613, 0.3608, 0.3584, 0.3572, 0.355 , 0.3547, 0.3525,\n",
       "            0.351 , 0.3503, 0.35  , 0.3474, 0.3467, 0.3452, 0.344 , 0.3425,\n",
       "            0.34  , 0.3389, 0.3328, 0.3318, 0.3289, 0.3281, 0.3218, 0.303 ,\n",
       "            0.3015], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.09375  , 0.1015625, 0.1171875,\n",
       "            0.1328125, 0.15625  , 0.1796875, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.3046875,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.6640625, 0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6796875, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.734375 , 0.734375 , 0.734375 , 0.734375 , 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.75     , 0.7578125, 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.7734375, 0.7734375,\n",
       "            0.7734375, 0.78125  , 0.78125  , 0.78125  , 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8125   , 0.8125   ,\n",
       "            0.8203125, 0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.8671875, 0.875    ,\n",
       "            0.875    , 0.875    , 0.875    , 0.875    , 0.875    , 0.875    ,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.9453125,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.01639344, 0.02459016,\n",
       "            0.02459016, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13114753,\n",
       "            0.13934426, 0.13934426, 0.14754099, 0.16393442, 0.18032786,\n",
       "            0.18852459, 0.18852459, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.21311475, 0.21311475, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.23770492, 0.24590164,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.28688523,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.36885247, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.44262296, 0.45901638,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59836066, 0.6229508 , 0.63114756, 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.479 , 0.4766, 0.4756, 0.4749, 0.4744, 0.474 , 0.4739,\n",
       "            0.4724, 0.4722, 0.471 , 0.47  , 0.4697, 0.4695, 0.4692, 0.469 ,\n",
       "            0.4685, 0.4683, 0.468 , 0.4678, 0.4673, 0.467 , 0.4668, 0.4663,\n",
       "            0.466 , 0.465 , 0.4646, 0.4636, 0.4607, 0.46  , 0.4592, 0.459 ,\n",
       "            0.4587, 0.4585, 0.453 , 0.451 , 0.4492, 0.448 , 0.4473, 0.4463,\n",
       "            0.4426, 0.441 , 0.4382, 0.437 , 0.4343, 0.434 , 0.4338, 0.4329,\n",
       "            0.4321, 0.428 , 0.4272, 0.4255, 0.4233, 0.422 , 0.4214, 0.421 ,\n",
       "            0.4194, 0.4192, 0.4187, 0.4177, 0.4175, 0.4172, 0.4163, 0.415 ,\n",
       "            0.4126, 0.412 , 0.4104, 0.4102, 0.4077, 0.407 , 0.4053, 0.405 ,\n",
       "            0.4048, 0.404 , 0.4028, 0.4019, 0.4014, 0.4006, 0.4   , 0.3992,\n",
       "            0.399 , 0.3984, 0.3982, 0.398 , 0.3977, 0.3965, 0.396 , 0.3955,\n",
       "            0.395 , 0.3943, 0.3936, 0.3933, 0.393 , 0.3928, 0.3926, 0.391 ,\n",
       "            0.3896, 0.3894, 0.3887, 0.3877, 0.3857, 0.385 , 0.3848, 0.3845,\n",
       "            0.3843, 0.3838, 0.382 , 0.3818, 0.3809, 0.38  , 0.3794, 0.3792,\n",
       "            0.3787, 0.378 , 0.3765, 0.376 , 0.3752, 0.3748, 0.3745, 0.3738,\n",
       "            0.373 , 0.3726, 0.3718, 0.3708, 0.37  , 0.3699, 0.3691, 0.3684,\n",
       "            0.3667, 0.3665, 0.3662, 0.3657, 0.3652, 0.365 , 0.3647, 0.3635,\n",
       "            0.3633, 0.3628, 0.3623, 0.362 , 0.3613, 0.3606, 0.3599, 0.3591,\n",
       "            0.3577, 0.357 , 0.3567, 0.3564, 0.3538, 0.3533, 0.3523, 0.352 ,\n",
       "            0.3516, 0.3508, 0.35  , 0.3494, 0.349 , 0.3486, 0.3484, 0.3467,\n",
       "            0.3457, 0.3455, 0.3452, 0.3442, 0.341 , 0.3396, 0.339 , 0.3389,\n",
       "            0.3386, 0.338 , 0.3372, 0.3367, 0.3347, 0.3337, 0.3325, 0.331 ,\n",
       "            0.3306, 0.3298, 0.3293, 0.329 , 0.3286, 0.3267, 0.3254, 0.3235,\n",
       "            0.323 , 0.3218, 0.3184, 0.3164, 0.3162, 0.3137, 0.3135, 0.3115,\n",
       "            0.3066, 0.3064, 0.303 , 0.3022, 0.2986, 0.291 , 0.276 , 0.272 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.0859375, 0.1015625,\n",
       "            0.109375 , 0.125    , 0.140625 , 0.1640625, 0.1796875, 0.1875   ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.265625 , 0.2734375, 0.2890625, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.6171875, 0.6171875, 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6796875,\n",
       "            0.6796875, 0.6796875, 0.6796875, 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.734375 , 0.734375 , 0.734375 , 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.7734375, 0.7734375, 0.7734375,\n",
       "            0.7734375, 0.78125  , 0.796875 , 0.796875 , 0.796875 , 0.796875 ,\n",
       "            0.796875 , 0.796875 , 0.796875 , 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8125   , 0.8203125, 0.8203125, 0.8203125, 0.828125 , 0.828125 ,\n",
       "            0.828125 , 0.8359375, 0.8359375, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.8828125,\n",
       "            0.8828125, 0.8828125, 0.8828125, 0.890625 , 0.890625 , 0.890625 ,\n",
       "            0.890625 , 0.8984375, 0.9140625, 0.9140625, 0.921875 , 0.921875 ,\n",
       "            0.921875 , 0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.20491803, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22131148, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.23770492, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.352459  , 0.352459  ,\n",
       "            0.352459  , 0.36065573, 0.36065573, 0.36885247, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.40983605, 0.40983605,\n",
       "            0.40983605, 0.40983605, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.44262296, 0.45081967, 0.45081967, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5081967 , 0.52459013, 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.71311474, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4707, 0.4685, 0.4678, 0.4663, 0.4658, 0.4656, 0.465 ,\n",
       "            0.4648, 0.4631, 0.463 , 0.4624, 0.462 , 0.4612, 0.4604, 0.4602,\n",
       "            0.46  , 0.4597, 0.4595, 0.4592, 0.459 , 0.4587, 0.4583, 0.458 ,\n",
       "            0.457 , 0.4563, 0.4556, 0.4553, 0.4548, 0.4539, 0.453 , 0.4517,\n",
       "            0.4482, 0.4478, 0.4465, 0.4458, 0.4456, 0.445 , 0.4412, 0.437 ,\n",
       "            0.4343, 0.4338, 0.4329, 0.432 , 0.431 , 0.429 , 0.4275, 0.4226,\n",
       "            0.4216, 0.418 , 0.4175, 0.417 , 0.416 , 0.4153, 0.4143, 0.4094,\n",
       "            0.4084, 0.4072, 0.404 , 0.4038, 0.4028, 0.4019, 0.3992, 0.3987,\n",
       "            0.3984, 0.398 , 0.3962, 0.3938, 0.3936, 0.3923, 0.3916, 0.3909,\n",
       "            0.389 , 0.3884, 0.387 , 0.3848, 0.3833, 0.383 , 0.3826, 0.3823,\n",
       "            0.382 , 0.3816, 0.3784, 0.377 , 0.3765, 0.3757, 0.3752, 0.3748,\n",
       "            0.3745, 0.3743, 0.374 , 0.3733, 0.3728, 0.3726, 0.3716, 0.371 ,\n",
       "            0.3704, 0.3699, 0.3696, 0.3691, 0.369 , 0.3684, 0.368 , 0.366 ,\n",
       "            0.3652, 0.365 , 0.3628, 0.3625, 0.361 , 0.36  , 0.3596, 0.3594,\n",
       "            0.3591, 0.359 , 0.3586, 0.3582, 0.358 , 0.3567, 0.3555, 0.3538,\n",
       "            0.3535, 0.3533, 0.3528, 0.3525, 0.3523, 0.3513, 0.35  , 0.3494,\n",
       "            0.349 , 0.3489, 0.3484, 0.348 , 0.3477, 0.3474, 0.347 , 0.3462,\n",
       "            0.3457, 0.3452, 0.3447, 0.3433, 0.3425, 0.3416, 0.3408, 0.3406,\n",
       "            0.3403, 0.3398, 0.3396, 0.3394, 0.339 , 0.3386, 0.338 , 0.3376,\n",
       "            0.3374, 0.3354, 0.334 , 0.3333, 0.3328, 0.3323, 0.3318, 0.3308,\n",
       "            0.3303, 0.3298, 0.3284, 0.328 , 0.327 , 0.3257, 0.3245, 0.3242,\n",
       "            0.3235, 0.3225, 0.3213, 0.321 , 0.3208, 0.3203, 0.319 , 0.3184,\n",
       "            0.3176, 0.3167, 0.3152, 0.3145, 0.3132, 0.313 , 0.3093, 0.3088,\n",
       "            0.3083, 0.3071, 0.307 , 0.306 , 0.304 , 0.303 , 0.3027, 0.3003,\n",
       "            0.2986, 0.298 , 0.297 , 0.2969, 0.2957, 0.2937, 0.292 , 0.2883,\n",
       "            0.288 , 0.2869, 0.2852, 0.2847, 0.2805, 0.2793, 0.2764, 0.275 ,\n",
       "            0.2717, 0.2695, 0.2612, 0.2498, 0.2434], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.2109375, 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.5859375, 0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.625    , 0.625    , 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6796875, 0.6796875, 0.6796875, 0.6796875, 0.6796875,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.734375 , 0.734375 , 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.734375 , 0.734375 , 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.75     , 0.75     , 0.7578125, 0.7578125, 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.796875 , 0.796875 , 0.796875 , 0.796875 ,\n",
       "            0.8046875, 0.8046875, 0.8046875, 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.8359375, 0.8359375, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.875    , 0.8828125, 0.8828125, 0.890625 ,\n",
       "            0.890625 , 0.890625 , 0.8984375, 0.8984375, 0.8984375, 0.8984375,\n",
       "            0.90625  , 0.90625  , 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 , 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.08196721,\n",
       "            0.09016393, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.20491803, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22131148, 0.23770492, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.31967214, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.40983605, 0.40983605, 0.40983605, 0.40983605,\n",
       "            0.40983605, 0.40983605, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5491803 ,\n",
       "            0.55737704, 0.57377046, 0.58196723, 0.58196723, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.74590164, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4622, 0.4602, 0.4597, 0.457 , 0.4568, 0.4565, 0.4548,\n",
       "            0.454 , 0.4536, 0.4534, 0.453 , 0.4526, 0.4524, 0.452 , 0.4517,\n",
       "            0.4512, 0.451 , 0.4507, 0.4504, 0.4502, 0.45  , 0.4497, 0.449 ,\n",
       "            0.4482, 0.448 , 0.4475, 0.4465, 0.4463, 0.445 , 0.4446, 0.4443,\n",
       "            0.4436, 0.4429, 0.4424, 0.4412, 0.44  , 0.4355, 0.434 , 0.433 ,\n",
       "            0.432 , 0.4312, 0.4292, 0.423 , 0.4197, 0.4194, 0.4185, 0.4175,\n",
       "            0.415 , 0.412 , 0.4119, 0.405 , 0.4043, 0.4014, 0.4006, 0.3992,\n",
       "            0.3977, 0.397 , 0.3967, 0.3965, 0.3916, 0.3862, 0.3845, 0.3828,\n",
       "            0.3823, 0.3801, 0.379 , 0.3784, 0.3782, 0.3774, 0.3757, 0.3755,\n",
       "            0.3752, 0.375 , 0.371 , 0.3706, 0.3696, 0.3684, 0.3667, 0.3665,\n",
       "            0.366 , 0.3628, 0.3599, 0.3594, 0.3591, 0.3584, 0.357 , 0.3557,\n",
       "            0.3535, 0.3528, 0.352 , 0.3518, 0.3513, 0.3508, 0.3506, 0.3503,\n",
       "            0.3499, 0.3477, 0.3474, 0.3467, 0.3457, 0.345 , 0.3435, 0.3428,\n",
       "            0.3418, 0.3406, 0.34  , 0.339 , 0.338 , 0.3376, 0.3374, 0.3357,\n",
       "            0.335 , 0.3345, 0.334 , 0.3335, 0.333 , 0.3328, 0.3325, 0.3323,\n",
       "            0.331 , 0.3298, 0.3284, 0.3281, 0.328 , 0.3276, 0.3274, 0.3271,\n",
       "            0.3267, 0.3262, 0.3254, 0.3252, 0.324 , 0.3237, 0.323 , 0.3228,\n",
       "            0.3225, 0.3223, 0.3218, 0.3215, 0.3213, 0.3208, 0.3206, 0.3203,\n",
       "            0.3198, 0.319 , 0.3186, 0.317 , 0.3162, 0.3147, 0.3135, 0.3127,\n",
       "            0.3123, 0.312 , 0.3108, 0.31  , 0.3098, 0.3096, 0.3079, 0.307 ,\n",
       "            0.3064, 0.3047, 0.3042, 0.304 , 0.3022, 0.3015, 0.3013, 0.3003,\n",
       "            0.3   , 0.2988, 0.2986, 0.298 , 0.297 , 0.2957, 0.295 , 0.2942,\n",
       "            0.2937, 0.293 , 0.2922, 0.2913, 0.2888, 0.2878, 0.2874, 0.286 ,\n",
       "            0.2856, 0.283 , 0.2827, 0.2817, 0.2812, 0.2805, 0.2786, 0.278 ,\n",
       "            0.2766, 0.2764, 0.2761, 0.2747, 0.2742, 0.2727, 0.2722, 0.272 ,\n",
       "            0.2712, 0.269 , 0.268 , 0.2668, 0.2656, 0.2637, 0.2595, 0.2588,\n",
       "            0.2583, 0.2559, 0.2515, 0.2478, 0.2463, 0.2422, 0.2386, 0.233 ,\n",
       "            0.2251, 0.2168], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0859375, 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.265625 , 0.2734375, 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.625    ,\n",
       "            0.625    , 0.625    , 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.75     , 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.765625 ,\n",
       "            0.765625 , 0.765625 , 0.78125  , 0.7890625, 0.796875 , 0.796875 ,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8125   , 0.8125   ,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.828125 , 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.8671875, 0.8671875, 0.8671875, 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.8828125, 0.8984375, 0.8984375, 0.8984375, 0.8984375,\n",
       "            0.90625  , 0.90625  , 0.90625  , 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.921875 , 0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.984375 , 0.984375 , 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.02459016, 0.03278688, 0.04098361, 0.04918033,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.1147541 , 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.16393442, 0.18032786, 0.19672132, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.22950819, 0.22950819,\n",
       "            0.22950819, 0.23770492, 0.23770492, 0.23770492, 0.23770492,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.27868852,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.40163934, 0.4180328 , 0.4180328 , 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45901638, 0.48360655, 0.5081967 ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.63114756, 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6967213 , 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.75409836, 0.76229507, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4539, 0.4521, 0.452 , 0.448 , 0.4478, 0.4475, 0.4473,\n",
       "            0.4453, 0.4443, 0.444 , 0.4436, 0.4434, 0.443 , 0.4424, 0.4421,\n",
       "            0.4417, 0.4414, 0.4407, 0.4404, 0.4402, 0.4397, 0.439 , 0.4387,\n",
       "            0.438 , 0.4375, 0.4368, 0.4355, 0.434 , 0.4336, 0.4329, 0.4326,\n",
       "            0.4316, 0.4312, 0.4307, 0.429 , 0.4277, 0.423 , 0.4211, 0.4202,\n",
       "            0.418 , 0.4175, 0.417 , 0.409 , 0.4053, 0.4045, 0.4033, 0.4028,\n",
       "            0.4   , 0.397 , 0.3943, 0.3882, 0.3867, 0.3857, 0.3853, 0.3843,\n",
       "            0.3823, 0.379 , 0.378 , 0.377 , 0.3738, 0.366 , 0.3657, 0.3616,\n",
       "            0.3608, 0.3591, 0.3584, 0.358 , 0.3552, 0.3542, 0.353 , 0.3525,\n",
       "            0.35  , 0.3496, 0.3462, 0.3452, 0.345 , 0.343 , 0.3428, 0.341 ,\n",
       "            0.3376, 0.3367, 0.3345, 0.3333, 0.3323, 0.3318, 0.331 , 0.3306,\n",
       "            0.3303, 0.3293, 0.3289, 0.3281, 0.3276, 0.3271, 0.327 , 0.3267,\n",
       "            0.3242, 0.324 , 0.322 , 0.3218, 0.3213, 0.32  , 0.319 , 0.3171,\n",
       "            0.3164, 0.3162, 0.315 , 0.313 , 0.3118, 0.3105, 0.3103, 0.3098,\n",
       "            0.3093, 0.3088, 0.3086, 0.308 , 0.3074, 0.305 , 0.3047, 0.3037,\n",
       "            0.3032, 0.3027, 0.3025, 0.3018, 0.3013, 0.2996, 0.2993, 0.2986,\n",
       "            0.2974, 0.2969, 0.2964, 0.2961, 0.296 , 0.2957, 0.2952, 0.2944,\n",
       "            0.2935, 0.2925, 0.292 , 0.2903, 0.2898, 0.2878, 0.2869, 0.2864,\n",
       "            0.2861, 0.2854, 0.2842, 0.2837, 0.2834, 0.2832, 0.2812, 0.2798,\n",
       "            0.279 , 0.278 , 0.2776, 0.2766, 0.2761, 0.2756, 0.2751, 0.274 ,\n",
       "            0.2737, 0.2734, 0.2725, 0.2708, 0.2693, 0.2686, 0.267 , 0.266 ,\n",
       "            0.2656, 0.2651, 0.2627, 0.2622, 0.2612, 0.2583, 0.258 , 0.2563,\n",
       "            0.2542, 0.254 , 0.2537, 0.253 , 0.2527, 0.251 , 0.2493, 0.2482,\n",
       "            0.248 , 0.2474, 0.2467, 0.2466, 0.2462, 0.246 , 0.2452, 0.2437,\n",
       "            0.2422, 0.2399, 0.2397, 0.2372, 0.236 , 0.2347, 0.2327, 0.2322,\n",
       "            0.2318, 0.2285, 0.2278, 0.2263, 0.2222, 0.2166, 0.2161, 0.2085,\n",
       "            0.2065, 0.2017, 0.1919], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.15625  , 0.1640625,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    , 0.625    ,\n",
       "            0.625    , 0.625    , 0.6328125, 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.6640625,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.6796875, 0.6796875,\n",
       "            0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.6953125, 0.703125 , 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.75     , 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875,\n",
       "            0.8046875, 0.8046875, 0.8046875, 0.8125   , 0.8125   , 0.8125   ,\n",
       "            0.8125   , 0.8125   , 0.8203125, 0.8203125, 0.828125 , 0.84375  ,\n",
       "            0.84375  , 0.84375  , 0.8515625, 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.8671875, 0.8671875, 0.8671875, 0.875    , 0.875    ,\n",
       "            0.890625 , 0.8984375, 0.8984375, 0.90625  , 0.90625  , 0.90625  ,\n",
       "            0.90625  , 0.9140625, 0.9140625, 0.9140625, 0.921875 , 0.921875 ,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.9453125, 0.9453125,\n",
       "            0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 , 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.03278688, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.16393442, 0.17213115,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.21311475, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.23770492, 0.23770492,\n",
       "            0.23770492, 0.25409836, 0.26229507, 0.2704918 , 0.2704918 ,\n",
       "            0.27868852, 0.27868852, 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.352459  ,\n",
       "            0.36065573, 0.37704918, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4180328 , 0.4180328 , 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.48360655,\n",
       "            0.4918033 , 0.5163934 , 0.5163934 , 0.5163934 , 0.5327869 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.58196723, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4453, 0.4438, 0.4395, 0.4392, 0.439 , 0.4382, 0.438 ,\n",
       "            0.4375, 0.4373, 0.4353, 0.435 , 0.4343, 0.434 , 0.433 , 0.4326,\n",
       "            0.4324, 0.432 , 0.4312, 0.4304, 0.4297, 0.4294, 0.429 , 0.4287,\n",
       "            0.428 , 0.4265, 0.426 , 0.4248, 0.4229, 0.4226, 0.4224, 0.4214,\n",
       "            0.421 , 0.42  , 0.4197, 0.4185, 0.417 , 0.4155, 0.4104, 0.4084,\n",
       "            0.4072, 0.405 , 0.4043, 0.4038, 0.395 , 0.3909, 0.39  , 0.3882,\n",
       "            0.388 , 0.3845, 0.3818, 0.3772, 0.3757, 0.3716, 0.3691, 0.3682,\n",
       "            0.3677, 0.3657, 0.3613, 0.36  , 0.3572, 0.3562, 0.3477, 0.3457,\n",
       "            0.3445, 0.343 , 0.3408, 0.34  , 0.3396, 0.339 , 0.3384, 0.338 ,\n",
       "            0.3337, 0.3333, 0.331 , 0.3308, 0.3286, 0.3242, 0.3235, 0.3225,\n",
       "            0.321 , 0.3198, 0.3196, 0.316 , 0.3147, 0.314 , 0.3137, 0.312 ,\n",
       "            0.3118, 0.3115, 0.3113, 0.3108, 0.309 , 0.3086, 0.3083, 0.3076,\n",
       "            0.3062, 0.3057, 0.3052, 0.3044, 0.3035, 0.3032, 0.3018, 0.301 ,\n",
       "            0.3005, 0.299 , 0.2986, 0.298 , 0.297 , 0.295 , 0.2935, 0.2932,\n",
       "            0.293 , 0.2922, 0.292 , 0.289 , 0.2883, 0.2869, 0.2861, 0.286 ,\n",
       "            0.2856, 0.2852, 0.2847, 0.2842, 0.284 , 0.283 , 0.2825, 0.2803,\n",
       "            0.28  , 0.2795, 0.2788, 0.2786, 0.2773, 0.2769, 0.2761, 0.2751,\n",
       "            0.2747, 0.2744, 0.2742, 0.2737, 0.2727, 0.2722, 0.272 , 0.2708,\n",
       "            0.2703, 0.27  , 0.269 , 0.2683, 0.2676, 0.2664, 0.2656, 0.2651,\n",
       "            0.2646, 0.2637, 0.263 , 0.262 , 0.2615, 0.2612, 0.26  , 0.2595,\n",
       "            0.2585, 0.2583, 0.2578, 0.2568, 0.2566, 0.2563, 0.2542, 0.2534,\n",
       "            0.2527, 0.252 , 0.251 , 0.2502, 0.2493, 0.2487, 0.2482, 0.2477,\n",
       "            0.2474, 0.247 , 0.2456, 0.2451, 0.244 , 0.2433, 0.2426, 0.2421,\n",
       "            0.2395, 0.2391, 0.2386, 0.2356, 0.2352, 0.2343, 0.2325, 0.2322,\n",
       "            0.2306, 0.2303, 0.2289, 0.2278, 0.2268, 0.2266, 0.2252, 0.2229,\n",
       "            0.2217, 0.2216, 0.2213, 0.2207, 0.2205, 0.2203, 0.2195, 0.2186,\n",
       "            0.2173, 0.2129, 0.211 , 0.2095, 0.2094, 0.2081, 0.2064, 0.2053,\n",
       "            0.2007, 0.1991, 0.1979, 0.1917, 0.1892, 0.1819, 0.1813, 0.1797,\n",
       "            0.1687], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.6640625, 0.6640625, 0.6640625, 0.6640625, 0.6640625, 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6875   , 0.6953125, 0.6953125, 0.6953125, 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.75     , 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.796875 , 0.8046875, 0.8046875, 0.8046875,\n",
       "            0.8046875, 0.8046875, 0.8125   , 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.828125 , 0.828125 , 0.828125 , 0.8359375, 0.8359375, 0.84375  ,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.8671875, 0.875    , 0.8828125, 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.8984375, 0.90625  , 0.90625  , 0.90625  , 0.9140625,\n",
       "            0.9140625, 0.9140625, 0.9140625, 0.921875 , 0.921875 , 0.9296875,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9375   , 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 0.9921875, 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.02459016, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.16393442, 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.21311475, 0.21311475, 0.22131148, 0.22950819, 0.22950819,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.23770492, 0.24590164,\n",
       "            0.24590164, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.27868852, 0.27868852, 0.28688523, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.3442623 , 0.352459  , 0.352459  ,\n",
       "            0.36065573, 0.3852459 , 0.39344263, 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5327869 , 0.5409836 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.59016395, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4368, 0.4358, 0.432 , 0.4307, 0.4304, 0.43  , 0.4297,\n",
       "            0.4292, 0.429 , 0.4268, 0.4258, 0.4253, 0.425 , 0.4238, 0.4233,\n",
       "            0.4226, 0.4224, 0.4219, 0.4216, 0.4211, 0.421 , 0.4197, 0.4192,\n",
       "            0.4187, 0.4185, 0.418 , 0.4177, 0.4158, 0.4153, 0.4143, 0.414 ,\n",
       "            0.4116, 0.4114, 0.4111, 0.41  , 0.4092, 0.4087, 0.4077, 0.4062,\n",
       "            0.4053, 0.4033, 0.3982, 0.3975, 0.3955, 0.3943, 0.3926, 0.3909,\n",
       "            0.3904, 0.3809, 0.3765, 0.3757, 0.3735, 0.3728, 0.3704, 0.3665,\n",
       "            0.365 , 0.3606, 0.3552, 0.3542, 0.353 , 0.3503, 0.349 , 0.344 ,\n",
       "            0.3433, 0.3386, 0.3384, 0.3298, 0.3281, 0.3271, 0.3235, 0.321 ,\n",
       "            0.3203, 0.32  , 0.3196, 0.3186, 0.3184, 0.317 , 0.3137, 0.3108,\n",
       "            0.3105, 0.3074, 0.304 , 0.3027, 0.3018, 0.3003, 0.2988, 0.2947,\n",
       "            0.294 , 0.2935, 0.2922, 0.292 , 0.2915, 0.2903, 0.29  , 0.2896,\n",
       "            0.288 , 0.2874, 0.2866, 0.2856, 0.2842, 0.2832, 0.283 , 0.2822,\n",
       "            0.2815, 0.281 , 0.2808, 0.2805, 0.2803, 0.279 , 0.277 , 0.2761,\n",
       "            0.276 , 0.2751, 0.272 , 0.2717, 0.2705, 0.27  , 0.2683, 0.266 ,\n",
       "            0.2646, 0.2642, 0.264 , 0.2637, 0.2634, 0.2632, 0.263 , 0.2607,\n",
       "            0.2605, 0.2593, 0.2585, 0.2573, 0.257 , 0.2566, 0.2559, 0.2556,\n",
       "            0.2554, 0.2542, 0.2537, 0.2532, 0.2524, 0.252 , 0.2515, 0.2507,\n",
       "            0.2496, 0.2494, 0.2493, 0.2487, 0.2466, 0.246 , 0.2456, 0.2445,\n",
       "            0.2438, 0.2433, 0.2426, 0.2422, 0.2406, 0.2394, 0.2386, 0.2384,\n",
       "            0.2382, 0.2372, 0.237 , 0.2368, 0.2352, 0.2351, 0.235 , 0.234 ,\n",
       "            0.2339, 0.2335, 0.2334, 0.2322, 0.2314, 0.2297, 0.2277, 0.2274,\n",
       "            0.2261, 0.226 , 0.2256, 0.2252, 0.2242, 0.2233, 0.2229, 0.2225,\n",
       "            0.2218, 0.2202, 0.2186, 0.2181, 0.2161, 0.2148, 0.2147, 0.2128,\n",
       "            0.2119, 0.2113, 0.2103, 0.21  , 0.2085, 0.2084, 0.2051, 0.2043,\n",
       "            0.2029, 0.2023, 0.2017, 0.2006, 0.1987, 0.1979, 0.197 , 0.1967,\n",
       "            0.1965, 0.1964, 0.1962, 0.196 , 0.1956, 0.1954, 0.1913, 0.1891,\n",
       "            0.1884, 0.1879, 0.1855, 0.1842, 0.1837, 0.1829, 0.1827, 0.1771,\n",
       "            0.1757, 0.1755, 0.1693, 0.1659, 0.1594, 0.1593, 0.1582, 0.1477],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0625   , 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.6171875, 0.625    , 0.625    , 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6796875, 0.6796875,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6953125, 0.6953125, 0.6953125,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.75     , 0.75     ,\n",
       "            0.75     , 0.75     , 0.7578125, 0.765625 , 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.8359375, 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.8671875, 0.875    , 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.9140625,\n",
       "            0.9140625, 0.9140625, 0.9140625, 0.921875 , 0.9296875, 0.9296875,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.9609375, 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625, 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.984375 , 0.984375 , 0.9921875, 0.9921875,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22950819, 0.22950819,\n",
       "            0.22950819, 0.22950819, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.28688523, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.31967214, 0.32786885, 0.3442623 ,\n",
       "            0.352459  , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4262295 , 0.4262295 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.44262296, 0.44262296, 0.45081967, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.55737704, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6803279 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4282, 0.428 , 0.4277, 0.424 , 0.4233, 0.4219, 0.4216,\n",
       "            0.421 , 0.4197, 0.418 , 0.4165, 0.4163, 0.4158, 0.4146, 0.414 ,\n",
       "            0.4126, 0.4119, 0.4114, 0.4111, 0.411 , 0.4097, 0.4087, 0.4084,\n",
       "            0.4082, 0.408 , 0.4065, 0.405 , 0.4043, 0.4033, 0.4004, 0.4001,\n",
       "            0.3994, 0.3982, 0.3975, 0.3958, 0.3938, 0.3933, 0.3909, 0.3857,\n",
       "            0.3843, 0.3826, 0.381 , 0.3804, 0.3774, 0.3772, 0.3667, 0.362 ,\n",
       "            0.3618, 0.359 , 0.3572, 0.3564, 0.3538, 0.3513, 0.344 , 0.3396,\n",
       "            0.3386, 0.3384, 0.333 , 0.3325, 0.327 , 0.3262, 0.3213, 0.3198,\n",
       "            0.3115, 0.311 , 0.3086, 0.3079, 0.3018, 0.3013, 0.301 , 0.3005,\n",
       "            0.299 , 0.2988, 0.2937, 0.291 , 0.2908, 0.2861, 0.2842, 0.2827,\n",
       "            0.2815, 0.28  , 0.2786, 0.2783, 0.275 , 0.2737, 0.2727, 0.2703,\n",
       "            0.2698, 0.2695, 0.269 , 0.2666, 0.2656, 0.2646, 0.2644, 0.2622,\n",
       "            0.262 , 0.2607, 0.2605, 0.2603, 0.2595, 0.2585, 0.258 , 0.2578,\n",
       "            0.2556, 0.2542, 0.254 , 0.2507, 0.2493, 0.249 , 0.2485, 0.2452,\n",
       "            0.2451, 0.2448, 0.2437, 0.2433, 0.243 , 0.2417, 0.2415, 0.2413,\n",
       "            0.2411, 0.241 , 0.2384, 0.237 , 0.2358, 0.2356, 0.2355, 0.2346,\n",
       "            0.2343, 0.2339, 0.2328, 0.2316, 0.231 , 0.2302, 0.2301, 0.2295,\n",
       "            0.2286, 0.228 , 0.2278, 0.2274, 0.2266, 0.2263, 0.2261, 0.2257,\n",
       "            0.2239, 0.2238, 0.2233, 0.2227, 0.2218, 0.2213, 0.2211, 0.2205,\n",
       "            0.2203, 0.22  , 0.217 , 0.2167, 0.2166, 0.2153, 0.2152, 0.2147,\n",
       "            0.2145, 0.2144, 0.2128, 0.2115, 0.2114, 0.211 , 0.2103, 0.209 ,\n",
       "            0.2079, 0.2064, 0.2051, 0.2043, 0.2035, 0.2032, 0.2023, 0.202 ,\n",
       "            0.2017, 0.2   , 0.1989, 0.1982, 0.195 , 0.1947, 0.1946, 0.1925,\n",
       "            0.1915, 0.1906, 0.19  , 0.1886, 0.1884, 0.1876, 0.1863, 0.1835,\n",
       "            0.1824, 0.181 , 0.1797, 0.1796, 0.1791, 0.1771, 0.1761, 0.1758,\n",
       "            0.1755, 0.1737, 0.1735, 0.1733, 0.1719, 0.1709, 0.1685, 0.1683,\n",
       "            0.1666, 0.1648, 0.1646, 0.1643, 0.1605, 0.1599, 0.159 , 0.1556,\n",
       "            0.1547, 0.1543, 0.1483, 0.1447, 0.1409, 0.1387, 0.1372, 0.1282],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.59375  , 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.625    , 0.625    , 0.6328125, 0.6328125, 0.640625 , 0.640625 ,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.6953125, 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.7421875, 0.75     , 0.75     , 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.7890625, 0.796875 , 0.796875 , 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8125   , 0.8125   , 0.8125   , 0.8203125, 0.828125 , 0.828125 ,\n",
       "            0.828125 , 0.828125 , 0.828125 , 0.828125 , 0.828125 , 0.8359375,\n",
       "            0.8359375, 0.8359375, 0.84375  , 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.875    , 0.8828125,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.90625  ,\n",
       "            0.9140625, 0.9140625, 0.9140625, 0.921875 , 0.921875 , 0.9296875,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9296875,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.953125 , 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 0.9921875, 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.01639344, 0.01639344,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.1147541 ,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.17213115, 0.18852459,\n",
       "            0.18852459, 0.18852459, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22131148, 0.22131148, 0.22950819, 0.22950819, 0.22950819,\n",
       "            0.22950819, 0.24590164, 0.25409836, 0.25409836, 0.26229507,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.27868852, 0.27868852,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.44262296, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5081967 , 0.5163934 , 0.5163934 , 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.5491803 , 0.55737704, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.60655737, 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.73770493, 0.74590164,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9918033 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.42   , 0.4194 , 0.4163 , 0.4158 , 0.4143 , 0.4128 ,\n",
       "            0.4126 , 0.4119 , 0.4102 , 0.4092 , 0.4072 , 0.407  , 0.4065 ,\n",
       "            0.4053 , 0.4045 , 0.403  , 0.4023 , 0.402  , 0.4014 , 0.4011 ,\n",
       "            0.4006 , 0.3994 , 0.3984 , 0.3982 , 0.3977 , 0.395  , 0.394  ,\n",
       "            0.3936 , 0.3926 , 0.3923 , 0.3887 , 0.3877 , 0.3865 , 0.3862 ,\n",
       "            0.3853 , 0.3835 , 0.3813 , 0.381  , 0.3782 , 0.3733 , 0.3708 ,\n",
       "            0.3694 , 0.368  , 0.364  , 0.3638 , 0.3523 , 0.3474 , 0.3472 ,\n",
       "            0.344  , 0.343  , 0.3416 , 0.3413 , 0.3357 , 0.3274 , 0.324  ,\n",
       "            0.3228 , 0.3223 , 0.3162 , 0.3154 , 0.3096 , 0.3086 , 0.304  ,\n",
       "            0.3008 , 0.2952 , 0.2922 , 0.2893 , 0.2842 , 0.2822 , 0.2817 ,\n",
       "            0.2812 , 0.28   , 0.279  , 0.2742 , 0.2703 , 0.2654 , 0.2644 ,\n",
       "            0.2617 , 0.2605 , 0.2595 , 0.2583 , 0.2576 , 0.2566 , 0.2537 ,\n",
       "            0.2534 , 0.251  , 0.2494 , 0.2485 , 0.248  , 0.2451 , 0.2445 ,\n",
       "            0.2441 , 0.2438 , 0.2437 , 0.2411 , 0.2401 , 0.239  , 0.2383 ,\n",
       "            0.2378 , 0.237  , 0.2368 , 0.2366 , 0.2347 , 0.2334 , 0.2325 ,\n",
       "            0.2323 , 0.2302 , 0.2274 , 0.2273 , 0.2272 , 0.2269 , 0.2244 ,\n",
       "            0.2229 , 0.2227 , 0.2218 , 0.2212 , 0.2207 , 0.2205 , 0.2197 ,\n",
       "            0.217  , 0.2161 , 0.2147 , 0.2144 , 0.2137 , 0.2134 , 0.2133 ,\n",
       "            0.2129 , 0.2119 , 0.2109 , 0.2108 , 0.2091 , 0.2085 , 0.2081 ,\n",
       "            0.2079 , 0.2076 , 0.206  , 0.2059 , 0.2053 , 0.205  , 0.2048 ,\n",
       "            0.2047 , 0.2032 , 0.2031 , 0.2023 , 0.202  , 0.201  , 0.2006 ,\n",
       "            0.2004 , 0.1995 , 0.1993 , 0.1987 , 0.196  , 0.1958 , 0.1953 ,\n",
       "            0.1952 , 0.195  , 0.1936 , 0.1934 , 0.1927 , 0.1923 , 0.1917 ,\n",
       "            0.1913 , 0.1912 , 0.1904 , 0.1901 , 0.1898 , 0.1892 , 0.1887 ,\n",
       "            0.1866 , 0.1864 , 0.1844 , 0.1841 , 0.1838 , 0.1826 , 0.1824 ,\n",
       "            0.1819 , 0.1814 , 0.1804 , 0.1798 , 0.1782 , 0.1768 , 0.1748 ,\n",
       "            0.1744 , 0.1733 , 0.1725 , 0.1707 , 0.1699 , 0.1698 , 0.1686 ,\n",
       "            0.1678 , 0.1656 , 0.1647 , 0.1641 , 0.1611 , 0.1608 , 0.16   ,\n",
       "            0.159  , 0.1578 , 0.157  , 0.1569 , 0.1565 , 0.1558 , 0.1548 ,\n",
       "            0.153  , 0.1525 , 0.1519 , 0.1504 , 0.15   , 0.1492 , 0.1484 ,\n",
       "            0.1464 , 0.1448 , 0.1443 , 0.1437 , 0.1401 , 0.1384 , 0.1377 ,\n",
       "            0.1357 , 0.1343 , 0.1334 , 0.1294 , 0.1242 , 0.1238 , 0.12   ,\n",
       "            0.1172 , 0.11066], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.515625 , 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.625    , 0.625    , 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.703125 , 0.7109375, 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.7265625, 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.734375 , 0.7421875, 0.7421875, 0.7421875, 0.75     , 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.8203125, 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.828125 , 0.828125 , 0.828125 , 0.8359375, 0.8359375, 0.8359375,\n",
       "            0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.8671875,\n",
       "            0.875    , 0.8828125, 0.8828125, 0.890625 , 0.8984375, 0.8984375,\n",
       "            0.8984375, 0.90625  , 0.90625  , 0.9140625, 0.9140625, 0.9140625,\n",
       "            0.921875 , 0.921875 , 0.921875 , 0.9296875, 0.9296875, 0.9296875,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.9453125, 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 0.9921875, 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.21311475, 0.21311475, 0.22131148, 0.22131148, 0.22131148,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.24590164, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.3114754 , 0.32786885,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4180328 , 0.43442622,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45081967, 0.45081967,\n",
       "            0.45901638, 0.46721312, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.59016395, 0.59836066, 0.59836066, 0.60655737, 0.60655737,\n",
       "            0.60655737, 0.6147541 , 0.6147541 , 0.6229508 , 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8606557 , 0.8770492 , 0.8770492 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4116 , 0.4111 , 0.411  , 0.4084 , 0.408  , 0.4065 ,\n",
       "            0.404  , 0.4038 , 0.4028 , 0.401  , 0.4004 , 0.3982 , 0.3977 ,\n",
       "            0.3975 , 0.397  , 0.3958 , 0.395  , 0.3933 , 0.3926 , 0.3923 ,\n",
       "            0.3914 , 0.39   , 0.3894 , 0.3877 , 0.3875 , 0.384  , 0.3835 ,\n",
       "            0.3826 , 0.3818 , 0.3816 , 0.3772 , 0.377  , 0.376  , 0.3752 ,\n",
       "            0.3745 , 0.3733 , 0.3716 , 0.3696 , 0.3691 , 0.3657 , 0.3616 ,\n",
       "            0.3574 , 0.3564 , 0.3552 , 0.3547 , 0.3518 , 0.3513 , 0.3381 ,\n",
       "            0.3345 , 0.333  , 0.332  , 0.3298 , 0.3293 , 0.3257 , 0.3208 ,\n",
       "            0.3123 , 0.3118 , 0.3108 , 0.3062 , 0.3    , 0.2996 , 0.2961 ,\n",
       "            0.2917 , 0.2869 , 0.2852 , 0.2798 , 0.279  , 0.2769 , 0.2747 ,\n",
       "            0.2742 , 0.2683 , 0.2673 , 0.2656 , 0.2646 , 0.2642 , 0.2627 ,\n",
       "            0.26   , 0.256  , 0.255  , 0.2542 , 0.247  , 0.2462 , 0.2456 ,\n",
       "            0.2448 , 0.2428 , 0.2421 , 0.2395 , 0.2391 , 0.2362 , 0.2347 ,\n",
       "            0.2344 , 0.2318 , 0.2316 , 0.2295 , 0.2294 , 0.2289 , 0.2283 ,\n",
       "            0.2257 , 0.2247 , 0.2242 , 0.2238 , 0.2225 , 0.2213 , 0.2194 ,\n",
       "            0.2185 , 0.2179 , 0.2172 , 0.2167 , 0.2166 , 0.2163 , 0.2162 ,\n",
       "            0.2142 , 0.2125 , 0.2113 , 0.2108 , 0.2106 , 0.2095 , 0.2074 ,\n",
       "            0.207  , 0.2058 , 0.2034 , 0.2031 , 0.2023 , 0.2009 , 0.2002 ,\n",
       "            0.1998 , 0.1996 , 0.1979 , 0.1976 , 0.1973 , 0.1958 , 0.1941 ,\n",
       "            0.1937 , 0.193  , 0.1929 , 0.1924 , 0.1919 , 0.1909 , 0.1907 ,\n",
       "            0.1904 , 0.1896 , 0.1891 , 0.1884 , 0.188  , 0.1876 , 0.1858 ,\n",
       "            0.1855 , 0.1848 , 0.1844 , 0.1833 , 0.1827 , 0.1824 , 0.1823 ,\n",
       "            0.1819 , 0.1813 , 0.1808 , 0.1804 , 0.1797 , 0.1794 , 0.179  ,\n",
       "            0.1787 , 0.1785 , 0.177  , 0.1765 , 0.1753 , 0.1744 , 0.174  ,\n",
       "            0.1738 , 0.1736 , 0.1735 , 0.1729 , 0.1718 , 0.1715 , 0.171  ,\n",
       "            0.17   , 0.1699 , 0.1678 , 0.1649 , 0.1648 , 0.1647 , 0.1646 ,\n",
       "            0.1632 , 0.1627 , 0.1621 , 0.1603 , 0.1598 , 0.158  , 0.1569 ,\n",
       "            0.1559 , 0.1538 , 0.1526 , 0.1525 , 0.1523 , 0.1505 , 0.1503 ,\n",
       "            0.1499 , 0.1481 , 0.1467 , 0.1456 , 0.1454 , 0.1444 , 0.1443 ,\n",
       "            0.1431 , 0.1421 , 0.1395 , 0.1388 , 0.1387 , 0.1378 , 0.1343 ,\n",
       "            0.1338 , 0.1329 , 0.1328 , 0.1317 , 0.1313 , 0.1295 , 0.1288 ,\n",
       "            0.1271 , 0.1251 , 0.12476, 0.12213, 0.12067, 0.1197 , 0.1192 ,\n",
       "            0.119  , 0.1186 , 0.1126 , 0.1105 , 0.1084 , 0.10376, 0.1036 ,\n",
       "            0.09534], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.078125 , 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2265625, 0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.6171875, 0.625    , 0.625    , 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.7109375,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.7421875, 0.75     , 0.75     ,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.7578125, 0.765625 , 0.765625 ,\n",
       "            0.765625 , 0.765625 , 0.78125  , 0.7890625, 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8046875, 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.8203125, 0.8203125, 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.8359375,\n",
       "            0.84375  , 0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.8515625, 0.859375 , 0.8671875, 0.8671875, 0.8671875,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8828125, 0.890625 , 0.890625 ,\n",
       "            0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375, 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.921875 , 0.921875 , 0.921875 ,\n",
       "            0.921875 , 0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.984375 , 0.984375 , 0.9921875, 0.9921875, 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.01639344, 0.01639344,\n",
       "            0.02459016, 0.03278688, 0.04098361, 0.04098361, 0.04918033,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.13934426, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.20491803, 0.21311475, 0.21311475, 0.22131148, 0.22131148,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.23770492, 0.24590164,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.27868852, 0.27868852, 0.28688523, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.39344263, 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.43442622, 0.43442622,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.46721312, 0.46721312, 0.47540984, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59016395, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4036 , 0.4028 , 0.402  , 0.4004 , 0.4001 , 0.3984 ,\n",
       "            0.3955 , 0.395  , 0.3936 , 0.3914 , 0.389  , 0.3882 , 0.3877 ,\n",
       "            0.386  , 0.3857 , 0.3833 , 0.3828 , 0.3826 , 0.3813 , 0.381  ,\n",
       "            0.3794 , 0.3774 , 0.3772 , 0.377  , 0.3728 , 0.3716 , 0.371  ,\n",
       "            0.3706 , 0.3652 , 0.365  , 0.364  , 0.3623 , 0.361  , 0.3591 ,\n",
       "            0.358  , 0.3567 , 0.353  , 0.3499 , 0.344  , 0.343  , 0.3423 ,\n",
       "            0.3416 , 0.3396 , 0.3386 , 0.324  , 0.322  , 0.321  , 0.3186 ,\n",
       "            0.3174 , 0.3147 , 0.3098 , 0.3057 , 0.2993 , 0.298  , 0.297  ,\n",
       "            0.2905 , 0.2842 , 0.2837 , 0.2822 , 0.275  , 0.27   , 0.269  ,\n",
       "            0.2644 , 0.263  , 0.2617 , 0.259  , 0.2556 , 0.2527 , 0.2522 ,\n",
       "            0.249  , 0.248  , 0.2467 , 0.2455 , 0.2413 , 0.2384 , 0.2382 ,\n",
       "            0.2374 , 0.2301 , 0.2294 , 0.2283 , 0.2264 , 0.2257 , 0.222  ,\n",
       "            0.2212 , 0.219  , 0.2162 , 0.2158 , 0.215  , 0.2148 , 0.2134 ,\n",
       "            0.213  , 0.21   , 0.2089 , 0.2085 , 0.2063 , 0.2058 , 0.2051 ,\n",
       "            0.204  , 0.2039 , 0.2024 , 0.2002 , 0.2001 , 0.1995 , 0.1982 ,\n",
       "            0.1981 , 0.1973 , 0.1971 , 0.1967 , 0.1954 , 0.1947 , 0.194  ,\n",
       "            0.1931 , 0.1925 , 0.1923 , 0.1918 , 0.1906 , 0.1896 , 0.1879 ,\n",
       "            0.1874 , 0.1863 , 0.186  , 0.1826 , 0.182  , 0.1814 , 0.181  ,\n",
       "            0.1803 , 0.1798 , 0.1796 , 0.1794 , 0.1781 , 0.1753 , 0.1752 ,\n",
       "            0.1749 , 0.1741 , 0.1738 , 0.1736 , 0.173  , 0.1729 , 0.1725 ,\n",
       "            0.1716 , 0.1715 , 0.1708 , 0.1698 , 0.1693 , 0.169  , 0.1675 ,\n",
       "            0.167  , 0.1669 , 0.1664 , 0.1659 , 0.1658 , 0.1654 , 0.1647 ,\n",
       "            0.1644 , 0.1636 , 0.1635 , 0.1627 , 0.1615 , 0.161  , 0.1609 ,\n",
       "            0.1606 , 0.1602 , 0.1594 , 0.159  , 0.1584 , 0.1575 , 0.1567 ,\n",
       "            0.1565 , 0.1562 , 0.155  , 0.1544 , 0.1542 , 0.154  , 0.1536 ,\n",
       "            0.1533 , 0.1516 , 0.1486 , 0.1482 , 0.1467 , 0.1466 , 0.146  ,\n",
       "            0.1459 , 0.1453 , 0.1451 , 0.144  , 0.1437 , 0.1421 , 0.1409 ,\n",
       "            0.1384 , 0.1381 , 0.1366 , 0.1355 , 0.1353 , 0.1337 , 0.1332 ,\n",
       "            0.133  , 0.1323 , 0.132  , 0.1318 , 0.1317 , 0.1299 , 0.129  ,\n",
       "            0.1279 , 0.1268 , 0.126  , 0.1255 , 0.1241 , 0.1232 , 0.12244,\n",
       "            0.12177, 0.12115, 0.12103, 0.1172 , 0.11633, 0.1158 , 0.11536,\n",
       "            0.11395, 0.1138 , 0.111  , 0.11066, 0.108  , 0.1069 , 0.1067 ,\n",
       "            0.1056 , 0.10486, 0.103  , 0.1025 , 0.10175, 0.0974 , 0.0967 ,\n",
       "            0.0945 , 0.0904 , 0.0888 , 0.08154], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3125   , 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.59375  ,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.625    , 0.625    , 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.7109375, 0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.765625 , 0.765625 , 0.7734375, 0.7734375, 0.7734375,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.796875 , 0.8046875, 0.8046875, 0.8046875, 0.8046875, 0.8125   ,\n",
       "            0.8125   , 0.8125   , 0.8203125, 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.828125 , 0.828125 , 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.84375  , 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.8671875, 0.875    , 0.875    ,\n",
       "            0.875    , 0.8828125, 0.8828125, 0.8828125, 0.890625 , 0.890625 ,\n",
       "            0.890625 , 0.890625 , 0.8984375, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.921875 , 0.921875 , 0.921875 , 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9375   , 0.9375   , 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.9921875,\n",
       "            0.9921875, 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.01639344, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.19672132, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.21311475, 0.21311475, 0.21311475,\n",
       "            0.22950819, 0.22950819, 0.23770492, 0.24590164, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.26229507, 0.2704918 , 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.3114754 , 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.48360655, 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.647541  , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3936 , 0.3926 , 0.3914 , 0.3906 , 0.3904 , 0.3887 ,\n",
       "            0.3848 , 0.3843 , 0.3828 , 0.3806 , 0.3801 , 0.378  , 0.377  ,\n",
       "            0.3767 , 0.3765 , 0.3743 , 0.3716 , 0.371  , 0.3706 , 0.3699 ,\n",
       "            0.3691 , 0.3674 , 0.367  , 0.3652 , 0.3647 , 0.3643 , 0.364  ,\n",
       "            0.36   , 0.3599 , 0.3586 , 0.3582 , 0.358  , 0.351  , 0.3508 ,\n",
       "            0.3499 , 0.3481 , 0.3467 , 0.3445 , 0.342  , 0.3381 , 0.3364 ,\n",
       "            0.328  , 0.3271 , 0.326  , 0.3254 , 0.324  , 0.3079 , 0.3076 ,\n",
       "            0.3074 , 0.3035 , 0.3018 , 0.298  , 0.292  , 0.2886 , 0.285  ,\n",
       "            0.284  , 0.28   , 0.2722 , 0.2666 , 0.266  , 0.2659 , 0.2559 ,\n",
       "            0.251  , 0.2507 , 0.2467 , 0.2451 , 0.2448 , 0.2422 , 0.2352 ,\n",
       "            0.235  , 0.2303 , 0.2294 , 0.2268 , 0.2264 , 0.2207 , 0.2205 ,\n",
       "            0.2194 , 0.2184 , 0.2124 , 0.2104 , 0.2101 , 0.2081 , 0.2069 ,\n",
       "            0.2051 , 0.2032 , 0.201  , 0.2002 , 0.1967 , 0.196  , 0.1958 ,\n",
       "            0.1956 , 0.1934 , 0.1897 , 0.189  , 0.1876 , 0.186  , 0.1846 ,\n",
       "            0.1841 , 0.1827 , 0.1824 , 0.1819 , 0.1803 , 0.1785 , 0.178  ,\n",
       "            0.1768 , 0.1766 , 0.1761 , 0.1759 , 0.1758 , 0.1755 , 0.1754 ,\n",
       "            0.1752 , 0.1741 , 0.1731 , 0.1724 , 0.1721 , 0.1687 , 0.1683 ,\n",
       "            0.1676 , 0.1664 , 0.1633 , 0.1619 , 0.1615 , 0.1608 , 0.1605 ,\n",
       "            0.1597 , 0.1594 , 0.159  , 0.1584 , 0.1573 , 0.1562 , 0.1555 ,\n",
       "            0.1548 , 0.154  , 0.1537 , 0.1532 , 0.1528 , 0.1521 , 0.1514 ,\n",
       "            0.1512 , 0.151  , 0.1509 , 0.1498 , 0.1495 , 0.1483 , 0.1482 ,\n",
       "            0.148  , 0.1462 , 0.146  , 0.1458 , 0.145  , 0.1438 , 0.1436 ,\n",
       "            0.1434 , 0.1432 , 0.1431 , 0.1421 , 0.1415 , 0.1411 , 0.141  ,\n",
       "            0.1407 , 0.14   , 0.1399 , 0.139  , 0.1388 , 0.1387 , 0.1385 ,\n",
       "            0.138  , 0.1378 , 0.1368 , 0.1359 , 0.1354 , 0.1346 , 0.1344 ,\n",
       "            0.1317 , 0.1312 , 0.1304 , 0.129  , 0.1279 , 0.1277 , 0.1276 ,\n",
       "            0.1266 , 0.1262 , 0.1261 , 0.1256 , 0.12463, 0.12146, 0.1201 ,\n",
       "            0.1188 , 0.1174 , 0.1166 , 0.11633, 0.1158 , 0.11554, 0.115  ,\n",
       "            0.1144 , 0.11395, 0.1136 , 0.1134 , 0.11316, 0.1124 , 0.1084 ,\n",
       "            0.1078 , 0.10724, 0.1067 , 0.1056 , 0.1043 , 0.1041 , 0.103  ,\n",
       "            0.1009 , 0.0997 , 0.0993 , 0.09875, 0.0981 , 0.0977 , 0.096  ,\n",
       "            0.09467, 0.0925 , 0.09076, 0.0906 , 0.089  , 0.0874 , 0.0854 ,\n",
       "            0.0848 , 0.083  , 0.0821 , 0.0805 , 0.0772 , 0.0742 , 0.06793],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.609375 , 0.609375 , 0.6171875,\n",
       "            0.6171875, 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.6484375, 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.6796875, 0.6796875,\n",
       "            0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.6953125, 0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.734375 , 0.734375 , 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.75     , 0.765625 , 0.765625 , 0.765625 , 0.7734375, 0.7734375,\n",
       "            0.7734375, 0.7734375, 0.7734375, 0.7734375, 0.78125  , 0.796875 ,\n",
       "            0.8046875, 0.8046875, 0.8046875, 0.8046875, 0.8046875, 0.8125   ,\n",
       "            0.8125   , 0.8125   , 0.8125   , 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.8671875, 0.8671875, 0.8671875, 0.875    , 0.875    ,\n",
       "            0.8828125, 0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.921875 , 0.921875 , 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9375   , 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625,\n",
       "            0.984375 , 0.984375 , 0.9921875, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.01639344, 0.01639344, 0.02459016, 0.02459016,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.20491803, 0.20491803, 0.21311475,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.3114754 , 0.31967214, 0.31967214,\n",
       "            0.31967214, 0.32786885, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.4918033 , 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.75409836, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.86885244, 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3818 , 0.3809 , 0.3796 , 0.3794 , 0.379  , 0.3774 ,\n",
       "            0.3728 , 0.3726 , 0.3723 , 0.3708 , 0.3687 , 0.3684 , 0.3662 ,\n",
       "            0.365  , 0.3645 , 0.3625 , 0.3616 , 0.3591 , 0.359  , 0.3586 ,\n",
       "            0.358  , 0.3564 , 0.3552 , 0.354  , 0.3533 , 0.3523 , 0.35   ,\n",
       "            0.348  , 0.3467 , 0.346  , 0.3457 , 0.3452 , 0.3384 , 0.337  ,\n",
       "            0.3354 , 0.3352 , 0.3335 , 0.3333 , 0.3318 , 0.3303 , 0.3286 ,\n",
       "            0.3237 , 0.3235 , 0.3127 , 0.3115 , 0.3113 , 0.311  , 0.3108 ,\n",
       "            0.3105 , 0.2947 , 0.293  , 0.2922 , 0.2903 , 0.2861 , 0.282  ,\n",
       "            0.274  , 0.2727 , 0.2725 , 0.2712 , 0.2654 , 0.256  , 0.254  ,\n",
       "            0.251  , 0.2493 , 0.2394 , 0.2366 , 0.2335 , 0.229  , 0.2285 ,\n",
       "            0.2268 , 0.2224 , 0.217  , 0.2157 , 0.2156 , 0.2148 , 0.2108 ,\n",
       "            0.209  , 0.207  , 0.2051 , 0.202  , 0.2012 , 0.1991 , 0.197  ,\n",
       "            0.1952 , 0.1947 , 0.1925 , 0.186  , 0.1855 , 0.1848 , 0.1841 ,\n",
       "            0.183  , 0.1827 , 0.1792 , 0.1766 , 0.1743 , 0.174  , 0.1711 ,\n",
       "            0.1703 , 0.1698 , 0.1697 , 0.1688 , 0.1654 , 0.1646 , 0.1641 ,\n",
       "            0.164  , 0.1638 , 0.1632 , 0.1626 , 0.1605 , 0.16   , 0.1594 ,\n",
       "            0.1587 , 0.1582 , 0.1577 , 0.1575 , 0.1571 , 0.1562 , 0.1549 ,\n",
       "            0.154  , 0.1538 , 0.1537 , 0.1506 , 0.1505 , 0.1483 , 0.1444 ,\n",
       "            0.144  , 0.1439 , 0.1438 , 0.1436 , 0.1428 , 0.1427 , 0.1426 ,\n",
       "            0.1412 , 0.1407 , 0.1406 , 0.1401 , 0.1392 , 0.1385 , 0.1384 ,\n",
       "            0.1383 , 0.1377 , 0.136  , 0.1356 , 0.1355 , 0.1353 , 0.1345 ,\n",
       "            0.1342 , 0.1339 , 0.1329 , 0.1321 , 0.132  , 0.1309 , 0.1307 ,\n",
       "            0.13   , 0.1292 , 0.1289 , 0.1285 , 0.127  , 0.1267 , 0.1263 ,\n",
       "            0.1262 , 0.1257 , 0.1251 , 0.1245 , 0.12445, 0.1243 , 0.124  ,\n",
       "            0.12366, 0.12335, 0.12305, 0.12213, 0.1219 , 0.1217 , 0.1213 ,\n",
       "            0.12054, 0.12   , 0.11993, 0.119  , 0.1186 , 0.1178 , 0.11694,\n",
       "            0.11475, 0.1138 , 0.11145, 0.11127, 0.111  , 0.1101 , 0.1097 ,\n",
       "            0.1084 , 0.1063 , 0.1056 , 0.1041 , 0.103  , 0.10284, 0.1021 ,\n",
       "            0.10175, 0.1009 , 0.10016, 0.1    , 0.09894, 0.0981 , 0.0977 ,\n",
       "            0.09753, 0.0933 , 0.0927 , 0.0922 , 0.09174, 0.09076, 0.0893 ,\n",
       "            0.0883 , 0.0863 , 0.0851 , 0.08496, 0.08435, 0.0836 , 0.0833 ,\n",
       "            0.0818 , 0.08105, 0.0806 , 0.0788 , 0.07697, 0.07544, 0.0752 ,\n",
       "            0.0742 , 0.074  , 0.0721 , 0.0716 , 0.06903, 0.0688 , 0.06793,\n",
       "            0.06198, 0.05646], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.2265625, 0.234375 , 0.2421875, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6796875, 0.6796875,\n",
       "            0.6796875, 0.6796875, 0.6796875, 0.6875   , 0.6953125, 0.6953125,\n",
       "            0.6953125, 0.6953125, 0.703125 , 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.7265625, 0.7265625, 0.734375 , 0.734375 ,\n",
       "            0.7421875, 0.7421875, 0.7421875, 0.75     , 0.75     , 0.765625 ,\n",
       "            0.765625 , 0.765625 , 0.7734375, 0.7734375, 0.78125  , 0.78125  ,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8046875, 0.8046875,\n",
       "            0.8046875, 0.8046875, 0.8046875, 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.8203125, 0.828125 , 0.828125 , 0.828125 ,\n",
       "            0.8359375, 0.8359375, 0.84375  , 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.8515625, 0.8515625, 0.859375 , 0.8671875, 0.8671875,\n",
       "            0.875    , 0.875    , 0.8828125, 0.8828125, 0.890625 , 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.921875 , 0.921875 ,\n",
       "            0.921875 , 0.921875 , 0.921875 , 0.9296875, 0.9296875, 0.9375   ,\n",
       "            0.9375   , 0.9375   , 0.9375   , 0.9453125, 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.9765625, 0.9765625, 0.984375 , 0.9921875, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.01639344, 0.02459016,\n",
       "            0.02459016, 0.03278688, 0.03278688, 0.04098361, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.19672132, 0.20491803, 0.20491803, 0.21311475, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.23770492, 0.23770492,\n",
       "            0.24590164, 0.24590164, 0.25409836, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.3114754 , 0.31967214, 0.31967214,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.352459  , 0.352459  , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.48360655, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.5163934 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.77868855, 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3704 , 0.3694 , 0.3684 , 0.3677 , 0.3667 , 0.3613 ,\n",
       "            0.361  , 0.3606 , 0.3596 , 0.3572 , 0.357  , 0.355  , 0.3538 ,\n",
       "            0.3535 , 0.353  , 0.351  , 0.3489 , 0.3472 , 0.347  , 0.3462 ,\n",
       "            0.3442 , 0.344  , 0.342  , 0.3416 , 0.34   , 0.3362 , 0.3354 ,\n",
       "            0.3345 , 0.3337 , 0.3335 , 0.3267 , 0.3232 , 0.3215 , 0.3206 ,\n",
       "            0.32   , 0.3193 , 0.317  , 0.3157 , 0.312  , 0.309  , 0.2988 ,\n",
       "            0.2986 , 0.298  , 0.2969 , 0.295  , 0.2944 , 0.2832 , 0.2788 ,\n",
       "            0.2786 , 0.2776 , 0.2712 , 0.267  , 0.262  , 0.2605 , 0.2576 ,\n",
       "            0.2563 , 0.2522 , 0.243  , 0.2411 , 0.2379 , 0.2335 , 0.2244 ,\n",
       "            0.2242 , 0.2181 , 0.2175 , 0.212  , 0.2113 , 0.2101 , 0.2095 ,\n",
       "            0.2031 , 0.2024 , 0.2    , 0.1978 , 0.1971 , 0.1962 , 0.1934 ,\n",
       "            0.1925 , 0.1887 , 0.1873 , 0.1863 , 0.1849 , 0.1835 , 0.1814 ,\n",
       "            0.1804 , 0.1731 , 0.1727 , 0.172  , 0.1711 , 0.169  , 0.1687 ,\n",
       "            0.1677 , 0.1644 , 0.1632 , 0.1631 , 0.1599 , 0.1593 , 0.1572 ,\n",
       "            0.1569 , 0.1558 , 0.1554 , 0.1542 , 0.1537 , 0.1532 , 0.1523 ,\n",
       "            0.1519 , 0.151  , 0.1509 , 0.1508 , 0.1497 , 0.1488 , 0.1473 ,\n",
       "            0.1464 , 0.1444 , 0.1443 , 0.143  , 0.1421 , 0.1416 , 0.141  ,\n",
       "            0.1409 , 0.1407 , 0.1405 , 0.1399 , 0.1376 , 0.1371 , 0.1343 ,\n",
       "            0.134  , 0.1329 , 0.1328 , 0.1322 , 0.1305 , 0.1294 , 0.1285 ,\n",
       "            0.1284 , 0.1279 , 0.1277 , 0.1276 , 0.127  , 0.1267 , 0.1256 ,\n",
       "            0.1254 , 0.12494, 0.1249 , 0.1226 , 0.12115, 0.12054, 0.12036,\n",
       "            0.12024, 0.12   , 0.11993, 0.1196 , 0.1194 , 0.119  , 0.1184 ,\n",
       "            0.1166 , 0.11633, 0.11536, 0.115  , 0.11475, 0.1138 , 0.1134 ,\n",
       "            0.11316, 0.1128 , 0.11163, 0.11127, 0.111  , 0.1103 , 0.1101 ,\n",
       "            0.1097 , 0.10913, 0.10895, 0.10876, 0.1084 , 0.1076 , 0.1074 ,\n",
       "            0.10724, 0.10706, 0.1067 , 0.1052 , 0.1043 , 0.10376, 0.1036 ,\n",
       "            0.103  , 0.10034, 0.0993 , 0.0991 , 0.0972 , 0.09686, 0.0967 ,\n",
       "            0.0959 , 0.0957 , 0.0955 , 0.0945 , 0.09436, 0.0933 , 0.09174,\n",
       "            0.0901 , 0.0893 , 0.0882 , 0.0874 , 0.0866 , 0.0863 , 0.0856 ,\n",
       "            0.0848 , 0.08435, 0.0804 , 0.0799 , 0.07935, 0.0788 , 0.07794,\n",
       "            0.0772 , 0.07666, 0.07654, 0.07587, 0.0741 , 0.074  , 0.07263,\n",
       "            0.0721 , 0.0715 , 0.0712 , 0.06995, 0.0688 , 0.0678 , 0.0672 ,\n",
       "            0.0655 , 0.0642 , 0.0637 , 0.0627 , 0.0611 , 0.06064, 0.05823,\n",
       "            0.05737, 0.05194, 0.047  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.2421875, 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125,\n",
       "            0.6328125, 0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.6796875, 0.6796875,\n",
       "            0.6796875, 0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.6953125, 0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.71875  ,\n",
       "            0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.734375 ,\n",
       "            0.734375 , 0.734375 , 0.7421875, 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.765625 , 0.765625 , 0.7734375, 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8046875, 0.8046875, 0.8046875,\n",
       "            0.8125   , 0.8125   , 0.8203125, 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.828125 , 0.8359375, 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.8671875, 0.8671875, 0.875    , 0.875    , 0.8828125,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.921875 , 0.921875 , 0.921875 , 0.921875 ,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9375   , 0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.984375 , 0.9921875, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.01639344, 0.02459016, 0.02459016, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.08196721, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.21311475,\n",
       "            0.22131148, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.37704918, 0.37704918, 0.37704918, 0.3852459 , 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.59016395, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.6147541 , 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.358  , 0.357  , 0.3567 , 0.356  , 0.3552 , 0.3496 ,\n",
       "            0.3494 , 0.3481 , 0.348  , 0.3455 , 0.3452 , 0.3433 , 0.3418 ,\n",
       "            0.3416 , 0.3396 , 0.3364 , 0.3354 , 0.335  , 0.3345 , 0.3323 ,\n",
       "            0.3298 , 0.3293 , 0.3284 , 0.3245 , 0.3223 , 0.322  , 0.3218 ,\n",
       "            0.3213 , 0.3147 , 0.3103 , 0.3086 , 0.3083 , 0.308  , 0.306  ,\n",
       "            0.3044 , 0.3037 , 0.3005 , 0.296  , 0.2874 , 0.2852 , 0.2847 ,\n",
       "            0.2842 , 0.2803 , 0.279  , 0.272  , 0.2664 , 0.2646 , 0.264  ,\n",
       "            0.2578 , 0.2537 , 0.251  , 0.249  , 0.2448 , 0.2411 , 0.2407 ,\n",
       "            0.2328 , 0.2285 , 0.2269 , 0.22   , 0.214  , 0.2115 , 0.2089 ,\n",
       "            0.2042 , 0.2028 , 0.196  , 0.1952 , 0.1942 , 0.193  , 0.1923 ,\n",
       "            0.1873 , 0.1863 , 0.1848 , 0.1837 , 0.183  , 0.1803 , 0.1791 ,\n",
       "            0.1775 , 0.1765 , 0.1758 , 0.1709 , 0.1708 , 0.1688 , 0.1647 ,\n",
       "            0.1635 , 0.1622 , 0.1571 , 0.1547 , 0.1534 , 0.1531 , 0.1521 ,\n",
       "            0.1489 , 0.1481 , 0.1478 , 0.1459 , 0.145  , 0.1449 , 0.1443 ,\n",
       "            0.1438 , 0.1436 , 0.1427 , 0.1406 , 0.1401 , 0.1398 , 0.1395 ,\n",
       "            0.1385 , 0.1364 , 0.1359 , 0.1342 , 0.1335 , 0.1332 , 0.133  ,\n",
       "            0.1329 , 0.1301 , 0.1289 , 0.1282 , 0.1277 , 0.1267 , 0.1265 ,\n",
       "            0.1261 , 0.1255 , 0.12476, 0.1238 , 0.1216 , 0.12103, 0.12067,\n",
       "            0.12   , 0.1196 , 0.1186 , 0.1184 , 0.11676, 0.11536, 0.115  ,\n",
       "            0.11456, 0.1142 , 0.11395, 0.1138 , 0.113  , 0.1126 , 0.11127,\n",
       "            0.111  , 0.1101 , 0.10913, 0.1084 , 0.1082 , 0.1078 , 0.1074 ,\n",
       "            0.1069 , 0.1056 , 0.10486, 0.1047 , 0.1043 , 0.1032 , 0.103  ,\n",
       "            0.10266, 0.10156, 0.1011 , 0.1009 , 0.10034, 0.10016, 0.0997 ,\n",
       "            0.09894, 0.0977 , 0.09753, 0.09686, 0.09656, 0.0964 , 0.0962 ,\n",
       "            0.09503, 0.09485, 0.094  , 0.093  , 0.0927 , 0.09204, 0.0901 ,\n",
       "            0.0899 , 0.0891 , 0.0887 , 0.0871 , 0.0868 , 0.0859 , 0.0854 ,\n",
       "            0.0848 , 0.08466, 0.08405, 0.0836 , 0.08154, 0.07965, 0.07935,\n",
       "            0.0778 , 0.0774 , 0.0763 , 0.0761 , 0.076  , 0.075  , 0.07477,\n",
       "            0.0729 , 0.0708 , 0.07056, 0.0702 , 0.0694 , 0.06903, 0.0683 ,\n",
       "            0.0672 , 0.0671 , 0.0667 , 0.0644 , 0.0637 , 0.0635 , 0.06335,\n",
       "            0.06323, 0.06256, 0.0621 , 0.06143, 0.05988, 0.0591 , 0.05865,\n",
       "            0.05728, 0.05646, 0.0555 , 0.0544 , 0.0535 , 0.053  , 0.0504 ,\n",
       "            0.0494 , 0.04468, 0.0401 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6953125, 0.6953125,\n",
       "            0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.71875  , 0.7265625, 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.734375 , 0.734375 , 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.765625 , 0.7734375, 0.7734375,\n",
       "            0.7734375, 0.7734375, 0.7890625, 0.796875 , 0.796875 , 0.796875 ,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.8203125, 0.8203125, 0.828125 , 0.828125 ,\n",
       "            0.8359375, 0.8359375, 0.84375  , 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.8515625, 0.859375 , 0.859375 , 0.8671875, 0.8671875,\n",
       "            0.875    , 0.875    , 0.8828125, 0.890625 , 0.890625 , 0.8984375,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.921875 , 0.921875 ,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625,\n",
       "            0.984375 , 0.9921875, 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.01639344, 0.02459016, 0.03278688, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.04918033, 0.05737705, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.21311475,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.2704918 , 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.30327868, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.33606556, 0.33606556,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.3852459 , 0.39344263, 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.4918033 , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.6147541 , 0.6147541 , 0.6229508 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.704918  , 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.90163934, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3452 , 0.3442 , 0.344  , 0.3435 , 0.3428 , 0.3384 ,\n",
       "            0.3381 , 0.3364 , 0.3362 , 0.3342 , 0.3333 , 0.3323 , 0.3306 ,\n",
       "            0.3303 , 0.3286 , 0.3252 , 0.3247 , 0.3242 , 0.324  , 0.3235 ,\n",
       "            0.3218 , 0.321  , 0.319  , 0.318  , 0.3167 , 0.313  , 0.3118 ,\n",
       "            0.3115 , 0.3113 , 0.3103 , 0.31   , 0.3088 , 0.3042 , 0.3    ,\n",
       "            0.2986 , 0.2979 , 0.2957 , 0.2947 , 0.2942 , 0.2927 , 0.2903 ,\n",
       "            0.286  , 0.278  , 0.2751 , 0.275  , 0.2722 , 0.2695 , 0.268  ,\n",
       "            0.263  , 0.2556 , 0.2551 , 0.2524 , 0.2489 , 0.2449 , 0.2422 ,\n",
       "            0.2395 , 0.2362 , 0.2334 , 0.2313 , 0.2256 , 0.2211 , 0.2203 ,\n",
       "            0.2119 , 0.208  , 0.2043 , 0.2031 , 0.1974 , 0.1965 , 0.1877 ,\n",
       "            0.187  , 0.1866 , 0.1859 , 0.185  , 0.1827 , 0.1807 , 0.179  ,\n",
       "            0.1759 , 0.1757 , 0.1749 , 0.1733 , 0.1725 , 0.1719 , 0.1699 ,\n",
       "            0.1663 , 0.1659 , 0.1611 , 0.161  , 0.1597 , 0.159  , 0.1581 ,\n",
       "            0.1512 , 0.1511 , 0.149  , 0.1476 , 0.1475 , 0.1456 , 0.1449 ,\n",
       "            0.1438 , 0.1428 , 0.1411 , 0.1409 , 0.1398 , 0.1378 , 0.1361 ,\n",
       "            0.1355 , 0.1353 , 0.1333 , 0.133  , 0.1327 , 0.1321 , 0.1305 ,\n",
       "            0.1301 , 0.1299 , 0.1279 , 0.1278 , 0.1263 , 0.1241 , 0.124  ,\n",
       "            0.1238 , 0.1229 , 0.12286, 0.1222 , 0.122  , 0.1216 , 0.1193 ,\n",
       "            0.1192 , 0.1186 , 0.1174 , 0.11694, 0.1166 , 0.11597, 0.11554,\n",
       "            0.11456, 0.11395, 0.1138 , 0.1122 , 0.1118 , 0.1101 , 0.1099 ,\n",
       "            0.10913, 0.10876, 0.1078 , 0.1076 , 0.1074 , 0.1063 , 0.10504,\n",
       "            0.1045 , 0.10394, 0.10376, 0.1032 , 0.10284, 0.10266, 0.1025 ,\n",
       "            0.10175, 0.0998 , 0.0997 , 0.0991 , 0.09894, 0.09875, 0.0979 ,\n",
       "            0.0974 , 0.0972 , 0.0964 , 0.096  , 0.0957 , 0.09534, 0.0945 ,\n",
       "            0.0942 , 0.0932 , 0.093  , 0.09235, 0.09204, 0.09174, 0.09155,\n",
       "            0.0914 , 0.09125, 0.0895 , 0.0891 , 0.089  , 0.0882 , 0.088  ,\n",
       "            0.0876 , 0.0873 , 0.0856 , 0.0848 , 0.083  , 0.0823 , 0.08124,\n",
       "            0.08105, 0.0801 , 0.0799 , 0.0798 , 0.07935, 0.0775 , 0.07544,\n",
       "            0.075  , 0.0734 , 0.0733 , 0.0724 , 0.07227, 0.0717 , 0.07104,\n",
       "            0.0708 , 0.06866, 0.06744, 0.0667 , 0.06635, 0.06464, 0.0641 ,\n",
       "            0.06323, 0.0631 , 0.0629 , 0.0603 , 0.0601 , 0.05975, 0.05954,\n",
       "            0.05933, 0.05823, 0.05814, 0.05634, 0.05624, 0.0542 , 0.0537 ,\n",
       "            0.05234, 0.051  , 0.05072, 0.05023, 0.04733, 0.04602, 0.04193,\n",
       "            0.03738], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.53125  ,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.625    , 0.625    , 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.6640625, 0.6640625, 0.6640625, 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.7265625, 0.734375 , 0.734375 , 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.7578125, 0.765625 , 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.7734375, 0.7734375, 0.78125  , 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.796875 , 0.796875 , 0.8046875, 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.8203125, 0.8203125, 0.8203125, 0.8203125,\n",
       "            0.828125 , 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.859375 , 0.859375 ,\n",
       "            0.8671875, 0.8671875, 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.921875 ,\n",
       "            0.921875 , 0.921875 , 0.9296875, 0.9296875, 0.9296875, 0.9296875,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.9453125, 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.984375 , 0.9921875, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.01639344, 0.02459016, 0.03278688, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.04918033, 0.05737705, 0.06557377, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.21311475, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.2704918 ,\n",
       "            0.2704918 , 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.30327868, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36065573,\n",
       "            0.36885247, 0.36885247, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.4262295 , 0.44262296, 0.45081967, 0.46721312, 0.46721312,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.5       , 0.5       ,\n",
       "            0.5163934 , 0.52459013, 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.60655737, 0.60655737, 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.647541  , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.72131145, 0.7295082 , 0.7295082 ,\n",
       "            0.7295082 , 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.94262296, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.334  , 0.3333 , 0.3325 , 0.332  , 0.3315 , 0.3303 ,\n",
       "            0.3271 , 0.327  , 0.3254 , 0.3247 , 0.3237 , 0.3218 , 0.3213 ,\n",
       "            0.3198 , 0.3196 , 0.3193 , 0.3179 , 0.315  , 0.3145 , 0.3137 ,\n",
       "            0.313  , 0.3115 , 0.3103 , 0.3086 , 0.308  , 0.304  , 0.3022 ,\n",
       "            0.302  , 0.3015 , 0.3013 , 0.3003 , 0.2996 , 0.296  , 0.2937 ,\n",
       "            0.2908 , 0.2896 , 0.2888 , 0.2876 , 0.2864 , 0.2856 , 0.2854 ,\n",
       "            0.283  , 0.28   , 0.2773 , 0.2693 , 0.2668 , 0.2666 , 0.261  ,\n",
       "            0.2588 , 0.2537 , 0.248  , 0.2437 , 0.2426 , 0.2415 , 0.2375 ,\n",
       "            0.2335 , 0.2299 , 0.229  , 0.2268 , 0.2235 , 0.2184 , 0.2147 ,\n",
       "            0.2053 , 0.2028 , 0.1985 , 0.1979 , 0.1925 , 0.1904 , 0.1833 ,\n",
       "            0.1827 , 0.1799 , 0.179  , 0.1787 , 0.1783 , 0.1765 , 0.1752 ,\n",
       "            0.1724 , 0.1698 , 0.1692 , 0.1688 , 0.1666 , 0.1653 , 0.1627 ,\n",
       "            0.1621 , 0.1582 , 0.1566 , 0.1558 , 0.1556 , 0.1548 , 0.1484 ,\n",
       "            0.1472 , 0.1465 , 0.1436 , 0.1426 , 0.1418 , 0.1409 , 0.1405 ,\n",
       "            0.1401 , 0.1388 , 0.1362 , 0.135  , 0.133  , 0.1327 , 0.1323 ,\n",
       "            0.131  , 0.1306 , 0.1287 , 0.1285 , 0.1279 , 0.1278 , 0.1277 ,\n",
       "            0.1259 , 0.12445, 0.1238 , 0.122  , 0.12177, 0.1214 , 0.1213 ,\n",
       "            0.12024, 0.119  , 0.1184 , 0.118  , 0.1178 , 0.11755, 0.11694,\n",
       "            0.115  , 0.11456, 0.11395, 0.1136 , 0.11316, 0.11084, 0.1105 ,\n",
       "            0.1103 , 0.10876, 0.10724, 0.10706, 0.1065 , 0.1054 , 0.1045 ,\n",
       "            0.1036 , 0.1023 , 0.10175, 0.10126, 0.1007 , 0.10016, 0.1    ,\n",
       "            0.0993 , 0.09875, 0.0981 , 0.0972 , 0.09656, 0.0964 , 0.0955 ,\n",
       "            0.09534, 0.09503, 0.0937 , 0.0935 , 0.0933 , 0.0932 , 0.09283,\n",
       "            0.09235, 0.09174, 0.0914 , 0.0906 , 0.0904 , 0.0901 , 0.0895 ,\n",
       "            0.0893 , 0.0891 , 0.0888 , 0.0885 , 0.0877 , 0.0866 , 0.0863 ,\n",
       "            0.086  , 0.0851 , 0.0845 , 0.08435, 0.08386, 0.0831 , 0.0818 ,\n",
       "            0.0806 , 0.0785 , 0.07837, 0.07825, 0.0774 , 0.0772 , 0.0771 ,\n",
       "            0.07587, 0.0752 , 0.0732 , 0.0724 , 0.07227, 0.07104, 0.0707 ,\n",
       "            0.0702 , 0.06903, 0.0689 , 0.06866, 0.0655 , 0.0649 , 0.06384,\n",
       "            0.0629 , 0.0621 , 0.06165, 0.0612 , 0.06097, 0.05835, 0.05823,\n",
       "            0.05792, 0.0578 , 0.0576 , 0.0572 , 0.05655, 0.05573, 0.0549 ,\n",
       "            0.0544 , 0.0527 , 0.05243, 0.0506 , 0.0494 , 0.04913, 0.04895,\n",
       "            0.0456 , 0.044  , 0.04053, 0.03595], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.296875 ,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.65625  , 0.65625  ,\n",
       "            0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6875   , 0.6875   ,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6953125, 0.6953125, 0.6953125,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.7109375, 0.71875  ,\n",
       "            0.71875  , 0.71875  , 0.7265625, 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.75     ,\n",
       "            0.75     , 0.75     , 0.7578125, 0.7578125, 0.765625 , 0.765625 ,\n",
       "            0.765625 , 0.765625 , 0.765625 , 0.7734375, 0.78125  , 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8125   ,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.828125 , 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.8515625, 0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.8828125, 0.890625 , 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.90625  , 0.9140625, 0.921875 , 0.921875 ,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.9921875,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.01639344, 0.02459016,\n",
       "            0.03278688, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.07377049, 0.08196721, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.25409836, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.31967214, 0.31967214, 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36065573, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.58196723, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.7295082 , 0.7295082 , 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.90983605, 0.91803277, 0.93442625,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.325  , 0.3245 , 0.3225 , 0.322  , 0.3215 , 0.321  ,\n",
       "            0.3208 , 0.32   , 0.3186 , 0.318  , 0.3176 , 0.3164 , 0.315  ,\n",
       "            0.3145 , 0.3142 , 0.313  , 0.3103 , 0.31   , 0.3096 , 0.3086 ,\n",
       "            0.3083 , 0.3076 , 0.3062 , 0.3052 , 0.305  , 0.3003 , 0.2988 ,\n",
       "            0.2986 , 0.2983 , 0.2969 , 0.2954 , 0.291  , 0.2898 , 0.2896 ,\n",
       "            0.2874 , 0.2861 , 0.286  , 0.2852 , 0.28   , 0.2783 , 0.2773 ,\n",
       "            0.2703 , 0.2678 , 0.2676 , 0.2612 , 0.2563 , 0.2544 , 0.2522 ,\n",
       "            0.2502 , 0.2438 , 0.241  , 0.2401 , 0.2372 , 0.2347 , 0.2323 ,\n",
       "            0.2314 , 0.2297 , 0.2252 , 0.2222 , 0.2203 , 0.2194 , 0.209  ,\n",
       "            0.2043 , 0.2037 , 0.199  , 0.1953 , 0.1906 , 0.1901 , 0.1865 ,\n",
       "            0.1836 , 0.1829 , 0.181  , 0.1804 , 0.1798 , 0.1796 , 0.178  ,\n",
       "            0.1771 , 0.174  , 0.1724 , 0.172  , 0.1708 , 0.1704 , 0.1697 ,\n",
       "            0.1669 , 0.165  , 0.1637 , 0.1631 , 0.1599 , 0.1569 , 0.1556 ,\n",
       "            0.1537 , 0.1505 , 0.1503 , 0.1495 , 0.1489 , 0.1481 , 0.1478 ,\n",
       "            0.1434 , 0.1427 , 0.1409 , 0.1401 , 0.1396 , 0.1377 , 0.1365 ,\n",
       "            0.1364 , 0.1359 , 0.1344 , 0.1338 , 0.133  , 0.1322 , 0.1315 ,\n",
       "            0.131  , 0.1305 , 0.1302 , 0.1299 , 0.1295 , 0.127  , 0.1261 ,\n",
       "            0.1259 , 0.1249 , 0.1243 , 0.1235 , 0.12335, 0.1232 , 0.12317,\n",
       "            0.1219 , 0.1214 , 0.12036, 0.11993, 0.1195 , 0.1178 , 0.1174 ,\n",
       "            0.1158 , 0.11554, 0.11456, 0.1138 , 0.11316, 0.1124 , 0.1122 ,\n",
       "            0.11084, 0.11066, 0.1103 , 0.1099 , 0.1093 , 0.10876, 0.1078 ,\n",
       "            0.10724, 0.1067 , 0.10614, 0.10596, 0.10504, 0.1045 , 0.1043 ,\n",
       "            0.10394, 0.1036 , 0.1034 , 0.1019 , 0.10175, 0.10156, 0.1007 ,\n",
       "            0.1    , 0.0991 , 0.09894, 0.09827, 0.0977 , 0.0974 , 0.0972 ,\n",
       "            0.09686, 0.09656, 0.0962 , 0.0957 , 0.09534, 0.09467, 0.0939 ,\n",
       "            0.0922 , 0.0914 , 0.09125, 0.0904 , 0.0903 , 0.0896 , 0.0893 ,\n",
       "            0.0891 , 0.0882 , 0.0876 , 0.0871 , 0.08374, 0.0828 , 0.0825 ,\n",
       "            0.0824 , 0.0818 , 0.08136, 0.08124, 0.0806 , 0.0786 , 0.07837,\n",
       "            0.07697, 0.07654, 0.0761 , 0.07574, 0.0745 , 0.074  , 0.07385,\n",
       "            0.07306, 0.0725 , 0.07135, 0.07104, 0.0702 , 0.06744, 0.06635,\n",
       "            0.066  , 0.06525, 0.0651 , 0.0649 , 0.06244, 0.06152, 0.06097,\n",
       "            0.06052, 0.05878, 0.058  , 0.05792, 0.05737, 0.0547 , 0.0544 ,\n",
       "            0.0539 , 0.0526 , 0.04904, 0.04648, 0.04385, 0.03876],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0625   , 0.078125 , 0.0859375, 0.09375  , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.625    , 0.6328125, 0.6328125,\n",
       "            0.6328125, 0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6796875, 0.6796875, 0.6796875, 0.6875   ,\n",
       "            0.6875   , 0.6875   , 0.6875   , 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.703125 , 0.7109375, 0.7109375, 0.7109375, 0.71875  , 0.71875  ,\n",
       "            0.71875  , 0.71875  , 0.71875  , 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.734375 , 0.7421875, 0.7421875, 0.75     ,\n",
       "            0.75     , 0.75     , 0.75     , 0.75     , 0.75     , 0.75     ,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.7734375,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.796875 ,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.828125 , 0.8359375, 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.84375  , 0.8515625, 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.8671875, 0.8671875,\n",
       "            0.875    , 0.875    , 0.8828125, 0.8828125, 0.890625 , 0.8984375,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9296875, 0.9296875, 0.9296875, 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.9609375, 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.9765625,\n",
       "            0.984375 , 0.9921875, 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00819672, 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.03278688, 0.04098361, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.09836066,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.24590164, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.26229507, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.352459  ,\n",
       "            0.36065573, 0.36065573, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.37704918, 0.3852459 , 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.44262296, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.45901638, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.52459013, 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.58196723, 0.59836066, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.6229508 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6885246 , 0.6967213 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.73770493, 0.73770493, 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.78688526, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.8032787 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3176 , 0.3171 , 0.316  , 0.3152 , 0.3142 , 0.314  ,\n",
       "            0.3137 , 0.313  , 0.3127 , 0.3118 , 0.3108 , 0.31   , 0.3098 ,\n",
       "            0.308  , 0.3079 , 0.3076 , 0.3062 , 0.306  , 0.3054 , 0.3042 ,\n",
       "            0.304  , 0.3032 , 0.3005 , 0.2986 , 0.2969 , 0.2964 , 0.2942 ,\n",
       "            0.2922 , 0.2915 , 0.291  , 0.2908 , 0.2896 , 0.289  , 0.2869 ,\n",
       "            0.2861 , 0.2852 , 0.2805 , 0.2803 , 0.279  , 0.2742 , 0.2722 ,\n",
       "            0.2715 , 0.265  , 0.258  , 0.2576 , 0.2559 , 0.2494 , 0.2467 ,\n",
       "            0.246  , 0.2397 , 0.2395 , 0.239  , 0.2382 , 0.2355 , 0.231  ,\n",
       "            0.2306 , 0.2294 , 0.2292 , 0.2273 , 0.2189 , 0.2162 , 0.214  ,\n",
       "            0.2124 , 0.2085 , 0.2034 , 0.2013 , 0.201  , 0.1976 , 0.1942 ,\n",
       "            0.1941 , 0.1919 , 0.1897 , 0.1887 , 0.1858 , 0.1852 , 0.1842 ,\n",
       "            0.1827 , 0.1821 , 0.1815 , 0.1805 , 0.179  , 0.177  , 0.1755 ,\n",
       "            0.1752 , 0.1748 , 0.169  , 0.1683 , 0.1682 , 0.1636 , 0.1621 ,\n",
       "            0.1617 , 0.1608 , 0.1605 , 0.1604 , 0.1602 , 0.1569 , 0.154  ,\n",
       "            0.1519 , 0.1517 , 0.1514 , 0.1503 , 0.1493 , 0.1483 , 0.1442 ,\n",
       "            0.143  , 0.1427 , 0.1425 , 0.1423 , 0.142  , 0.1406 , 0.1405 ,\n",
       "            0.1399 , 0.139  , 0.138  , 0.1378 , 0.136  , 0.1356 , 0.1355 ,\n",
       "            0.1349 , 0.1344 , 0.134  , 0.1337 , 0.1332 , 0.1328 , 0.1324 ,\n",
       "            0.1322 , 0.1318 , 0.1289 , 0.1284 , 0.1276 , 0.1263 , 0.1255 ,\n",
       "            0.1252 , 0.1251 , 0.1243 , 0.1241 , 0.1236 , 0.12335, 0.12244,\n",
       "            0.12213, 0.12103, 0.1207 , 0.1193 , 0.1188 , 0.1186 , 0.11816,\n",
       "            0.11676, 0.1158 , 0.115  , 0.11475, 0.11456, 0.1144 , 0.1142 ,\n",
       "            0.1136 , 0.11316, 0.113  , 0.1118 , 0.11145, 0.11127, 0.111  ,\n",
       "            0.11066, 0.1103 , 0.1093 , 0.10876, 0.1082 , 0.1076 , 0.10706,\n",
       "            0.1067 , 0.1065 , 0.1052 , 0.10504, 0.1045 , 0.1041 , 0.1036 ,\n",
       "            0.1025 , 0.1023 , 0.1019 , 0.0997 , 0.09894, 0.0986 , 0.09827,\n",
       "            0.09686, 0.0964 , 0.0962 , 0.09534, 0.0932 , 0.0925 , 0.09106,\n",
       "            0.09076, 0.0903 , 0.0896 , 0.0895 , 0.0888 , 0.0885 , 0.0874 ,\n",
       "            0.0845 , 0.08405, 0.08386, 0.0824 , 0.0823 , 0.0821 , 0.08154,\n",
       "            0.0804 , 0.0802 , 0.0792 , 0.0789 , 0.0774 , 0.0741 , 0.07385,\n",
       "            0.0721 , 0.0716 , 0.0715 , 0.0703 , 0.06995, 0.0698 , 0.0695 ,\n",
       "            0.06915, 0.06696, 0.06683, 0.0666 , 0.065  , 0.06464, 0.0645 ,\n",
       "            0.06223, 0.06165, 0.06152, 0.05865, 0.0551 , 0.05127, 0.04968,\n",
       "            0.04376], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0546875, 0.0625   , 0.078125 , 0.0859375, 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.140625 , 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.1796875, 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.25     , 0.265625 , 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.3515625, 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.53125  , 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.640625 ,\n",
       "            0.640625 , 0.6484375, 0.6484375, 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.6796875, 0.6796875, 0.6796875, 0.6875   , 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.7109375, 0.7109375, 0.7109375,\n",
       "            0.7109375, 0.71875  , 0.71875  , 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.7421875, 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.75     , 0.75     , 0.75     , 0.75     , 0.75     , 0.75     ,\n",
       "            0.75     , 0.7578125, 0.7578125, 0.765625 , 0.765625 , 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.8046875, 0.8046875, 0.8125   ,\n",
       "            0.8125   , 0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.8359375,\n",
       "            0.8359375, 0.84375  , 0.84375  , 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.875    , 0.8828125,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.90625  , 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9375   ,\n",
       "            0.9453125, 0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.953125 ,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.9921875,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.01639344, 0.02459016,\n",
       "            0.03278688, 0.03278688, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.06557377, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.26229507, 0.26229507, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.33606556, 0.33606556, 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.39344263, 0.40163934, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.45901638, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5       , 0.5081967 ,\n",
       "            0.5163934 , 0.5163934 , 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6229508 , 0.6229508 , 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.6557377 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.73770493, 0.73770493, 0.73770493,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.92622954, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3125 , 0.3123 , 0.3118 , 0.3115 , 0.311  , 0.3108 ,\n",
       "            0.3088 , 0.3086 , 0.3083 , 0.308  , 0.3079 , 0.3076 , 0.3074 ,\n",
       "            0.3066 , 0.306  , 0.3052 , 0.3044 , 0.304  , 0.3032 , 0.303  ,\n",
       "            0.3025 , 0.2998 , 0.2996 , 0.2993 , 0.297  , 0.2969 , 0.2957 ,\n",
       "            0.295  , 0.2937 , 0.292  , 0.2913 , 0.2876 , 0.2866 , 0.2861 ,\n",
       "            0.2852 , 0.2805 , 0.2798 , 0.279  , 0.273  , 0.265  , 0.263  ,\n",
       "            0.2625 , 0.2588 , 0.2556 , 0.2502 , 0.249  , 0.2429 , 0.2411 ,\n",
       "            0.241  , 0.2407 , 0.239  , 0.2386 , 0.2379 , 0.2374 , 0.2332 ,\n",
       "            0.2316 , 0.2274 , 0.2257 , 0.2249 , 0.2205 , 0.2157 , 0.2156 ,\n",
       "            0.2152 , 0.2118 , 0.2089 , 0.2084 , 0.2065 , 0.2043 , 0.2035 ,\n",
       "            0.1971 , 0.1965 , 0.1964 , 0.1956 , 0.1954 , 0.1953 , 0.1943 ,\n",
       "            0.1934 , 0.1924 , 0.1903 , 0.1901 , 0.1853 , 0.1846 , 0.1842 ,\n",
       "            0.1815 , 0.1783 , 0.1779 , 0.1772 , 0.1771 , 0.1766 , 0.1761 ,\n",
       "            0.1749 , 0.1709 , 0.169  , 0.1677 , 0.1674 , 0.1669 , 0.1643 ,\n",
       "            0.1604 , 0.1592 , 0.1588 , 0.1577 , 0.1572 , 0.1567 , 0.1566 ,\n",
       "            0.1565 , 0.1547 , 0.1544 , 0.1542 , 0.1534 , 0.1519 , 0.1509 ,\n",
       "            0.1506 , 0.15   , 0.1497 , 0.1494 , 0.149  , 0.1489 , 0.1488 ,\n",
       "            0.1482 , 0.1475 , 0.147  , 0.1467 , 0.1438 , 0.1437 , 0.1427 ,\n",
       "            0.1415 , 0.1409 , 0.1404 , 0.1401 , 0.1399 , 0.1394 , 0.1387 ,\n",
       "            0.138  , 0.137  , 0.1366 , 0.1356 , 0.135  , 0.1346 , 0.1343 ,\n",
       "            0.1338 , 0.1329 , 0.1328 , 0.1315 , 0.1312 , 0.1304 , 0.1301 ,\n",
       "            0.1298 , 0.1295 , 0.1293 , 0.1284 , 0.127  , 0.1265 , 0.1262 ,\n",
       "            0.1261 , 0.12476, 0.12445, 0.1239 , 0.12335, 0.12274, 0.12177,\n",
       "            0.12146, 0.12103, 0.12   , 0.1195 , 0.119  , 0.1186 , 0.1184 ,\n",
       "            0.11597, 0.11456, 0.1138 , 0.1128 , 0.112  , 0.11163, 0.11145,\n",
       "            0.1097 , 0.1095 , 0.10913, 0.10706, 0.1069 , 0.10614, 0.1058 ,\n",
       "            0.1043 , 0.103  , 0.10266, 0.1023 , 0.10175, 0.1007 , 0.0979 ,\n",
       "            0.0972 , 0.0955 , 0.09503, 0.09467, 0.0939 , 0.0933 , 0.0927 ,\n",
       "            0.09204, 0.09155, 0.0901 , 0.086  , 0.0848 , 0.08344, 0.0825 ,\n",
       "            0.0824 , 0.0823 , 0.082  , 0.0818 , 0.08167, 0.08136, 0.08124,\n",
       "            0.07947, 0.07684, 0.07666, 0.07654, 0.0749 , 0.0742 , 0.074  ,\n",
       "            0.07355, 0.0724 , 0.06854, 0.06464, 0.0592 , 0.059  , 0.05203],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0625   , 0.09375  , 0.1015625, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.15625  , 0.171875 , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5625   , 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.578125 ,\n",
       "            0.578125 , 0.5859375, 0.5859375, 0.5859375, 0.5859375, 0.59375  ,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.609375 ,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.640625 , 0.640625 , 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6875   , 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.703125 , 0.703125 , 0.703125 , 0.703125 , 0.7109375,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.71875  , 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.7421875, 0.75     , 0.75     , 0.75     ,\n",
       "            0.75     , 0.75     , 0.75     , 0.75     , 0.75     , 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.765625 , 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8046875, 0.8125   ,\n",
       "            0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.8359375, 0.84375  ,\n",
       "            0.84375  , 0.8515625, 0.8515625, 0.859375 , 0.859375 , 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.8671875, 0.8671875, 0.8671875,\n",
       "            0.8828125, 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.90625  ,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.9765625, 0.984375 ,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.01639344, 0.01639344, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.04918033, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.13114753, 0.13934426, 0.14754099,\n",
       "            0.1557377 , 0.16393442, 0.17213115, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.22131148, 0.22950819,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.26229507, 0.26229507,\n",
       "            0.2704918 , 0.2704918 , 0.27868852, 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.33606556, 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.37704918, 0.39344263, 0.39344263, 0.40163934, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4180328 , 0.4262295 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.47540984,\n",
       "            0.47540984, 0.47540984, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.57377046, 0.59016395,\n",
       "            0.59836066, 0.6147541 , 0.6229508 , 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.74590164, 0.74590164, 0.74590164, 0.74590164,\n",
       "            0.74590164, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3157 , 0.3147 , 0.3145 , 0.3137 , 0.3132 , 0.313  ,\n",
       "            0.3127 , 0.3123 , 0.312  , 0.3118 , 0.311  , 0.3108 , 0.3093 ,\n",
       "            0.309  , 0.3086 , 0.3079 , 0.3074 , 0.3071 , 0.307  , 0.3066 ,\n",
       "            0.3064 , 0.3062 , 0.3052 , 0.3042 , 0.304  , 0.3035 , 0.302  ,\n",
       "            0.3013 , 0.3003 , 0.2996 , 0.298  , 0.2957 , 0.2947 , 0.2925 ,\n",
       "            0.2917 , 0.2888 , 0.2869 , 0.2861 , 0.2825 , 0.279  , 0.2742 ,\n",
       "            0.2732 , 0.273  , 0.27   , 0.267  , 0.2644 , 0.259  , 0.2556 ,\n",
       "            0.2554 , 0.255  , 0.254  , 0.2505 , 0.2456 , 0.244  , 0.2437 ,\n",
       "            0.243  , 0.2429 , 0.2426 , 0.239  , 0.2356 , 0.2355 , 0.2327 ,\n",
       "            0.2325 , 0.2299 , 0.2281 , 0.2278 , 0.2257 , 0.2252 , 0.2181 ,\n",
       "            0.2167 , 0.2157 , 0.2156 , 0.2152 , 0.2142 , 0.2139 , 0.2118 ,\n",
       "            0.2109 , 0.2095 , 0.2073 , 0.2068 , 0.2065 , 0.2009 , 0.2006 ,\n",
       "            0.1995 , 0.1993 , 0.199  , 0.1984 , 0.1971 , 0.1946 , 0.1898 ,\n",
       "            0.1897 , 0.1896 , 0.189  , 0.1877 , 0.1873 , 0.1858 , 0.1816 ,\n",
       "            0.181  , 0.1798 , 0.178  , 0.1771 , 0.1764 , 0.1755 , 0.1753 ,\n",
       "            0.1741 , 0.1735 , 0.1726 , 0.1724 , 0.1711 , 0.171  , 0.1705 ,\n",
       "            0.1703 , 0.1685 , 0.1683 , 0.1676 , 0.1669 , 0.1659 , 0.1656 ,\n",
       "            0.1654 , 0.1641 , 0.1638 , 0.163  , 0.1622 , 0.162  , 0.1615 ,\n",
       "            0.1611 , 0.161  , 0.1604 , 0.1603 , 0.1582 , 0.1569 , 0.1559 ,\n",
       "            0.1556 , 0.1552 , 0.1548 , 0.1547 , 0.1545 , 0.1539 , 0.1514 ,\n",
       "            0.1505 , 0.1503 , 0.15   , 0.1498 , 0.1494 , 0.149  , 0.1487 ,\n",
       "            0.1484 , 0.1472 , 0.1469 , 0.1464 , 0.1442 , 0.143  , 0.1426 ,\n",
       "            0.1418 , 0.1417 , 0.1409 , 0.1407 , 0.1406 , 0.1403 , 0.1392 ,\n",
       "            0.1381 , 0.1376 , 0.1375 , 0.1371 , 0.136  , 0.1327 , 0.1317 ,\n",
       "            0.1315 , 0.1312 , 0.1311 , 0.1301 , 0.1295 , 0.1289 , 0.1263 ,\n",
       "            0.12463, 0.1235 , 0.1232 , 0.1223 , 0.12177, 0.1217 , 0.1207 ,\n",
       "            0.1197 , 0.1193 , 0.1192 , 0.1184 , 0.11816, 0.11633, 0.1158 ,\n",
       "            0.11536, 0.1142 , 0.11395, 0.112  , 0.11145, 0.111  , 0.1095 ,\n",
       "            0.1076 , 0.1063 , 0.10596, 0.1043 , 0.1021 , 0.1    , 0.09894,\n",
       "            0.09875, 0.09845, 0.0981 , 0.0972 , 0.09705, 0.0967 , 0.09656,\n",
       "            0.0957 , 0.09467, 0.09235, 0.0904 , 0.0903 , 0.0898 , 0.0895 ,\n",
       "            0.0887 , 0.0869 , 0.0866 , 0.08154, 0.0775 , 0.0715 , 0.06995,\n",
       "            0.06305], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.0234375, 0.03125  , 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.0859375, 0.09375  , 0.1015625, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1796875,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2265625, 0.234375 , 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.2890625, 0.3046875, 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375, 0.5234375,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.5390625, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.5859375,\n",
       "            0.5859375, 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.6171875, 0.625    ,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.6484375, 0.6484375, 0.6484375, 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.6640625, 0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.703125 ,\n",
       "            0.703125 , 0.703125 , 0.7109375, 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625, 0.7265625,\n",
       "            0.7265625, 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.75     ,\n",
       "            0.75     , 0.75     , 0.75     , 0.7578125, 0.765625 , 0.765625 ,\n",
       "            0.765625 , 0.765625 , 0.765625 , 0.7734375, 0.78125  , 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.796875 , 0.796875 , 0.8046875, 0.8046875,\n",
       "            0.8125   , 0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.8359375,\n",
       "            0.8359375, 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.8671875, 0.8671875, 0.8671875, 0.8671875, 0.875    , 0.875    ,\n",
       "            0.8828125, 0.8828125, 0.890625 , 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.9609375, 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625, 0.9765625,\n",
       "            0.984375 , 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.01639344, 0.02459016, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.07377049, 0.07377049, 0.08196721, 0.09016393, 0.09836066,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.21311475, 0.21311475, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.26229507, 0.2704918 ,\n",
       "            0.27868852, 0.27868852, 0.27868852, 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.352459  , 0.36065573, 0.36885247, 0.36885247,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.45901638,\n",
       "            0.47540984, 0.47540984, 0.48360655, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.56557375, 0.56557375,\n",
       "            0.57377046, 0.58196723, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.60655737, 0.6147541 , 0.6147541 , 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3237 , 0.323  , 0.3228 , 0.3225 , 0.3223 , 0.3218 ,\n",
       "            0.321  , 0.3208 , 0.3198 , 0.3193 , 0.3188 , 0.3184 , 0.318  ,\n",
       "            0.3179 , 0.3176 , 0.3174 , 0.3171 , 0.317  , 0.3167 , 0.3154 ,\n",
       "            0.3152 , 0.3147 , 0.3145 , 0.3125 , 0.31   , 0.3096 , 0.3093 ,\n",
       "            0.3086 , 0.3083 , 0.3071 , 0.3047 , 0.3037 , 0.3008 , 0.2988 ,\n",
       "            0.2986 , 0.2976 , 0.2932 , 0.2903 , 0.29   , 0.2898 , 0.2896 ,\n",
       "            0.2874 , 0.2866 , 0.2854 , 0.283  , 0.2783 , 0.2769 , 0.276  ,\n",
       "            0.2751 , 0.271  , 0.2688 , 0.2664 , 0.266  , 0.2637 , 0.263  ,\n",
       "            0.2627 , 0.2605 , 0.258  , 0.2563 , 0.256  , 0.2559 , 0.255  ,\n",
       "            0.2544 , 0.2542 , 0.2524 , 0.2467 , 0.2466 , 0.2456 , 0.2437 ,\n",
       "            0.2429 , 0.2421 , 0.241  , 0.2407 , 0.2394 , 0.239  , 0.2383 ,\n",
       "            0.2363 , 0.2325 , 0.2323 , 0.2316 , 0.2297 , 0.2292 , 0.2286 ,\n",
       "            0.226  , 0.2255 , 0.2244 , 0.2235 , 0.2216 , 0.2205 , 0.22   ,\n",
       "            0.2191 , 0.2166 , 0.2161 , 0.2157 , 0.2153 , 0.2152 , 0.2128 ,\n",
       "            0.2118 , 0.2115 , 0.207  , 0.2059 , 0.2056 , 0.205  , 0.2045 ,\n",
       "            0.202  , 0.2018 , 0.2017 , 0.2015 , 0.2007 , 0.1996 , 0.1978 ,\n",
       "            0.1968 , 0.1967 , 0.196  , 0.1959 , 0.1958 , 0.1946 , 0.1925 ,\n",
       "            0.1924 , 0.1923 , 0.1921 , 0.1906 , 0.1896 , 0.1893 , 0.1891 ,\n",
       "            0.189  , 0.188  , 0.1877 , 0.1873 , 0.1858 , 0.1852 , 0.1849 ,\n",
       "            0.1833 , 0.1831 , 0.1827 , 0.1823 , 0.1821 , 0.182  , 0.1799 ,\n",
       "            0.1796 , 0.1792 , 0.1791 , 0.1783 , 0.178  , 0.1779 , 0.1774 ,\n",
       "            0.1768 , 0.1754 , 0.1748 , 0.174  , 0.1735 , 0.1718 , 0.1715 ,\n",
       "            0.1711 , 0.1707 , 0.1705 , 0.1704 , 0.1697 , 0.1693 , 0.1686 ,\n",
       "            0.1682 , 0.166  , 0.1643 , 0.1641 , 0.164  , 0.163  , 0.1626 ,\n",
       "            0.1624 , 0.1619 , 0.1615 , 0.1592 , 0.159  , 0.1582 , 0.156  ,\n",
       "            0.1554 , 0.1548 , 0.1542 , 0.1536 , 0.1514 , 0.1508 , 0.149  ,\n",
       "            0.1471 , 0.1467 , 0.1464 , 0.1455 , 0.1445 , 0.1444 , 0.1437 ,\n",
       "            0.1432 , 0.1431 , 0.1421 , 0.1418 , 0.1416 , 0.1392 , 0.139  ,\n",
       "            0.1388 , 0.138  , 0.1371 , 0.1361 , 0.1354 , 0.1335 , 0.1334 ,\n",
       "            0.1293 , 0.128  , 0.1265 , 0.126  , 0.1252 , 0.1242 , 0.12335,\n",
       "            0.12286, 0.1226 , 0.1204 , 0.12036, 0.1197 , 0.1193 , 0.118  ,\n",
       "            0.11615, 0.11597, 0.115  , 0.1144 , 0.1142 , 0.1103 , 0.1093 ,\n",
       "            0.10876, 0.1086 , 0.1054 , 0.10126, 0.09705, 0.0904 , 0.086  ,\n",
       "            0.0799 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.125    , 0.1328125, 0.140625 , 0.15625  ,\n",
       "            0.1640625, 0.1875   , 0.1953125, 0.203125 , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.40625  , 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.4765625, 0.484375 ,\n",
       "            0.484375 , 0.484375 , 0.484375 , 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.5      , 0.5      , 0.5      , 0.5      ,\n",
       "            0.5      , 0.5      , 0.5078125, 0.5078125, 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.546875 , 0.546875 , 0.5546875,\n",
       "            0.5546875, 0.5546875, 0.5546875, 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5703125, 0.5703125, 0.5703125, 0.5703125, 0.5703125,\n",
       "            0.5703125, 0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.6171875,\n",
       "            0.6171875, 0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.6484375, 0.65625  , 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.6953125, 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.71875  , 0.71875  , 0.71875  , 0.71875  , 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.7421875, 0.7421875,\n",
       "            0.7421875, 0.75     , 0.765625 , 0.7734375, 0.78125  , 0.78125  ,\n",
       "            0.78125  , 0.78125  , 0.78125  , 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.8203125,\n",
       "            0.828125 , 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.859375 , 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.890625 , 0.890625 , 0.8984375, 0.8984375,\n",
       "            0.90625  , 0.9140625, 0.9296875, 0.9296875, 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.9609375,\n",
       "            0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.9765625, 0.9765625,\n",
       "            0.984375 , 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.01639344, 0.01639344, 0.03278688, 0.04098361, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.05737705, 0.06557377, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.09016393, 0.09836066, 0.09836066,\n",
       "            0.10655738, 0.1147541 , 0.12295082, 0.13114753, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.21311475, 0.22131148, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.2704918 ,\n",
       "            0.2704918 , 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.29508197, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4180328 ,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.52459013, 0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.6229508 , 0.6229508 , 0.63114756,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6721311 , 0.6803279 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.76229507, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.339  , 0.3386 , 0.3384 , 0.3357 , 0.3342 , 0.3337 ,\n",
       "            0.3335 , 0.333  , 0.3328 , 0.3325 , 0.332  , 0.3315 , 0.3298 ,\n",
       "            0.3296 , 0.3289 , 0.3284 , 0.3281 , 0.328  , 0.327  , 0.326  ,\n",
       "            0.3257 , 0.3252 , 0.3242 , 0.3237 , 0.3235 , 0.3228 , 0.3223 ,\n",
       "            0.3218 , 0.32   , 0.3196 , 0.3193 , 0.3186 , 0.3176 , 0.317  ,\n",
       "            0.3142 , 0.314  , 0.3132 , 0.3118 , 0.31   , 0.3088 , 0.3079 ,\n",
       "            0.3066 , 0.3035 , 0.3032 , 0.303  , 0.2993 , 0.298  , 0.2969 ,\n",
       "            0.2961 , 0.2954 , 0.2927 , 0.2922 , 0.2917 , 0.2913 , 0.291  ,\n",
       "            0.2908 , 0.2903 , 0.289  , 0.2878 , 0.2876 , 0.2861 , 0.286  ,\n",
       "            0.2837 , 0.2812 , 0.2795 , 0.2778 , 0.2764 , 0.2732 , 0.273  ,\n",
       "            0.2725 , 0.2708 , 0.27   , 0.2695 , 0.2693 , 0.268  , 0.2678 ,\n",
       "            0.2676 , 0.2666 , 0.2659 , 0.2644 , 0.263  , 0.2622 , 0.2612 ,\n",
       "            0.258  , 0.2554 , 0.2542 , 0.253  , 0.252  , 0.2512 , 0.2505 ,\n",
       "            0.2487 , 0.2485 , 0.248  , 0.2478 , 0.2471 , 0.2467 , 0.2463 ,\n",
       "            0.2462 , 0.2458 , 0.2452 , 0.243  , 0.2421 , 0.241  , 0.2401 ,\n",
       "            0.2382 , 0.237  , 0.2362 , 0.2356 , 0.2355 , 0.2346 , 0.2316 ,\n",
       "            0.2311 , 0.2306 , 0.2301 , 0.229  , 0.2285 , 0.2278 , 0.2273 ,\n",
       "            0.2269 , 0.2266 , 0.2256 , 0.2239 , 0.2235 , 0.2227 , 0.2225 ,\n",
       "            0.2224 , 0.2217 , 0.2216 , 0.2213 , 0.2211 , 0.2207 , 0.2205 ,\n",
       "            0.2175 , 0.2168 , 0.2156 , 0.2153 , 0.215  , 0.2147 , 0.2144 ,\n",
       "            0.214  , 0.2124 , 0.211  , 0.2101 , 0.2091 , 0.209  , 0.2086 ,\n",
       "            0.2081 , 0.2079 , 0.207  , 0.2065 , 0.2059 , 0.2048 , 0.2042 ,\n",
       "            0.2032 , 0.2026 , 0.2018 , 0.2002 , 0.199  , 0.1989 , 0.1967 ,\n",
       "            0.196  , 0.1959 , 0.195  , 0.1927 , 0.1923 , 0.1913 , 0.191  ,\n",
       "            0.1909 , 0.1901 , 0.1898 , 0.1879 , 0.1848 , 0.1844 , 0.1842 ,\n",
       "            0.1838 , 0.1794 , 0.1791 , 0.1776 , 0.1771 , 0.1763 , 0.1753 ,\n",
       "            0.1735 , 0.1718 , 0.1714 , 0.171  , 0.1705 , 0.1699 , 0.169  ,\n",
       "            0.1688 , 0.1678 , 0.1671 , 0.167  , 0.1665 , 0.1658 , 0.1656 ,\n",
       "            0.1599 , 0.1597 , 0.1589 , 0.1559 , 0.1552 , 0.1547 , 0.1542 ,\n",
       "            0.1526 , 0.1525 , 0.1503 , 0.1488 , 0.1471 , 0.1466 , 0.1455 ,\n",
       "            0.1453 , 0.1448 , 0.1444 , 0.1436 , 0.1406 , 0.1381 , 0.1359 ,\n",
       "            0.1345 , 0.1344 , 0.1316 , 0.1279 , 0.1255 , 0.12115, 0.1144 ,\n",
       "            0.10596, 0.10126], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.1171875, 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2734375, 0.2890625, 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.3515625, 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.3671875, 0.375    , 0.3828125, 0.3828125,\n",
       "            0.390625 , 0.390625 , 0.390625 , 0.390625 , 0.3984375, 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.421875 , 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4296875, 0.4375   , 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.4921875, 0.4921875,\n",
       "            0.4921875, 0.4921875, 0.4921875, 0.5      , 0.5      , 0.5078125,\n",
       "            0.5078125, 0.515625 , 0.515625 , 0.515625 , 0.515625 , 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.53125  , 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5625   , 0.5625   ,\n",
       "            0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.59375  , 0.59375  , 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.6015625, 0.6015625, 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.625    , 0.625    , 0.6328125, 0.6484375, 0.6484375,\n",
       "            0.65625  , 0.65625  , 0.6640625, 0.671875 , 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6796875, 0.6796875, 0.6796875, 0.6796875, 0.6953125,\n",
       "            0.703125 , 0.703125 , 0.703125 , 0.703125 , 0.703125 , 0.703125 ,\n",
       "            0.7109375, 0.7109375, 0.71875  , 0.71875  , 0.7265625, 0.7265625,\n",
       "            0.734375 , 0.75     , 0.7578125, 0.765625 , 0.765625 , 0.765625 ,\n",
       "            0.765625 , 0.7734375, 0.7890625, 0.7890625, 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.796875 , 0.8046875, 0.8125   , 0.8125   , 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.875    , 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.9453125, 0.9453125, 0.953125 , 0.953125 ,\n",
       "            0.953125 , 0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.9765625, 0.9765625, 0.9765625, 0.984375 , 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.00819672,\n",
       "            0.00819672, 0.00819672, 0.00819672, 0.00819672, 0.02459016,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.04098361, 0.04918033,\n",
       "            0.04918033, 0.04918033, 0.05737705, 0.05737705, 0.06557377,\n",
       "            0.07377049, 0.08196721, 0.08196721, 0.09016393, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.13934426, 0.14754099, 0.1557377 , 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.20491803,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.24590164, 0.24590164, 0.25409836, 0.25409836,\n",
       "            0.25409836, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.3114754 , 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.39344263, 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.47540984, 0.47540984, 0.48360655, 0.4918033 , 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.52459013, 0.5409836 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6967213 , 0.6967213 , 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3591, 0.3582, 0.3574, 0.352 , 0.3516, 0.3513, 0.3508,\n",
       "            0.3506, 0.3503, 0.3477, 0.3472, 0.347 , 0.3464, 0.346 , 0.3457,\n",
       "            0.3442, 0.344 , 0.3438, 0.3425, 0.3413, 0.341 , 0.3406, 0.3394,\n",
       "            0.3389, 0.3386, 0.3374, 0.3372, 0.337 , 0.3367, 0.3354, 0.335 ,\n",
       "            0.3345, 0.334 , 0.333 , 0.3328, 0.332 , 0.33  , 0.3293, 0.329 ,\n",
       "            0.3289, 0.3286, 0.3284, 0.3276, 0.3274, 0.327 , 0.3267, 0.3264,\n",
       "            0.3262, 0.3257, 0.325 , 0.3247, 0.3245, 0.3225, 0.322 , 0.321 ,\n",
       "            0.3193, 0.3174, 0.3167, 0.3162, 0.3137, 0.3132, 0.313 , 0.312 ,\n",
       "            0.3118, 0.3113, 0.31  , 0.3093, 0.3088, 0.306 , 0.3044, 0.304 ,\n",
       "            0.3005, 0.3   , 0.2998, 0.298 , 0.2979, 0.2976, 0.2974, 0.2966,\n",
       "            0.2957, 0.2944, 0.293 , 0.2915, 0.2905, 0.2903, 0.289 , 0.288 ,\n",
       "            0.287 , 0.2869, 0.2854, 0.2852, 0.285 , 0.2847, 0.283 , 0.2817,\n",
       "            0.2815, 0.2812, 0.279 , 0.2788, 0.2786, 0.2778, 0.2776, 0.277 ,\n",
       "            0.2751, 0.2747, 0.2737, 0.273 , 0.2725, 0.2722, 0.2712, 0.271 ,\n",
       "            0.2703, 0.2688, 0.268 , 0.2678, 0.2676, 0.2666, 0.266 , 0.2656,\n",
       "            0.2651, 0.2637, 0.2634, 0.263 , 0.2617, 0.2612, 0.2605, 0.2603,\n",
       "            0.2578, 0.2563, 0.2559, 0.2556, 0.255 , 0.2546, 0.2544, 0.2542,\n",
       "            0.254 , 0.2537, 0.2532, 0.2527, 0.252 , 0.2502, 0.2496, 0.2494,\n",
       "            0.2489, 0.2452, 0.2445, 0.244 , 0.2437, 0.2434, 0.2413, 0.2411,\n",
       "            0.2406, 0.2379, 0.237 , 0.2366, 0.2363, 0.2347, 0.2328, 0.2299,\n",
       "            0.2289, 0.228 , 0.2274, 0.226 , 0.2227, 0.2225, 0.2222, 0.2216,\n",
       "            0.2211, 0.2203, 0.2186, 0.218 , 0.2162, 0.2156, 0.2147, 0.2135,\n",
       "            0.2123, 0.2091, 0.208 , 0.2079, 0.2076, 0.2068, 0.2064, 0.2047,\n",
       "            0.2043, 0.2028, 0.2004, 0.1998, 0.1965, 0.1948, 0.1941, 0.1927,\n",
       "            0.1919, 0.1893, 0.1886, 0.188 , 0.187 , 0.1857, 0.1848, 0.1844,\n",
       "            0.1835, 0.1824, 0.1816, 0.1783, 0.178 , 0.1735, 0.1731, 0.1725,\n",
       "            0.1698, 0.1686, 0.167 , 0.1624, 0.1584, 0.1583, 0.1543, 0.1477,\n",
       "            0.1339, 0.1315], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.0078125, 0.015625 , 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.1953125,\n",
       "            0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.2734375,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.2890625, 0.3046875, 0.3203125,\n",
       "            0.328125 , 0.34375  , 0.34375  , 0.3515625, 0.3515625, 0.3671875,\n",
       "            0.3828125, 0.390625 , 0.390625 , 0.390625 , 0.390625 , 0.390625 ,\n",
       "            0.390625 , 0.390625 , 0.3984375, 0.3984375, 0.3984375, 0.3984375,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.4765625, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5078125, 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5546875, 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.609375 , 0.609375 , 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.6484375, 0.65625  , 0.65625  , 0.6640625, 0.6640625,\n",
       "            0.671875 , 0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.7421875, 0.75     , 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.8046875, 0.8046875, 0.8046875, 0.8046875,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.8359375, 0.8515625,\n",
       "            0.859375 , 0.859375 , 0.875    , 0.875    , 0.8828125, 0.8828125,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9296875, 0.9375   , 0.9375   , 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.953125 , 0.953125 , 0.953125 , 0.9609375,\n",
       "            0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.984375 , 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00819672, 0.00819672, 0.00819672, 0.01639344,\n",
       "            0.03278688, 0.04098361, 0.04098361, 0.04918033, 0.05737705,\n",
       "            0.05737705, 0.06557377, 0.07377049, 0.07377049, 0.07377049,\n",
       "            0.09016393, 0.09016393, 0.09836066, 0.09836066, 0.10655738,\n",
       "            0.1147541 , 0.12295082, 0.12295082, 0.13114753, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.16393442,\n",
       "            0.16393442, 0.16393442, 0.17213115, 0.18032786, 0.18032786,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.21311475, 0.21311475,\n",
       "            0.21311475, 0.21311475, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.23770492, 0.23770492, 0.24590164, 0.24590164, 0.26229507,\n",
       "            0.26229507, 0.2704918 , 0.2704918 , 0.27868852, 0.27868852,\n",
       "            0.27868852, 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36065573, 0.36065573, 0.36065573,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.39344263, 0.40163934,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.59836066, 0.59836066, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.6393443 , 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.647541  , 0.6557377 , 0.6557377 ,\n",
       "            0.6639344 , 0.6639344 , 0.6803279 , 0.6803279 , 0.6885246 ,\n",
       "            0.6885246 , 0.6967213 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.76229507, 0.7704918 , 0.77868855,\n",
       "            0.795082  , 0.795082  , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.381 , 0.3801, 0.3782, 0.3777, 0.377 , 0.376 , 0.3752,\n",
       "            0.3745, 0.3738, 0.372 , 0.3718, 0.3716, 0.371 , 0.3708, 0.3706,\n",
       "            0.3704, 0.37  , 0.3684, 0.368 , 0.3677, 0.3672, 0.3665, 0.366 ,\n",
       "            0.3655, 0.3647, 0.3645, 0.364 , 0.3623, 0.362 , 0.3613, 0.361 ,\n",
       "            0.3608, 0.3606, 0.3604, 0.3599, 0.359 , 0.358 , 0.3572, 0.3567,\n",
       "            0.3564, 0.3552, 0.3545, 0.3538, 0.3535, 0.3528, 0.3523, 0.3516,\n",
       "            0.3506, 0.3496, 0.349 , 0.3486, 0.3474, 0.3472, 0.3467, 0.3464,\n",
       "            0.3455, 0.3452, 0.3438, 0.343 , 0.3428, 0.342 , 0.3416, 0.341 ,\n",
       "            0.3403, 0.3386, 0.3381, 0.3372, 0.3367, 0.3364, 0.3362, 0.3357,\n",
       "            0.3352, 0.3347, 0.3337, 0.3318, 0.3315, 0.3306, 0.3303, 0.33  ,\n",
       "            0.3289, 0.328 , 0.327 , 0.3264, 0.325 , 0.3245, 0.3237, 0.3218,\n",
       "            0.3215, 0.321 , 0.32  , 0.3193, 0.3188, 0.3167, 0.3154, 0.3137,\n",
       "            0.3135, 0.3132, 0.3123, 0.312 , 0.3118, 0.311 , 0.31  , 0.3093,\n",
       "            0.308 , 0.3079, 0.3076, 0.3064, 0.3062, 0.3052, 0.305 , 0.3044,\n",
       "            0.304 , 0.3027, 0.3022, 0.302 , 0.3013, 0.3005, 0.3   , 0.2998,\n",
       "            0.2993, 0.299 , 0.2986, 0.2961, 0.2957, 0.2954, 0.295 , 0.2944,\n",
       "            0.293 , 0.2925, 0.2922, 0.292 , 0.2893, 0.287 , 0.2866, 0.2852,\n",
       "            0.2847, 0.2842, 0.2832, 0.2827, 0.2825, 0.2778, 0.2769, 0.2764,\n",
       "            0.2732, 0.2712, 0.2708, 0.2705, 0.2693, 0.2688, 0.2686, 0.2676,\n",
       "            0.2673, 0.267 , 0.266 , 0.263 , 0.261 , 0.2605, 0.2595, 0.259 ,\n",
       "            0.258 , 0.2573, 0.257 , 0.2551, 0.2542, 0.253 , 0.2505, 0.2494,\n",
       "            0.2474, 0.2466, 0.2458, 0.2451, 0.2449, 0.2441, 0.2422, 0.2413,\n",
       "            0.2407, 0.2399, 0.2374, 0.2372, 0.234 , 0.2338, 0.2334, 0.2332,\n",
       "            0.228 , 0.2264, 0.2239, 0.223 , 0.2222, 0.2207, 0.218 , 0.2166,\n",
       "            0.214 , 0.2108, 0.2103, 0.2091, 0.2032, 0.2031, 0.1996, 0.1989,\n",
       "            0.1936, 0.1731, 0.172 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.046875 , 0.0546875, 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.09375  , 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.125    , 0.125    , 0.125    , 0.125    ,\n",
       "            0.1328125, 0.1328125, 0.1484375, 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1796875,\n",
       "            0.1796875, 0.1796875, 0.1953125, 0.203125 , 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.2578125, 0.2734375,\n",
       "            0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.4375   , 0.4453125, 0.453125 , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5      , 0.5      ,\n",
       "            0.5078125, 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.5390625, 0.546875 , 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.625    , 0.6328125, 0.640625 , 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6953125,\n",
       "            0.703125 , 0.703125 , 0.703125 , 0.7109375, 0.71875  , 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.734375 , 0.7421875, 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.7734375, 0.78125  , 0.78125  , 0.7890625, 0.7890625,\n",
       "            0.796875 , 0.8125   , 0.8125   , 0.8203125, 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.8359375, 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.859375 , 0.859375 , 0.8671875, 0.875    , 0.875    , 0.8828125,\n",
       "            0.8828125, 0.8828125, 0.890625 , 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.9609375, 0.96875  , 0.96875  , 0.96875  ,\n",
       "            0.96875  , 0.96875  , 0.96875  , 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.984375 , 0.984375 , 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.26229507, 0.27868852, 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.30327868, 0.3114754 , 0.3114754 ,\n",
       "            0.3114754 , 0.3114754 , 0.31967214, 0.33606556, 0.33606556,\n",
       "            0.33606556, 0.33606556, 0.33606556, 0.33606556, 0.352459  ,\n",
       "            0.36885247, 0.37704918, 0.39344263, 0.40163934, 0.40163934,\n",
       "            0.4180328 , 0.43442622, 0.45081967, 0.45081967, 0.45081967,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.59016395, 0.59016395, 0.59016395, 0.59016395, 0.59836066,\n",
       "            0.59836066, 0.59836066, 0.60655737, 0.60655737, 0.60655737,\n",
       "            0.60655737, 0.6147541 , 0.6147541 , 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6639344 ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.72131145, 0.72131145,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.428 , 0.4268, 0.4253, 0.4248, 0.4233, 0.4226, 0.422 ,\n",
       "            0.4219, 0.4216, 0.4204, 0.4194, 0.4192, 0.4185, 0.4175, 0.4172,\n",
       "            0.417 , 0.4163, 0.4158, 0.4155, 0.4153, 0.415 , 0.414 , 0.412 ,\n",
       "            0.4119, 0.4116, 0.4106, 0.4102, 0.4097, 0.4087, 0.4067, 0.4062,\n",
       "            0.4055, 0.405 , 0.4045, 0.404 , 0.4038, 0.4036, 0.4026, 0.4019,\n",
       "            0.4011, 0.4   , 0.3994, 0.399 , 0.3987, 0.3984, 0.3982, 0.398 ,\n",
       "            0.3972, 0.397 , 0.3955, 0.3953, 0.3928, 0.3926, 0.392 , 0.3916,\n",
       "            0.391 , 0.3901, 0.39  , 0.389 , 0.3875, 0.3872, 0.3867, 0.3865,\n",
       "            0.3843, 0.3828, 0.3818, 0.3813, 0.381 , 0.3806, 0.3794, 0.3784,\n",
       "            0.3782, 0.3772, 0.3752, 0.375 , 0.373 , 0.3726, 0.372 , 0.3713,\n",
       "            0.3704, 0.3696, 0.3694, 0.3687, 0.3684, 0.367 , 0.3667, 0.3665,\n",
       "            0.366 , 0.3655, 0.3652, 0.3638, 0.3635, 0.3633, 0.3628, 0.3623,\n",
       "            0.361 , 0.3608, 0.3604, 0.36  , 0.3599, 0.3596, 0.3594, 0.3591,\n",
       "            0.3584, 0.3582, 0.358 , 0.3574, 0.3567, 0.3564, 0.3562, 0.3555,\n",
       "            0.3547, 0.3545, 0.3542, 0.3538, 0.3528, 0.3525, 0.3523, 0.3513,\n",
       "            0.3508, 0.3494, 0.3486, 0.3481, 0.3472, 0.3457, 0.3445, 0.344 ,\n",
       "            0.3428, 0.3416, 0.3413, 0.3398, 0.3396, 0.3381, 0.3362, 0.336 ,\n",
       "            0.334 , 0.3335, 0.3328, 0.3323, 0.3315, 0.3313, 0.33  , 0.3298,\n",
       "            0.329 , 0.328 , 0.3276, 0.3274, 0.3271, 0.3267, 0.3264, 0.3254,\n",
       "            0.325 , 0.3247, 0.32  , 0.3198, 0.318 , 0.3176, 0.3154, 0.3152,\n",
       "            0.3132, 0.313 , 0.3103, 0.31  , 0.309 , 0.3086, 0.3083, 0.308 ,\n",
       "            0.3074, 0.307 , 0.3066, 0.3062, 0.3054, 0.3042, 0.3025, 0.3015,\n",
       "            0.3013, 0.2998, 0.298 , 0.2979, 0.2976, 0.2974, 0.295 , 0.2944,\n",
       "            0.2932, 0.292 , 0.2913, 0.288 , 0.2864, 0.2837, 0.2798, 0.278 ,\n",
       "            0.2776, 0.2747, 0.2695, 0.2683, 0.268 , 0.2656, 0.2622, 0.2605,\n",
       "            0.2595, 0.2583, 0.256 , 0.2527, 0.252 , 0.2517, 0.2482, 0.2264,\n",
       "            0.2198], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.03125  , 0.03125  , 0.03125  , 0.0390625, 0.046875 , 0.0546875,\n",
       "            0.0625   , 0.078125 , 0.0859375, 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.1015625, 0.1171875, 0.1328125, 0.140625 , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.25     , 0.2578125, 0.265625 ,\n",
       "            0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3125   , 0.3125   , 0.3125   , 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.3359375, 0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.375    ,\n",
       "            0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.5859375, 0.6015625,\n",
       "            0.6171875, 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.703125 , 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.7578125, 0.7578125,\n",
       "            0.7578125, 0.765625 , 0.765625 , 0.765625 , 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.828125 , 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.921875 , 0.9296875, 0.9375   , 0.9375   , 0.9453125,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.9609375, 0.9609375, 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.09016393, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.1557377 , 0.16393442, 0.18032786, 0.18852459,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.30327868, 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.352459  , 0.36065573, 0.37704918, 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4262295 , 0.43442622, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.46721312, 0.47540984, 0.47540984, 0.4918033 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.58196723, 0.58196723, 0.59016395,\n",
       "            0.60655737, 0.60655737, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6721311 , 0.6721311 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 , 0.6885246 ,\n",
       "            0.6885246 , 0.6967213 , 0.6967213 , 0.6967213 , 0.6967213 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.7295082 , 0.7295082 , 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4978, 0.4941, 0.4895, 0.4883, 0.4878, 0.4856, 0.4854,\n",
       "            0.4849, 0.4812, 0.4802, 0.4795, 0.4783, 0.4773, 0.4766, 0.475 ,\n",
       "            0.4749, 0.4739, 0.4734, 0.4731, 0.4722, 0.4717, 0.4714, 0.471 ,\n",
       "            0.4695, 0.4685, 0.4683, 0.468 , 0.4675, 0.466 , 0.4653, 0.4648,\n",
       "            0.464 , 0.4622, 0.462 , 0.4575, 0.4573, 0.4563, 0.455 , 0.4548,\n",
       "            0.4543, 0.4521, 0.4514, 0.4504, 0.45  , 0.4482, 0.4421, 0.4382,\n",
       "            0.436 , 0.4358, 0.4336, 0.4329, 0.4316, 0.4297, 0.429 , 0.4287,\n",
       "            0.4282, 0.428 , 0.4275, 0.4272, 0.427 , 0.4268, 0.426 , 0.4248,\n",
       "            0.4243, 0.423 , 0.4216, 0.4214, 0.421 , 0.4197, 0.419 , 0.4182,\n",
       "            0.418 , 0.4177, 0.4175, 0.4165, 0.414 , 0.4136, 0.4133, 0.4128,\n",
       "            0.4126, 0.4124, 0.412 , 0.4119, 0.4111, 0.4106, 0.4104, 0.4097,\n",
       "            0.409 , 0.4087, 0.4084, 0.4077, 0.4067, 0.4062, 0.405 , 0.4048,\n",
       "            0.404 , 0.4036, 0.402 , 0.4   , 0.3984, 0.3975, 0.3972, 0.397 ,\n",
       "            0.3953, 0.3943, 0.3936, 0.392 , 0.3918, 0.391 , 0.3909, 0.3906,\n",
       "            0.3901, 0.3892, 0.3887, 0.388 , 0.3877, 0.3875, 0.3867, 0.3862,\n",
       "            0.3853, 0.385 , 0.3843, 0.3838, 0.3835, 0.382 , 0.3818, 0.381 ,\n",
       "            0.3804, 0.3801, 0.3796, 0.3794, 0.3774, 0.3772, 0.3745, 0.374 ,\n",
       "            0.3738, 0.3718, 0.371 , 0.3704, 0.3699, 0.3696, 0.3684, 0.3682,\n",
       "            0.3674, 0.3667, 0.3662, 0.366 , 0.365 , 0.364 , 0.363 , 0.3623,\n",
       "            0.361 , 0.3608, 0.3591, 0.3574, 0.3564, 0.3562, 0.354 , 0.353 ,\n",
       "            0.3523, 0.3506, 0.35  , 0.3496, 0.3494, 0.349 , 0.3481, 0.3472,\n",
       "            0.3464, 0.3435, 0.343 , 0.3428, 0.342 , 0.3418, 0.3367, 0.336 ,\n",
       "            0.3323, 0.3313, 0.3303, 0.3296, 0.3274, 0.3267, 0.3245, 0.3235,\n",
       "            0.3228, 0.321 , 0.3184, 0.3179, 0.3176, 0.3162, 0.316 , 0.3137,\n",
       "            0.31  , 0.3064, 0.3052, 0.3032, 0.302 , 0.2979, 0.2932, 0.2927,\n",
       "            0.2869, 0.2754, 0.2734], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.43442622, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.03125  , 0.0390625, 0.046875 , 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.140625 , 0.1484375,\n",
       "            0.1796875, 0.1953125, 0.1953125, 0.1953125, 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.28125  , 0.2890625, 0.296875 , 0.3125   ,\n",
       "            0.328125 , 0.328125 , 0.34375  , 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.3984375, 0.40625  , 0.4140625, 0.4140625,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.453125 , 0.453125 , 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.4765625, 0.484375 , 0.484375 , 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.5234375, 0.53125  , 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.578125 ,\n",
       "            0.59375  , 0.59375  , 0.59375  , 0.6015625, 0.6171875, 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.640625 , 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.7734375, 0.7734375, 0.78125  , 0.796875 , 0.8046875,\n",
       "            0.8046875, 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.84375  ,\n",
       "            0.8515625, 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.8984375, 0.8984375, 0.90625  , 0.90625  ,\n",
       "            0.9140625, 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.12295082,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.23770492,\n",
       "            0.24590164, 0.26229507, 0.2704918 , 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.31967214, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.43442622, 0.45081967,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5163934 ,\n",
       "            0.5163934 , 0.5163934 , 0.5163934 , 0.52459013, 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.57377046, 0.57377046, 0.58196723, 0.59016395, 0.59016395,\n",
       "            0.59836066, 0.60655737, 0.60655737, 0.60655737, 0.6147541 ,\n",
       "            0.6229508 , 0.63114756, 0.63114756, 0.63114756, 0.6393443 ,\n",
       "            0.6393443 , 0.647541  , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.71311474, 0.7295082 , 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8442623 ,\n",
       "            0.852459  , 0.852459  , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.571 , 0.5674, 0.561 , 0.5586, 0.558 , 0.557 , 0.554 ,\n",
       "            0.5483, 0.5444, 0.5415, 0.541 , 0.5396, 0.539 , 0.538 , 0.534 ,\n",
       "            0.5317, 0.5303, 0.53  , 0.5293, 0.5283, 0.528 , 0.527 , 0.5254,\n",
       "            0.525 , 0.524 , 0.5234, 0.521 , 0.5195, 0.519 , 0.5186, 0.518 ,\n",
       "            0.5166, 0.516 , 0.514 , 0.5127, 0.511 , 0.5093, 0.508 , 0.5073,\n",
       "            0.5063, 0.5054, 0.505 , 0.5015, 0.4978, 0.4946, 0.494 , 0.4927,\n",
       "            0.486 , 0.4856, 0.4854, 0.4824, 0.481 , 0.4795, 0.4788, 0.4775,\n",
       "            0.476 , 0.4753, 0.4734, 0.473 , 0.472 , 0.4717, 0.4712, 0.4702,\n",
       "            0.4697, 0.4688, 0.4685, 0.4666, 0.4646, 0.464 , 0.4636, 0.4631,\n",
       "            0.463 , 0.4614, 0.461 , 0.4604, 0.4602, 0.4597, 0.459 , 0.4587,\n",
       "            0.4578, 0.4575, 0.457 , 0.4563, 0.456 , 0.4556, 0.4546, 0.4534,\n",
       "            0.453 , 0.4526, 0.4521, 0.4514, 0.4512, 0.4495, 0.4492, 0.449 ,\n",
       "            0.4485, 0.4478, 0.4465, 0.4463, 0.4436, 0.4434, 0.4426, 0.4414,\n",
       "            0.4412, 0.4397, 0.4395, 0.439 , 0.4385, 0.4377, 0.4373, 0.4365,\n",
       "            0.436 , 0.4355, 0.434 , 0.4304, 0.43  , 0.4297, 0.4294, 0.428 ,\n",
       "            0.4275, 0.4253, 0.4238, 0.422 , 0.4211, 0.4204, 0.4187, 0.4165,\n",
       "            0.4158, 0.4133, 0.412 , 0.4114, 0.4097, 0.4092, 0.4077, 0.4065,\n",
       "            0.406 , 0.405 , 0.4043, 0.404 , 0.4033, 0.403 , 0.402 , 0.4016,\n",
       "            0.4014, 0.4011, 0.4001, 0.3994, 0.3982, 0.3977, 0.3972, 0.3967,\n",
       "            0.3965, 0.396 , 0.3958, 0.395 , 0.3943, 0.393 , 0.392 , 0.391 ,\n",
       "            0.39  , 0.3865, 0.3843, 0.3838, 0.3835, 0.3828, 0.3826, 0.3823,\n",
       "            0.3818, 0.38  , 0.3782, 0.3777, 0.3772, 0.3767, 0.3765, 0.376 ,\n",
       "            0.3745, 0.3735, 0.3726, 0.3694, 0.3682, 0.3647, 0.3586, 0.3582,\n",
       "            0.3572, 0.3557, 0.3547, 0.3542, 0.354 , 0.3528, 0.3477, 0.3452,\n",
       "            0.3438, 0.342 , 0.3352, 0.3306, 0.3286, 0.3267, 0.326 , 0.3196,\n",
       "            0.317 , 0.3052, 0.2922, 0.2825], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.1875, dtype=float32),\n",
       "    'tpr': array(0.6393443, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1796875, 0.1796875, 0.1875   , 0.1953125, 0.21875  ,\n",
       "            0.21875  , 0.21875  , 0.21875  , 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.2421875, 0.2578125, 0.2578125, 0.265625 , 0.265625 , 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.3046875, 0.3125   , 0.3125   , 0.3125   ,\n",
       "            0.3125   , 0.3125   , 0.3125   , 0.3203125, 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.375    , 0.375    , 0.3828125, 0.390625 , 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.453125 ,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.4765625, 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.515625 , 0.515625 , 0.53125  , 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.6328125, 0.640625 , 0.6484375, 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.8203125, 0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5081967 , 0.5081967 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.59836066, 0.6147541 ,\n",
       "            0.6229508 , 0.6393443 , 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.704918  ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.76229507, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8114754 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.86885244, 0.8770492 ,\n",
       "            0.8770492 , 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.93442625, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.636 , 0.63  , 0.6265, 0.626 , 0.619 , 0.6177, 0.6167,\n",
       "            0.6025, 0.599 , 0.5986, 0.5947, 0.594 , 0.592 , 0.589 , 0.586 ,\n",
       "            0.5845, 0.584 , 0.5835, 0.583 , 0.5815, 0.58  , 0.5786, 0.5767,\n",
       "            0.576 , 0.5757, 0.575 , 0.574 , 0.5737, 0.573 , 0.5723, 0.5713,\n",
       "            0.5703, 0.57  , 0.5693, 0.567 , 0.5654, 0.563 , 0.56  , 0.5596,\n",
       "            0.559 , 0.558 , 0.556 , 0.5557, 0.5547, 0.554 , 0.548 , 0.5474,\n",
       "            0.546 , 0.5454, 0.5386, 0.5366, 0.5356, 0.5347, 0.5337, 0.53  ,\n",
       "            0.5293, 0.5264, 0.525 , 0.5244, 0.5225, 0.5195, 0.519 , 0.5176,\n",
       "            0.517 , 0.5166, 0.516 , 0.5156, 0.515 , 0.5146, 0.514 , 0.513 ,\n",
       "            0.511 , 0.51  , 0.509 , 0.507 , 0.5063, 0.506 , 0.505 , 0.504 ,\n",
       "            0.5034, 0.501 , 0.4998, 0.4993, 0.4983, 0.498 , 0.4966, 0.4958,\n",
       "            0.4956, 0.4946, 0.4944, 0.494 , 0.4934, 0.4927, 0.492 , 0.4917,\n",
       "            0.491 , 0.49  , 0.4895, 0.489 , 0.4885, 0.488 , 0.4878, 0.4873,\n",
       "            0.486 , 0.4858, 0.4844, 0.484 , 0.4836, 0.483 , 0.4827, 0.4817,\n",
       "            0.4807, 0.479 , 0.477 , 0.4724, 0.4722, 0.4707, 0.47  , 0.4697,\n",
       "            0.468 , 0.4675, 0.4656, 0.465 , 0.4631, 0.462 , 0.4614, 0.4595,\n",
       "            0.4592, 0.4583, 0.4578, 0.4526, 0.4524, 0.452 , 0.4514, 0.4465,\n",
       "            0.446 , 0.4456, 0.4436, 0.4434, 0.443 , 0.4414, 0.439 , 0.4387,\n",
       "            0.4382, 0.438 , 0.436 , 0.4355, 0.4353, 0.4343, 0.434 , 0.4324,\n",
       "            0.432 , 0.4312, 0.4275, 0.4272, 0.4268, 0.425 , 0.4246, 0.423 ,\n",
       "            0.422 , 0.4216, 0.421 , 0.4207, 0.42  , 0.4197, 0.4192, 0.4143,\n",
       "            0.4138, 0.4133, 0.4111, 0.4104, 0.4084, 0.4075, 0.4072, 0.407 ,\n",
       "            0.405 , 0.4045, 0.4016, 0.3967, 0.3955, 0.3945, 0.394 , 0.3928,\n",
       "            0.3896, 0.389 , 0.387 , 0.3857, 0.3855, 0.384 , 0.382 , 0.381 ,\n",
       "            0.3796, 0.3767, 0.3765, 0.3628, 0.3613, 0.3606, 0.358 , 0.3425,\n",
       "            0.3376, 0.3352, 0.3281, 0.3242, 0.3176, 0.3052, 0.2915, 0.2913,\n",
       "            0.2883], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3828125, dtype=float32),\n",
       "    'tpr': array(0.8114754, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.046875 , 0.046875 , 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.1015625, 0.109375 , 0.1171875,\n",
       "            0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375, 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.171875 , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.234375 , 0.2421875, 0.25     , 0.25     , 0.2578125,\n",
       "            0.265625 , 0.265625 , 0.265625 , 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.2890625, 0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.328125 ,\n",
       "            0.34375  , 0.3515625, 0.3515625, 0.3515625, 0.359375 , 0.359375 ,\n",
       "            0.3671875, 0.3671875, 0.375    , 0.3828125, 0.390625 , 0.390625 ,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.40625  , 0.40625  , 0.4140625,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.4765625, 0.4921875, 0.5      , 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.59375  , 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.71875  , 0.7265625, 0.7421875, 0.7421875, 0.75     , 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.31967214, 0.32786885, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.47540984, 0.48360655,\n",
       "            0.48360655, 0.5       , 0.5081967 , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5327869 , 0.5409836 ,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.58196723, 0.59836066,\n",
       "            0.60655737, 0.60655737, 0.6147541 , 0.6229508 , 0.6229508 ,\n",
       "            0.63114756, 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.6967213 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.74590164, 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.75409836, 0.75409836, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8114754 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.852459  , 0.852459  ,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.97540987, 0.97540987, 0.97540987,\n",
       "            0.97540987, 0.97540987, 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6904, 0.6875, 0.682 , 0.6763, 0.674 , 0.6685, 0.667 ,\n",
       "            0.65  , 0.6494, 0.649 , 0.6426, 0.639 , 0.635 , 0.633 , 0.632 ,\n",
       "            0.6304, 0.629 , 0.627 , 0.6255, 0.625 , 0.624 , 0.623 , 0.6226,\n",
       "            0.6216, 0.6196, 0.6187, 0.618 , 0.6177, 0.6157, 0.614 , 0.6123,\n",
       "            0.6113, 0.61  , 0.608 , 0.6045, 0.6016, 0.601 , 0.6   , 0.5986,\n",
       "            0.5967, 0.596 , 0.593 , 0.591 , 0.5903, 0.5835, 0.5815, 0.579 ,\n",
       "            0.574 , 0.5723, 0.572 , 0.5693, 0.5684, 0.568 , 0.5674, 0.565 ,\n",
       "            0.5645, 0.564 , 0.5625, 0.562 , 0.561 , 0.5605, 0.56  , 0.5576,\n",
       "            0.557 , 0.5566, 0.556 , 0.5557, 0.555 , 0.5537, 0.5522, 0.551 ,\n",
       "            0.5503, 0.55  , 0.5493, 0.548 , 0.5474, 0.5464, 0.546 , 0.5444,\n",
       "            0.544 , 0.543 , 0.5425, 0.542 , 0.539 , 0.5386, 0.537 , 0.5366,\n",
       "            0.535 , 0.534 , 0.5337, 0.533 , 0.5327, 0.532 , 0.5312, 0.5303,\n",
       "            0.5293, 0.529 , 0.5283, 0.528 , 0.5264, 0.525 , 0.5244, 0.5225,\n",
       "            0.522 , 0.5205, 0.519 , 0.516 , 0.515 , 0.5146, 0.512 , 0.5117,\n",
       "            0.509 , 0.508 , 0.507 , 0.5063, 0.505 , 0.502 , 0.5   , 0.4983,\n",
       "            0.4978, 0.4966, 0.4932, 0.4924, 0.4915, 0.4912, 0.491 , 0.4902,\n",
       "            0.49  , 0.4895, 0.4885, 0.4866, 0.4856, 0.4849, 0.4846, 0.4824,\n",
       "            0.4822, 0.481 , 0.4802, 0.4778, 0.4775, 0.4768, 0.4758, 0.4746,\n",
       "            0.4744, 0.4731, 0.473 , 0.4727, 0.4717, 0.471 , 0.4697, 0.468 ,\n",
       "            0.4653, 0.4648, 0.4622, 0.4597, 0.4592, 0.4573, 0.457 , 0.4565,\n",
       "            0.456 , 0.4524, 0.4521, 0.452 , 0.449 , 0.447 , 0.4448, 0.4395,\n",
       "            0.4358, 0.4353, 0.4343, 0.434 , 0.4321, 0.432 , 0.4304, 0.426 ,\n",
       "            0.424 , 0.4236, 0.4233, 0.4226, 0.4167, 0.416 , 0.4158, 0.415 ,\n",
       "            0.4148, 0.411 , 0.4053, 0.4036, 0.4019, 0.3967, 0.392 , 0.3901,\n",
       "            0.389 , 0.3887, 0.3877, 0.3833, 0.383 , 0.3718, 0.3677, 0.3662,\n",
       "            0.3657, 0.352 , 0.3416, 0.3394, 0.3303, 0.3289, 0.318 , 0.305 ,\n",
       "            0.2944, 0.2908, 0.2903], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.53125, dtype=float32),\n",
       "    'tpr': array(0.9508197, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0625   , 0.0703125, 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.109375 , 0.125    , 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.2421875, 0.2421875, 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.25     , 0.2578125, 0.2734375, 0.28125  , 0.28125  , 0.2890625,\n",
       "            0.296875 , 0.3046875, 0.3046875, 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.34375  , 0.34375  , 0.3515625, 0.3515625, 0.3515625, 0.3515625,\n",
       "            0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.3671875, 0.3828125,\n",
       "            0.3828125, 0.390625 , 0.390625 , 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.4609375, 0.46875  , 0.46875  , 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.515625 , 0.5234375, 0.53125  , 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.65625  ,\n",
       "            0.65625  , 0.6640625, 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01639344, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.10655738, 0.1147541 , 0.12295082, 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.27868852, 0.28688523, 0.30327868, 0.3114754 , 0.32786885,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40163934, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45081967, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.48360655, 0.4918033 , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5327869 , 0.5409836 , 0.5409836 , 0.5491803 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.55737704, 0.56557375, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.6147541 , 0.6147541 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6721311 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.7295082 , 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.94262296, 0.94262296, 0.94262296, 0.94262296,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7397, 0.7334, 0.7236, 0.7217, 0.715 , 0.714 , 0.6978,\n",
       "            0.697 , 0.6924, 0.6875, 0.6816, 0.677 , 0.673 , 0.6724, 0.672 ,\n",
       "            0.67  , 0.6685, 0.668 , 0.6675, 0.666 , 0.665 , 0.6636, 0.663 ,\n",
       "            0.662 , 0.6616, 0.66  , 0.659 , 0.6587, 0.657 , 0.6543, 0.65  ,\n",
       "            0.648 , 0.644 , 0.64  , 0.6377, 0.6367, 0.636 , 0.6323, 0.6274,\n",
       "            0.627 , 0.626 , 0.6255, 0.6226, 0.6206, 0.6196, 0.619 , 0.6143,\n",
       "            0.612 , 0.6104, 0.6094, 0.6064, 0.606 , 0.6055, 0.605 , 0.603 ,\n",
       "            0.602 , 0.6016, 0.6006, 0.5996, 0.598 , 0.597 , 0.5967, 0.595 ,\n",
       "            0.5947, 0.594 , 0.5938, 0.592 , 0.5903, 0.59  , 0.5884, 0.5874,\n",
       "            0.5864, 0.5854, 0.585 , 0.584 , 0.5835, 0.582 , 0.5815, 0.581 ,\n",
       "            0.5796, 0.579 , 0.578 , 0.5767, 0.575 , 0.573 , 0.5728, 0.5713,\n",
       "            0.5703, 0.569 , 0.5684, 0.568 , 0.5674, 0.567 , 0.5664, 0.564 ,\n",
       "            0.5635, 0.5625, 0.562 , 0.5605, 0.56  , 0.5596, 0.559 , 0.5586,\n",
       "            0.5576, 0.5566, 0.5547, 0.5513, 0.548 , 0.5474, 0.547 , 0.546 ,\n",
       "            0.545 , 0.5435, 0.543 , 0.5405, 0.5396, 0.539 , 0.5356, 0.535 ,\n",
       "            0.5337, 0.5317, 0.5312, 0.5293, 0.5283, 0.527 , 0.5234, 0.5225,\n",
       "            0.522 , 0.5215, 0.519 , 0.5156, 0.5137, 0.513 , 0.5127, 0.511 ,\n",
       "            0.5107, 0.5103, 0.51  , 0.5083, 0.5034, 0.502 , 0.5015, 0.4983,\n",
       "            0.4973, 0.497 , 0.4946, 0.4944, 0.494 , 0.4937, 0.4905, 0.4883,\n",
       "            0.4866, 0.4858, 0.4846, 0.4802, 0.477 , 0.4746, 0.4734, 0.471 ,\n",
       "            0.4705, 0.4683, 0.4673, 0.4624, 0.4595, 0.4521, 0.4502, 0.4495,\n",
       "            0.4487, 0.4482, 0.447 , 0.4446, 0.4436, 0.4375, 0.4348, 0.434 ,\n",
       "            0.4333, 0.4268, 0.4255, 0.4253, 0.4207, 0.4155, 0.4128, 0.4111,\n",
       "            0.4048, 0.3992, 0.397 , 0.3967, 0.395 , 0.3901, 0.39  , 0.386 ,\n",
       "            0.373 , 0.372 , 0.3716, 0.3713, 0.363 , 0.3481, 0.342 , 0.3335,\n",
       "            0.333 , 0.319 , 0.3052, 0.3005, 0.2905, 0.29  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6171875, dtype=float32),\n",
       "    'tpr': array(0.9672131, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.1015625,\n",
       "            0.109375 , 0.1171875, 0.125    , 0.125    , 0.1328125, 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.15625  , 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.21875  , 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.296875 , 0.296875 , 0.296875 , 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.3515625, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.3671875, 0.3671875, 0.3671875, 0.3671875, 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.4140625,\n",
       "            0.4140625, 0.421875 , 0.421875 , 0.421875 , 0.4296875, 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.6328125, 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   ,\n",
       "            0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.14754099, 0.1557377 , 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.22950819, 0.23770492, 0.24590164, 0.25409836, 0.2704918 ,\n",
       "            0.27868852, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.37704918, 0.37704918, 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.40983605, 0.43442622, 0.44262296,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.48360655, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.59836066, 0.60655737,\n",
       "            0.6229508 , 0.6229508 , 0.63114756, 0.63114756, 0.6393443 ,\n",
       "            0.647541  , 0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.71311474, 0.7295082 , 0.73770493, 0.73770493, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.78688526, 0.795082  , 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.78  , 0.7783, 0.7734, 0.763 , 0.758 , 0.7524, 0.751 ,\n",
       "            0.736 , 0.734 , 0.727 , 0.723 , 0.7188, 0.7163, 0.7134, 0.7104,\n",
       "            0.7075, 0.704 , 0.703 , 0.7026, 0.7017, 0.701 , 0.6997, 0.699 ,\n",
       "            0.6953, 0.6943, 0.694 , 0.6934, 0.692 , 0.6895, 0.687 , 0.683 ,\n",
       "            0.681 , 0.679 , 0.675 , 0.674 , 0.673 , 0.672 , 0.6685, 0.6665,\n",
       "            0.6636, 0.662 , 0.6616, 0.6577, 0.6553, 0.655 , 0.652 , 0.65  ,\n",
       "            0.649 , 0.6416, 0.6406, 0.64  , 0.639 , 0.6387, 0.637 , 0.636 ,\n",
       "            0.635 , 0.6343, 0.634 , 0.6333, 0.633 , 0.632 , 0.6313, 0.6304,\n",
       "            0.63  , 0.6294, 0.629 , 0.6284, 0.628 , 0.6265, 0.6255, 0.624 ,\n",
       "            0.6235, 0.623 , 0.6226, 0.622 , 0.6216, 0.621 , 0.6206, 0.62  ,\n",
       "            0.6177, 0.6167, 0.615 , 0.6147, 0.6133, 0.6113, 0.6104, 0.61  ,\n",
       "            0.6094, 0.609 , 0.6084, 0.603 , 0.6025, 0.6016, 0.6   , 0.5996,\n",
       "            0.599 , 0.598 , 0.5977, 0.597 , 0.5967, 0.595 , 0.5938, 0.5933,\n",
       "            0.591 , 0.5903, 0.59  , 0.5884, 0.5864, 0.5854, 0.5845, 0.5835,\n",
       "            0.5815, 0.581 , 0.5806, 0.5796, 0.579 , 0.577 , 0.5767, 0.5757,\n",
       "            0.5747, 0.574 , 0.5737, 0.5723, 0.57  , 0.5693, 0.569 , 0.5684,\n",
       "            0.567 , 0.566 , 0.5645, 0.5625, 0.56  , 0.5596, 0.557 , 0.5566,\n",
       "            0.5537, 0.5522, 0.5513, 0.55  , 0.5493, 0.549 , 0.5483, 0.545 ,\n",
       "            0.544 , 0.542 , 0.5415, 0.541 , 0.5396, 0.539 , 0.5366, 0.5347,\n",
       "            0.5337, 0.5312, 0.528 , 0.527 , 0.5234, 0.523 , 0.5176, 0.516 ,\n",
       "            0.515 , 0.513 , 0.511 , 0.5103, 0.5083, 0.508 , 0.5063, 0.5034,\n",
       "            0.4995, 0.4968, 0.4937, 0.4893, 0.487 , 0.4849, 0.4824, 0.4822,\n",
       "            0.4736, 0.4653, 0.4626, 0.4624, 0.4622, 0.4595, 0.4587, 0.4563,\n",
       "            0.455 , 0.4534, 0.4497, 0.4487, 0.4434, 0.4426, 0.4348, 0.4343,\n",
       "            0.4329, 0.4287, 0.4238, 0.4202, 0.4185, 0.411 , 0.4045, 0.4033,\n",
       "            0.4019, 0.4006, 0.4001, 0.3984, 0.3958, 0.3955, 0.3772, 0.377 ,\n",
       "            0.3757, 0.3755, 0.3708, 0.3535, 0.3433, 0.3372, 0.3345, 0.3193,\n",
       "            0.306 , 0.305 , 0.2898, 0.289 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6328125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0546875,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.078125 , 0.078125 , 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.140625 , 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.1640625, 0.1640625, 0.1640625,\n",
       "            0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.1953125, 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.203125 , 0.203125 , 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.234375 , 0.2421875,\n",
       "            0.2421875, 0.2421875, 0.25     , 0.25     , 0.2734375, 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.328125 , 0.328125 , 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.3984375,\n",
       "            0.3984375, 0.40625  , 0.4140625, 0.421875 , 0.421875 , 0.421875 ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.578125 , 0.578125 , 0.5859375, 0.59375  , 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125, 0.640625 ,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.921875 , 0.9296875, 0.9375   , 0.9453125,\n",
       "            0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875,\n",
       "            1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.23770492, 0.24590164,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.36885247, 0.37704918, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.43442622, 0.44262296, 0.45901638, 0.45901638,\n",
       "            0.46721312, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5409836 , 0.5491803 , 0.55737704, 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.55737704, 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59836066,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.6393443 , 0.6393443 ,\n",
       "            0.647541  , 0.647541  , 0.6557377 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.72131145, 0.72131145, 0.7295082 , 0.74590164,\n",
       "            0.74590164, 0.75409836, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.7704918 , 0.77868855, 0.78688526, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.9672131 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8164, 0.8135, 0.8096, 0.7993, 0.791 , 0.787 , 0.785 ,\n",
       "            0.7715, 0.769 , 0.76  , 0.7573, 0.7544, 0.7485, 0.748 , 0.7466,\n",
       "            0.741 , 0.7393, 0.7383, 0.736 , 0.7354, 0.7344, 0.734 , 0.7334,\n",
       "            0.733 , 0.7324, 0.7295, 0.727 , 0.725 , 0.7246, 0.7236, 0.7207,\n",
       "            0.719 , 0.718 , 0.7114, 0.7095, 0.707 , 0.705 , 0.7046, 0.704 ,\n",
       "            0.699 , 0.6987, 0.6978, 0.6963, 0.696 , 0.695 , 0.692 , 0.688 ,\n",
       "            0.6875, 0.684 , 0.6836, 0.683 , 0.6826, 0.682 , 0.678 , 0.6763,\n",
       "            0.673 , 0.6714, 0.669 , 0.6685, 0.668 , 0.6675, 0.667 , 0.6665,\n",
       "            0.666 , 0.6655, 0.664 , 0.6636, 0.663 , 0.662 , 0.661 , 0.66  ,\n",
       "            0.6597, 0.658 , 0.6577, 0.6567, 0.656 , 0.6553, 0.655 , 0.6543,\n",
       "            0.654 , 0.652 , 0.6514, 0.651 , 0.6504, 0.6494, 0.649 , 0.6484,\n",
       "            0.6475, 0.647 , 0.646 , 0.6455, 0.644 , 0.6426, 0.6406, 0.6387,\n",
       "            0.637 , 0.636 , 0.6353, 0.6333, 0.633 , 0.6323, 0.631 , 0.63  ,\n",
       "            0.628 , 0.6274, 0.626 , 0.6255, 0.625 , 0.624 , 0.6216, 0.6187,\n",
       "            0.618 , 0.6167, 0.616 , 0.6147, 0.6143, 0.6123, 0.612 , 0.6113,\n",
       "            0.6084, 0.608 , 0.6074, 0.607 , 0.606 , 0.6045, 0.604 , 0.603 ,\n",
       "            0.602 , 0.601 , 0.6006, 0.598 , 0.594 , 0.5933, 0.593 , 0.591 ,\n",
       "            0.589 , 0.5884, 0.587 , 0.586 , 0.5845, 0.5806, 0.5796, 0.576 ,\n",
       "            0.5757, 0.574 , 0.5737, 0.573 , 0.5723, 0.572 , 0.5703, 0.57  ,\n",
       "            0.5684, 0.568 , 0.5635, 0.559 , 0.5576, 0.555 , 0.554 , 0.549 ,\n",
       "            0.547 , 0.5454, 0.545 , 0.5415, 0.539 , 0.532 , 0.5312, 0.53  ,\n",
       "            0.5293, 0.5283, 0.5273, 0.527 , 0.5244, 0.522 , 0.521 , 0.5195,\n",
       "            0.518 , 0.5166, 0.507 , 0.497 , 0.4944, 0.489 , 0.4856, 0.4763,\n",
       "            0.4756, 0.4731, 0.4712, 0.4702, 0.4673, 0.4663, 0.466 , 0.4636,\n",
       "            0.4607, 0.453 , 0.452 , 0.4438, 0.4436, 0.4412, 0.4373, 0.433 ,\n",
       "            0.4282, 0.426 , 0.4177, 0.4124, 0.4106, 0.4072, 0.407 , 0.4062,\n",
       "            0.402 , 0.4016, 0.3823, 0.382 , 0.3806, 0.3804, 0.3599, 0.3457,\n",
       "            0.3418, 0.3372, 0.3206, 0.3127, 0.3054, 0.2898, 0.289 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6640625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625, 0.046875 ,\n",
       "            0.0546875, 0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.1015625,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.140625 , 0.1484375, 0.15625  , 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.1953125, 0.203125 , 0.203125 ,\n",
       "            0.203125 , 0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.2421875, 0.25     , 0.25     , 0.25     , 0.2578125,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.2890625,\n",
       "            0.2890625, 0.3046875, 0.3203125, 0.3203125, 0.3203125, 0.3359375,\n",
       "            0.3359375, 0.34375  , 0.34375  , 0.34375  , 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.3671875, 0.375    , 0.3828125, 0.3828125, 0.3828125,\n",
       "            0.390625 , 0.390625 , 0.390625 , 0.40625  , 0.40625  , 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.4609375, 0.4609375, 0.4609375, 0.46875  , 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.5      , 0.515625 , 0.515625 ,\n",
       "            0.5234375, 0.5390625, 0.5390625, 0.5390625, 0.546875 , 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.5859375, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.22950819, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.28688523, 0.29508197, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.36885247, 0.37704918,\n",
       "            0.3852459 , 0.39344263, 0.40163934, 0.40983605, 0.4262295 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.48360655, 0.4918033 , 0.5       , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.5327869 , 0.5409836 ,\n",
       "            0.5491803 , 0.5491803 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.63114756, 0.6393443 , 0.647541  , 0.647541  ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.75409836, 0.76229507, 0.76229507,\n",
       "            0.7704918 , 0.77868855, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.91803277, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.92622954, 0.92622954, 0.93442625,\n",
       "            0.94262296, 0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.844 , 0.84  , 0.8374, 0.827 , 0.8174, 0.814 , 0.8125,\n",
       "            0.7993, 0.797 , 0.786 , 0.784 , 0.782 , 0.776 , 0.7754, 0.775 ,\n",
       "            0.7686, 0.7676, 0.7666, 0.7627, 0.762 , 0.7617, 0.7603, 0.76  ,\n",
       "            0.7593, 0.758 , 0.757 , 0.7534, 0.751 , 0.75  , 0.7485, 0.746 ,\n",
       "            0.745 , 0.737 , 0.734 , 0.7314, 0.731 , 0.729 , 0.727 , 0.7246,\n",
       "            0.722 , 0.721 , 0.72  , 0.718 , 0.7173, 0.7163, 0.71  , 0.708 ,\n",
       "            0.7075, 0.707 , 0.705 , 0.7026, 0.7   , 0.698 , 0.697 , 0.696 ,\n",
       "            0.695 , 0.694 , 0.6934, 0.692 , 0.6914, 0.691 , 0.69  , 0.689 ,\n",
       "            0.6875, 0.686 , 0.684 , 0.6836, 0.683 , 0.682 , 0.681 , 0.6807,\n",
       "            0.68  , 0.6797, 0.679 , 0.677 , 0.6753, 0.675 , 0.6743, 0.6733,\n",
       "            0.6724, 0.6704, 0.67  , 0.6694, 0.6665, 0.666 , 0.6655, 0.662 ,\n",
       "            0.6606, 0.659 , 0.6587, 0.6577, 0.657 , 0.654 , 0.6533, 0.653 ,\n",
       "            0.651 , 0.65  , 0.6494, 0.6484, 0.648 , 0.6475, 0.647 , 0.644 ,\n",
       "            0.643 , 0.6426, 0.642 , 0.6416, 0.6406, 0.6377, 0.636 , 0.635 ,\n",
       "            0.634 , 0.6333, 0.6313, 0.631 , 0.6294, 0.6284, 0.628 , 0.627 ,\n",
       "            0.625 , 0.6245, 0.624 , 0.623 , 0.6216, 0.6187, 0.615 , 0.6143,\n",
       "            0.6133, 0.613 , 0.6094, 0.6055, 0.604 , 0.603 , 0.602 , 0.6016,\n",
       "            0.601 , 0.6006, 0.5996, 0.598 , 0.5977, 0.5957, 0.5947, 0.593 ,\n",
       "            0.588 , 0.579 , 0.578 , 0.574 , 0.5728, 0.5703, 0.565 , 0.5605,\n",
       "            0.555 , 0.5547, 0.5522, 0.548 , 0.5474, 0.5454, 0.5444, 0.544 ,\n",
       "            0.5366, 0.5356, 0.534 , 0.533 , 0.5283, 0.5234, 0.509 , 0.5073,\n",
       "            0.505 , 0.5044, 0.4956, 0.4883, 0.4868, 0.4824, 0.482 , 0.4807,\n",
       "            0.4797, 0.4758, 0.4746, 0.4724, 0.471 , 0.4607, 0.4592, 0.452 ,\n",
       "            0.451 , 0.448 , 0.4446, 0.4412, 0.435 , 0.4326, 0.424 , 0.4233,\n",
       "            0.417 , 0.4158, 0.4124, 0.4116, 0.411 , 0.4072, 0.407 , 0.388 ,\n",
       "            0.387 , 0.3862, 0.385 , 0.3848, 0.3655, 0.3474, 0.346 , 0.339 ,\n",
       "            0.321 , 0.3184, 0.3057, 0.2898, 0.2888], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6796875, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.046875 , 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.140625 , 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.15625  , 0.15625  , 0.15625  , 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.171875 , 0.171875 , 0.171875 ,\n",
       "            0.1796875, 0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.203125 ,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.28125  ,\n",
       "            0.296875 , 0.3046875, 0.3203125, 0.3203125, 0.3203125, 0.328125 ,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.359375 , 0.359375 , 0.359375 ,\n",
       "            0.359375 , 0.359375 , 0.375    , 0.3828125, 0.390625 , 0.390625 ,\n",
       "            0.3984375, 0.3984375, 0.3984375, 0.40625  , 0.4140625, 0.4140625,\n",
       "            0.4140625, 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.5234375, 0.5234375, 0.53125  , 0.5390625, 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.6328125,\n",
       "            0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.22950819, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.3442623 , 0.352459  , 0.36065573, 0.36065573,\n",
       "            0.36885247, 0.37704918, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.4180328 , 0.4262295 , 0.43442622, 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.45081967, 0.45081967, 0.45901638, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.5       , 0.5081967 , 0.5081967 , 0.5163934 , 0.5163934 ,\n",
       "            0.5163934 , 0.5409836 , 0.5409836 , 0.5409836 , 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.56557375, 0.57377046,\n",
       "            0.59016395, 0.59836066, 0.60655737, 0.6147541 , 0.6147541 ,\n",
       "            0.6147541 , 0.63114756, 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6639344 , 0.6639344 , 0.6639344 , 0.6639344 , 0.6721311 ,\n",
       "            0.6803279 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.71311474, 0.71311474, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.74590164, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.795082  , 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8360656 , 0.852459  ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8770492 , 0.8770492 ,\n",
       "            0.8770492 , 0.8852459 , 0.8852459 , 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.92622954, 0.92622954, 0.93442625, 0.93442625,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.868 , 0.8633, 0.862 , 0.8516, 0.841 , 0.838 , 0.8364,\n",
       "            0.8247, 0.822 , 0.8105, 0.8086, 0.807 , 0.801 , 0.799 , 0.7935,\n",
       "            0.793 , 0.788 , 0.7876, 0.787 , 0.786 , 0.784 , 0.7837, 0.783 ,\n",
       "            0.7827, 0.7812, 0.778 , 0.7764, 0.776 , 0.774 , 0.772 , 0.771 ,\n",
       "            0.7695, 0.769 , 0.7603, 0.7593, 0.7573, 0.7563, 0.7554, 0.753 ,\n",
       "            0.752 , 0.7515, 0.7456, 0.745 , 0.7446, 0.744 , 0.7427, 0.74  ,\n",
       "            0.736 , 0.731 , 0.7305, 0.7295, 0.7256, 0.725 , 0.7246, 0.724 ,\n",
       "            0.7227, 0.722 , 0.7207, 0.72  , 0.7183, 0.7173, 0.7163, 0.716 ,\n",
       "            0.7144, 0.7134, 0.7124, 0.7114, 0.711 , 0.71  , 0.708 , 0.707 ,\n",
       "            0.706 , 0.705 , 0.7046, 0.7036, 0.7026, 0.702 , 0.7   , 0.6997,\n",
       "            0.699 , 0.6987, 0.698 , 0.6973, 0.697 , 0.695 , 0.6943, 0.6934,\n",
       "            0.693 , 0.692 , 0.69  , 0.6895, 0.689 , 0.683 , 0.6826, 0.6816,\n",
       "            0.681 , 0.6807, 0.6797, 0.6772, 0.6763, 0.676 , 0.675 , 0.6743,\n",
       "            0.674 , 0.673 , 0.6724, 0.6714, 0.6704, 0.67  , 0.6685, 0.6675,\n",
       "            0.6655, 0.664 , 0.6636, 0.6616, 0.6597, 0.658 , 0.6562, 0.656 ,\n",
       "            0.6553, 0.655 , 0.654 , 0.652 , 0.6504, 0.648 , 0.647 , 0.646 ,\n",
       "            0.6455, 0.6426, 0.641 , 0.6396, 0.635 , 0.633 , 0.632 , 0.6313,\n",
       "            0.631 , 0.63  , 0.629 , 0.6284, 0.6265, 0.626 , 0.6245, 0.621 ,\n",
       "            0.6206, 0.62  , 0.619 , 0.6187, 0.6157, 0.6147, 0.599 , 0.5977,\n",
       "            0.595 , 0.591 , 0.59  , 0.5884, 0.5874, 0.581 , 0.5796, 0.5767,\n",
       "            0.5747, 0.5728, 0.5664, 0.566 , 0.5625, 0.56  , 0.5576, 0.557 ,\n",
       "            0.5522, 0.5493, 0.5474, 0.5454, 0.54  , 0.5396, 0.5273, 0.518 ,\n",
       "            0.5156, 0.515 , 0.507 , 0.5015, 0.4993, 0.4988, 0.4912, 0.4907,\n",
       "            0.4863, 0.484 , 0.4827, 0.4824, 0.4697, 0.4675, 0.4612, 0.4595,\n",
       "            0.4558, 0.4531, 0.4507, 0.4434, 0.4404, 0.4377, 0.4307, 0.4248,\n",
       "            0.4224, 0.4192, 0.4172, 0.417 , 0.414 , 0.4138, 0.3962, 0.3933,\n",
       "            0.3918, 0.3909, 0.3904, 0.3728, 0.3518, 0.3506, 0.343 , 0.3257,\n",
       "            0.3235, 0.3074, 0.2915, 0.2903], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7109375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  ,\n",
       "            0.03125  , 0.03125  , 0.0390625, 0.046875 , 0.046875 , 0.0546875,\n",
       "            0.0546875, 0.0546875, 0.0703125, 0.0703125, 0.078125 , 0.078125 ,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.1171875, 0.1171875, 0.1171875, 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.15625  , 0.15625  , 0.15625  , 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.25     , 0.265625 ,\n",
       "            0.2734375, 0.2734375, 0.28125  , 0.2890625, 0.2890625, 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.3359375, 0.3359375, 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.3828125, 0.390625 , 0.3984375, 0.3984375, 0.40625  ,\n",
       "            0.40625  , 0.40625  , 0.4140625, 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5078125, 0.5078125, 0.515625 , 0.515625 , 0.5234375,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.21311475, 0.22131148, 0.22950819, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.26229507, 0.2704918 , 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.30327868, 0.30327868, 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.33606556, 0.3442623 , 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.3852459 ,\n",
       "            0.39344263, 0.39344263, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5081967 , 0.5081967 , 0.5081967 , 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5491803 , 0.5491803 , 0.55737704, 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.60655737,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.6557377 , 0.6639344 , 0.6639344 ,\n",
       "            0.6639344 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.72131145, 0.7295082 , 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.75409836, 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.90163934, 0.90983605, 0.91803277,\n",
       "            0.91803277, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.94262296, 0.9508197 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.889 , 0.884 , 0.883 , 0.8735, 0.862 , 0.8594, 0.858 ,\n",
       "            0.8477, 0.8447, 0.832 , 0.8315, 0.8306, 0.8247, 0.8237, 0.821 ,\n",
       "            0.817 , 0.8164, 0.8154, 0.8115, 0.8105, 0.81  , 0.8086, 0.807 ,\n",
       "            0.806 , 0.8057, 0.805 , 0.8027, 0.801 , 0.8   , 0.7983, 0.796 ,\n",
       "            0.795 , 0.7935, 0.792 , 0.7915, 0.7827, 0.782 , 0.7817, 0.78  ,\n",
       "            0.779 , 0.778 , 0.7773, 0.774 , 0.7705, 0.77  , 0.7676, 0.767 ,\n",
       "            0.764 , 0.762 , 0.7603, 0.756 , 0.7534, 0.7524, 0.752 , 0.7505,\n",
       "            0.75  , 0.7485, 0.7476, 0.747 , 0.7466, 0.745 , 0.744 , 0.7417,\n",
       "            0.7407, 0.7397, 0.7393, 0.7383, 0.736 , 0.735 , 0.7344, 0.7334,\n",
       "            0.732 , 0.7314, 0.7295, 0.729 , 0.7285, 0.728 , 0.727 , 0.7266,\n",
       "            0.7256, 0.7246, 0.724 , 0.723 , 0.7227, 0.7217, 0.721 , 0.7197,\n",
       "            0.719 , 0.7188, 0.718 , 0.7163, 0.715 , 0.713 , 0.7124, 0.712 ,\n",
       "            0.7095, 0.7056, 0.705 , 0.7046, 0.704 , 0.703 , 0.702 , 0.7017,\n",
       "            0.701 , 0.7007, 0.6997, 0.6987, 0.6978, 0.697 , 0.6953, 0.6943,\n",
       "            0.694 , 0.6934, 0.6924, 0.692 , 0.688 , 0.686 , 0.6855, 0.685 ,\n",
       "            0.6846, 0.681 , 0.6807, 0.679 , 0.6787, 0.677 , 0.675 , 0.6743,\n",
       "            0.6724, 0.669 , 0.668 , 0.6665, 0.666 , 0.665 , 0.6597, 0.659 ,\n",
       "            0.658 , 0.6567, 0.653 , 0.652 , 0.651 , 0.6504, 0.65  , 0.649 ,\n",
       "            0.6475, 0.645 , 0.6445, 0.6426, 0.6396, 0.639 , 0.6387, 0.638 ,\n",
       "            0.632 , 0.6226, 0.6206, 0.6113, 0.611 , 0.61  , 0.6074, 0.6055,\n",
       "            0.6045, 0.604 , 0.598 , 0.592 , 0.5894, 0.582 , 0.58  , 0.578 ,\n",
       "            0.5767, 0.5703, 0.5693, 0.569 , 0.5684, 0.561 , 0.559 , 0.557 ,\n",
       "            0.5557, 0.5513, 0.5464, 0.5283, 0.5264, 0.5254, 0.5166, 0.5127,\n",
       "            0.512 , 0.5103, 0.501 , 0.5005, 0.5   , 0.4956, 0.4924, 0.4912,\n",
       "            0.4778, 0.4753, 0.4692, 0.467 , 0.463 , 0.4607, 0.458 , 0.4497,\n",
       "            0.4478, 0.4465, 0.4363, 0.4304, 0.4275, 0.4243, 0.422 , 0.4219,\n",
       "            0.4192, 0.4187, 0.4048, 0.3977, 0.3958, 0.395 , 0.3943, 0.3772,\n",
       "            0.355 , 0.3525, 0.3447, 0.3298, 0.3245, 0.3079, 0.2913, 0.29  ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.75, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.1171875, 0.1171875, 0.1171875,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.1484375, 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.15625  , 0.15625  , 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.21875  , 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.2421875, 0.2578125, 0.265625 , 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.3046875, 0.328125 , 0.3359375, 0.3359375, 0.3359375, 0.3359375,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.3671875, 0.3671875, 0.3828125,\n",
       "            0.3828125, 0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.4140625,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5      , 0.5078125, 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 ,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.21311475, 0.22131148, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.28688523, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36885247, 0.37704918, 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.40983605, 0.4262295 , 0.43442622,\n",
       "            0.43442622, 0.45081967, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.46721312, 0.48360655, 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.5327869 , 0.5409836 , 0.55737704, 0.55737704, 0.56557375,\n",
       "            0.56557375, 0.57377046, 0.58196723, 0.59016395, 0.59016395,\n",
       "            0.6147541 , 0.6229508 , 0.63114756, 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.647541  , 0.647541  , 0.647541  , 0.6557377 ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6967213 , 0.704918  , 0.704918  , 0.71311474, 0.72131145,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.77868855, 0.78688526, 0.78688526, 0.795082  ,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8278689 , 0.8278689 , 0.8360656 , 0.8442623 , 0.852459  ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8770492 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.91803277, 0.91803277, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.97540987, 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.907 , 0.902 , 0.9014, 0.8926, 0.881 , 0.879 , 0.8774,\n",
       "            0.868 , 0.865 , 0.8525, 0.852 , 0.8516, 0.8467, 0.8447, 0.8413,\n",
       "            0.8384, 0.838 , 0.8364, 0.8335, 0.832 , 0.831 , 0.829 , 0.828 ,\n",
       "            0.8276, 0.8257, 0.823 , 0.822 , 0.82  , 0.817 , 0.816 , 0.814 ,\n",
       "            0.8125, 0.8057, 0.8047, 0.8022, 0.802 , 0.801 , 0.8003, 0.7944,\n",
       "            0.794 , 0.788 , 0.7847, 0.783 , 0.7793, 0.775 , 0.7744, 0.774 ,\n",
       "            0.7734, 0.771 , 0.77  , 0.7686, 0.768 , 0.7666, 0.7637, 0.762 ,\n",
       "            0.7617, 0.7603, 0.758 , 0.757 , 0.756 , 0.7554, 0.755 , 0.7544,\n",
       "            0.7534, 0.753 , 0.752 , 0.7515, 0.7505, 0.75  , 0.748 , 0.7476,\n",
       "            0.7466, 0.746 , 0.745 , 0.7446, 0.744 , 0.743 , 0.7417, 0.741 ,\n",
       "            0.7407, 0.7383, 0.7373, 0.7354, 0.735 , 0.7344, 0.7334, 0.7295,\n",
       "            0.7285, 0.728 , 0.7275, 0.727 , 0.7266, 0.726 , 0.7246, 0.723 ,\n",
       "            0.7207, 0.7197, 0.719 , 0.7188, 0.717 , 0.7163, 0.716 , 0.7153,\n",
       "            0.7144, 0.714 , 0.7134, 0.713 , 0.711 , 0.7104, 0.71  , 0.7095,\n",
       "            0.708 , 0.7065, 0.706 , 0.7056, 0.702 , 0.7017, 0.701 , 0.6973,\n",
       "            0.695 , 0.694 , 0.6934, 0.693 , 0.6895, 0.687 , 0.6865, 0.686 ,\n",
       "            0.6855, 0.6836, 0.6807, 0.6777, 0.676 , 0.6753, 0.6743, 0.6724,\n",
       "            0.6704, 0.6694, 0.668 , 0.667 , 0.6665, 0.6655, 0.6606, 0.6597,\n",
       "            0.659 , 0.656 , 0.6484, 0.647 , 0.6416, 0.634 , 0.632 , 0.631 ,\n",
       "            0.6294, 0.6274, 0.623 , 0.621 , 0.6196, 0.6074, 0.604 , 0.599 ,\n",
       "            0.594 , 0.5938, 0.5933, 0.5854, 0.5845, 0.584 , 0.5815, 0.573 ,\n",
       "            0.5723, 0.572 , 0.569 , 0.5654, 0.5635, 0.539 , 0.537 , 0.5356,\n",
       "            0.5273, 0.527 , 0.525 , 0.5215, 0.511 , 0.5103, 0.506 , 0.503 ,\n",
       "            0.5015, 0.501 , 0.4866, 0.484 , 0.478 , 0.475 , 0.4707, 0.4688,\n",
       "            0.4668, 0.46  , 0.4573, 0.4539, 0.4426, 0.4375, 0.4338, 0.4307,\n",
       "            0.4277, 0.4272, 0.4253, 0.4248, 0.4138, 0.403 , 0.4006, 0.4001,\n",
       "            0.3992, 0.3833, 0.3596, 0.3552, 0.348 , 0.336 , 0.3262, 0.309 ,\n",
       "            0.2925, 0.2908], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.75, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.1015625, 0.1015625, 0.109375 ,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.140625 , 0.140625 , 0.1484375, 0.1484375, 0.15625  , 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.21875  , 0.2265625, 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.234375 , 0.234375 , 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2734375, 0.2734375, 0.2734375, 0.2734375, 0.28125  ,\n",
       "            0.296875 , 0.3046875, 0.3125   , 0.3125   , 0.3125   , 0.328125 ,\n",
       "            0.328125 , 0.3359375, 0.34375  , 0.34375  , 0.34375  , 0.359375 ,\n",
       "            0.359375 , 0.359375 , 0.3671875, 0.375    , 0.3828125, 0.390625 ,\n",
       "            0.390625 , 0.3984375, 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.4921875, 0.5      ,\n",
       "            0.5      , 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625,\n",
       "            0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.02459016, 0.03278688, 0.04098361,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.09016393,\n",
       "            0.09836066, 0.10655738, 0.1147541 , 0.12295082, 0.13934426,\n",
       "            0.14754099, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40983605, 0.4262295 ,\n",
       "            0.4262295 , 0.4262295 , 0.43442622, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.48360655, 0.4918033 ,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.59016395, 0.60655737, 0.6147541 , 0.63114756, 0.63114756,\n",
       "            0.6393443 , 0.6393443 , 0.647541  , 0.647541  , 0.647541  ,\n",
       "            0.647541  , 0.6557377 , 0.6721311 , 0.6803279 , 0.6885246 ,\n",
       "            0.6967213 , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.73770493, 0.73770493, 0.74590164, 0.75409836, 0.76229507,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8114754 , 0.8114754 , 0.8114754 ,\n",
       "            0.8114754 , 0.8196721 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.8442623 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.90163934, 0.90163934,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.90983605, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.923 , 0.917 , 0.909 , 0.8975, 0.896 , 0.8945, 0.886 ,\n",
       "            0.8833, 0.8706, 0.87  , 0.8657, 0.8643, 0.86  , 0.858 , 0.8555,\n",
       "            0.853 , 0.852 , 0.85  , 0.848 , 0.8477, 0.847 , 0.8447, 0.844 ,\n",
       "            0.842 , 0.841 , 0.84  , 0.8374, 0.835 , 0.833 , 0.832 , 0.827 ,\n",
       "            0.825 , 0.8223, 0.8213, 0.8203, 0.82  , 0.8164, 0.816 , 0.8135,\n",
       "            0.808 , 0.8076, 0.8047, 0.8037, 0.8027, 0.801 , 0.797 , 0.7964,\n",
       "            0.7954, 0.793 , 0.792 , 0.7905, 0.79  , 0.7896, 0.7886, 0.7856,\n",
       "            0.7847, 0.783 , 0.7827, 0.7817, 0.779 , 0.7783, 0.778 , 0.7773,\n",
       "            0.777 , 0.7764, 0.776 , 0.7744, 0.774 , 0.772 , 0.7715, 0.771 ,\n",
       "            0.77  , 0.7695, 0.769 , 0.7686, 0.766 , 0.7656, 0.7646, 0.7637,\n",
       "            0.763 , 0.762 , 0.76  , 0.758 , 0.757 , 0.7554, 0.7544, 0.7534,\n",
       "            0.753 , 0.7524, 0.75  , 0.7485, 0.747 , 0.7456, 0.7446, 0.743 ,\n",
       "            0.7417, 0.7407, 0.7397, 0.7393, 0.739 , 0.737 , 0.736 , 0.735 ,\n",
       "            0.7344, 0.7334, 0.7324, 0.732 , 0.731 , 0.7305, 0.73  , 0.7295,\n",
       "            0.727 , 0.726 , 0.723 , 0.7227, 0.72  , 0.7173, 0.715 , 0.714 ,\n",
       "            0.7134, 0.713 , 0.7124, 0.711 , 0.7095, 0.707 , 0.706 , 0.705 ,\n",
       "            0.701 , 0.6987, 0.698 , 0.6973, 0.696 , 0.6953, 0.6934, 0.6895,\n",
       "            0.689 , 0.688 , 0.6855, 0.685 , 0.6826, 0.679 , 0.678 , 0.673 ,\n",
       "            0.671 , 0.6646, 0.662 , 0.6597, 0.6543, 0.654 , 0.651 , 0.6484,\n",
       "            0.6426, 0.636 , 0.635 , 0.6226, 0.6187, 0.6167, 0.61  , 0.6094,\n",
       "            0.608 , 0.603 , 0.601 , 0.597 , 0.5933, 0.588 , 0.585 , 0.5845,\n",
       "            0.5835, 0.5796, 0.5747, 0.549 , 0.5474, 0.5454, 0.5425, 0.5376,\n",
       "            0.537 , 0.533 , 0.5205, 0.52  , 0.5186, 0.515 , 0.5137, 0.51  ,\n",
       "            0.4946, 0.4912, 0.486 , 0.4827, 0.4775, 0.4763, 0.4749, 0.4727,\n",
       "            0.4644, 0.4604, 0.4485, 0.4438, 0.4392, 0.436 , 0.4326, 0.4314,\n",
       "            0.4307, 0.4302, 0.421 , 0.408 , 0.4048, 0.4045, 0.4036, 0.3894,\n",
       "            0.3638, 0.3567, 0.3499, 0.3423, 0.327 , 0.3093, 0.2925, 0.2908],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7578125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.078125 , 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.09375  , 0.09375  , 0.1015625, 0.1015625, 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.1328125, 0.140625 , 0.140625 , 0.140625 , 0.140625 ,\n",
       "            0.140625 , 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.234375 , 0.234375 , 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.2578125, 0.2578125, 0.265625 , 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.2890625, 0.2890625, 0.296875 , 0.3046875, 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.3515625, 0.359375 , 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.40625  , 0.4140625, 0.4296875, 0.4375   , 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.4765625, 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5      , 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18852459, 0.19672132, 0.20491803, 0.21311475, 0.22131148,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.29508197, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40983605, 0.40983605,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.44262296, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.48360655, 0.4918033 , 0.5       , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59016395, 0.59016395, 0.59836066, 0.6147541 , 0.6229508 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.73770493, 0.75409836,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.7704918 , 0.77868855,\n",
       "            0.78688526, 0.78688526, 0.78688526, 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8278689 ,\n",
       "            0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 , 0.8442623 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90983605, 0.90983605,\n",
       "            0.90983605, 0.90983605, 0.90983605, 0.91803277, 0.92622954,\n",
       "            0.93442625, 0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.9672131 , 0.9672131 ,\n",
       "            0.97540987, 0.97540987, 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.936 , 0.9307, 0.93  , 0.9233, 0.912 , 0.9106, 0.9097,\n",
       "            0.9023, 0.8994, 0.8877, 0.8867, 0.8833, 0.8813, 0.8765, 0.8755,\n",
       "            0.8726, 0.871 , 0.8696, 0.8677, 0.865 , 0.8647, 0.862 , 0.8613,\n",
       "            0.86  , 0.859 , 0.8574, 0.856 , 0.8525, 0.85  , 0.8496, 0.8467,\n",
       "            0.8438, 0.8423, 0.8413, 0.8394, 0.839 , 0.838 , 0.8364, 0.836 ,\n",
       "            0.8315, 0.826 , 0.824 , 0.822 , 0.8213, 0.821 , 0.818 , 0.817 ,\n",
       "            0.814 , 0.8125, 0.812 , 0.8115, 0.811 , 0.8096, 0.8086, 0.808 ,\n",
       "            0.8076, 0.806 , 0.805 , 0.804 , 0.8027, 0.8022, 0.802 , 0.8013,\n",
       "            0.8   , 0.7993, 0.7983, 0.798 , 0.7974, 0.7964, 0.796 , 0.7954,\n",
       "            0.794 , 0.7925, 0.7915, 0.791 , 0.7905, 0.7896, 0.789 , 0.7886,\n",
       "            0.7876, 0.786 , 0.7856, 0.785 , 0.7847, 0.784 , 0.7837, 0.783 ,\n",
       "            0.7827, 0.7793, 0.778 , 0.7773, 0.777 , 0.775 , 0.7744, 0.7725,\n",
       "            0.7715, 0.7705, 0.769 , 0.768 , 0.7666, 0.7656, 0.7646, 0.7617,\n",
       "            0.761 , 0.7603, 0.7583, 0.7573, 0.757 , 0.7563, 0.756 , 0.755 ,\n",
       "            0.7544, 0.754 , 0.753 , 0.7524, 0.7515, 0.751 , 0.7505, 0.7495,\n",
       "            0.746 , 0.745 , 0.7446, 0.7437, 0.743 , 0.7417, 0.739 , 0.7373,\n",
       "            0.737 , 0.736 , 0.735 , 0.7324, 0.7314, 0.7285, 0.726 , 0.724 ,\n",
       "            0.723 , 0.7207, 0.719 , 0.7188, 0.718 , 0.716 , 0.713 , 0.7104,\n",
       "            0.709 , 0.7065, 0.703 , 0.7026, 0.6973, 0.697 , 0.694 , 0.6895,\n",
       "            0.6846, 0.682 , 0.6807, 0.6777, 0.675 , 0.6724, 0.67  , 0.6587,\n",
       "            0.652 , 0.65  , 0.6377, 0.6333, 0.633 , 0.6265, 0.6245, 0.622 ,\n",
       "            0.6196, 0.6167, 0.6113, 0.6055, 0.6035, 0.597 , 0.596 , 0.592 ,\n",
       "            0.587 , 0.5596, 0.558 , 0.556 , 0.549 , 0.548 , 0.5444, 0.5317,\n",
       "            0.5303, 0.5283, 0.5254, 0.524 , 0.519 , 0.5186, 0.5034, 0.4998,\n",
       "            0.4949, 0.491 , 0.4854, 0.4844, 0.4832, 0.483 , 0.4714, 0.4673,\n",
       "            0.455 , 0.4504, 0.4453, 0.442 , 0.4385, 0.4368, 0.4365, 0.436 ,\n",
       "            0.43  , 0.413 , 0.4097, 0.4094, 0.4082, 0.3945, 0.368 , 0.3594,\n",
       "            0.3525, 0.3467, 0.3284, 0.3103, 0.293 , 0.291 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7734375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375,\n",
       "            0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.1015625, 0.1171875,\n",
       "            0.125    , 0.1328125, 0.1328125, 0.140625 , 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1796875,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.234375 , 0.234375 , 0.2421875,\n",
       "            0.2421875, 0.25     , 0.25     , 0.265625 , 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.2890625, 0.2890625, 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.3203125, 0.328125 , 0.3359375, 0.3359375, 0.3515625,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.3984375, 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.46875  ,\n",
       "            0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.484375 , 0.4921875,\n",
       "            0.5      , 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.6640625, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.23770492, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.27868852, 0.28688523, 0.28688523, 0.29508197, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.32786885, 0.33606556, 0.3442623 ,\n",
       "            0.352459  , 0.36065573, 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40983605, 0.40983605,\n",
       "            0.40983605, 0.40983605, 0.43442622, 0.44262296, 0.44262296,\n",
       "            0.45901638, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.5081967 , 0.5081967 , 0.5163934 , 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.57377046, 0.57377046, 0.59016395, 0.59836066,\n",
       "            0.60655737, 0.6147541 , 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.72131145, 0.72131145, 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.7704918 , 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.77868855, 0.795082  , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.852459  , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.947 , 0.9424, 0.9414, 0.9355, 0.9253, 0.924 , 0.923 ,\n",
       "            0.916 , 0.9136, 0.903 , 0.9014, 0.901 , 0.899 , 0.8965, 0.8916,\n",
       "            0.888 , 0.8867, 0.8857, 0.8833, 0.882 , 0.8813, 0.8804, 0.878 ,\n",
       "            0.877 , 0.876 , 0.8745, 0.874 , 0.8726, 0.868 , 0.866 , 0.8657,\n",
       "            0.8643, 0.861 , 0.86  , 0.859 , 0.8584, 0.8555, 0.855 , 0.854 ,\n",
       "            0.848 , 0.8433, 0.843 , 0.8423, 0.8394, 0.8384, 0.8374, 0.836 ,\n",
       "            0.8315, 0.831 , 0.8306, 0.83  , 0.8286, 0.8276, 0.8267, 0.8247,\n",
       "            0.8237, 0.823 , 0.8223, 0.8213, 0.82  , 0.8193, 0.8184, 0.816 ,\n",
       "            0.8154, 0.8145, 0.814 , 0.813 , 0.8105, 0.81  , 0.8096, 0.8086,\n",
       "            0.808 , 0.8066, 0.804 , 0.8037, 0.803 , 0.8027, 0.8013, 0.8003,\n",
       "            0.799 , 0.798 , 0.796 , 0.7935, 0.7925, 0.7905, 0.79  , 0.7896,\n",
       "            0.789 , 0.7886, 0.785 , 0.7847, 0.783 , 0.781 , 0.7803, 0.78  ,\n",
       "            0.779 , 0.778 , 0.777 , 0.7764, 0.7744, 0.774 , 0.7734, 0.7725,\n",
       "            0.7715, 0.771 , 0.77  , 0.767 , 0.7656, 0.7646, 0.7637, 0.763 ,\n",
       "            0.7627, 0.762 , 0.7603, 0.756 , 0.7544, 0.754 , 0.751 , 0.75  ,\n",
       "            0.746 , 0.7446, 0.742 , 0.741 , 0.7407, 0.7393, 0.739 , 0.7373,\n",
       "            0.737 , 0.736 , 0.7305, 0.7295, 0.729 , 0.7236, 0.723 , 0.72  ,\n",
       "            0.719 , 0.716 , 0.715 , 0.708 , 0.706 , 0.701 , 0.7   , 0.6963,\n",
       "            0.6953, 0.6885, 0.674 , 0.667 , 0.6646, 0.6533, 0.6504, 0.6475,\n",
       "            0.642 , 0.641 , 0.636 , 0.632 , 0.625 , 0.6216, 0.619 , 0.618 ,\n",
       "            0.61  , 0.6094, 0.6035, 0.599 , 0.572 , 0.5703, 0.5693, 0.567 ,\n",
       "            0.562 , 0.559 , 0.5566, 0.542 , 0.541 , 0.5386, 0.5356, 0.5293,\n",
       "            0.528 , 0.5127, 0.5083, 0.5044, 0.4998, 0.4966, 0.4937, 0.493 ,\n",
       "            0.4922, 0.4797, 0.475 , 0.4624, 0.458 , 0.4521, 0.4487, 0.4448,\n",
       "            0.4434, 0.4429, 0.4426, 0.4387, 0.4192, 0.4153, 0.4138, 0.4019,\n",
       "            0.3735, 0.3625, 0.3562, 0.354 , 0.3306, 0.3123, 0.2944, 0.2925],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.0859375, 0.09375  ,\n",
       "            0.09375  , 0.09375  , 0.09375  , 0.109375 , 0.1171875, 0.1328125,\n",
       "            0.140625 , 0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.15625  , 0.15625  , 0.15625  , 0.1640625, 0.1640625, 0.1640625,\n",
       "            0.1796875, 0.1796875, 0.1796875, 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.21875  , 0.2265625, 0.2265625, 0.2265625, 0.2265625,\n",
       "            0.2421875, 0.2421875, 0.2578125, 0.2578125, 0.265625 , 0.2734375,\n",
       "            0.2734375, 0.2734375, 0.2734375, 0.2734375, 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.3203125,\n",
       "            0.3359375, 0.3359375, 0.3359375, 0.34375  , 0.3515625, 0.359375 ,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.375    , 0.390625 ,\n",
       "            0.3984375, 0.40625  , 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.484375 , 0.4921875, 0.5      , 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  ,\n",
       "            0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.18852459, 0.19672132, 0.20491803,\n",
       "            0.21311475, 0.22131148, 0.24590164, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.28688523, 0.29508197, 0.30327868,\n",
       "            0.3114754 , 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36885247, 0.37704918, 0.37704918,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40163934, 0.40983605,\n",
       "            0.4180328 , 0.43442622, 0.44262296, 0.45081967, 0.45081967,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.4918033 ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.63114756,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6721311 , 0.6721311 , 0.6803279 , 0.6885246 , 0.704918  ,\n",
       "            0.71311474, 0.72131145, 0.72131145, 0.7295082 , 0.73770493,\n",
       "            0.74590164, 0.75409836, 0.76229507, 0.76229507, 0.7704918 ,\n",
       "            0.7704918 , 0.77868855, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8114754 , 0.8196721 , 0.8196721 , 0.8196721 ,\n",
       "            0.8278689 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.852459  , 0.8606557 , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9508197 , 0.9508197 ,\n",
       "            0.9508197 , 0.9590164 , 0.9672131 , 0.97540987, 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.956 , 0.952 , 0.951 , 0.9463, 0.9365, 0.9355, 0.934 ,\n",
       "            0.928 , 0.926 , 0.916 , 0.9146, 0.914 , 0.9126, 0.91  , 0.9062,\n",
       "            0.9053, 0.902 , 0.9014, 0.9   , 0.8975, 0.896 , 0.8955, 0.895 ,\n",
       "            0.892 , 0.891 , 0.8906, 0.889 , 0.8877, 0.883 , 0.8813, 0.881 ,\n",
       "            0.8804, 0.8765, 0.875 , 0.874 , 0.872 , 0.8716, 0.871 , 0.8706,\n",
       "            0.869 , 0.8633, 0.859 , 0.8584, 0.8564, 0.855 , 0.854 , 0.8535,\n",
       "            0.8486, 0.8477, 0.846 , 0.8447, 0.844 , 0.8438, 0.8423, 0.841 ,\n",
       "            0.84  , 0.839 , 0.8384, 0.8374, 0.837 , 0.8364, 0.8335, 0.8325,\n",
       "            0.832 , 0.831 , 0.8306, 0.83  , 0.8296, 0.8286, 0.8276, 0.827 ,\n",
       "            0.8267, 0.8257, 0.824 , 0.8237, 0.8228, 0.822 , 0.8213, 0.821 ,\n",
       "            0.8193, 0.819 , 0.8154, 0.815 , 0.8135, 0.811 , 0.81  , 0.8096,\n",
       "            0.8086, 0.807 , 0.8057, 0.803 , 0.8027, 0.801 , 0.8003, 0.8   ,\n",
       "            0.799 , 0.7983, 0.797 , 0.7964, 0.795 , 0.7944, 0.794 , 0.793 ,\n",
       "            0.7915, 0.791 , 0.7905, 0.79  , 0.7896, 0.7886, 0.788 , 0.7866,\n",
       "            0.786 , 0.785 , 0.784 , 0.782 , 0.7817, 0.7812, 0.7803, 0.7783,\n",
       "            0.7754, 0.7725, 0.7715, 0.769 , 0.7676, 0.7627, 0.762 , 0.7593,\n",
       "            0.7583, 0.758 , 0.755 , 0.7524, 0.75  , 0.749 , 0.745 , 0.742 ,\n",
       "            0.74  , 0.7373, 0.737 , 0.736 , 0.7334, 0.7324, 0.731 , 0.722 ,\n",
       "            0.7197, 0.7173, 0.715 , 0.7114, 0.706 , 0.689 , 0.682 , 0.6797,\n",
       "            0.6694, 0.6685, 0.6616, 0.658 , 0.6523, 0.6504, 0.6475, 0.6396,\n",
       "            0.639 , 0.635 , 0.6313, 0.623 , 0.616 , 0.612 , 0.59  , 0.5815,\n",
       "            0.5806, 0.5786, 0.576 , 0.571 , 0.57  , 0.5537, 0.5527, 0.549 ,\n",
       "            0.548 , 0.5474, 0.54  , 0.538 , 0.5225, 0.518 , 0.5146, 0.512 ,\n",
       "            0.5093, 0.503 , 0.489 , 0.4841, 0.471 , 0.467 , 0.46  , 0.4568,\n",
       "            0.452 , 0.4512, 0.4507, 0.4492, 0.4482, 0.4268, 0.422 , 0.4219,\n",
       "            0.4207, 0.4106, 0.3809, 0.3667, 0.3635, 0.3608, 0.334 , 0.315 ,\n",
       "            0.2974, 0.2952], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8203125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.078125 , 0.0859375,\n",
       "            0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.09375  , 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.1171875, 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.15625  ,\n",
       "            0.15625  , 0.1640625, 0.1640625, 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.21875  ,\n",
       "            0.2265625, 0.2265625, 0.2265625, 0.234375 , 0.25     , 0.2578125,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.2734375, 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.2890625, 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.328125 , 0.3359375, 0.3359375, 0.34375  , 0.3515625,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.375    ,\n",
       "            0.3828125, 0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.421875 , 0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.453125 ,\n",
       "            0.4609375, 0.46875  , 0.46875  , 0.46875  , 0.46875  , 0.4765625,\n",
       "            0.484375 , 0.4921875, 0.5      , 0.5      , 0.5078125, 0.515625 ,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.6640625, 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.20491803, 0.22131148, 0.23770492, 0.24590164, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.28688523, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40163934, 0.40163934, 0.40983605, 0.4180328 , 0.4262295 ,\n",
       "            0.43442622, 0.43442622, 0.45081967, 0.45081967, 0.45081967,\n",
       "            0.47540984, 0.48360655, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5081967 , 0.5163934 , 0.52459013, 0.52459013, 0.5327869 ,\n",
       "            0.5327869 , 0.5327869 , 0.5409836 , 0.5491803 , 0.55737704,\n",
       "            0.56557375, 0.56557375, 0.57377046, 0.58196723, 0.59016395,\n",
       "            0.59836066, 0.6229508 , 0.6393443 , 0.6393443 , 0.647541  ,\n",
       "            0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6885246 , 0.6967213 , 0.704918  , 0.71311474,\n",
       "            0.71311474, 0.72131145, 0.7295082 , 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.77868855, 0.77868855,\n",
       "            0.78688526, 0.795082  , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 ,\n",
       "            0.8442623 , 0.8442623 , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9672131 , 0.97540987, 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.964 , 0.9604, 0.9595, 0.955 , 0.9463, 0.9453, 0.9443,\n",
       "            0.939 , 0.9365, 0.9277, 0.9263, 0.926 , 0.925 , 0.9224, 0.919 ,\n",
       "            0.918 , 0.9175, 0.9146, 0.914 , 0.9126, 0.91  , 0.909 , 0.908 ,\n",
       "            0.9077, 0.905 , 0.9043, 0.903 , 0.902 , 0.9014, 0.896 , 0.895 ,\n",
       "            0.894 , 0.891 , 0.8906, 0.89  , 0.888 , 0.887 , 0.8853, 0.8843,\n",
       "            0.8833, 0.8774, 0.8745, 0.8735, 0.873 , 0.872 , 0.8716, 0.8696,\n",
       "            0.869 , 0.8687, 0.8647, 0.8643, 0.8633, 0.863 , 0.8613, 0.861 ,\n",
       "            0.86  , 0.8594, 0.8584, 0.8574, 0.8564, 0.8555, 0.8545, 0.854 ,\n",
       "            0.8535, 0.853 , 0.8525, 0.8496, 0.849 , 0.8486, 0.848 , 0.8477,\n",
       "            0.847 , 0.8457, 0.8447, 0.8438, 0.8433, 0.841 , 0.8403, 0.84  ,\n",
       "            0.8384, 0.838 , 0.8374, 0.836 , 0.8354, 0.835 , 0.833 , 0.8315,\n",
       "            0.83  , 0.8276, 0.8267, 0.8257, 0.824 , 0.823 , 0.8213, 0.8203,\n",
       "            0.82  , 0.8193, 0.8174, 0.8164, 0.816 , 0.815 , 0.814 , 0.8125,\n",
       "            0.812 , 0.8105, 0.81  , 0.8086, 0.808 , 0.807 , 0.8066, 0.806 ,\n",
       "            0.8057, 0.805 , 0.8047, 0.8022, 0.8003, 0.799 , 0.798 , 0.797 ,\n",
       "            0.7954, 0.7935, 0.7896, 0.7886, 0.786 , 0.784 , 0.781 , 0.78  ,\n",
       "            0.779 , 0.778 , 0.7773, 0.777 , 0.776 , 0.7744, 0.774 , 0.7725,\n",
       "            0.7686, 0.768 , 0.767 , 0.761 , 0.76  , 0.757 , 0.7563, 0.7534,\n",
       "            0.752 , 0.7505, 0.7495, 0.742 , 0.7383, 0.738 , 0.7373, 0.7334,\n",
       "            0.7266, 0.723 , 0.7046, 0.6973, 0.695 , 0.6865, 0.6855, 0.676 ,\n",
       "            0.675 , 0.6733, 0.6675, 0.6646, 0.6626, 0.6562, 0.655 , 0.65  ,\n",
       "            0.6455, 0.637 , 0.636 , 0.6294, 0.625 , 0.608 , 0.594 , 0.5933,\n",
       "            0.5913, 0.591 , 0.5845, 0.584 , 0.5664, 0.5654, 0.5615, 0.561 ,\n",
       "            0.56  , 0.5522, 0.55  , 0.534 , 0.5293, 0.529 , 0.5264, 0.5205,\n",
       "            0.515 , 0.514 , 0.5005, 0.495 , 0.4817, 0.4783, 0.4702, 0.467 ,\n",
       "            0.462 , 0.4617, 0.461 , 0.4607, 0.4587, 0.437 , 0.432 , 0.4314,\n",
       "            0.4302, 0.422 , 0.3909, 0.3755, 0.3745, 0.369 , 0.3408, 0.3215,\n",
       "            0.3037, 0.3013], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.828125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 ,\n",
       "            0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.1015625, 0.109375 , 0.1171875, 0.125    ,\n",
       "            0.1328125, 0.140625 , 0.1484375, 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.15625  , 0.15625  , 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1953125, 0.1953125, 0.203125 , 0.2109375, 0.2109375, 0.2109375,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.21875  , 0.21875  , 0.2265625,\n",
       "            0.2265625, 0.2421875, 0.2578125, 0.265625 , 0.2734375, 0.28125  ,\n",
       "            0.28125  , 0.28125  , 0.28125  , 0.28125  , 0.2890625, 0.296875 ,\n",
       "            0.3125   , 0.328125 , 0.328125 , 0.3359375, 0.3359375, 0.34375  ,\n",
       "            0.3515625, 0.359375 , 0.359375 , 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.40625  , 0.421875 , 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.484375 ,\n",
       "            0.4921875, 0.5      , 0.5      , 0.5078125, 0.515625 , 0.5234375,\n",
       "            0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125,\n",
       "            0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 ,\n",
       "            0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375, 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.13934426, 0.14754099, 0.1557377 ,\n",
       "            0.16393442, 0.17213115, 0.18032786, 0.18852459, 0.19672132,\n",
       "            0.21311475, 0.22131148, 0.23770492, 0.25409836, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.28688523,\n",
       "            0.30327868, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.3442623 , 0.352459  , 0.36065573, 0.3852459 , 0.3852459 ,\n",
       "            0.39344263, 0.40163934, 0.40163934, 0.40163934, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.44262296, 0.45081967,\n",
       "            0.45081967, 0.45901638, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.5       , 0.5081967 , 0.5163934 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.5409836 , 0.5409836 , 0.5409836 , 0.5491803 ,\n",
       "            0.55737704, 0.56557375, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.6147541 , 0.6229508 , 0.6393443 ,\n",
       "            0.6393443 , 0.6557377 , 0.6639344 , 0.6721311 , 0.6721311 ,\n",
       "            0.6803279 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.71311474, 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.73770493, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "            0.7704918 , 0.7704918 , 0.78688526, 0.8032787 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8278689 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.91803277,\n",
       "            0.92622954, 0.93442625, 0.93442625, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9707, 0.9673, 0.9663, 0.963 , 0.9546, 0.9536, 0.953 ,\n",
       "            0.948 , 0.9463, 0.938 , 0.9365, 0.936 , 0.9355, 0.933 , 0.93  ,\n",
       "            0.929 , 0.928 , 0.926 , 0.9253, 0.9243, 0.922 , 0.921 , 0.92  ,\n",
       "            0.9194, 0.9165, 0.916 , 0.9146, 0.914 , 0.9087, 0.908 , 0.907 ,\n",
       "            0.9062, 0.906 , 0.9043, 0.9033, 0.9014, 0.901 , 0.8984, 0.897 ,\n",
       "            0.896 , 0.89  , 0.888 , 0.886 , 0.885 , 0.883 , 0.882 , 0.88  ,\n",
       "            0.8794, 0.878 , 0.877 , 0.8755, 0.8745, 0.8735, 0.873 , 0.8726,\n",
       "            0.872 , 0.8716, 0.87  , 0.8696, 0.869 , 0.8677, 0.8667, 0.8657,\n",
       "            0.865 , 0.864 , 0.8633, 0.863 , 0.862 , 0.8613, 0.8604, 0.8594,\n",
       "            0.8584, 0.857 , 0.8555, 0.855 , 0.854 , 0.8535, 0.853 , 0.8525,\n",
       "            0.8516, 0.85  , 0.8496, 0.847 , 0.8457, 0.8447, 0.8433, 0.842 ,\n",
       "            0.8413, 0.8403, 0.839 , 0.8374, 0.837 , 0.8364, 0.836 , 0.8354,\n",
       "            0.8345, 0.8335, 0.832 , 0.83  , 0.8286, 0.828 , 0.8276, 0.8257,\n",
       "            0.8247, 0.824 , 0.8237, 0.823 , 0.8228, 0.822 , 0.821 , 0.8154,\n",
       "            0.815 , 0.814 , 0.813 , 0.8115, 0.811 , 0.806 , 0.804 , 0.8027,\n",
       "            0.8003, 0.799 , 0.796 , 0.7954, 0.795 , 0.7925, 0.7905, 0.7896,\n",
       "            0.789 , 0.7847, 0.784 , 0.777 , 0.776 , 0.7754, 0.772 , 0.7715,\n",
       "            0.7695, 0.7676, 0.767 , 0.766 , 0.762 , 0.7583, 0.754 , 0.7534,\n",
       "            0.7515, 0.741 , 0.7397, 0.719 , 0.7124, 0.7095, 0.704 , 0.701 ,\n",
       "            0.6914, 0.69  , 0.6885, 0.683 , 0.6787, 0.6772, 0.673 , 0.669 ,\n",
       "            0.664 , 0.659 , 0.651 , 0.65  , 0.641 , 0.637 , 0.6255, 0.605 ,\n",
       "            0.6025, 0.5977, 0.5957, 0.577 , 0.5767, 0.5737, 0.572 , 0.5713,\n",
       "            0.563 , 0.5596, 0.545 , 0.5444, 0.5386, 0.537 , 0.5303, 0.5264,\n",
       "            0.524 , 0.5234, 0.51  , 0.5044, 0.49  , 0.4873, 0.478 , 0.475 ,\n",
       "            0.4695, 0.469 , 0.4688, 0.465 , 0.4443, 0.439 , 0.438 , 0.4368,\n",
       "            0.4314, 0.3984, 0.3857, 0.3782, 0.3738, 0.3438, 0.324 , 0.3062,\n",
       "            0.3037], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.828125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  ,\n",
       "            0.03125  , 0.0390625, 0.0390625, 0.0390625, 0.046875 , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0703125, 0.078125 ,\n",
       "            0.078125 , 0.0859375, 0.0859375, 0.09375  , 0.09375  , 0.1015625,\n",
       "            0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.1328125, 0.140625 , 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.2421875, 0.2421875, 0.2421875, 0.25     ,\n",
       "            0.2578125, 0.265625 , 0.2734375, 0.28125  , 0.28125  , 0.2890625,\n",
       "            0.2890625, 0.296875 , 0.296875 , 0.3046875, 0.3046875, 0.3125   ,\n",
       "            0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.359375 , 0.359375 , 0.359375 , 0.3671875,\n",
       "            0.3828125, 0.390625 , 0.4140625, 0.421875 , 0.421875 , 0.4296875,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.453125 ,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.46875  , 0.46875  , 0.46875  ,\n",
       "            0.46875  , 0.4765625, 0.4921875, 0.5      , 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.671875 , 0.6796875, 0.6875   , 0.6953125, 0.703125 ,\n",
       "            0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     ,\n",
       "            0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625, 0.796875 ,\n",
       "            0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375, 0.84375  ,\n",
       "            0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.19672132, 0.21311475, 0.22131148, 0.22950819,\n",
       "            0.24590164, 0.25409836, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.28688523, 0.28688523, 0.29508197, 0.30327868, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.352459  ,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.40163934, 0.40163934, 0.40163934, 0.40983605, 0.4180328 ,\n",
       "            0.4262295 , 0.43442622, 0.43442622, 0.43442622, 0.44262296,\n",
       "            0.44262296, 0.46721312, 0.46721312, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.5163934 , 0.52459013,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5409836 , 0.5491803 , 0.55737704, 0.56557375,\n",
       "            0.57377046, 0.57377046, 0.57377046, 0.59016395, 0.60655737,\n",
       "            0.6229508 , 0.63114756, 0.63114756, 0.6393443 , 0.647541  ,\n",
       "            0.6639344 , 0.6721311 , 0.6721311 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.7295082 , 0.73770493, 0.74590164, 0.74590164, 0.75409836,\n",
       "            0.76229507, 0.76229507, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "            0.77868855, 0.795082  , 0.8032787 , 0.8114754 , 0.8114754 ,\n",
       "            0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.91803277, 0.92622954,\n",
       "            0.92622954, 0.93442625, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9590164 , 0.9590164 , 0.9672131 , 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.975 , 0.972 , 0.971 , 0.9683, 0.9604, 0.96  , 0.959 ,\n",
       "            0.955 , 0.953 , 0.946 , 0.9443, 0.9434, 0.941 , 0.938 , 0.9375,\n",
       "            0.936 , 0.934 , 0.9326, 0.9307, 0.9297, 0.928 , 0.9253, 0.9243,\n",
       "            0.924 , 0.9233, 0.923 , 0.9185, 0.9175, 0.9165, 0.9155, 0.9146,\n",
       "            0.9136, 0.913 , 0.9116, 0.911 , 0.908 , 0.9062, 0.906 , 0.9004,\n",
       "            0.8994, 0.8975, 0.8965, 0.896 , 0.8926, 0.892 , 0.8916, 0.891 ,\n",
       "            0.89  , 0.8896, 0.8877, 0.8867, 0.8857, 0.8853, 0.885 , 0.8843,\n",
       "            0.884 , 0.8823, 0.882 , 0.8813, 0.8804, 0.88  , 0.879 , 0.8784,\n",
       "            0.8774, 0.877 , 0.8765, 0.876 , 0.8755, 0.875 , 0.8745, 0.874 ,\n",
       "            0.8735, 0.873 , 0.8716, 0.8706, 0.87  , 0.8677, 0.867 , 0.866 ,\n",
       "            0.865 , 0.8647, 0.864 , 0.8633, 0.863 , 0.862 , 0.8594, 0.8584,\n",
       "            0.858 , 0.8555, 0.854 , 0.853 , 0.852 , 0.8506, 0.8496, 0.848 ,\n",
       "            0.8477, 0.847 , 0.8467, 0.846 , 0.8457, 0.845 , 0.8447, 0.844 ,\n",
       "            0.8438, 0.8413, 0.84  , 0.839 , 0.838 , 0.8374, 0.837 , 0.8364,\n",
       "            0.836 , 0.8354, 0.835 , 0.8345, 0.8335, 0.829 , 0.8276, 0.827 ,\n",
       "            0.8267, 0.8257, 0.824 , 0.82  , 0.817 , 0.8154, 0.813 , 0.8096,\n",
       "            0.809 , 0.807 , 0.806 , 0.803 , 0.8027, 0.7983, 0.797 , 0.791 ,\n",
       "            0.7905, 0.7886, 0.784 , 0.782 , 0.781 , 0.7803, 0.78  , 0.778 ,\n",
       "            0.7744, 0.7676, 0.766 , 0.7534, 0.753 , 0.7314, 0.7246, 0.7217,\n",
       "            0.718 , 0.714 , 0.7046, 0.701 , 0.6963, 0.6904, 0.6895, 0.6875,\n",
       "            0.6807, 0.6763, 0.6704, 0.6626, 0.661 , 0.6514, 0.6475, 0.639 ,\n",
       "            0.616 , 0.6147, 0.6123, 0.6084, 0.6055, 0.587 , 0.5864, 0.584 ,\n",
       "            0.581 , 0.5806, 0.5723, 0.568 , 0.5576, 0.553 , 0.5474, 0.546 ,\n",
       "            0.5386, 0.5356, 0.532 , 0.5317, 0.5186, 0.512 , 0.498 , 0.4956,\n",
       "            0.4856, 0.4827, 0.478 , 0.477 , 0.4766, 0.4763, 0.472 , 0.4517,\n",
       "            0.446 , 0.4448, 0.4436, 0.44  , 0.4055, 0.3945, 0.3833, 0.3792,\n",
       "            0.3481, 0.3281, 0.31  , 0.3076], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.84375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.015625 ,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625, 0.0390625,\n",
       "            0.046875 , 0.0625   , 0.0625   , 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0703125, 0.078125 , 0.0859375, 0.0859375, 0.09375  , 0.09375  ,\n",
       "            0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.140625 , 0.1484375, 0.1484375, 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.171875 , 0.171875 , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125, 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.2109375, 0.21875  , 0.2265625,\n",
       "            0.234375 , 0.234375 , 0.25     , 0.2578125, 0.2578125, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.2734375, 0.28125  , 0.2890625, 0.2890625,\n",
       "            0.2890625, 0.296875 , 0.296875 , 0.296875 , 0.3046875, 0.3046875,\n",
       "            0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.328125 , 0.3359375,\n",
       "            0.34375  , 0.3515625, 0.3515625, 0.359375 , 0.359375 , 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.40625  , 0.4140625,\n",
       "            0.421875 , 0.4375   , 0.4375   , 0.4375   , 0.4375   , 0.4375   ,\n",
       "            0.4453125, 0.4453125, 0.453125 , 0.453125 , 0.453125 , 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.7109375, 0.71875  , 0.7265625, 0.734375 ,\n",
       "            0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  ,\n",
       "            0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.18852459, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22131148, 0.23770492, 0.24590164, 0.25409836, 0.25409836,\n",
       "            0.26229507, 0.2704918 , 0.27868852, 0.28688523, 0.29508197,\n",
       "            0.30327868, 0.30327868, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.33606556, 0.3442623 , 0.352459  , 0.36065573, 0.36885247,\n",
       "            0.36885247, 0.36885247, 0.3852459 , 0.39344263, 0.39344263,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.45901638, 0.46721312,\n",
       "            0.47540984, 0.4918033 , 0.4918033 , 0.5081967 , 0.5163934 ,\n",
       "            0.52459013, 0.52459013, 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.57377046,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.60655737, 0.6229508 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6803279 , 0.6803279 ,\n",
       "            0.6885246 , 0.6885246 , 0.704918  , 0.71311474, 0.71311474,\n",
       "            0.72131145, 0.7295082 , 0.75409836, 0.75409836, 0.75409836,\n",
       "            0.76229507, 0.7704918 , 0.7704918 , 0.7704918 , 0.78688526,\n",
       "            0.78688526, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8196721 , 0.8278689 , 0.8278689 , 0.8360656 , 0.8360656 ,\n",
       "            0.8360656 , 0.8442623 , 0.852459  , 0.8606557 , 0.8606557 ,\n",
       "            0.8606557 , 0.8606557 , 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.90163934,\n",
       "            0.90983605, 0.91803277, 0.92622954, 0.92622954, 0.94262296,\n",
       "            0.94262296, 0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 ,\n",
       "            0.97540987, 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.979 , 0.9766, 0.9756, 0.9727, 0.966 , 0.9653, 0.9644,\n",
       "            0.961 , 0.9595, 0.9526, 0.951 , 0.95  , 0.948 , 0.9453, 0.945 ,\n",
       "            0.9434, 0.942 , 0.9404, 0.9385, 0.9375, 0.9365, 0.936 , 0.9336,\n",
       "            0.933 , 0.9326, 0.9316, 0.931 , 0.9307, 0.9277, 0.926 , 0.9253,\n",
       "            0.9243, 0.924 , 0.923 , 0.9224, 0.9214, 0.921 , 0.9204, 0.9175,\n",
       "            0.9155, 0.9146, 0.9097, 0.909 , 0.908 , 0.9077, 0.9062, 0.906 ,\n",
       "            0.9023, 0.902 , 0.9014, 0.901 , 0.898 , 0.8975, 0.8965, 0.896 ,\n",
       "            0.8955, 0.895 , 0.894 , 0.8936, 0.893 , 0.891 , 0.8906, 0.89  ,\n",
       "            0.889 , 0.888 , 0.8877, 0.887 , 0.886 , 0.8857, 0.8853, 0.8843,\n",
       "            0.8833, 0.883 , 0.881 , 0.8794, 0.8784, 0.8774, 0.877 , 0.8765,\n",
       "            0.876 , 0.8755, 0.875 , 0.874 , 0.873 , 0.8726, 0.8706, 0.87  ,\n",
       "            0.8696, 0.8667, 0.866 , 0.8657, 0.8647, 0.862 , 0.8613, 0.8604,\n",
       "            0.86  , 0.8594, 0.859 , 0.858 , 0.8574, 0.857 , 0.8564, 0.856 ,\n",
       "            0.854 , 0.8535, 0.8525, 0.852 , 0.8516, 0.8506, 0.8496, 0.849 ,\n",
       "            0.8486, 0.8477, 0.847 , 0.846 , 0.845 , 0.842 , 0.84  , 0.839 ,\n",
       "            0.8384, 0.838 , 0.8374, 0.8364, 0.832 , 0.8296, 0.828 , 0.826 ,\n",
       "            0.825 , 0.823 , 0.8223, 0.8213, 0.8193, 0.8154, 0.815 , 0.8115,\n",
       "            0.811 , 0.809 , 0.805 , 0.8037, 0.8003, 0.7964, 0.7944, 0.794 ,\n",
       "            0.793 , 0.7925, 0.7896, 0.7803, 0.78  , 0.7783, 0.7656, 0.7646,\n",
       "            0.743 , 0.7363, 0.7334, 0.7314, 0.726 , 0.7173, 0.7134, 0.713 ,\n",
       "            0.7095, 0.7017, 0.701 , 0.693 , 0.688 , 0.682 , 0.6743, 0.6724,\n",
       "            0.6616, 0.658 , 0.6523, 0.6274, 0.6245, 0.6226, 0.619 , 0.615 ,\n",
       "            0.596 , 0.5947, 0.591 , 0.59  , 0.5815, 0.5767, 0.5693, 0.562 ,\n",
       "            0.5557, 0.5547, 0.547 , 0.544 , 0.5405, 0.54  , 0.526 , 0.52  ,\n",
       "            0.5054, 0.503 , 0.4924, 0.4895, 0.4866, 0.4836, 0.4832, 0.4827,\n",
       "            0.478 , 0.458 , 0.452 , 0.4507, 0.4495, 0.4468, 0.4111, 0.4019,\n",
       "            0.3872, 0.3833, 0.3513, 0.3306, 0.3123, 0.3096], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8515625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.0078125, 0.0078125, 0.0078125,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.0546875, 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0625   , 0.078125 , 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.1015625, 0.1015625, 0.109375 , 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.125    , 0.125    , 0.1328125, 0.1484375, 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.15625  , 0.1640625, 0.1640625, 0.171875 ,\n",
       "            0.171875 , 0.1796875, 0.1875   , 0.1875   , 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.203125 ,\n",
       "            0.2109375, 0.2109375, 0.21875  , 0.234375 , 0.234375 , 0.234375 ,\n",
       "            0.2421875, 0.25     , 0.2578125, 0.2578125, 0.2734375, 0.2734375,\n",
       "            0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.328125 ,\n",
       "            0.3359375, 0.3359375, 0.3515625, 0.359375 , 0.359375 , 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375,\n",
       "            0.46875  , 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.53125  , 0.5390625, 0.546875 ,\n",
       "            0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    , 0.8828125,\n",
       "            0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875,\n",
       "            0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625,\n",
       "            0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.1557377 , 0.16393442, 0.17213115, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.21311475, 0.22131148, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.25409836, 0.26229507, 0.2704918 ,\n",
       "            0.2704918 , 0.29508197, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36885247,\n",
       "            0.36885247, 0.36885247, 0.37704918, 0.3852459 , 0.39344263,\n",
       "            0.39344263, 0.40163934, 0.40983605, 0.4180328 , 0.43442622,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.45081967, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.4918033 , 0.5       ,\n",
       "            0.5163934 , 0.52459013, 0.5327869 , 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.55737704, 0.57377046, 0.57377046, 0.58196723,\n",
       "            0.59016395, 0.59836066, 0.6229508 , 0.6229508 , 0.6393443 ,\n",
       "            0.647541  , 0.6557377 , 0.6639344 , 0.6721311 , 0.6803279 ,\n",
       "            0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.71311474, 0.73770493,\n",
       "            0.74590164, 0.74590164, 0.75409836, 0.76229507, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.8606557 , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.89344263, 0.89344263, 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90983605, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.94262296, 0.9508197 , 0.9590164 ,\n",
       "            0.9672131 , 0.9672131 , 0.97540987, 0.97540987, 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9824, 0.98  , 0.9795, 0.977 , 0.9707, 0.97  , 0.969 ,\n",
       "            0.9663, 0.965 , 0.9585, 0.957 , 0.956 , 0.9546, 0.9517, 0.95  ,\n",
       "            0.9487, 0.9478, 0.9453, 0.945 , 0.9434, 0.9414, 0.9404, 0.94  ,\n",
       "            0.9395, 0.9385, 0.938 , 0.936 , 0.9336, 0.933 , 0.9326, 0.9316,\n",
       "            0.9307, 0.93  , 0.9287, 0.926 , 0.924 , 0.923 , 0.9185, 0.918 ,\n",
       "            0.917 , 0.916 , 0.9146, 0.914 , 0.912 , 0.9116, 0.911 , 0.9106,\n",
       "            0.91  , 0.907 , 0.9067, 0.9062, 0.906 , 0.9053, 0.904 , 0.9033,\n",
       "            0.903 , 0.9014, 0.901 , 0.9   , 0.8994, 0.899 , 0.8984, 0.897 ,\n",
       "            0.8965, 0.896 , 0.8955, 0.894 , 0.8916, 0.8906, 0.8887, 0.888 ,\n",
       "            0.887 , 0.8867, 0.886 , 0.8843, 0.8833, 0.883 , 0.882 , 0.8813,\n",
       "            0.881 , 0.878 , 0.8774, 0.877 , 0.8765, 0.876 , 0.873 , 0.8726,\n",
       "            0.872 , 0.8716, 0.871 , 0.8706, 0.87  , 0.8687, 0.868 , 0.8667,\n",
       "            0.8657, 0.865 , 0.864 , 0.863 , 0.8623, 0.861 , 0.8594, 0.859 ,\n",
       "            0.8574, 0.8564, 0.8535, 0.8516, 0.8506, 0.8496, 0.849 , 0.848 ,\n",
       "            0.844 , 0.8413, 0.84  , 0.839 , 0.837 , 0.8364, 0.835 , 0.8345,\n",
       "            0.8335, 0.8315, 0.831 , 0.828 , 0.8276, 0.827 , 0.824 , 0.8237,\n",
       "            0.821 , 0.819 , 0.8184, 0.816 , 0.812 , 0.808 , 0.8076, 0.8066,\n",
       "            0.806 , 0.805 , 0.8047, 0.804 , 0.7935, 0.793 , 0.79  , 0.7783,\n",
       "            0.7764, 0.755 , 0.7485, 0.745 , 0.739 , 0.731 , 0.7256, 0.724 ,\n",
       "            0.722 , 0.7153, 0.7134, 0.7046, 0.7   , 0.694 , 0.6865, 0.684 ,\n",
       "            0.672 , 0.669 , 0.6665, 0.6396, 0.6353, 0.633 , 0.631 , 0.626 ,\n",
       "            0.607 , 0.6064, 0.6055, 0.601 , 0.5996, 0.592 , 0.586 , 0.5835,\n",
       "            0.5713, 0.565 , 0.5645, 0.5566, 0.554 , 0.55  , 0.549 , 0.5356,\n",
       "            0.5293, 0.514 , 0.512 , 0.501 , 0.498 , 0.4966, 0.4922, 0.4917,\n",
       "            0.491 , 0.4858, 0.4663, 0.46  , 0.4585, 0.4573, 0.4565, 0.4194,\n",
       "            0.4119, 0.3933, 0.39  , 0.3567, 0.3357, 0.3174, 0.3145],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8828125, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.0390625, 0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0625   ,\n",
       "            0.0625   , 0.0703125, 0.078125 , 0.09375  , 0.1015625, 0.109375 ,\n",
       "            0.109375 , 0.109375 , 0.109375 , 0.125    , 0.125    , 0.1328125,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.203125 , 0.203125 , 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.234375 , 0.25     , 0.2578125, 0.2578125, 0.2734375,\n",
       "            0.28125  , 0.28125  , 0.2890625, 0.2890625, 0.296875 , 0.296875 ,\n",
       "            0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3203125, 0.328125 ,\n",
       "            0.328125 , 0.328125 , 0.328125 , 0.3359375, 0.3359375, 0.34375  ,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.375    , 0.3828125,\n",
       "            0.390625 , 0.3984375, 0.40625  , 0.4140625, 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5625   , 0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625,\n",
       "            0.6015625, 0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 ,\n",
       "            0.6484375, 0.65625  , 0.671875 , 0.6796875, 0.6875   , 0.6953125,\n",
       "            0.703125 , 0.7109375, 0.71875  , 0.7265625, 0.734375 , 0.7421875,\n",
       "            0.75     , 0.7578125, 0.765625 , 0.7734375, 0.78125  , 0.7890625,\n",
       "            0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 , 0.8359375,\n",
       "            0.84375  , 0.8515625, 0.8671875, 0.875    , 0.8828125, 0.890625 ,\n",
       "            0.8984375, 0.90625  , 0.9140625, 0.921875 , 0.9296875, 0.9375   ,\n",
       "            0.9453125, 0.953125 , 0.9609375, 0.96875  , 0.9765625, 0.984375 ,\n",
       "            0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.13114753,\n",
       "            0.13934426, 0.14754099, 0.1557377 , 0.16393442, 0.17213115,\n",
       "            0.18032786, 0.19672132, 0.20491803, 0.21311475, 0.22950819,\n",
       "            0.23770492, 0.24590164, 0.25409836, 0.25409836, 0.26229507,\n",
       "            0.2704918 , 0.27868852, 0.29508197, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36885247, 0.36885247, 0.3852459 , 0.39344263, 0.39344263,\n",
       "            0.40163934, 0.40983605, 0.4180328 , 0.4262295 , 0.44262296,\n",
       "            0.44262296, 0.45081967, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.48360655, 0.5       , 0.5163934 , 0.5327869 , 0.5327869 ,\n",
       "            0.5327869 , 0.5409836 , 0.55737704, 0.56557375, 0.57377046,\n",
       "            0.57377046, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6721311 , 0.6803279 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.704918  , 0.704918  , 0.72131145,\n",
       "            0.7295082 , 0.74590164, 0.74590164, 0.75409836, 0.77868855,\n",
       "            0.77868855, 0.78688526, 0.78688526, 0.795082  , 0.8032787 ,\n",
       "            0.8114754 , 0.8196721 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.8606557 ,\n",
       "            0.8606557 , 0.86885244, 0.86885244, 0.86885244, 0.8770492 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.91803277, 0.93442625,\n",
       "            0.94262296, 0.94262296, 0.9508197 , 0.9590164 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9854, 0.9834, 0.9824, 0.9805, 0.9746, 0.974 , 0.9736,\n",
       "            0.971 , 0.969 , 0.964 , 0.9624, 0.9614, 0.96  , 0.9575, 0.956 ,\n",
       "            0.955 , 0.9546, 0.954 , 0.9517, 0.951 , 0.9497, 0.9478, 0.9473,\n",
       "            0.9463, 0.946 , 0.9453, 0.945 , 0.9434, 0.9404, 0.94  , 0.9395,\n",
       "            0.939 , 0.938 , 0.9365, 0.9336, 0.931 , 0.9307, 0.9272, 0.927 ,\n",
       "            0.926 , 0.9253, 0.9224, 0.9214, 0.9204, 0.92  , 0.9194, 0.9185,\n",
       "            0.9165, 0.916 , 0.9155, 0.915 , 0.913 , 0.9116, 0.911 , 0.9106,\n",
       "            0.9097, 0.9087, 0.908 , 0.9067, 0.9062, 0.906 , 0.9053, 0.9043,\n",
       "            0.904 , 0.9014, 0.901 , 0.899 , 0.8984, 0.8975, 0.897 , 0.8965,\n",
       "            0.8955, 0.8936, 0.893 , 0.8926, 0.8916, 0.891 , 0.888 , 0.8877,\n",
       "            0.8867, 0.885 , 0.884 , 0.8833, 0.883 , 0.8823, 0.882 , 0.881 ,\n",
       "            0.88  , 0.879 , 0.8774, 0.877 , 0.876 , 0.8755, 0.8745, 0.873 ,\n",
       "            0.872 , 0.8716, 0.871 , 0.87  , 0.869 , 0.868 , 0.867 , 0.865 ,\n",
       "            0.8623, 0.8613, 0.861 , 0.8604, 0.8594, 0.856 , 0.8525, 0.851 ,\n",
       "            0.8506, 0.8486, 0.848 , 0.8467, 0.846 , 0.845 , 0.8438, 0.842 ,\n",
       "            0.84  , 0.839 , 0.8384, 0.836 , 0.832 , 0.828 , 0.8228, 0.821 ,\n",
       "            0.8193, 0.8184, 0.817 , 0.8164, 0.806 , 0.805 , 0.802 , 0.7905,\n",
       "            0.7876, 0.766 , 0.76  , 0.759 , 0.757 , 0.751 , 0.744 , 0.7373,\n",
       "            0.7354, 0.734 , 0.7285, 0.725 , 0.7246, 0.7163, 0.712 , 0.7056,\n",
       "            0.698 , 0.6953, 0.682 , 0.681 , 0.6797, 0.652 , 0.6455, 0.643 ,\n",
       "            0.6426, 0.636 , 0.6177, 0.617 , 0.6167, 0.612 , 0.6094, 0.602 ,\n",
       "            0.598 , 0.5957, 0.5815, 0.5747, 0.574 , 0.5664, 0.5654, 0.5596,\n",
       "            0.5586, 0.5454, 0.5396, 0.5234, 0.5225, 0.5103, 0.5073, 0.502 ,\n",
       "            0.501 , 0.5   , 0.4944, 0.4758, 0.469 , 0.4673, 0.467 , 0.466 ,\n",
       "            0.4292, 0.4236, 0.4006, 0.3975, 0.3633, 0.342 , 0.3237, 0.3206],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8984375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.015625 ,\n",
       "            0.015625 , 0.015625 , 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.03125  , 0.0390625,\n",
       "            0.046875 , 0.0546875, 0.0625   , 0.0625   , 0.0625   , 0.0703125,\n",
       "            0.0703125, 0.0703125, 0.09375  , 0.1015625, 0.109375 , 0.109375 ,\n",
       "            0.109375 , 0.109375 , 0.125    , 0.125    , 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.171875 , 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1875   , 0.1953125,\n",
       "            0.1953125, 0.203125 , 0.21875  , 0.234375 , 0.234375 , 0.2578125,\n",
       "            0.2578125, 0.2578125, 0.265625 , 0.265625 , 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.2890625, 0.296875 , 0.296875 , 0.3046875, 0.3046875,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.328125 ,\n",
       "            0.3359375, 0.34375  , 0.3515625, 0.359375 , 0.359375 , 0.359375 ,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.390625 , 0.3984375, 0.40625  ,\n",
       "            0.4140625, 0.4140625, 0.421875 , 0.4296875, 0.4375   , 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.453125 , 0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125,\n",
       "            0.515625 , 0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.671875 , 0.6875   , 0.6953125, 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.13934426, 0.14754099, 0.1557377 , 0.16393442,\n",
       "            0.17213115, 0.18032786, 0.19672132, 0.20491803, 0.21311475,\n",
       "            0.22950819, 0.23770492, 0.25409836, 0.25409836, 0.25409836,\n",
       "            0.2704918 , 0.27868852, 0.30327868, 0.3114754 , 0.31967214,\n",
       "            0.32786885, 0.33606556, 0.3442623 , 0.352459  , 0.36065573,\n",
       "            0.36065573, 0.36885247, 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4180328 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45081967, 0.45901638, 0.45901638, 0.46721312, 0.47540984,\n",
       "            0.4918033 , 0.5       , 0.52459013, 0.5327869 , 0.5327869 ,\n",
       "            0.5409836 , 0.5491803 , 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.60655737,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6639344 , 0.6721311 , 0.6803279 , 0.6885246 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.7295082 , 0.73770493, 0.74590164,\n",
       "            0.75409836, 0.75409836, 0.77868855, 0.77868855, 0.78688526,\n",
       "            0.795082  , 0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.89344263, 0.89344263, 0.89344263, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9508197 , 0.9590164 , 0.9672131 , 0.97540987,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.988 , 0.986 , 0.9854, 0.9834, 0.9785, 0.978 , 0.9775,\n",
       "            0.975 , 0.9736, 0.9688, 0.9673, 0.9663, 0.9653, 0.963 , 0.9624,\n",
       "            0.9614, 0.9604, 0.96  , 0.9595, 0.9575, 0.957 , 0.9556, 0.954 ,\n",
       "            0.953 , 0.9526, 0.952 , 0.951 , 0.9507, 0.9478, 0.947 , 0.9463,\n",
       "            0.9453, 0.945 , 0.9434, 0.9404, 0.938 , 0.9375, 0.935 , 0.9346,\n",
       "            0.9336, 0.933 , 0.93  , 0.9297, 0.9287, 0.927 , 0.9263, 0.9253,\n",
       "            0.925 , 0.9243, 0.924 , 0.9224, 0.921 , 0.9204, 0.9194, 0.919 ,\n",
       "            0.918 , 0.9175, 0.916 , 0.9155, 0.915 , 0.9146, 0.914 , 0.913 ,\n",
       "            0.911 , 0.9106, 0.91  , 0.908 , 0.907 , 0.9067, 0.9062, 0.906 ,\n",
       "            0.9043, 0.903 , 0.9023, 0.902 , 0.9014, 0.901 , 0.8984, 0.898 ,\n",
       "            0.8965, 0.8936, 0.893 , 0.8916, 0.8906, 0.89  , 0.8896, 0.889 ,\n",
       "            0.8887, 0.8877, 0.886 , 0.8857, 0.8853, 0.883 , 0.8823, 0.882 ,\n",
       "            0.8804, 0.8794, 0.8784, 0.8774, 0.8755, 0.873 , 0.872 , 0.8706,\n",
       "            0.87  , 0.869 , 0.8667, 0.863 , 0.862 , 0.8613, 0.8604, 0.859 ,\n",
       "            0.858 , 0.8574, 0.856 , 0.8555, 0.852 , 0.8516, 0.8496, 0.8477,\n",
       "            0.847 , 0.845 , 0.844 , 0.843 , 0.84  , 0.834 , 0.8335, 0.8315,\n",
       "            0.83  , 0.8296, 0.8286, 0.8276, 0.819 , 0.817 , 0.813 , 0.8022,\n",
       "            0.7983, 0.777 , 0.771 , 0.7705, 0.7676, 0.7617, 0.7554, 0.749 ,\n",
       "            0.746 , 0.7417, 0.737 , 0.7354, 0.7275, 0.724 , 0.717 , 0.709 ,\n",
       "            0.706 , 0.694 , 0.693 , 0.6904, 0.6626, 0.656 , 0.6533, 0.6465,\n",
       "            0.6274, 0.627 , 0.622 , 0.6196, 0.612 , 0.6104, 0.6055, 0.591 ,\n",
       "            0.584 , 0.5757, 0.575 , 0.5693, 0.5684, 0.5547, 0.549 , 0.5327,\n",
       "            0.5312, 0.519 , 0.5186, 0.516 , 0.5103, 0.51  , 0.509 , 0.503 ,\n",
       "            0.4844, 0.4775, 0.4766, 0.4756, 0.4744, 0.4377, 0.4338, 0.4077,\n",
       "            0.405 , 0.3699, 0.3484, 0.3298, 0.3267], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8984375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0390625,\n",
       "            0.0390625, 0.0390625, 0.046875 , 0.0546875, 0.0546875, 0.0625   ,\n",
       "            0.0703125, 0.0703125, 0.0703125, 0.0703125, 0.0859375, 0.09375  ,\n",
       "            0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.125    , 0.1328125, 0.140625 , 0.1484375,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  ,\n",
       "            0.1640625, 0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.2109375, 0.2109375,\n",
       "            0.21875  , 0.234375 , 0.234375 , 0.2421875, 0.2578125, 0.2578125,\n",
       "            0.265625 , 0.2734375, 0.2734375, 0.28125  , 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3046875, 0.3125   , 0.3203125,\n",
       "            0.328125 , 0.328125 , 0.328125 , 0.328125 , 0.3359375, 0.3515625,\n",
       "            0.359375 , 0.359375 , 0.359375 , 0.3671875, 0.3828125, 0.390625 ,\n",
       "            0.40625  , 0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4375   ,\n",
       "            0.4375   , 0.4375   , 0.4375   , 0.4453125, 0.4453125, 0.4453125,\n",
       "            0.4453125, 0.453125 , 0.4609375, 0.4609375, 0.4609375, 0.46875  ,\n",
       "            0.4765625, 0.484375 , 0.4921875, 0.4921875, 0.5      , 0.5078125,\n",
       "            0.5234375, 0.53125  , 0.5390625, 0.546875 , 0.5546875, 0.5625   ,\n",
       "            0.5703125, 0.578125 , 0.5859375, 0.59375  , 0.6015625, 0.6015625,\n",
       "            0.609375 , 0.6171875, 0.625    , 0.6328125, 0.640625 , 0.6484375,\n",
       "            0.65625  , 0.671875 , 0.6875   , 0.6953125, 0.703125 , 0.7109375,\n",
       "            0.71875  , 0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125,\n",
       "            0.765625 , 0.78125  , 0.7890625, 0.796875 , 0.8046875, 0.8125   ,\n",
       "            0.8203125, 0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 ,\n",
       "            0.8671875, 0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  ,\n",
       "            0.9140625, 0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 ,\n",
       "            0.9609375, 0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.1557377 , 0.16393442, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.22131148, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.27868852, 0.28688523, 0.3114754 ,\n",
       "            0.31967214, 0.32786885, 0.33606556, 0.3442623 , 0.36065573,\n",
       "            0.36065573, 0.36885247, 0.37704918, 0.37704918, 0.37704918,\n",
       "            0.3852459 , 0.40163934, 0.40163934, 0.4180328 , 0.4262295 ,\n",
       "            0.44262296, 0.44262296, 0.45081967, 0.45901638, 0.45901638,\n",
       "            0.46721312, 0.47540984, 0.48360655, 0.48360655, 0.5       ,\n",
       "            0.5163934 , 0.52459013, 0.52459013, 0.52459013, 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.56557375, 0.57377046, 0.58196723,\n",
       "            0.58196723, 0.58196723, 0.59016395, 0.59836066, 0.6147541 ,\n",
       "            0.63114756, 0.63114756, 0.6393443 , 0.647541  , 0.6803279 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.71311474,\n",
       "            0.7295082 , 0.7295082 , 0.73770493, 0.74590164, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.77868855, 0.78688526, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8196721 , 0.8278689 , 0.8360656 ,\n",
       "            0.8360656 , 0.8360656 , 0.8442623 , 0.852459  , 0.86885244,\n",
       "            0.86885244, 0.86885244, 0.86885244, 0.8770492 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.89344263,\n",
       "            0.89344263, 0.89344263, 0.90163934, 0.90163934, 0.90983605,\n",
       "            0.91803277, 0.92622954, 0.92622954, 0.93442625, 0.94262296,\n",
       "            0.9508197 , 0.9590164 , 0.9590164 , 0.9672131 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9897, 0.9883, 0.988 , 0.986 , 0.9814, 0.981 , 0.9805,\n",
       "            0.9785, 0.977 , 0.9727, 0.9717, 0.9707, 0.9697, 0.968 , 0.9673,\n",
       "            0.966 , 0.965 , 0.9644, 0.9624, 0.961 , 0.9595, 0.9585, 0.9575,\n",
       "            0.957 , 0.9565, 0.954 , 0.9526, 0.9517, 0.951 , 0.9497, 0.9473,\n",
       "            0.9443, 0.944 , 0.9424, 0.941 , 0.94  , 0.9385, 0.938 , 0.9375,\n",
       "            0.937 , 0.9365, 0.934 , 0.9336, 0.933 , 0.9326, 0.932 , 0.9316,\n",
       "            0.9307, 0.929 , 0.9287, 0.9277, 0.9272, 0.927 , 0.9263, 0.926 ,\n",
       "            0.9253, 0.925 , 0.9243, 0.924 , 0.9233, 0.923 , 0.9224, 0.922 ,\n",
       "            0.9204, 0.9194, 0.919 , 0.917 , 0.916 , 0.9155, 0.915 , 0.9146,\n",
       "            0.9126, 0.912 , 0.91  , 0.9087, 0.907 , 0.9062, 0.906 , 0.9033,\n",
       "            0.903 , 0.902 , 0.9014, 0.901 , 0.9   , 0.8994, 0.899 , 0.8984,\n",
       "            0.8975, 0.8965, 0.896 , 0.895 , 0.8926, 0.8916, 0.89  , 0.889 ,\n",
       "            0.888 , 0.887 , 0.8857, 0.883 , 0.882 , 0.8804, 0.8784, 0.877 ,\n",
       "            0.873 , 0.8726, 0.871 , 0.8696, 0.8687, 0.8667, 0.8623, 0.862 ,\n",
       "            0.8604, 0.86  , 0.859 , 0.8584, 0.8574, 0.8564, 0.8535, 0.851 ,\n",
       "            0.8467, 0.844 , 0.8413, 0.841 , 0.8403, 0.8384, 0.8306, 0.828 ,\n",
       "            0.8237, 0.8135, 0.809 , 0.788 , 0.782 , 0.779 , 0.7734, 0.767 ,\n",
       "            0.7603, 0.758 , 0.7573, 0.7544, 0.7485, 0.7466, 0.739 , 0.736 ,\n",
       "            0.7285, 0.7207, 0.7173, 0.706 , 0.7036, 0.7017, 0.674 , 0.6665,\n",
       "            0.664 , 0.6567, 0.638 , 0.6377, 0.637 , 0.632 , 0.63  , 0.6226,\n",
       "            0.622 , 0.6147, 0.6006, 0.5938, 0.5854, 0.5845, 0.5786, 0.5776,\n",
       "            0.5635, 0.5576, 0.5415, 0.54  , 0.5293, 0.5273, 0.5244, 0.5186,\n",
       "            0.518 , 0.517 , 0.511 , 0.4922, 0.4854, 0.485 , 0.4832, 0.482 ,\n",
       "            0.445 , 0.4426, 0.4138, 0.4111, 0.3752, 0.3533, 0.3342, 0.3308],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.90625, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.0078125, 0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.03125  , 0.0390625, 0.0390625, 0.0546875, 0.0625   ,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.09375  ,\n",
       "            0.09375  , 0.1015625, 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.125    , 0.125    , 0.1328125, 0.1328125, 0.140625 , 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.171875 , 0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1875   , 0.1953125, 0.1953125, 0.1953125, 0.203125 ,\n",
       "            0.203125 , 0.2109375, 0.2109375, 0.21875  , 0.2265625, 0.234375 ,\n",
       "            0.234375 , 0.25     , 0.2578125, 0.2734375, 0.2734375, 0.28125  ,\n",
       "            0.28125  , 0.28125  , 0.28125  , 0.2890625, 0.296875 , 0.3046875,\n",
       "            0.3046875, 0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.328125 ,\n",
       "            0.328125 , 0.328125 , 0.3359375, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.375    , 0.3828125, 0.390625 , 0.40625  , 0.4140625, 0.421875 ,\n",
       "            0.4296875, 0.4296875, 0.4375   , 0.4375   , 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875, 0.4921875,\n",
       "            0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  , 0.5390625,\n",
       "            0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 , 0.5859375,\n",
       "            0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875, 0.625    ,\n",
       "            0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.671875 , 0.6796875,\n",
       "            0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  , 0.7265625,\n",
       "            0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 , 0.7734375,\n",
       "            0.78125  , 0.796875 , 0.8046875, 0.8125   , 0.8203125, 0.828125 ,\n",
       "            0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875, 0.875    ,\n",
       "            0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625, 0.921875 ,\n",
       "            0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375, 0.96875  ,\n",
       "            0.9765625, 0.984375 , 0.9921875, 1.       ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04098361, 0.04918033, 0.05737705, 0.06557377, 0.07377049,\n",
       "            0.08196721, 0.09016393, 0.09836066, 0.10655738, 0.1147541 ,\n",
       "            0.12295082, 0.13114753, 0.14754099, 0.16393442, 0.18032786,\n",
       "            0.19672132, 0.20491803, 0.22131148, 0.23770492, 0.23770492,\n",
       "            0.24590164, 0.25409836, 0.25409836, 0.26229507, 0.27868852,\n",
       "            0.28688523, 0.29508197, 0.3114754 , 0.31967214, 0.32786885,\n",
       "            0.3442623 , 0.36065573, 0.36065573, 0.36065573, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.39344263, 0.40163934, 0.40163934,\n",
       "            0.40983605, 0.43442622, 0.44262296, 0.45081967, 0.45901638,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.4918033 ,\n",
       "            0.5       , 0.5163934 , 0.52459013, 0.52459013, 0.5409836 ,\n",
       "            0.5491803 , 0.55737704, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.59836066, 0.6229508 ,\n",
       "            0.6229508 , 0.63114756, 0.6393443 , 0.647541  , 0.6557377 ,\n",
       "            0.6803279 , 0.6885246 , 0.6885246 , 0.6967213 , 0.6967213 ,\n",
       "            0.704918  , 0.704918  , 0.71311474, 0.72131145, 0.7295082 ,\n",
       "            0.7295082 , 0.74590164, 0.74590164, 0.75409836, 0.7704918 ,\n",
       "            0.77868855, 0.78688526, 0.795082  , 0.8032787 , 0.8032787 ,\n",
       "            0.8114754 , 0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 ,\n",
       "            0.8442623 , 0.852459  , 0.8606557 , 0.86885244, 0.86885244,\n",
       "            0.86885244, 0.8770492 , 0.8852459 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.89344263, 0.89344263, 0.89344263,\n",
       "            0.90163934, 0.90163934, 0.90983605, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.9836066 , 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.991 , 0.99  , 0.9897, 0.9883, 0.9844, 0.984 , 0.9834,\n",
       "            0.982 , 0.9805, 0.9766, 0.9756, 0.975 , 0.9746, 0.9736, 0.972 ,\n",
       "            0.971 , 0.97  , 0.969 , 0.9673, 0.966 , 0.9644, 0.9634, 0.963 ,\n",
       "            0.9624, 0.962 , 0.9614, 0.96  , 0.9585, 0.958 , 0.9575, 0.957 ,\n",
       "            0.9565, 0.9556, 0.953 , 0.95  , 0.9487, 0.9478, 0.9473, 0.946 ,\n",
       "            0.945 , 0.944 , 0.9434, 0.943 , 0.942 , 0.941 , 0.94  , 0.9395,\n",
       "            0.9385, 0.938 , 0.9375, 0.937 , 0.936 , 0.9346, 0.934 , 0.9336,\n",
       "            0.933 , 0.9326, 0.932 , 0.9316, 0.931 , 0.9307, 0.93  , 0.9287,\n",
       "            0.928 , 0.9277, 0.9253, 0.925 , 0.924 , 0.9233, 0.923 , 0.9224,\n",
       "            0.9214, 0.92  , 0.9185, 0.918 , 0.9175, 0.917 , 0.916 , 0.9155,\n",
       "            0.915 , 0.914 , 0.9126, 0.912 , 0.9116, 0.9106, 0.91  , 0.909 ,\n",
       "            0.908 , 0.9077, 0.907 , 0.9067, 0.906 , 0.9053, 0.9043, 0.902 ,\n",
       "            0.9014, 0.8994, 0.8984, 0.8975, 0.8965, 0.8955, 0.893 , 0.8926,\n",
       "            0.8916, 0.89  , 0.887 , 0.883 , 0.8813, 0.881 , 0.8794, 0.879 ,\n",
       "            0.877 , 0.8726, 0.8716, 0.8706, 0.87  , 0.8696, 0.869 , 0.867 ,\n",
       "            0.864 , 0.862 , 0.8584, 0.8564, 0.8545, 0.852 , 0.851 , 0.849 ,\n",
       "            0.842 , 0.8394, 0.8345, 0.8247, 0.82  , 0.7983, 0.7944, 0.7925,\n",
       "            0.79  , 0.7847, 0.779 , 0.7715, 0.7695, 0.768 , 0.7666, 0.76  ,\n",
       "            0.7573, 0.7505, 0.7476, 0.7397, 0.7324, 0.7285, 0.7197, 0.715 ,\n",
       "            0.7134, 0.6855, 0.6772, 0.676 , 0.675 , 0.6675, 0.65  , 0.6484,\n",
       "            0.648 , 0.643 , 0.6406, 0.636 , 0.6323, 0.6255, 0.6113, 0.6045,\n",
       "            0.604 , 0.5957, 0.589 , 0.588 , 0.574 , 0.568 , 0.5513, 0.5503,\n",
       "            0.5415, 0.5376, 0.534 , 0.5283, 0.528 , 0.527 , 0.5205, 0.502 ,\n",
       "            0.4963, 0.4946, 0.4924, 0.4915, 0.455 , 0.4546, 0.422 , 0.4197,\n",
       "            0.3828, 0.3606, 0.3416, 0.338 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9375, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "            0.       , 0.       , 0.       , 0.       , 0.0078125, 0.0078125,\n",
       "            0.0078125, 0.0078125, 0.015625 , 0.015625 , 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375, 0.0234375,\n",
       "            0.0234375, 0.0390625, 0.0390625, 0.0390625, 0.0546875, 0.0546875,\n",
       "            0.0625   , 0.0625   , 0.0703125, 0.0703125, 0.0703125, 0.0859375,\n",
       "            0.09375  , 0.09375  , 0.109375 , 0.109375 , 0.109375 , 0.1171875,\n",
       "            0.1171875, 0.125    , 0.1328125, 0.1328125, 0.1328125, 0.140625 ,\n",
       "            0.1484375, 0.1484375, 0.1484375, 0.1484375, 0.15625  , 0.1640625,\n",
       "            0.1640625, 0.171875 , 0.1796875, 0.1796875, 0.1875   , 0.1875   ,\n",
       "            0.1875   , 0.1953125, 0.203125 , 0.203125 , 0.203125 , 0.2109375,\n",
       "            0.21875  , 0.2265625, 0.2265625, 0.234375 , 0.25     , 0.2578125,\n",
       "            0.2734375, 0.2734375, 0.28125  , 0.28125  , 0.28125  , 0.28125  ,\n",
       "            0.2890625, 0.296875 , 0.3046875, 0.3046875, 0.3046875, 0.3125   ,\n",
       "            0.3125   , 0.3203125, 0.328125 , 0.328125 , 0.328125 , 0.328125 ,\n",
       "            0.328125 , 0.3359375, 0.3515625, 0.3515625, 0.359375 , 0.3671875,\n",
       "            0.3671875, 0.375    , 0.3828125, 0.3984375, 0.40625  , 0.40625  ,\n",
       "            0.4140625, 0.421875 , 0.4296875, 0.4296875, 0.4375   , 0.4453125,\n",
       "            0.4453125, 0.4453125, 0.4453125, 0.4453125, 0.453125 , 0.4609375,\n",
       "            0.4609375, 0.4609375, 0.46875  , 0.4765625, 0.484375 , 0.4921875,\n",
       "            0.4921875, 0.5      , 0.5078125, 0.515625 , 0.5234375, 0.53125  ,\n",
       "            0.5390625, 0.546875 , 0.5546875, 0.5625   , 0.5703125, 0.578125 ,\n",
       "            0.5859375, 0.59375  , 0.6015625, 0.6015625, 0.609375 , 0.6171875,\n",
       "            0.625    , 0.6328125, 0.640625 , 0.6484375, 0.65625  , 0.671875 ,\n",
       "            0.6796875, 0.6875   , 0.6953125, 0.703125 , 0.7109375, 0.71875  ,\n",
       "            0.7265625, 0.734375 , 0.7421875, 0.75     , 0.7578125, 0.765625 ,\n",
       "            0.7734375, 0.78125  , 0.796875 , 0.8046875, 0.8125   , 0.8203125,\n",
       "            0.828125 , 0.8359375, 0.84375  , 0.8515625, 0.859375 , 0.8671875,\n",
       "            0.875    , 0.8828125, 0.890625 , 0.8984375, 0.90625  , 0.9140625,\n",
       "            0.921875 , 0.9296875, 0.9375   , 0.9453125, 0.953125 , 0.9609375,\n",
       "            0.96875  , 0.9765625, 0.984375 , 0.9921875, 1.       ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00819672, 0.01639344, 0.02459016, 0.03278688,\n",
       "            0.04918033, 0.05737705, 0.06557377, 0.07377049, 0.08196721,\n",
       "            0.09016393, 0.09836066, 0.10655738, 0.1147541 , 0.12295082,\n",
       "            0.13114753, 0.14754099, 0.16393442, 0.18032786, 0.19672132,\n",
       "            0.20491803, 0.22131148, 0.22131148, 0.23770492, 0.24590164,\n",
       "            0.25409836, 0.25409836, 0.26229507, 0.27868852, 0.28688523,\n",
       "            0.29508197, 0.3114754 , 0.31967214, 0.32786885, 0.33606556,\n",
       "            0.352459  , 0.36065573, 0.36065573, 0.36885247, 0.37704918,\n",
       "            0.37704918, 0.3852459 , 0.3852459 , 0.39344263, 0.40163934,\n",
       "            0.40983605, 0.4262295 , 0.4262295 , 0.43442622, 0.44262296,\n",
       "            0.45901638, 0.46721312, 0.47540984, 0.47540984, 0.48360655,\n",
       "            0.4918033 , 0.5       , 0.5081967 , 0.52459013, 0.5491803 ,\n",
       "            0.5491803 , 0.55737704, 0.57377046, 0.58196723, 0.58196723,\n",
       "            0.58196723, 0.59016395, 0.59836066, 0.59836066, 0.6229508 ,\n",
       "            0.6229508 , 0.6393443 , 0.647541  , 0.6557377 , 0.6639344 ,\n",
       "            0.6885246 , 0.6967213 , 0.704918  , 0.704918  , 0.704918  ,\n",
       "            0.72131145, 0.7295082 , 0.73770493, 0.74590164, 0.74590164,\n",
       "            0.75409836, 0.76229507, 0.7704918 , 0.77868855, 0.795082  ,\n",
       "            0.8032787 , 0.8032787 , 0.8114754 , 0.8196721 , 0.8278689 ,\n",
       "            0.8278689 , 0.8360656 , 0.8360656 , 0.8360656 , 0.8442623 ,\n",
       "            0.852459  , 0.8606557 , 0.86885244, 0.86885244, 0.86885244,\n",
       "            0.8770492 , 0.8770492 , 0.8770492 , 0.8852459 , 0.8852459 ,\n",
       "            0.8852459 , 0.8852459 , 0.8852459 , 0.89344263, 0.89344263,\n",
       "            0.89344263, 0.90163934, 0.91803277, 0.92622954, 0.92622954,\n",
       "            0.93442625, 0.94262296, 0.9508197 , 0.9590164 , 0.9590164 ,\n",
       "            0.9590164 , 0.97540987, 0.9836066 , 0.9836066 , 0.9836066 ,\n",
       "            0.9836066 , 0.9836066 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 , 0.9918033 ,\n",
       "            0.9918033 , 0.9918033 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9927, 0.9917, 0.991 , 0.99  , 0.9863, 0.986 , 0.9844,\n",
       "            0.9834, 0.98  , 0.979 , 0.9785, 0.978 , 0.977 , 0.9756, 0.9746,\n",
       "            0.974 , 0.973 , 0.971 , 0.9697, 0.9688, 0.968 , 0.9673, 0.967 ,\n",
       "            0.9663, 0.966 , 0.9653, 0.9634, 0.963 , 0.9624, 0.962 , 0.9614,\n",
       "            0.9604, 0.958 , 0.9556, 0.955 , 0.9546, 0.9536, 0.952 , 0.9517,\n",
       "            0.951 , 0.95  , 0.9497, 0.949 , 0.9487, 0.9478, 0.947 , 0.9463,\n",
       "            0.946 , 0.9453, 0.945 , 0.944 , 0.943 , 0.942 , 0.9414, 0.941 ,\n",
       "            0.9404, 0.94  , 0.9395, 0.939 , 0.9385, 0.9375, 0.937 , 0.9365,\n",
       "            0.9355, 0.935 , 0.933 , 0.9326, 0.9316, 0.931 , 0.9307, 0.929 ,\n",
       "            0.9272, 0.9263, 0.926 , 0.9253, 0.9243, 0.9233, 0.922 , 0.9214,\n",
       "            0.921 , 0.9204, 0.9194, 0.9185, 0.918 , 0.9165, 0.916 , 0.9155,\n",
       "            0.915 , 0.9146, 0.914 , 0.9136, 0.9106, 0.91  , 0.9097, 0.9087,\n",
       "            0.908 , 0.907 , 0.9062, 0.9053, 0.9043, 0.9023, 0.9014, 0.9004,\n",
       "            0.899 , 0.8965, 0.8955, 0.8926, 0.892 , 0.891 , 0.8896, 0.889 ,\n",
       "            0.8887, 0.8867, 0.886 , 0.8823, 0.8804, 0.88  , 0.8794, 0.878 ,\n",
       "            0.873 , 0.8726, 0.869 , 0.867 , 0.864 , 0.8623, 0.8613, 0.861 ,\n",
       "            0.859 , 0.8525, 0.85  , 0.8447, 0.836 , 0.83  , 0.809 , 0.806 ,\n",
       "            0.803 , 0.8003, 0.796 , 0.7905, 0.782 , 0.781 , 0.7793, 0.7783,\n",
       "            0.771 , 0.768 , 0.7617, 0.7593, 0.7515, 0.7437, 0.7397, 0.733 ,\n",
       "            0.726 , 0.7246, 0.6978, 0.688 , 0.687 , 0.6855, 0.678 , 0.661 ,\n",
       "            0.659 , 0.6587, 0.654 , 0.6514, 0.6504, 0.643 , 0.6357, 0.622 ,\n",
       "            0.615 , 0.6147, 0.6064, 0.599 , 0.5986, 0.5845, 0.5786, 0.5615,\n",
       "            0.561 , 0.5537, 0.5474, 0.5444, 0.5386, 0.538 , 0.5366, 0.5303,\n",
       "            0.512 , 0.5073, 0.5044, 0.502 , 0.501 , 0.4668, 0.4653, 0.4304,\n",
       "            0.4282, 0.3906, 0.368 , 0.3486, 0.345 ], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.23728813, 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5508475 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.61864406, 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7288136 , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7711864 , 0.7881356 , 0.7881356 , 0.7881356 , 0.7881356 ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.7966102 , 0.7966102 ,\n",
       "            0.7966102 , 0.7966102 , 0.7966102 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8220339 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.83898306, 0.83898306, 0.83898306, 0.84745765,\n",
       "            0.84745765, 0.86440676, 0.86440676, 0.87288135, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9237288 , 0.9237288 , 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.94067794, 0.94067794, 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 0.9915254 , 0.9915254 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03787879, 0.04545455, 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12878788, 0.12878788,\n",
       "            0.13636364, 0.13636364, 0.14393939, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.17424242, 0.18181819, 0.1969697 , 0.20454545,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.21969697, 0.22727273,\n",
       "            0.24242425, 0.25      , 0.25      , 0.25757575, 0.25757575,\n",
       "            0.27272728, 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.37878788, 0.37878788, 0.38636363,\n",
       "            0.38636363, 0.38636363, 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46969697, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5833333 , 0.5833333 , 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.67424244,\n",
       "            0.68939394, 0.70454544, 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75      , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.431 , 0.4268, 0.4192, 0.4177, 0.4167, 0.414 , 0.4133,\n",
       "            0.4128, 0.4124, 0.412 , 0.4119, 0.411 , 0.4104, 0.4092, 0.409 ,\n",
       "            0.4087, 0.4077, 0.4072, 0.407 , 0.4067, 0.4065, 0.4055, 0.4053,\n",
       "            0.4048, 0.4043, 0.404 , 0.4038, 0.4036, 0.403 , 0.4028, 0.4023,\n",
       "            0.402 , 0.4019, 0.4016, 0.4014, 0.4011, 0.401 , 0.4006, 0.4004,\n",
       "            0.3997, 0.3994, 0.3992, 0.398 , 0.3972, 0.3945, 0.3928, 0.392 ,\n",
       "            0.3918, 0.3877, 0.386 , 0.383 , 0.3826, 0.3818, 0.3796, 0.379 ,\n",
       "            0.3782, 0.3757, 0.3748, 0.3735, 0.369 , 0.3687, 0.3684, 0.368 ,\n",
       "            0.3672, 0.3665, 0.365 , 0.3647, 0.3645, 0.3643, 0.364 , 0.3638,\n",
       "            0.3628, 0.3616, 0.3613, 0.3606, 0.36  , 0.3591, 0.3584, 0.3572,\n",
       "            0.3567, 0.3564, 0.3562, 0.356 , 0.3557, 0.3555, 0.355 , 0.3525,\n",
       "            0.352 , 0.3513, 0.351 , 0.3508, 0.35  , 0.3496, 0.3494, 0.3489,\n",
       "            0.3477, 0.3472, 0.347 , 0.346 , 0.3452, 0.345 , 0.3447, 0.3445,\n",
       "            0.3442, 0.344 , 0.3435, 0.3433, 0.3428, 0.3425, 0.3423, 0.3416,\n",
       "            0.3413, 0.341 , 0.3406, 0.3398, 0.3396, 0.3394, 0.339 , 0.3384,\n",
       "            0.3374, 0.3372, 0.337 , 0.336 , 0.3352, 0.3347, 0.3345, 0.3342,\n",
       "            0.3337, 0.3335, 0.3328, 0.3323, 0.3315, 0.3308, 0.3306, 0.33  ,\n",
       "            0.3298, 0.3296, 0.329 , 0.3284, 0.3267, 0.3262, 0.326 , 0.3254,\n",
       "            0.3252, 0.3242, 0.324 , 0.3235, 0.323 , 0.3225, 0.3223, 0.322 ,\n",
       "            0.3218, 0.3215, 0.321 , 0.32  , 0.3198, 0.3193, 0.3186, 0.3179,\n",
       "            0.3174, 0.3167, 0.3164, 0.3162, 0.3157, 0.3154, 0.3152, 0.3147,\n",
       "            0.3142, 0.3137, 0.3127, 0.3115, 0.3108, 0.3105, 0.31  , 0.3093,\n",
       "            0.3079, 0.3074, 0.3057, 0.305 , 0.304 , 0.3037, 0.3035, 0.302 ,\n",
       "            0.2969, 0.294 , 0.2937, 0.2935, 0.2917, 0.2888, 0.2876, 0.2832,\n",
       "            0.282 , 0.2817, 0.2815, 0.2805, 0.2786, 0.2776, 0.275 , 0.2734,\n",
       "            0.273 , 0.25  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.05084746, 0.05932203, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.20338982, 0.21186441, 0.22881356,\n",
       "            0.23728813, 0.2542373 , 0.26271185, 0.27118644, 0.2881356 ,\n",
       "            0.30508474, 0.3220339 , 0.33050847, 0.33898306, 0.3559322 ,\n",
       "            0.3644068 , 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.7033898 ,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.779661  , 0.779661  ,\n",
       "            0.779661  , 0.7881356 , 0.7881356 , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.7966102 , 0.7966102 , 0.7966102 ,\n",
       "            0.80508476, 0.80508476, 0.80508476, 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8220339 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.84745765, 0.8559322 , 0.8559322 ,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.88135594, 0.89830506,\n",
       "            0.89830506, 0.90677965, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9237288 , 0.9237288 , 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.94067794, 0.94067794, 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.11363637, 0.11363637,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.14393939, 0.14393939, 0.1590909 , 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.21969697,\n",
       "            0.22727273, 0.22727273, 0.23484848, 0.23484848, 0.24242425,\n",
       "            0.2651515 , 0.2651515 , 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.31060606,\n",
       "            0.3181818 , 0.3181818 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.36363637, 0.36363637,\n",
       "            0.37121212, 0.37121212, 0.37878788, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.43939394, 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5151515 , 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.54545456, 0.54545456, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.6969697 , 0.7121212 , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4138, 0.413 , 0.4072, 0.4053, 0.404 , 0.4026, 0.4006,\n",
       "            0.4001, 0.4   , 0.3997, 0.398 , 0.3972, 0.3955, 0.3953, 0.3945,\n",
       "            0.3943, 0.3938, 0.3936, 0.393 , 0.3928, 0.3918, 0.3916, 0.3914,\n",
       "            0.391 , 0.3901, 0.39  , 0.3896, 0.3894, 0.3892, 0.3887, 0.3884,\n",
       "            0.388 , 0.3877, 0.3867, 0.3818, 0.3794, 0.3787, 0.3782, 0.3752,\n",
       "            0.3733, 0.3694, 0.3684, 0.3657, 0.3655, 0.3643, 0.363 , 0.3628,\n",
       "            0.3618, 0.3591, 0.3567, 0.3533, 0.3513, 0.3508, 0.3503, 0.35  ,\n",
       "            0.3499, 0.3496, 0.3494, 0.3486, 0.3484, 0.3481, 0.3477, 0.346 ,\n",
       "            0.3457, 0.3455, 0.3452, 0.3447, 0.3442, 0.343 , 0.3425, 0.342 ,\n",
       "            0.3413, 0.3408, 0.3406, 0.34  , 0.3396, 0.3394, 0.338 , 0.337 ,\n",
       "            0.3367, 0.3364, 0.3357, 0.3347, 0.3345, 0.3337, 0.3333, 0.333 ,\n",
       "            0.3328, 0.3313, 0.331 , 0.3308, 0.3303, 0.3296, 0.3289, 0.3281,\n",
       "            0.328 , 0.3274, 0.327 , 0.326 , 0.3252, 0.325 , 0.3247, 0.3242,\n",
       "            0.324 , 0.3237, 0.3235, 0.3232, 0.3228, 0.3225, 0.3223, 0.322 ,\n",
       "            0.3218, 0.3215, 0.3213, 0.321 , 0.3203, 0.3196, 0.3193, 0.3184,\n",
       "            0.3174, 0.317 , 0.3167, 0.3162, 0.3157, 0.3154, 0.315 , 0.3147,\n",
       "            0.314 , 0.3137, 0.3132, 0.3123, 0.3118, 0.3113, 0.3108, 0.3105,\n",
       "            0.3098, 0.3079, 0.3074, 0.3071, 0.3066, 0.3064, 0.3047, 0.3044,\n",
       "            0.304 , 0.3035, 0.3032, 0.3025, 0.3018, 0.301 , 0.3005, 0.3   ,\n",
       "            0.2986, 0.2983, 0.298 , 0.2974, 0.297 , 0.2969, 0.2964, 0.2961,\n",
       "            0.295 , 0.2944, 0.2935, 0.2927, 0.2925, 0.2915, 0.2913, 0.2908,\n",
       "            0.2905, 0.2903, 0.2898, 0.289 , 0.2878, 0.2861, 0.286 , 0.2854,\n",
       "            0.2844, 0.284 , 0.2827, 0.282 , 0.2815, 0.28  , 0.2786, 0.278 ,\n",
       "            0.2778, 0.2761, 0.276 , 0.2712, 0.2693, 0.2673, 0.2668, 0.2622,\n",
       "            0.2607, 0.2566, 0.256 , 0.2546, 0.254 , 0.2507, 0.2502, 0.2471,\n",
       "            0.2456, 0.2451, 0.2207], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.08474576,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.15254237, 0.16101696, 0.1779661 , 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.23728813, 0.2457627 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.29661018, 0.30508474, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.3559322 , 0.3644068 , 0.38135594,\n",
       "            0.3898305 , 0.40677965, 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5508475 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.61864406, 0.61864406, 0.62711865, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.779661  , 0.779661  ,\n",
       "            0.779661  , 0.7881356 , 0.7881356 , 0.7881356 , 0.7881356 ,\n",
       "            0.7881356 , 0.7881356 , 0.7881356 , 0.7966102 , 0.7966102 ,\n",
       "            0.7966102 , 0.80508476, 0.80508476, 0.80508476, 0.80508476,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.84745765, 0.84745765,\n",
       "            0.8559322 , 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.89830506, 0.89830506, 0.89830506, 0.89830506, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.91525424, 0.91525424, 0.9237288 ,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.94067794, 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.08333334, 0.09090909, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12121212, 0.12121212,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.16666667, 0.16666667, 0.16666667, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.22727273, 0.23484848, 0.23484848,\n",
       "            0.23484848, 0.23484848, 0.24242425, 0.24242425, 0.25      ,\n",
       "            0.2651515 , 0.28787878, 0.29545453, 0.3030303 , 0.3181818 ,\n",
       "            0.3181818 , 0.32575756, 0.32575756, 0.33333334, 0.33333334,\n",
       "            0.3409091 , 0.3409091 , 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.37878788, 0.3939394 ,\n",
       "            0.40151516, 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5       , 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.5151515 , 0.52272725, 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6287879 , 0.6439394 ,\n",
       "            0.65909094, 0.65909094, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4006, 0.3955, 0.395 , 0.3938, 0.3914, 0.391 , 0.3904,\n",
       "            0.3882, 0.3877, 0.3875, 0.387 , 0.3867, 0.3855, 0.385 , 0.3843,\n",
       "            0.3838, 0.3833, 0.3828, 0.382 , 0.3818, 0.3816, 0.3809, 0.3804,\n",
       "            0.3801, 0.38  , 0.3794, 0.3792, 0.379 , 0.3787, 0.378 , 0.3777,\n",
       "            0.3774, 0.377 , 0.3762, 0.3757, 0.3755, 0.3723, 0.3691, 0.367 ,\n",
       "            0.3667, 0.3647, 0.3645, 0.3625, 0.3606, 0.356 , 0.3547, 0.3516,\n",
       "            0.3513, 0.3506, 0.3486, 0.3477, 0.347 , 0.3447, 0.3389, 0.3384,\n",
       "            0.3354, 0.3347, 0.3345, 0.3342, 0.334 , 0.3328, 0.3325, 0.332 ,\n",
       "            0.3318, 0.3313, 0.3306, 0.3296, 0.3289, 0.3284, 0.3267, 0.3264,\n",
       "            0.3262, 0.3254, 0.3252, 0.325 , 0.3245, 0.3242, 0.3237, 0.3228,\n",
       "            0.321 , 0.3184, 0.3179, 0.3174, 0.317 , 0.3167, 0.3164, 0.3162,\n",
       "            0.316 , 0.3154, 0.314 , 0.3135, 0.3132, 0.3127, 0.3125, 0.3115,\n",
       "            0.3108, 0.3105, 0.31  , 0.3079, 0.3076, 0.307 , 0.3066, 0.3064,\n",
       "            0.3062, 0.306 , 0.3052, 0.3047, 0.3044, 0.304 , 0.3035, 0.3032,\n",
       "            0.303 , 0.3025, 0.3018, 0.3015, 0.3013, 0.301 , 0.3005, 0.3   ,\n",
       "            0.299 , 0.2988, 0.2983, 0.298 , 0.2979, 0.2976, 0.2974, 0.2969,\n",
       "            0.2966, 0.2961, 0.296 , 0.2952, 0.2944, 0.2942, 0.2937, 0.2922,\n",
       "            0.2915, 0.2913, 0.29  , 0.2896, 0.2888, 0.2886, 0.288 , 0.287 ,\n",
       "            0.286 , 0.2852, 0.285 , 0.2847, 0.2844, 0.284 , 0.2837, 0.2827,\n",
       "            0.2817, 0.2815, 0.2808, 0.2803, 0.2795, 0.2788, 0.2786, 0.278 ,\n",
       "            0.2778, 0.2776, 0.277 , 0.2756, 0.275 , 0.2742, 0.2732, 0.272 ,\n",
       "            0.2717, 0.2715, 0.2708, 0.27  , 0.2698, 0.268 , 0.2676, 0.267 ,\n",
       "            0.2668, 0.2666, 0.2654, 0.2642, 0.263 , 0.2627, 0.2625, 0.2622,\n",
       "            0.2595, 0.259 , 0.2573, 0.256 , 0.2551, 0.2542, 0.2537, 0.2534,\n",
       "            0.252 , 0.2493, 0.2482, 0.243 , 0.2418, 0.2375, 0.2356, 0.2338,\n",
       "            0.231 , 0.2294, 0.229 , 0.2283, 0.2251, 0.2247, 0.2217, 0.2198,\n",
       "            0.2194, 0.1942], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.07627118, 0.10169491,\n",
       "            0.11016949, 0.12711865, 0.13559322, 0.1440678 , 0.16101696,\n",
       "            0.16101696, 0.1779661 , 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.22881356, 0.23728813, 0.2457627 , 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.33050847, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.38135594, 0.3983051 , 0.40677965, 0.41525424, 0.41525424,\n",
       "            0.42372882, 0.44067797, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.69491524, 0.69491524, 0.69491524, 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.720339  , 0.720339  ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7881356 , 0.7881356 , 0.7881356 , 0.7881356 , 0.7966102 ,\n",
       "            0.7966102 , 0.80508476, 0.80508476, 0.80508476, 0.80508476,\n",
       "            0.8135593 , 0.8135593 , 0.8135593 , 0.8305085 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.84745765, 0.8559322 , 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.87288135, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.9237288 , 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.09090909, 0.09090909, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.15151516, 0.1590909 , 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.18939394, 0.1969697 ,\n",
       "            0.1969697 , 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.21969697, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25      , 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.29545453, 0.3030303 , 0.3030303 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.33333334, 0.3409091 ,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.4318182 , 0.43939394,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46969697, 0.4848485 ,\n",
       "            0.4848485 , 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3855, 0.381 , 0.3804, 0.3787, 0.376 , 0.3748, 0.3745,\n",
       "            0.3738, 0.3733, 0.372 , 0.3716, 0.3713, 0.371 , 0.37  , 0.3696,\n",
       "            0.3694, 0.369 , 0.3687, 0.3684, 0.368 , 0.3674, 0.3672, 0.367 ,\n",
       "            0.3667, 0.3662, 0.3655, 0.365 , 0.3647, 0.3645, 0.3643, 0.3638,\n",
       "            0.3635, 0.3633, 0.3623, 0.362 , 0.361 , 0.3599, 0.3542, 0.354 ,\n",
       "            0.352 , 0.3486, 0.348 , 0.3477, 0.3455, 0.3403, 0.3386, 0.3354,\n",
       "            0.335 , 0.334 , 0.3308, 0.3296, 0.3281, 0.3274, 0.3208, 0.3176,\n",
       "            0.317 , 0.3167, 0.3162, 0.315 , 0.3147, 0.3142, 0.314 , 0.313 ,\n",
       "            0.3123, 0.311 , 0.3103, 0.31  , 0.3098, 0.3093, 0.308 , 0.3076,\n",
       "            0.3066, 0.3064, 0.306 , 0.3054, 0.3047, 0.3044, 0.304 , 0.3037,\n",
       "            0.3035, 0.3008, 0.299 , 0.2988, 0.297 , 0.2969, 0.2966, 0.296 ,\n",
       "            0.2957, 0.295 , 0.2942, 0.294 , 0.2935, 0.2927, 0.2925, 0.292 ,\n",
       "            0.2908, 0.2905, 0.29  , 0.2896, 0.289 , 0.2874, 0.2866, 0.2864,\n",
       "            0.286 , 0.2856, 0.2854, 0.2852, 0.2847, 0.2844, 0.2842, 0.284 ,\n",
       "            0.2837, 0.2832, 0.2827, 0.2812, 0.281 , 0.28  , 0.2788, 0.2786,\n",
       "            0.278 , 0.2778, 0.2773, 0.2766, 0.2764, 0.276 , 0.2756, 0.2754,\n",
       "            0.2751, 0.275 , 0.274 , 0.2737, 0.273 , 0.2722, 0.2708, 0.27  ,\n",
       "            0.2683, 0.2678, 0.267 , 0.2668, 0.2664, 0.2651, 0.2646, 0.2644,\n",
       "            0.264 , 0.2632, 0.263 , 0.2622, 0.2617, 0.2607, 0.2605, 0.2603,\n",
       "            0.2593, 0.259 , 0.2583, 0.2576, 0.2573, 0.2568, 0.256 , 0.2556,\n",
       "            0.2554, 0.2551, 0.255 , 0.2546, 0.2544, 0.2534, 0.252 , 0.2515,\n",
       "            0.2502, 0.25  , 0.2493, 0.2487, 0.248 , 0.2478, 0.247 , 0.2467,\n",
       "            0.2463, 0.2441, 0.243 , 0.2426, 0.2413, 0.2407, 0.2397, 0.2391,\n",
       "            0.2379, 0.236 , 0.2355, 0.2352, 0.234 , 0.2319, 0.2313, 0.2292,\n",
       "            0.2285, 0.2264, 0.2257, 0.2249, 0.2246, 0.2239, 0.215 , 0.2135,\n",
       "            0.2091, 0.2076, 0.2073, 0.2023, 0.2006, 0.2001, 0.1993, 0.1959,\n",
       "            0.1927, 0.1909, 0.1903, 0.1648], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.06779661, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11864407, 0.13559322, 0.15254237, 0.16949153, 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.33050847, 0.33898306,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 , 0.5508475 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.6101695 , 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.63559324, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.720339  , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.779661  , 0.779661  , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8135593 , 0.8135593 , 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.8305085 , 0.83898306, 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.89830506, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.18939394, 0.1969697 , 0.1969697 , 0.1969697 , 0.20454545,\n",
       "            0.20454545, 0.20454545, 0.21969697, 0.22727273, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.28787878, 0.29545453, 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.32575756, 0.32575756, 0.32575756,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.4090909 , 0.41666666, 0.42424244, 0.42424244,\n",
       "            0.42424244, 0.4318182 , 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.46212122, 0.4848485 , 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3708, 0.3672, 0.366 , 0.3608, 0.3606, 0.3594, 0.3591,\n",
       "            0.359 , 0.3586, 0.3582, 0.3572, 0.357 , 0.356 , 0.3557, 0.3555,\n",
       "            0.3552, 0.355 , 0.3545, 0.354 , 0.3538, 0.3533, 0.353 , 0.3523,\n",
       "            0.352 , 0.3518, 0.3513, 0.351 , 0.35  , 0.3496, 0.3486, 0.3484,\n",
       "            0.3472, 0.3464, 0.346 , 0.3445, 0.344 , 0.339 , 0.3372, 0.3362,\n",
       "            0.3325, 0.3323, 0.331 , 0.3306, 0.3303, 0.3245, 0.3228, 0.3198,\n",
       "            0.3184, 0.3176, 0.3137, 0.3118, 0.31  , 0.3093, 0.3083, 0.3032,\n",
       "            0.2998, 0.299 , 0.2988, 0.2986, 0.2983, 0.297 , 0.2964, 0.2961,\n",
       "            0.2957, 0.2944, 0.294 , 0.2927, 0.292 , 0.2893, 0.289 , 0.2888,\n",
       "            0.2886, 0.2883, 0.288 , 0.2878, 0.2874, 0.2869, 0.286 , 0.2847,\n",
       "            0.283 , 0.2822, 0.282 , 0.2808, 0.28  , 0.2798, 0.278 , 0.2776,\n",
       "            0.2773, 0.2756, 0.2747, 0.274 , 0.2737, 0.2734, 0.2732, 0.2727,\n",
       "            0.271 , 0.2708, 0.2705, 0.2695, 0.2688, 0.2673, 0.267 , 0.2668,\n",
       "            0.2664, 0.2659, 0.2656, 0.2654, 0.265 , 0.2646, 0.2644, 0.264 ,\n",
       "            0.2634, 0.263 , 0.2625, 0.2612, 0.261 , 0.2607, 0.258 , 0.2578,\n",
       "            0.2576, 0.257 , 0.2563, 0.256 , 0.2559, 0.2554, 0.255 , 0.2546,\n",
       "            0.2542, 0.2534, 0.2527, 0.2524, 0.252 , 0.2517, 0.2515, 0.251 ,\n",
       "            0.2502, 0.2493, 0.2471, 0.2466, 0.2462, 0.246 , 0.2452, 0.2441,\n",
       "            0.2429, 0.2422, 0.2421, 0.2411, 0.2406, 0.2401, 0.2394, 0.239 ,\n",
       "            0.2378, 0.2358, 0.2356, 0.235 , 0.2344, 0.2343, 0.2339, 0.2338,\n",
       "            0.2335, 0.233 , 0.2325, 0.2319, 0.2316, 0.2303, 0.2297, 0.2294,\n",
       "            0.2286, 0.2272, 0.2268, 0.2264, 0.2257, 0.2251, 0.2249, 0.2224,\n",
       "            0.222 , 0.2202, 0.2198, 0.2189, 0.2186, 0.2168, 0.2161, 0.2148,\n",
       "            0.2142, 0.2137, 0.2123, 0.2114, 0.2108, 0.2098, 0.2089, 0.207 ,\n",
       "            0.2034, 0.2028, 0.2018, 0.2012, 0.2   , 0.1989, 0.1984, 0.19  ,\n",
       "            0.1877, 0.1843, 0.1838, 0.1815, 0.1768, 0.1753, 0.1744, 0.1735,\n",
       "            0.1704, 0.1699, 0.1674, 0.1653, 0.1647, 0.1396], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.10169491, 0.11016949, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.18644068,\n",
       "            0.19491525, 0.21186441, 0.22881356, 0.23728813, 0.2542373 ,\n",
       "            0.2542373 , 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33898306, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.63559324, 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7881356 , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8135593 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 , 0.8305085 ,\n",
       "            0.83898306, 0.83898306, 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.89830506, 0.89830506, 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06818182, 0.07575758, 0.08333334, 0.08333334, 0.09090909,\n",
       "            0.09090909, 0.09848485, 0.09848485, 0.09848485, 0.10606061,\n",
       "            0.12121212, 0.13636364, 0.14393939, 0.15151516, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.18939394, 0.18939394,\n",
       "            0.1969697 , 0.1969697 , 0.1969697 , 0.20454545, 0.20454545,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.31060606, 0.31060606, 0.31060606, 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.49242425, 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.59090906, 0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3564, 0.3542, 0.3538, 0.3533, 0.3477, 0.3467, 0.3464,\n",
       "            0.3462, 0.3457, 0.3455, 0.3452, 0.345 , 0.3447, 0.3445, 0.344 ,\n",
       "            0.3435, 0.3433, 0.343 , 0.3428, 0.3425, 0.3418, 0.3408, 0.34  ,\n",
       "            0.339 , 0.3389, 0.3386, 0.3376, 0.3374, 0.3372, 0.337 , 0.3364,\n",
       "            0.3362, 0.3354, 0.335 , 0.3337, 0.3318, 0.3315, 0.331 , 0.3284,\n",
       "            0.328 , 0.3242, 0.3223, 0.319 , 0.3167, 0.3154, 0.3147, 0.3135,\n",
       "            0.3086, 0.3066, 0.304 , 0.3015, 0.2964, 0.294 , 0.2927, 0.291 ,\n",
       "            0.2898, 0.2864, 0.282 , 0.2815, 0.281 , 0.2786, 0.278 , 0.277 ,\n",
       "            0.2766, 0.2761, 0.2751, 0.2742, 0.2712, 0.27  , 0.2695, 0.269 ,\n",
       "            0.2688, 0.2686, 0.2678, 0.2659, 0.2622, 0.2617, 0.2615, 0.2612,\n",
       "            0.2595, 0.2593, 0.2585, 0.2559, 0.2556, 0.255 , 0.2546, 0.254 ,\n",
       "            0.2534, 0.253 , 0.2524, 0.2522, 0.252 , 0.2517, 0.249 , 0.2487,\n",
       "            0.2482, 0.2478, 0.2477, 0.2467, 0.2463, 0.2462, 0.246 , 0.2458,\n",
       "            0.2452, 0.2449, 0.2448, 0.2445, 0.2437, 0.2429, 0.2421, 0.2418,\n",
       "            0.2415, 0.2388, 0.2383, 0.2382, 0.2375, 0.2367, 0.2363, 0.2358,\n",
       "            0.2356, 0.2352, 0.2351, 0.235 , 0.2347, 0.2338, 0.2334, 0.233 ,\n",
       "            0.2327, 0.2319, 0.2318, 0.2316, 0.2307, 0.2302, 0.2301, 0.2294,\n",
       "            0.2286, 0.2269, 0.2261, 0.2257, 0.2252, 0.224 , 0.2229, 0.222 ,\n",
       "            0.2218, 0.2211, 0.2203, 0.219 , 0.2181, 0.2175, 0.2167, 0.2161,\n",
       "            0.2142, 0.2139, 0.2137, 0.2135, 0.2134, 0.2133, 0.2125, 0.2108,\n",
       "            0.2106, 0.21  , 0.2098, 0.2096, 0.208 , 0.2074, 0.2064, 0.2063,\n",
       "            0.2056, 0.205 , 0.2043, 0.204 , 0.2026, 0.2024, 0.2   , 0.1993,\n",
       "            0.199 , 0.1981, 0.1978, 0.1968, 0.1947, 0.194 , 0.1936, 0.1913,\n",
       "            0.1906, 0.1893, 0.1891, 0.1886, 0.1877, 0.1873, 0.1846, 0.1805,\n",
       "            0.1799, 0.1797, 0.1787, 0.1768, 0.1755, 0.1754, 0.1677, 0.165 ,\n",
       "            0.163 , 0.1617, 0.159 , 0.1544, 0.153 , 0.1517, 0.1508, 0.1481,\n",
       "            0.1476, 0.1453, 0.1432, 0.1423, 0.1184], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.12711865, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.3220339 , 0.33050847, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.4661017 , 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.63559324, 0.63559324,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.8305085 , 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.83898306, 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.89830506,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06818182, 0.06818182, 0.07575758, 0.07575758, 0.08333334,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.12878788, 0.14393939, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.17424242, 0.18181819,\n",
       "            0.18181819, 0.1969697 , 0.1969697 , 0.1969697 , 0.1969697 ,\n",
       "            0.20454545, 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.31060606, 0.31060606, 0.31060606, 0.31060606,\n",
       "            0.3181818 , 0.3181818 , 0.32575756, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.47727272, 0.49242425, 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.57575756, 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.84090906,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3423 , 0.3413 , 0.3408 , 0.3403 , 0.3345 , 0.334  ,\n",
       "            0.3337 , 0.333  , 0.3325 , 0.3323 , 0.332  , 0.3318 , 0.3315 ,\n",
       "            0.3313 , 0.3308 , 0.3306 , 0.3303 , 0.33   , 0.3293 , 0.3286 ,\n",
       "            0.3284 , 0.327  , 0.3264 , 0.3262 , 0.3254 , 0.3252 , 0.3237 ,\n",
       "            0.3235 , 0.323  , 0.3225 , 0.3213 , 0.321  , 0.3193 , 0.319  ,\n",
       "            0.3174 , 0.3162 , 0.313  , 0.3118 , 0.309  , 0.3074 , 0.3025 ,\n",
       "            0.301  , 0.3005 , 0.2983 , 0.297  , 0.2927 , 0.2908 , 0.2878 ,\n",
       "            0.2852 , 0.285  , 0.279  , 0.2764 , 0.2756 , 0.273  , 0.2717 ,\n",
       "            0.2693 , 0.2646 , 0.2644 , 0.2642 , 0.2637 , 0.2632 , 0.2612 ,\n",
       "            0.261  , 0.2595 , 0.2585 , 0.258  , 0.2576 , 0.2566 , 0.255  ,\n",
       "            0.2534 , 0.2522 , 0.252  , 0.2517 , 0.2512 , 0.251  , 0.2507 ,\n",
       "            0.2502 , 0.2498 , 0.2489 , 0.2477 , 0.2438 , 0.2433 , 0.2429 ,\n",
       "            0.2424 , 0.2422 , 0.2417 , 0.2411 , 0.2399 , 0.2374 , 0.237  ,\n",
       "            0.2366 , 0.2363 , 0.2352 , 0.2344 , 0.2339 , 0.2334 , 0.2332 ,\n",
       "            0.2319 , 0.2299 , 0.2294 , 0.2292 , 0.2289 , 0.2285 , 0.2281 ,\n",
       "            0.2277 , 0.2273 , 0.2272 , 0.2269 , 0.2266 , 0.2263 , 0.2257 ,\n",
       "            0.2247 , 0.2239 , 0.2238 , 0.223  , 0.2227 , 0.2216 , 0.2194 ,\n",
       "            0.2191 , 0.2186 , 0.2177 , 0.2175 , 0.2173 , 0.2163 , 0.2161 ,\n",
       "            0.2158 , 0.2148 , 0.2147 , 0.2145 , 0.2139 , 0.2135 , 0.2128 ,\n",
       "            0.2125 , 0.2115 , 0.2108 , 0.2106 , 0.2101 , 0.2098 , 0.2089 ,\n",
       "            0.2079 , 0.2076 , 0.2069 , 0.206  , 0.2058 , 0.2048 , 0.2035 ,\n",
       "            0.2028 , 0.2026 , 0.2017 , 0.201  , 0.1996 , 0.1982 , 0.1981 ,\n",
       "            0.1948 , 0.1943 , 0.194  , 0.1937 , 0.1936 , 0.193  , 0.1927 ,\n",
       "            0.1909 , 0.1903 , 0.1898 , 0.1892 , 0.1884 , 0.1882 , 0.1873 ,\n",
       "            0.1865 , 0.1855 , 0.1852 , 0.1846 , 0.1831 , 0.1821 , 0.1813 ,\n",
       "            0.1797 , 0.1791 , 0.1785 , 0.1782 , 0.1781 , 0.1775 , 0.1766 ,\n",
       "            0.1744 , 0.1741 , 0.1735 , 0.1704 , 0.1694 , 0.1693 , 0.1686 ,\n",
       "            0.1683 , 0.1678 , 0.1664 , 0.1646 , 0.1608 , 0.1602 , 0.1587 ,\n",
       "            0.1583 , 0.1559 , 0.1544 , 0.1481 , 0.1444 , 0.1432 , 0.142  ,\n",
       "            0.1392 , 0.1349 , 0.1333 , 0.132  , 0.1309 , 0.1285 , 0.1276 ,\n",
       "            0.126  , 0.1238 , 0.12305, 0.10034], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.02542373, 0.03389831, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.09322034, 0.12711865, 0.13559322,\n",
       "            0.15254237, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.31355932, 0.3220339 , 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.44067797, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8135593 ,\n",
       "            0.8220339 , 0.8220339 , 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.83898306, 0.83898306, 0.83898306, 0.84745765, 0.84745765,\n",
       "            0.8559322 , 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9237288 , 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.07575758, 0.08333334,\n",
       "            0.08333334, 0.09848485, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.1969697 , 0.1969697 , 0.20454545,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25      , 0.25757575, 0.2651515 , 0.27272728,\n",
       "            0.28030303, 0.28030303, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.31060606, 0.31060606, 0.31060606, 0.3181818 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46212122, 0.47727272, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.5530303 , 0.56060606, 0.57575756,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.99242425,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3284 , 0.3281 , 0.327  , 0.3215 , 0.3208 , 0.3203 ,\n",
       "            0.319  , 0.3188 , 0.3186 , 0.3184 , 0.3179 , 0.3176 , 0.3171 ,\n",
       "            0.3164 , 0.316  , 0.315  , 0.3142 , 0.313  , 0.3125 , 0.3123 ,\n",
       "            0.3118 , 0.3115 , 0.3105 , 0.3098 , 0.3093 , 0.3088 , 0.3079 ,\n",
       "            0.3076 , 0.3074 , 0.3066 , 0.3047 , 0.303  , 0.3018 , 0.3013 ,\n",
       "            0.301  , 0.2979 , 0.2954 , 0.2947 , 0.293  , 0.2861 , 0.286  ,\n",
       "            0.2856 , 0.2825 , 0.2808 , 0.2776 , 0.2751 , 0.2722 , 0.2688 ,\n",
       "            0.2683 , 0.2622 , 0.2595 , 0.2588 , 0.2556 , 0.2544 , 0.2527 ,\n",
       "            0.2478 , 0.2474 , 0.2473 , 0.247  , 0.2462 , 0.2441 , 0.2438 ,\n",
       "            0.2422 , 0.2417 , 0.2413 , 0.2405 , 0.2395 , 0.2368 , 0.2363 ,\n",
       "            0.235  , 0.2344 , 0.2343 , 0.2339 , 0.2338 , 0.2334 , 0.2325 ,\n",
       "            0.2322 , 0.2316 , 0.2302 , 0.2299 , 0.2266 , 0.2252 , 0.2242 ,\n",
       "            0.2238 , 0.2234 , 0.2229 , 0.222  , 0.2195 , 0.2189 , 0.2186 ,\n",
       "            0.2184 , 0.2172 , 0.2162 , 0.2157 , 0.2152 , 0.2144 , 0.2128 ,\n",
       "            0.2115 , 0.2114 , 0.2113 , 0.2104 , 0.21   , 0.2095 , 0.2091 ,\n",
       "            0.209  , 0.2089 , 0.2085 , 0.2084 , 0.2073 , 0.2065 , 0.2058 ,\n",
       "            0.2051 , 0.2048 , 0.2047 , 0.2045 , 0.2021 , 0.2013 , 0.2012 ,\n",
       "            0.2007 , 0.1995 , 0.1993 , 0.1991 , 0.1984 , 0.1981 , 0.1979 ,\n",
       "            0.1974 , 0.1967 , 0.1959 , 0.1954 , 0.1953 , 0.195  , 0.1947 ,\n",
       "            0.1943 , 0.1942 , 0.1941 , 0.1923 , 0.1919 , 0.1913 , 0.1909 ,\n",
       "            0.1903 , 0.1896 , 0.189  , 0.1886 , 0.1879 , 0.1877 , 0.1876 ,\n",
       "            0.1873 , 0.1865 , 0.1852 , 0.1844 , 0.1842 , 0.1833 , 0.1826 ,\n",
       "            0.1813 , 0.1797 , 0.1794 , 0.1758 , 0.1757 , 0.1755 , 0.1753 ,\n",
       "            0.1752 , 0.1749 , 0.1748 , 0.1747 , 0.1743 , 0.1733 , 0.1724 ,\n",
       "            0.1719 , 0.171  , 0.1699 , 0.1694 , 0.1685 , 0.1682 , 0.167  ,\n",
       "            0.1661 , 0.1647 , 0.1637 , 0.1627 , 0.1616 , 0.1611 , 0.1599 ,\n",
       "            0.1597 , 0.1592 , 0.1582 , 0.1577 , 0.1559 , 0.1556 , 0.1547 ,\n",
       "            0.151  , 0.1509 , 0.1508 , 0.15   , 0.1499 , 0.1495 , 0.149  ,\n",
       "            0.1475 , 0.146  , 0.1425 , 0.1418 , 0.1395 , 0.1394 , 0.1393 ,\n",
       "            0.1367 , 0.1355 , 0.1354 , 0.13   , 0.1256 , 0.1252 , 0.1241 ,\n",
       "            0.1214 , 0.1172 , 0.1158 , 0.1142 , 0.113  , 0.111  , 0.1099 ,\n",
       "            0.10876, 0.1067 , 0.10596, 0.0845 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05932203, 0.06779661, 0.07627118, 0.11864407,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7118644 , 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.779661  , 0.779661  , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.8305085 , 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.84745765, 0.84745765, 0.8559322 , 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.89830506,\n",
       "            0.89830506, 0.90677965, 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9237288 , 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.12878788, 0.13636364, 0.13636364, 0.13636364,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.16666667, 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18181819, 0.18181819, 0.18939394,\n",
       "            0.18939394, 0.1969697 , 0.1969697 , 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25      , 0.25      , 0.25757575, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.29545453, 0.3030303 , 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.3181818 , 0.3181818 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.59090906, 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.99242425,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.316  , 0.3157 , 0.3142 , 0.3137 , 0.3096 , 0.3086 ,\n",
       "            0.3083 , 0.307  , 0.3062 , 0.306  , 0.3054 , 0.3052 , 0.305  ,\n",
       "            0.3035 , 0.303  , 0.3018 , 0.3013 , 0.3005 , 0.3    , 0.2996 ,\n",
       "            0.2993 , 0.298  , 0.2979 , 0.2974 , 0.2966 , 0.2954 , 0.2952 ,\n",
       "            0.2944 , 0.2942 , 0.2932 , 0.2925 , 0.292  , 0.2903 , 0.2888 ,\n",
       "            0.2874 , 0.2864 , 0.286  , 0.283  , 0.2808 , 0.28   , 0.2786 ,\n",
       "            0.2712 , 0.271  , 0.2703 , 0.267  , 0.2654 , 0.2625 , 0.259  ,\n",
       "            0.2568 , 0.2524 , 0.2452 , 0.2428 , 0.2421 , 0.2388 , 0.2366 ,\n",
       "            0.2314 , 0.2306 , 0.2303 , 0.2302 , 0.2295 , 0.2277 , 0.2269 ,\n",
       "            0.2256 , 0.2251 , 0.2247 , 0.2239 , 0.2233 , 0.223  , 0.2197 ,\n",
       "            0.2189 , 0.2184 , 0.2177 , 0.2172 , 0.217  , 0.2168 , 0.2167 ,\n",
       "            0.2161 , 0.2157 , 0.2152 , 0.2139 , 0.2125 , 0.2124 , 0.2096 ,\n",
       "            0.2084 , 0.2079 , 0.2074 , 0.207  , 0.2063 , 0.2051 , 0.2048 ,\n",
       "            0.2045 , 0.2024 , 0.2015 , 0.2013 , 0.2012 , 0.2009 , 0.1993 ,\n",
       "            0.1987 , 0.1984 , 0.1981 , 0.196  , 0.1946 , 0.1943 , 0.1941 ,\n",
       "            0.1931 , 0.1927 , 0.1925 , 0.1921 , 0.1919 , 0.1918 , 0.1913 ,\n",
       "            0.1912 , 0.191  , 0.1898 , 0.1891 , 0.1884 , 0.188  , 0.1877 ,\n",
       "            0.1858 , 0.1855 , 0.1844 , 0.1842 , 0.1841 , 0.1833 , 0.1823 ,\n",
       "            0.1821 , 0.1816 , 0.1812 , 0.1807 , 0.1799 , 0.1794 , 0.1792 ,\n",
       "            0.1785 , 0.1782 , 0.1774 , 0.1771 , 0.1764 , 0.1759 , 0.1752 ,\n",
       "            0.1747 , 0.1746 , 0.1729 , 0.1725 , 0.1724 , 0.1714 , 0.1708 ,\n",
       "            0.1705 , 0.1699 , 0.1698 , 0.1693 , 0.1678 , 0.1671 , 0.167  ,\n",
       "            0.166  , 0.165  , 0.164  , 0.1624 , 0.1619 , 0.1594 , 0.1584 ,\n",
       "            0.1582 , 0.1581 , 0.158  , 0.1575 , 0.1573 , 0.1572 , 0.1565 ,\n",
       "            0.1558 , 0.1556 , 0.1549 , 0.1548 , 0.1545 , 0.1527 , 0.1517 ,\n",
       "            0.1514 , 0.1509 , 0.1506 , 0.1498 , 0.149  , 0.1483 , 0.1467 ,\n",
       "            0.1466 , 0.146  , 0.1444 , 0.144  , 0.1438 , 0.1425 , 0.1422 ,\n",
       "            0.1417 , 0.1401 , 0.1398 , 0.1385 , 0.1383 , 0.1354 , 0.1353 ,\n",
       "            0.1343 , 0.1342 , 0.1329 , 0.1326 , 0.1322 , 0.13   , 0.1296 ,\n",
       "            0.1257 , 0.12494, 0.1229 , 0.12286, 0.1225 , 0.1201 , 0.119  ,\n",
       "            0.1188 , 0.115  , 0.1095 , 0.10913, 0.10876, 0.10614, 0.1025 ,\n",
       "            0.1011 , 0.0993 , 0.0974 , 0.0967 , 0.09485, 0.0945 , 0.0925 ,\n",
       "            0.09155, 0.07196], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01694915, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.09322034, 0.11864407,\n",
       "            0.12711865, 0.15254237, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.22033899, 0.22881356, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.4661017 , 0.4661017 ,\n",
       "            0.4661017 , 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6864407 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.779661  , 0.779661  , 0.779661  , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.80508476, 0.8135593 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 , 0.8305085 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.84745765, 0.8559322 ,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.90677965, 0.91525424, 0.91525424, 0.9237288 , 0.9237288 ,\n",
       "            0.9237288 , 0.9322034 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9915254 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.01515152, 0.01515152,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.08333334, 0.08333334, 0.09090909, 0.09090909, 0.09848485,\n",
       "            0.09848485, 0.09848485, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.12878788, 0.12878788, 0.13636364,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.16666667, 0.18181819, 0.18181819, 0.18181819, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.1969697 , 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25      , 0.25757575, 0.25757575, 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.3030303 , 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.3030303 , 0.31060606, 0.31060606,\n",
       "            0.31060606, 0.3181818 , 0.3181818 , 0.32575756, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.37878788, 0.3939394 , 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.4848485 , 0.49242425,\n",
       "            0.5       , 0.5       , 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.57575756, 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.304  , 0.3013 , 0.298  , 0.297  , 0.2964 , 0.2961 ,\n",
       "            0.2952 , 0.2942 , 0.294  , 0.2937 , 0.2935 , 0.2932 , 0.2927 ,\n",
       "            0.2925 , 0.2915 , 0.29   , 0.2886 , 0.2874 , 0.2869 , 0.2864 ,\n",
       "            0.2847 , 0.2842 , 0.284  , 0.2834 , 0.282  , 0.2817 , 0.2812 ,\n",
       "            0.281  , 0.2808 , 0.2788 , 0.2786 , 0.2769 , 0.2761 , 0.2747 ,\n",
       "            0.273  , 0.2717 , 0.2695 , 0.268  , 0.2659 , 0.2654 , 0.2642 ,\n",
       "            0.2566 , 0.2554 , 0.2551 , 0.255  , 0.2517 , 0.2496 , 0.2474 ,\n",
       "            0.243  , 0.2413 , 0.2363 , 0.2285 , 0.2264 , 0.2256 , 0.2222 ,\n",
       "            0.222  , 0.22   , 0.215  , 0.2139 , 0.2137 , 0.2135 , 0.2129 ,\n",
       "            0.2109 , 0.2101 , 0.2086 , 0.2084 , 0.2076 , 0.2068 , 0.2063 ,\n",
       "            0.2034 , 0.202  , 0.2017 , 0.2013 , 0.2009 , 0.2006 , 0.2004 ,\n",
       "            0.2002 , 0.1993 , 0.199  , 0.1984 , 0.1967 , 0.196  , 0.1947 ,\n",
       "            0.1927 , 0.1918 , 0.1906 , 0.1903 , 0.1887 , 0.1884 , 0.1874 ,\n",
       "            0.1866 , 0.1858 , 0.1849 , 0.1843 , 0.1841 , 0.1838 , 0.183  ,\n",
       "            0.1824 , 0.1814 , 0.1813 , 0.1783 , 0.178  , 0.1779 , 0.1774 ,\n",
       "            0.1772 , 0.1763 , 0.1759 , 0.1755 , 0.1754 , 0.1753 , 0.1752 ,\n",
       "            0.1749 , 0.1748 , 0.1747 , 0.1743 , 0.1731 , 0.173  , 0.1725 ,\n",
       "            0.1716 , 0.1711 , 0.1677 , 0.1676 , 0.1666 , 0.1656 , 0.1653 ,\n",
       "            0.1649 , 0.1647 , 0.164  , 0.1632 , 0.163  , 0.1619 , 0.1615 ,\n",
       "            0.1614 , 0.1609 , 0.1605 , 0.1597 , 0.1587 , 0.1582 , 0.1581 ,\n",
       "            0.158  , 0.1577 , 0.1571 , 0.157  , 0.1559 , 0.155  , 0.1549 ,\n",
       "            0.1548 , 0.1543 , 0.154  , 0.1533 , 0.1528 , 0.1527 , 0.1519 ,\n",
       "            0.1515 , 0.1506 , 0.1505 , 0.1497 , 0.1483 , 0.1476 , 0.1461 ,\n",
       "            0.1451 , 0.1427 , 0.142  , 0.1417 , 0.1416 , 0.1415 , 0.141  ,\n",
       "            0.1409 , 0.1407 , 0.139  , 0.1385 , 0.1383 , 0.138  , 0.1378 ,\n",
       "            0.1364 , 0.1346 , 0.1342 , 0.134  , 0.1335 , 0.1329 , 0.1327 ,\n",
       "            0.1317 , 0.1295 , 0.1289 , 0.1288 , 0.1279 , 0.1273 , 0.1272 ,\n",
       "            0.1265 , 0.1257 , 0.1251 , 0.12317, 0.1226 , 0.1225 , 0.1214 ,\n",
       "            0.1193 , 0.119  , 0.118  , 0.1172 , 0.11676, 0.11597, 0.11536,\n",
       "            0.11395, 0.1136 , 0.1103 , 0.1095 , 0.1065 , 0.1063 , 0.10596,\n",
       "            0.10376, 0.1025 , 0.1023 , 0.0997 , 0.094  , 0.0939 , 0.0937 ,\n",
       "            0.09106, 0.0877 , 0.0865 , 0.0845 , 0.0823 , 0.0804 , 0.0798 ,\n",
       "            0.07837, 0.0775 , 0.05954], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.07627118, 0.08474576,\n",
       "            0.10169491, 0.11864407, 0.1440678 , 0.15254237, 0.16949153,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.22033899, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.60169494, 0.60169494, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.65254235, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7033898 , 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.779661  , 0.779661  , 0.779661  , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8220339 ,\n",
       "            0.8305085 , 0.8305085 , 0.8305085 , 0.8305085 , 0.84745765,\n",
       "            0.84745765, 0.84745765, 0.8559322 , 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.89830506,\n",
       "            0.89830506, 0.89830506, 0.90677965, 0.90677965, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.9237288 , 0.9237288 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.94067794, 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 0.9915254 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03787879, 0.03787879, 0.03787879, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.0530303 , 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.09090909, 0.09090909,\n",
       "            0.09848485, 0.09848485, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.13636364,\n",
       "            0.13636364, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.1969697 , 0.20454545,\n",
       "            0.20454545, 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.25      , 0.25757575, 0.25757575, 0.2651515 ,\n",
       "            0.2651515 , 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.31060606, 0.31060606,\n",
       "            0.3181818 , 0.3181818 , 0.3181818 , 0.3181818 , 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.75      , 0.75757575,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2913 , 0.291  , 0.288  , 0.2874 , 0.286  , 0.2852 ,\n",
       "            0.2837 , 0.2832 , 0.2825 , 0.2822 , 0.282  , 0.2815 , 0.2812 ,\n",
       "            0.281  , 0.2805 , 0.279  , 0.277  , 0.2761 , 0.2747 , 0.2742 ,\n",
       "            0.2734 , 0.2722 , 0.272  , 0.2715 , 0.2705 , 0.269  , 0.2688 ,\n",
       "            0.2683 , 0.268  , 0.2676 , 0.266  , 0.2656 , 0.263  , 0.262  ,\n",
       "            0.2615 , 0.2598 , 0.2595 , 0.2576 , 0.2554 , 0.2542 , 0.2524 ,\n",
       "            0.2505 , 0.2438 , 0.2428 , 0.2415 , 0.2401 , 0.2384 , 0.2374 ,\n",
       "            0.2334 , 0.2277 , 0.2266 , 0.2208 , 0.2207 , 0.213  , 0.2109 ,\n",
       "            0.2098 , 0.2079 , 0.2039 , 0.1993 , 0.1982 , 0.1978 , 0.1974 ,\n",
       "            0.197  , 0.1952 , 0.1943 , 0.1931 , 0.1925 , 0.1924 , 0.1913 ,\n",
       "            0.1912 , 0.1877 , 0.1876 , 0.1865 , 0.1864 , 0.1858 , 0.1853 ,\n",
       "            0.185  , 0.1849 , 0.1848 , 0.1837 , 0.1827 , 0.1812 , 0.181  ,\n",
       "            0.1803 , 0.1771 , 0.1764 , 0.1763 , 0.1748 , 0.1747 , 0.1746 ,\n",
       "            0.1737 , 0.1735 , 0.1726 , 0.1718 , 0.1703 , 0.1694 , 0.1683 ,\n",
       "            0.1682 , 0.1676 , 0.167  , 0.1658 , 0.1637 , 0.1627 , 0.1626 ,\n",
       "            0.1622 , 0.1619 , 0.1617 , 0.1616 , 0.1614 , 0.1604 , 0.1602 ,\n",
       "            0.1599 , 0.1598 , 0.1597 , 0.1594 , 0.1593 , 0.1589 , 0.1586 ,\n",
       "            0.1572 , 0.1567 , 0.1562 , 0.1561 , 0.156  , 0.1543 , 0.1527 ,\n",
       "            0.1525 , 0.1523 , 0.1511 , 0.1504 , 0.1497 , 0.1495 , 0.1494 ,\n",
       "            0.1484 , 0.1477 , 0.1471 , 0.1466 , 0.146  , 0.1459 , 0.1458 ,\n",
       "            0.1449 , 0.1432 , 0.1431 , 0.143  , 0.1426 , 0.1422 , 0.1417 ,\n",
       "            0.141  , 0.1409 , 0.1399 , 0.1398 , 0.1394 , 0.139  , 0.138  ,\n",
       "            0.1378 , 0.1372 , 0.1364 , 0.1356 , 0.1354 , 0.1346 , 0.133  ,\n",
       "            0.1328 , 0.1326 , 0.1311 , 0.1299 , 0.128  , 0.1278 , 0.1272 ,\n",
       "            0.1268 , 0.1267 , 0.1266 , 0.1262 , 0.1257 , 0.1256 , 0.1245 ,\n",
       "            0.12366, 0.1236 , 0.12213, 0.1217 , 0.12103, 0.12   , 0.1188 ,\n",
       "            0.1186 , 0.1184 , 0.11816, 0.1172 , 0.1166 , 0.11633, 0.11597,\n",
       "            0.11456, 0.1138 , 0.1134 , 0.112  , 0.11127, 0.11084, 0.11066,\n",
       "            0.1101 , 0.10895, 0.1082 , 0.1069 , 0.10504, 0.10486, 0.1047 ,\n",
       "            0.10266, 0.1    , 0.0967 , 0.09656, 0.0964 , 0.0959 , 0.09515,\n",
       "            0.0939 , 0.0927 , 0.0922 , 0.09155, 0.086  , 0.08417, 0.0827 ,\n",
       "            0.08093, 0.0798 , 0.0786 , 0.0761 , 0.0745 , 0.0734 , 0.0729 ,\n",
       "            0.0712 , 0.0708 , 0.06995, 0.0533 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.08474576,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.22033899, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.63559324, 0.6440678 ,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.65254235, 0.66101694,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7033898 , 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.779661  , 0.779661  ,\n",
       "            0.779661  , 0.7881356 , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8220339 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.8305085 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.9322034 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.13636364, 0.13636364, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.16666667, 0.17424242, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.18939394, 0.1969697 , 0.1969697 ,\n",
       "            0.20454545, 0.20454545, 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.3181818 ,\n",
       "            0.3181818 , 0.3181818 , 0.3181818 , 0.3181818 , 0.32575756,\n",
       "            0.3409091 , 0.3560606 , 0.36363637, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.47727272, 0.47727272, 0.4848485 , 0.49242425, 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.6060606 , 0.6060606 , 0.6212121 ,\n",
       "            0.6287879 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6818182 , 0.6969697 , 0.70454544, 0.70454544, 0.719697  ,\n",
       "            0.72727275, 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.97727275, 0.9848485 , 0.99242425, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2788 , 0.2783 , 0.2751 , 0.274  , 0.2737 , 0.2734 ,\n",
       "            0.2715 , 0.2712 , 0.2705 , 0.2703 , 0.27   , 0.2698 , 0.2695 ,\n",
       "            0.2693 , 0.2688 , 0.2686 , 0.2683 , 0.2678 , 0.2668 , 0.2642 ,\n",
       "            0.2637 , 0.2622 , 0.2617 , 0.2605 , 0.2595 , 0.2585 , 0.2576 ,\n",
       "            0.256  , 0.2559 , 0.2554 , 0.255  , 0.2546 , 0.253  , 0.2527 ,\n",
       "            0.2496 , 0.2482 , 0.247  , 0.2467 , 0.2463 , 0.2445 , 0.2421 ,\n",
       "            0.239  , 0.2372 , 0.2314 , 0.229  , 0.2277 , 0.2256 , 0.2247 ,\n",
       "            0.2246 , 0.2194 , 0.2128 , 0.2123 , 0.2054 , 0.1985 , 0.1979 ,\n",
       "            0.1956 , 0.1942 , 0.1935 , 0.1882 , 0.1844 , 0.1838 , 0.1833 ,\n",
       "            0.1829 , 0.1824 , 0.1823 , 0.1797 , 0.1794 , 0.1779 , 0.1774 ,\n",
       "            0.1771 , 0.1764 , 0.1753 , 0.1729 , 0.1716 , 0.1715 , 0.1708 ,\n",
       "            0.1704 , 0.17   , 0.1699 , 0.1694 , 0.1687 , 0.1675 , 0.1671 ,\n",
       "            0.1653 , 0.165  , 0.1633 , 0.1621 , 0.162  , 0.1611 , 0.1598 ,\n",
       "            0.1597 , 0.1594 , 0.159  , 0.1575 , 0.157  , 0.1552 , 0.1543 ,\n",
       "            0.1534 , 0.1532 , 0.1531 , 0.1525 , 0.1514 , 0.1509 , 0.1508 ,\n",
       "            0.148  , 0.1472 , 0.1469 , 0.1467 , 0.1466 , 0.1465 , 0.1455 ,\n",
       "            0.145  , 0.1449 , 0.1448 , 0.1445 , 0.1442 , 0.1436 , 0.1423 ,\n",
       "            0.1418 , 0.1414 , 0.1412 , 0.1382 , 0.138  , 0.1377 , 0.1364 ,\n",
       "            0.1359 , 0.135  , 0.1349 , 0.1345 , 0.1339 , 0.1337 , 0.1333 ,\n",
       "            0.1329 , 0.1327 , 0.1322 , 0.1312 , 0.1307 , 0.1301 , 0.1287 ,\n",
       "            0.1284 , 0.1282 , 0.1279 , 0.1274 , 0.1273 , 0.127  , 0.1267 ,\n",
       "            0.1266 , 0.1265 , 0.1256 , 0.1254 , 0.12476, 0.1236 , 0.12335,\n",
       "            0.1225 , 0.1222 , 0.1214 , 0.1213 , 0.12054, 0.1186 , 0.11694,\n",
       "            0.11676, 0.11633, 0.11554, 0.113  , 0.1128 , 0.1126 , 0.1124 ,\n",
       "            0.11163, 0.11145, 0.1099 , 0.1097 , 0.10876, 0.1082 , 0.108  ,\n",
       "            0.10724, 0.1063 , 0.1052 , 0.1047 , 0.1041 , 0.1036 , 0.1034 ,\n",
       "            0.1032 , 0.10126, 0.1005 , 0.10034, 0.1    , 0.0991 , 0.09894,\n",
       "            0.09875, 0.09705, 0.096  , 0.09485, 0.09467, 0.094  , 0.0939 ,\n",
       "            0.0898 , 0.0871 , 0.0865 , 0.0859 , 0.08435, 0.08405, 0.08344,\n",
       "            0.0827 , 0.0824 , 0.082  , 0.0774 , 0.0745 , 0.07367, 0.07135,\n",
       "            0.0702 , 0.06915, 0.0672 , 0.0662 , 0.065  , 0.0644 , 0.0629 ,\n",
       "            0.06232, 0.0619 , 0.04672], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.09322034, 0.12711865,\n",
       "            0.13559322, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.63559324, 0.6440678 ,\n",
       "            0.6440678 , 0.6440678 , 0.65254235, 0.65254235, 0.66101694,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.779661  , 0.779661  , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.7966102 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.89830506,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.90677965, 0.91525424,\n",
       "            0.91525424, 0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03787879, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.04545455, 0.0530303 ,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.08333334, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.10606061, 0.10606061, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.14393939, 0.14393939, 0.15151516, 0.15151516, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.1969697 , 0.20454545, 0.20454545,\n",
       "            0.21212122, 0.21212122, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28030303, 0.28030303,\n",
       "            0.28787878, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.33333334, 0.3409091 ,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.4090909 ,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2659 , 0.2654 , 0.262  , 0.2617 , 0.2612 , 0.2595 ,\n",
       "            0.2593 , 0.259  , 0.2588 , 0.2583 , 0.258  , 0.2578 , 0.2573 ,\n",
       "            0.2563 , 0.2551 , 0.253  , 0.2527 , 0.252  , 0.2515 , 0.251  ,\n",
       "            0.2502 , 0.25   , 0.2487 , 0.2483 , 0.2471 , 0.246  , 0.2448 ,\n",
       "            0.2444 , 0.2434 , 0.2428 , 0.2426 , 0.2417 , 0.239  , 0.2374 ,\n",
       "            0.237  , 0.236  , 0.2343 , 0.2338 , 0.2325 , 0.2322 , 0.2278 ,\n",
       "            0.226  , 0.223  , 0.2175 , 0.2173 , 0.2161 , 0.2147 , 0.2129 ,\n",
       "            0.2079 , 0.2004 , 0.1995 , 0.1927 , 0.1924 , 0.1913 , 0.1853 ,\n",
       "            0.1833 , 0.1823 , 0.1815 , 0.1772 , 0.1754 , 0.1715 , 0.1711 ,\n",
       "            0.1705 , 0.17   , 0.1685 , 0.1676 , 0.1674 , 0.1653 , 0.1652 ,\n",
       "            0.1647 , 0.1646 , 0.1638 , 0.1611 , 0.1603 , 0.159  , 0.1584 ,\n",
       "            0.1583 , 0.158  , 0.1578 , 0.157  , 0.1565 , 0.1561 , 0.1559 ,\n",
       "            0.1544 , 0.1533 , 0.1515 , 0.1503 , 0.1499 , 0.1492 , 0.1482 ,\n",
       "            0.148  , 0.1477 , 0.1469 , 0.1451 , 0.1447 , 0.1432 , 0.1422 ,\n",
       "            0.142  , 0.1418 , 0.1411 , 0.1409 , 0.1395 , 0.1388 , 0.1387 ,\n",
       "            0.1367 , 0.1366 , 0.1365 , 0.1356 , 0.1351 , 0.1349 , 0.134  ,\n",
       "            0.1338 , 0.1333 , 0.1329 , 0.1328 , 0.1326 , 0.1318 , 0.1313 ,\n",
       "            0.1302 , 0.1301 , 0.13   , 0.1299 , 0.1294 , 0.1279 , 0.1278 ,\n",
       "            0.1267 , 0.1261 , 0.1249 , 0.12463, 0.1239 , 0.1238 , 0.1229 ,\n",
       "            0.1226 , 0.1222 , 0.12146, 0.121  , 0.12036, 0.11993, 0.1194 ,\n",
       "            0.1193 , 0.1192 , 0.119  , 0.1186 , 0.1178 , 0.11755, 0.1172 ,\n",
       "            0.11694, 0.11633, 0.1158 , 0.11554, 0.11475, 0.1138 , 0.113  ,\n",
       "            0.112  , 0.11145, 0.111  , 0.1105 , 0.1103 , 0.1099 , 0.1078 ,\n",
       "            0.1074 , 0.10724, 0.1063 , 0.1043 , 0.1036 , 0.103  , 0.10266,\n",
       "            0.1023 , 0.1021 , 0.1019 , 0.10175, 0.10156, 0.10144, 0.1009 ,\n",
       "            0.1005 , 0.10034, 0.0997 , 0.0995 , 0.09827, 0.0981 , 0.09753,\n",
       "            0.0974 , 0.09705, 0.0964 , 0.096  , 0.0955 , 0.09534, 0.09467,\n",
       "            0.0945 , 0.0939 , 0.09235, 0.0906 , 0.0903 , 0.0888 , 0.0887 ,\n",
       "            0.0882 , 0.088  , 0.0854 , 0.08167, 0.0808 , 0.0801 , 0.07904,\n",
       "            0.0789 , 0.0785 , 0.0775 , 0.07684, 0.075  , 0.07434, 0.07367,\n",
       "            0.0698 , 0.0678 , 0.0667 , 0.0631 , 0.0628 , 0.06177, 0.0612 ,\n",
       "            0.0603 , 0.05966, 0.05856, 0.05823, 0.04428], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.05932203, 0.07627118, 0.11016949, 0.12711865, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.4661017 , 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.55932206, 0.5677966 ,\n",
       "            0.58474576, 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7033898 , 0.7033898 ,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7288136 ,\n",
       "            0.7372881 , 0.7542373 , 0.7542373 , 0.7542373 , 0.7542373 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.83898306, 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.87288135, 0.88135594, 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.90677965, 0.9237288 ,\n",
       "            0.9237288 , 0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.9322034 , 0.94067794, 0.94067794,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.03787879, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.09848485, 0.10606061, 0.10606061,\n",
       "            0.10606061, 0.12121212, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.14393939, 0.15151516, 0.15151516, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.20454545, 0.21212122,\n",
       "            0.21212122, 0.21212122, 0.21969697, 0.22727273, 0.22727273,\n",
       "            0.23484848, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.28030303, 0.28787878, 0.28787878, 0.29545453,\n",
       "            0.29545453, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.32575756, 0.33333334, 0.33333334, 0.3409091 ,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37878788,\n",
       "            0.37878788, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.4848485 , 0.5       , 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.52272725, 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.57575756, 0.57575756,\n",
       "            0.5833333 , 0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.70454544, 0.719697  , 0.7348485 , 0.7348485 , 0.74242425,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.9166667 , 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2522 , 0.2517 , 0.2494 , 0.2493 , 0.2473 , 0.2471 ,\n",
       "            0.247  , 0.2463 , 0.2462 , 0.2458 , 0.2441 , 0.244  , 0.2434 ,\n",
       "            0.2429 , 0.2422 , 0.2417 , 0.241  , 0.2407 , 0.2394 , 0.2383 ,\n",
       "            0.2375 , 0.2374 , 0.236  , 0.2352 , 0.2339 , 0.2338 , 0.2328 ,\n",
       "            0.2327 , 0.2319 , 0.2314 , 0.2306 , 0.228  , 0.2273 , 0.2256 ,\n",
       "            0.2252 , 0.2244 , 0.2224 , 0.222  , 0.2175 , 0.2166 , 0.2144 ,\n",
       "            0.2073 , 0.2068 , 0.2058 , 0.2047 , 0.2002 , 0.1965 , 0.1886 ,\n",
       "            0.1859 , 0.1841 , 0.1799 , 0.1791 , 0.1735 , 0.1733 , 0.17   ,\n",
       "            0.1692 , 0.1688 , 0.1625 , 0.1616 , 0.1599 , 0.1584 , 0.1581 ,\n",
       "            0.1575 , 0.156  , 0.1549 , 0.1547 , 0.153  , 0.1519 , 0.1515 ,\n",
       "            0.151  , 0.1503 , 0.1487 , 0.1477 , 0.1467 , 0.1465 , 0.1455 ,\n",
       "            0.1454 , 0.1448 , 0.144  , 0.1421 , 0.1412 , 0.1411 , 0.1385 ,\n",
       "            0.1383 , 0.1376 , 0.1373 , 0.1372 , 0.1371 , 0.1365 , 0.1361 ,\n",
       "            0.1326 , 0.1312 , 0.1311 , 0.131  , 0.1307 , 0.1301 , 0.1295 ,\n",
       "            0.1289 , 0.1288 , 0.1278 , 0.1272 , 0.1268 , 0.1262 , 0.1251 ,\n",
       "            0.1239 , 0.1235 , 0.1229 , 0.12213, 0.122  , 0.1219 , 0.12177,\n",
       "            0.1217 , 0.1213 , 0.12103, 0.1207 , 0.1192 , 0.1188 , 0.1186 ,\n",
       "            0.1184 , 0.118  , 0.1178 , 0.1158 , 0.11536, 0.11475, 0.1134 ,\n",
       "            0.11316, 0.1126 , 0.1124 , 0.1122 , 0.112  , 0.11163, 0.11145,\n",
       "            0.1101 , 0.1099 , 0.1097 , 0.10895, 0.10876, 0.1084 , 0.1076 ,\n",
       "            0.1074 , 0.1069 , 0.1067 , 0.1065 , 0.1052 , 0.10504, 0.1043 ,\n",
       "            0.1034 , 0.10284, 0.1023 , 0.1009 , 0.10016, 0.0997 , 0.0995 ,\n",
       "            0.09753, 0.0974 , 0.09705, 0.0967 , 0.09656, 0.0964 , 0.096  ,\n",
       "            0.0959 , 0.094  , 0.0935 , 0.0933 , 0.093  , 0.09283, 0.0927 ,\n",
       "            0.0922 , 0.09204, 0.09106, 0.0909 , 0.0904 , 0.0899 , 0.0898 ,\n",
       "            0.0896 , 0.0876 , 0.0868 , 0.0866 , 0.086  , 0.0851 , 0.08496,\n",
       "            0.08405, 0.0831 , 0.08124, 0.0799 , 0.07947, 0.0774 , 0.07666,\n",
       "            0.0764 , 0.07574, 0.0742 , 0.0741 , 0.0733 , 0.0724 , 0.0709 ,\n",
       "            0.0707 , 0.07043, 0.0667 , 0.06635, 0.0661 , 0.066  , 0.06464,\n",
       "            0.0636 , 0.05988, 0.05975, 0.0589 , 0.05676, 0.0556 , 0.0549 ,\n",
       "            0.0541 , 0.04208], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.03389831, 0.05932203,\n",
       "            0.07627118, 0.10169491, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3644068 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7881356 , 0.7966102 , 0.8135593 , 0.8135593 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.89830506, 0.89830506, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.90677965, 0.91525424,\n",
       "            0.91525424, 0.9237288 , 0.9237288 , 0.9237288 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 0.9915254 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00757576, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03787879, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.11363637, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12121212, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.15151516,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.17424242, 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.1969697 , 0.21212122,\n",
       "            0.21212122, 0.21969697, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.24242425, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3030303 , 0.3030303 , 0.31060606, 0.32575756, 0.32575756,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.37121212, 0.37121212, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.38636363, 0.3939394 , 0.40151516, 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.4469697 , 0.4469697 , 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.5151515 , 0.5151515 , 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.6060606 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.70454544, 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.74242425,\n",
       "            0.75      , 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2395 , 0.2388 , 0.2375 , 0.2358 , 0.2356 , 0.2355 ,\n",
       "            0.235  , 0.2347 , 0.2343 , 0.233  , 0.2319 , 0.2318 , 0.231  ,\n",
       "            0.2307 , 0.2306 , 0.2303 , 0.2299 , 0.229  , 0.2285 , 0.2273 ,\n",
       "            0.2268 , 0.2249 , 0.2246 , 0.2244 , 0.2234 , 0.2233 , 0.2222 ,\n",
       "            0.222  , 0.2218 , 0.2208 , 0.2203 , 0.2198 , 0.2181 , 0.2179 ,\n",
       "            0.2157 , 0.2156 , 0.2152 , 0.2128 , 0.2109 , 0.2069 , 0.206  ,\n",
       "            0.2059 , 0.2047 , 0.199  , 0.1976 , 0.1962 , 0.1959 , 0.1901 ,\n",
       "            0.1871 , 0.1794 , 0.1771 , 0.1758 , 0.1704 , 0.1693 , 0.1653 ,\n",
       "            0.1641 , 0.1636 , 0.1599 , 0.1592 , 0.1556 , 0.1532 , 0.1514 ,\n",
       "            0.1494 , 0.1493 , 0.149  , 0.1487 , 0.1476 , 0.1467 , 0.1462 ,\n",
       "            0.145  , 0.1444 , 0.1436 , 0.1434 , 0.1431 , 0.1426 , 0.1425 ,\n",
       "            0.1421 , 0.1392 , 0.1384 , 0.1381 , 0.1372 , 0.137  , 0.1368 ,\n",
       "            0.1362 , 0.1356 , 0.1343 , 0.134  , 0.1328 , 0.1322 , 0.1305 ,\n",
       "            0.13   , 0.1293 , 0.129  , 0.1284 , 0.128  , 0.1251 , 0.12445,\n",
       "            0.1235 , 0.12335, 0.12305, 0.1229 , 0.1222 , 0.12177, 0.1216 ,\n",
       "            0.12103, 0.12024, 0.1188 , 0.11755, 0.1174 , 0.11633, 0.11597,\n",
       "            0.1152 , 0.11456, 0.1144 , 0.1142 , 0.1138 , 0.1134 , 0.113  ,\n",
       "            0.1128 , 0.112  , 0.11163, 0.11145, 0.11127, 0.111  , 0.11084,\n",
       "            0.1103 , 0.1101 , 0.10913, 0.1086 , 0.1074 , 0.10724, 0.1065 ,\n",
       "            0.1063 , 0.10614, 0.10596, 0.10504, 0.1043 , 0.1032 , 0.103  ,\n",
       "            0.10284, 0.1019 , 0.10175, 0.10126, 0.1011 , 0.1007 , 0.1005 ,\n",
       "            0.0995 , 0.09845, 0.0981 , 0.09753, 0.09656, 0.096  , 0.0959 ,\n",
       "            0.0955 , 0.094  , 0.0939 , 0.0935 , 0.0933 , 0.093  , 0.0927 ,\n",
       "            0.0925 , 0.0914 , 0.0909 , 0.0906 , 0.0904 , 0.0898 , 0.0896 ,\n",
       "            0.0893 , 0.089  , 0.0885 , 0.0876 , 0.0873 , 0.0871 , 0.0869 ,\n",
       "            0.0866 , 0.0865 , 0.0862 , 0.0859 , 0.0857 , 0.08435, 0.08417,\n",
       "            0.08344, 0.0833 , 0.083  , 0.0828 , 0.0824 , 0.08124, 0.0806 ,\n",
       "            0.0805 , 0.0799 , 0.07935, 0.0792 , 0.07904, 0.07544, 0.07434,\n",
       "            0.0742 , 0.07355, 0.0733 , 0.0732 , 0.0712 , 0.0709 , 0.0707 ,\n",
       "            0.0703 , 0.06915, 0.06793, 0.0656 , 0.06537, 0.06384, 0.0631 ,\n",
       "            0.06232, 0.06152, 0.0613 , 0.06085, 0.0576 , 0.05737, 0.05685,\n",
       "            0.0547 , 0.0543 , 0.0535 , 0.05252, 0.04968, 0.04062],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.03389831, 0.05084746,\n",
       "            0.05932203, 0.08474576, 0.10169491, 0.11016949, 0.12711865,\n",
       "            0.13559322, 0.15254237, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.5508475 , 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.65254235, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6779661 , 0.6779661 , 0.6779661 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7033898 , 0.7033898 , 0.720339  , 0.7288136 ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7881356 , 0.7881356 , 0.7966102 , 0.80508476, 0.80508476,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.83898306, 0.83898306,\n",
       "            0.84745765, 0.84745765, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.87288135, 0.87288135, 0.87288135, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.89830506, 0.89830506, 0.89830506, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.9237288 , 0.9322034 , 0.9322034 ,\n",
       "            0.9322034 , 0.9322034 , 0.94067794, 0.9491525 , 0.9491525 ,\n",
       "            0.9576271 , 0.9576271 , 0.9576271 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.03787879, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.10606061, 0.11363637,\n",
       "            0.11363637, 0.11363637, 0.12121212, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.12878788, 0.13636364, 0.1590909 , 0.1590909 ,\n",
       "            0.16666667, 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.24242425, 0.25      ,\n",
       "            0.25      , 0.25757575, 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3030303 , 0.31060606,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.33333334,\n",
       "            0.3409091 , 0.3560606 , 0.37121212, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.4090909 , 0.4090909 ,\n",
       "            0.41666666, 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.54545456, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6136364 ,\n",
       "            0.6212121 , 0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.7348485 , 0.74242425,\n",
       "            0.75      , 0.7651515 , 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8863636 , 0.8939394 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.95454544, 0.9621212 , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2274 , 0.2269 , 0.2268 , 0.2263 , 0.2261 , 0.226  ,\n",
       "            0.2257 , 0.2256 , 0.2252 , 0.2249 , 0.2225 , 0.2217 , 0.2216 ,\n",
       "            0.2212 , 0.2207 , 0.2195 , 0.2191 , 0.2184 , 0.2179 , 0.2177 ,\n",
       "            0.2157 , 0.2156 , 0.2152 , 0.2145 , 0.214  , 0.2134 , 0.2133 ,\n",
       "            0.2123 , 0.2118 , 0.2114 , 0.2108 , 0.2106 , 0.2091 , 0.2085 ,\n",
       "            0.2074 , 0.206  , 0.2026 , 0.2006 , 0.1991 , 0.1967 , 0.195  ,\n",
       "            0.194  , 0.191  , 0.1897 , 0.1884 , 0.1814 , 0.1796 , 0.1735 ,\n",
       "            0.1716 , 0.1666 , 0.162  , 0.1606 , 0.1602 , 0.1597 , 0.1564 ,\n",
       "            0.1525 , 0.152  , 0.1504 , 0.1451 , 0.1444 , 0.1426 , 0.1422 ,\n",
       "            0.1414 , 0.1412 , 0.1409 , 0.1405 , 0.1393 , 0.1392 , 0.1389 ,\n",
       "            0.1377 , 0.1373 , 0.1357 , 0.1342 , 0.132  , 0.1312 , 0.1307 ,\n",
       "            0.13   , 0.1298 , 0.1292 , 0.1289 , 0.1284 , 0.1278 , 0.1249 ,\n",
       "            0.1239 , 0.12317, 0.1223 , 0.122  , 0.12177, 0.1216 , 0.1197 ,\n",
       "            0.1186 , 0.1174 , 0.1172 , 0.11694, 0.11615, 0.11536, 0.1152 ,\n",
       "            0.115  , 0.11456, 0.11316, 0.1122 , 0.111  , 0.1101 , 0.1099 ,\n",
       "            0.1095 , 0.1086 , 0.1084 , 0.1082 , 0.1074 , 0.10724, 0.1069 ,\n",
       "            0.1067 , 0.1065 , 0.1056 , 0.10504, 0.10486, 0.1045 , 0.1043 ,\n",
       "            0.10394, 0.10376, 0.1034 , 0.1032 , 0.103  , 0.10266, 0.10144,\n",
       "            0.10126, 0.1005 , 0.10034, 0.1    , 0.0993 , 0.0991 , 0.0986 ,\n",
       "            0.09845, 0.0981 , 0.0974 , 0.09705, 0.0967 , 0.09656, 0.0964 ,\n",
       "            0.0959 , 0.0957 , 0.09503, 0.0937 , 0.0927 , 0.0922 , 0.09204,\n",
       "            0.09155, 0.09106, 0.0906 , 0.0904 , 0.0899 , 0.0898 , 0.0891 ,\n",
       "            0.0887 , 0.0882 , 0.0879 , 0.0877 , 0.0874 , 0.0871 , 0.0865 ,\n",
       "            0.0862 , 0.086  , 0.0856 , 0.08417, 0.08405, 0.08344, 0.0831 ,\n",
       "            0.082  , 0.0818 , 0.08167, 0.08093, 0.0806 , 0.0804 , 0.0799 ,\n",
       "            0.07935, 0.0788 , 0.07837, 0.07764, 0.0775 , 0.0774 , 0.0763 ,\n",
       "            0.07587, 0.07544, 0.07465, 0.07434, 0.0729 , 0.0725 , 0.0717 ,\n",
       "            0.0709 , 0.07043, 0.0695 , 0.06903, 0.0689 , 0.0688 , 0.0677 ,\n",
       "            0.0673 , 0.06696, 0.0629 , 0.0619 , 0.06165, 0.06085, 0.06064,\n",
       "            0.0576 , 0.05698, 0.05685, 0.05646, 0.0541 , 0.0533 , 0.05292,\n",
       "            0.05167, 0.0463 , 0.04037], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01694915, 0.03389831, 0.05932203, 0.07627118,\n",
       "            0.09322034, 0.11016949, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.1779661 , 0.18644068, 0.20338982,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.31355932, 0.3220339 , 0.33050847, 0.34745762,\n",
       "            0.3559322 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.65254235, 0.65254235, 0.66101694,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.720339  , 0.720339  ,\n",
       "            0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7711864 , 0.7711864 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7881356 , 0.7966102 , 0.7966102 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.8305085 , 0.83898306, 0.83898306, 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.87288135, 0.87288135, 0.87288135, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.90677965, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.91525424, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.9322034 , 0.9322034 , 0.9322034 , 0.9322034 , 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03787879, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.11363637, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.13636364, 0.14393939,\n",
       "            0.14393939, 0.15151516, 0.1590909 , 0.1590909 , 0.16666667,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.25757575,\n",
       "            0.2651515 , 0.2651515 , 0.28030303, 0.28787878, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.31060606, 0.3181818 ,\n",
       "            0.3181818 , 0.3181818 , 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.36363637, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.5       , 0.50757575, 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5833333 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.65909094, 0.6666667 , 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.67424244, 0.6818182 , 0.6969697 , 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.7348485 , 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.8484849 , 0.8636364 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2172 , 0.217  , 0.2168 , 0.2167 , 0.2166 , 0.2162 ,\n",
       "            0.2161 , 0.2157 , 0.2156 , 0.2152 , 0.2148 , 0.2134 , 0.2128 ,\n",
       "            0.212  , 0.2119 , 0.2113 , 0.2106 , 0.2101 , 0.21   , 0.2098 ,\n",
       "            0.2094 , 0.209  , 0.2081 , 0.2075 , 0.207  , 0.2069 , 0.2068 ,\n",
       "            0.2058 , 0.2056 , 0.2045 , 0.204  , 0.2024 , 0.2023 , 0.2012 ,\n",
       "            0.1971 , 0.195  , 0.1935 , 0.1927 , 0.1913 , 0.1896 , 0.1882 ,\n",
       "            0.187  , 0.1848 , 0.178  , 0.1768 , 0.1725 , 0.1692 , 0.164  ,\n",
       "            0.1599 , 0.1587 , 0.1584 , 0.1548 , 0.1527 , 0.1505 , 0.1482 ,\n",
       "            0.1439 , 0.1436 , 0.1434 , 0.1412 , 0.1405 , 0.1404 , 0.14   ,\n",
       "            0.1399 , 0.1398 , 0.1381 , 0.1375 , 0.1366 , 0.1348 , 0.133  ,\n",
       "            0.1329 , 0.1315 , 0.1313 , 0.1302 , 0.1301 , 0.1298 , 0.129  ,\n",
       "            0.1289 , 0.1285 , 0.1279 , 0.1278 , 0.1272 , 0.1251 , 0.124  ,\n",
       "            0.1236 , 0.12274, 0.1226 , 0.1217 , 0.1214 , 0.1201 , 0.11816,\n",
       "            0.1172 , 0.11694, 0.11676, 0.11633, 0.1158 , 0.11554, 0.115  ,\n",
       "            0.1144 , 0.11316, 0.1118 , 0.11163, 0.111  , 0.1099 , 0.1095 ,\n",
       "            0.1093 , 0.1084 , 0.1082 , 0.108  , 0.1078 , 0.10724, 0.1063 ,\n",
       "            0.10614, 0.10596, 0.1056 , 0.10486, 0.1047 , 0.1045 , 0.10394,\n",
       "            0.10376, 0.1034 , 0.103  , 0.10284, 0.10156, 0.10144, 0.1009 ,\n",
       "            0.10034, 0.1    , 0.0997 , 0.0993 , 0.0986 , 0.0979 , 0.0977 ,\n",
       "            0.0974 , 0.0972 , 0.09705, 0.09686, 0.0967 , 0.0962 , 0.0959 ,\n",
       "            0.09534, 0.0942 , 0.0939 , 0.0932 , 0.09283, 0.0925 , 0.09235,\n",
       "            0.09186, 0.09125, 0.09106, 0.0909 , 0.09076, 0.0904 , 0.0898 ,\n",
       "            0.089  , 0.0888 , 0.0882 , 0.088  , 0.0879 , 0.0876 , 0.0874 ,\n",
       "            0.0859 , 0.0854 , 0.0845 , 0.08417, 0.0833 , 0.0825 , 0.0824 ,\n",
       "            0.082  , 0.08136, 0.0806 , 0.0801 , 0.0799 , 0.07904, 0.0788 ,\n",
       "            0.0778 , 0.07764, 0.0775 , 0.07654, 0.0764 , 0.076  , 0.07574,\n",
       "            0.07556, 0.07544, 0.07477, 0.0745 , 0.07227, 0.0716 , 0.0715 ,\n",
       "            0.0703 , 0.0694 , 0.06757, 0.06586, 0.06464, 0.0645 , 0.0636 ,\n",
       "            0.0629 , 0.0612 , 0.05988, 0.05942, 0.05933, 0.05814, 0.0575 ,\n",
       "            0.05707, 0.05612, 0.05573, 0.0544 , 0.0471 , 0.04312],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.08474576, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.19491525, 0.20338982, 0.22033899,\n",
       "            0.23728813, 0.2542373 , 0.26271185, 0.27118644, 0.2881356 ,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.41525424, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.6101695 , 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.65254235, 0.65254235, 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.66101694, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.720339  , 0.720339  , 0.720339  , 0.7288136 , 0.7288136 ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.779661  , 0.779661  , 0.7966102 , 0.7966102 , 0.7966102 ,\n",
       "            0.80508476, 0.80508476, 0.8220339 , 0.8220339 , 0.8220339 ,\n",
       "            0.8305085 , 0.8305085 , 0.8305085 , 0.8305085 , 0.8305085 ,\n",
       "            0.83898306, 0.83898306, 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.87288135, 0.87288135,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.89830506,\n",
       "            0.89830506, 0.90677965, 0.90677965, 0.90677965, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.94067794,\n",
       "            0.94067794, 0.94067794, 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9915254 , 0.9915254 , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03787879, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.0530303 , 0.06060606, 0.06060606,\n",
       "            0.06060606, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.10606061, 0.11363637, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.14393939, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.1590909 , 0.16666667, 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.22727273, 0.22727273,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.27272728, 0.28030303, 0.28030303,\n",
       "            0.28787878, 0.28787878, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3181818 , 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.36363637, 0.37121212, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.47727272, 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.50757575, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.5378788 , 0.5378788 , 0.54545456, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.6060606 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.7651515 , 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.8181818 , 0.82575756, 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2124 , 0.212  , 0.2115 , 0.211  , 0.2104 , 0.2103 ,\n",
       "            0.2101 , 0.21   , 0.2098 , 0.2096 , 0.2095 , 0.2094 , 0.2091 ,\n",
       "            0.209  , 0.2086 , 0.2085 , 0.2084 , 0.2075 , 0.2074 , 0.2064 ,\n",
       "            0.2063 , 0.206  , 0.2058 , 0.2051 , 0.205  , 0.2047 , 0.2037 ,\n",
       "            0.2034 , 0.2028 , 0.2024 , 0.2021 , 0.1998 , 0.1995 , 0.1978 ,\n",
       "            0.196  , 0.1952 , 0.1936 , 0.1907 , 0.1897 , 0.1887 , 0.1865 ,\n",
       "            0.1864 , 0.1799 , 0.1794 , 0.1764 , 0.1724 , 0.1666 , 0.1649 ,\n",
       "            0.1637 , 0.1636 , 0.1617 , 0.159  , 0.1582 , 0.1552 , 0.1515 ,\n",
       "            0.1493 , 0.1488 , 0.1484 , 0.1466 , 0.1464 , 0.1456 , 0.1454 ,\n",
       "            0.1451 , 0.1449 , 0.1436 , 0.1431 , 0.1417 , 0.1398 , 0.1382 ,\n",
       "            0.1376 , 0.1371 , 0.1367 , 0.1348 , 0.1343 , 0.1342 , 0.1339 ,\n",
       "            0.1338 , 0.1332 , 0.1329 , 0.1323 , 0.1316 , 0.1313 , 0.1296 ,\n",
       "            0.1292 , 0.1289 , 0.1274 , 0.1273 , 0.127  , 0.1268 , 0.1267 ,\n",
       "            0.12445, 0.12335, 0.12274, 0.1225 , 0.122  , 0.12115, 0.12085,\n",
       "            0.12067, 0.1204 , 0.12024, 0.1198 , 0.1197 , 0.119  , 0.11694,\n",
       "            0.11676, 0.1152 , 0.11475, 0.1142 , 0.1138 , 0.1134 , 0.11316,\n",
       "            0.113  , 0.1126 , 0.112  , 0.1118 , 0.11163, 0.11145, 0.111  ,\n",
       "            0.1105 , 0.1103 , 0.1093 , 0.10913, 0.1086 , 0.1084 , 0.1074 ,\n",
       "            0.10724, 0.1069 , 0.1063 , 0.10596, 0.1058 , 0.1054 , 0.1043 ,\n",
       "            0.1041 , 0.10394, 0.10376, 0.1032 , 0.103  , 0.10284, 0.1019 ,\n",
       "            0.10144, 0.1011 , 0.10016, 0.0998 , 0.0995 , 0.0993 , 0.09845,\n",
       "            0.09827, 0.0981 , 0.0974 , 0.0972 , 0.09705, 0.09686, 0.0967 ,\n",
       "            0.09656, 0.0939 , 0.0933 , 0.09283, 0.0927 , 0.09235, 0.09155,\n",
       "            0.0914 , 0.09125, 0.0898 , 0.0896 , 0.0895 , 0.0893 , 0.0887 ,\n",
       "            0.0885 , 0.0877 , 0.0869 , 0.0862 , 0.0854 , 0.08435, 0.08417,\n",
       "            0.0836 , 0.083  , 0.0827 , 0.0824 , 0.0823 , 0.082  , 0.08167,\n",
       "            0.0804 , 0.0799 , 0.07935, 0.07904, 0.07806, 0.0778 , 0.0772 ,\n",
       "            0.07477, 0.0733 , 0.07306, 0.07227, 0.07196, 0.0709 , 0.0689 ,\n",
       "            0.0672 , 0.06696, 0.0666 , 0.0662 , 0.0642 , 0.0635 , 0.06335,\n",
       "            0.0629 , 0.0627 , 0.06165, 0.05185, 0.0495 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.08474576,\n",
       "            0.11016949, 0.11864407, 0.13559322, 0.15254237, 0.16949153,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.59322035, 0.59322035,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.65254235, 0.65254235, 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.69491524, 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.720339  , 0.720339  ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7288136 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7457627 , 0.7457627 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 , 0.7542373 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.7966102 , 0.7966102 , 0.80508476, 0.8135593 , 0.8135593 ,\n",
       "            0.8135593 , 0.8220339 , 0.8220339 , 0.8220339 , 0.8220339 ,\n",
       "            0.8220339 , 0.8220339 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.8559322 , 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.87288135, 0.87288135, 0.87288135,\n",
       "            0.87288135, 0.88135594, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.91525424, 0.9237288 ,\n",
       "            0.9237288 , 0.9237288 , 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.07575758, 0.08333334, 0.09090909, 0.09090909,\n",
       "            0.09090909, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.15151516, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18181819, 0.18181819, 0.18939394,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.23484848, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.27272728, 0.28030303, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.29545453, 0.29545453, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.3409091 ,\n",
       "            0.3560606 , 0.37121212, 0.37121212, 0.37878788, 0.37878788,\n",
       "            0.37878788, 0.38636363, 0.38636363, 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.5       , 0.5151515 ,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.5833333 , 0.59090906, 0.5984849 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.215  , 0.2142 , 0.2139 , 0.2135 , 0.2133 , 0.2124 ,\n",
       "            0.2123 , 0.2109 , 0.2104 , 0.2103 , 0.2091 , 0.209  , 0.2086 ,\n",
       "            0.2081 , 0.208  , 0.2079 , 0.2075 , 0.2074 , 0.2073 , 0.2068 ,\n",
       "            0.2065 , 0.2063 , 0.206  , 0.2059 , 0.2056 , 0.2053 , 0.205  ,\n",
       "            0.2048 , 0.2042 , 0.2031 , 0.2024 , 0.2015 , 0.2013 , 0.1987 ,\n",
       "            0.1984 , 0.1979 , 0.1978 , 0.1934 , 0.1921 , 0.1919 , 0.1893 ,\n",
       "            0.1871 , 0.1865 , 0.1858 , 0.1857 , 0.1848 , 0.1843 , 0.179  ,\n",
       "            0.1765 , 0.1735 , 0.1714 , 0.1703 , 0.1699 , 0.1671 , 0.1664 ,\n",
       "            0.1625 , 0.1622 , 0.1587 , 0.1581 , 0.1571 , 0.1562 , 0.1554 ,\n",
       "            0.1549 , 0.154  , 0.1539 , 0.1525 , 0.152  , 0.1519 , 0.1512 ,\n",
       "            0.1504 , 0.1495 , 0.1483 , 0.147  , 0.1456 , 0.1454 , 0.1439 ,\n",
       "            0.143  , 0.1423 , 0.1421 , 0.142  , 0.1417 , 0.1414 , 0.1411 ,\n",
       "            0.141  , 0.1405 , 0.1401 , 0.1384 , 0.1382 , 0.138  , 0.1376 ,\n",
       "            0.1357 , 0.1354 , 0.1343 , 0.1333 , 0.1326 , 0.1322 , 0.1312 ,\n",
       "            0.13   , 0.1293 , 0.1289 , 0.1283 , 0.1277 , 0.1274 , 0.127  ,\n",
       "            0.1267 , 0.126  , 0.1259 , 0.1255 , 0.1249 , 0.12445, 0.1239 ,\n",
       "            0.12305, 0.1229 , 0.12274, 0.1225 , 0.1219 , 0.1214 , 0.121  ,\n",
       "            0.12054, 0.12036, 0.11993, 0.1194 , 0.1186 , 0.1184 , 0.11816,\n",
       "            0.1172 , 0.11694, 0.11676, 0.11633, 0.1158 , 0.11554, 0.115  ,\n",
       "            0.11475, 0.11456, 0.1144 , 0.1142 , 0.11395, 0.1138 , 0.11316,\n",
       "            0.113  , 0.1126 , 0.1124 , 0.1122 , 0.112  , 0.1118 , 0.11145,\n",
       "            0.11084, 0.11066, 0.1105 , 0.1097 , 0.1093 , 0.10913, 0.10895,\n",
       "            0.10706, 0.1065 , 0.1063 , 0.10596, 0.1054 , 0.10486, 0.1047 ,\n",
       "            0.1045 , 0.1043 , 0.1023 , 0.1019 , 0.10175, 0.1009 , 0.1007 ,\n",
       "            0.1005 , 0.10034, 0.1    , 0.0991 , 0.0974 , 0.09705, 0.0967 ,\n",
       "            0.09656, 0.0964 , 0.09515, 0.09485, 0.0937 , 0.09283, 0.0922 ,\n",
       "            0.09204, 0.09155, 0.09125, 0.0909 , 0.0906 , 0.0896 , 0.0895 ,\n",
       "            0.0893 , 0.089  , 0.088  , 0.0874 , 0.0862 , 0.0851 , 0.08496,\n",
       "            0.0848 , 0.0836 , 0.0821 , 0.08093, 0.07965, 0.0792 , 0.07904,\n",
       "            0.0774 , 0.0764 , 0.07556, 0.075  , 0.07367, 0.0729 , 0.07056,\n",
       "            0.06964, 0.06052, 0.05844], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27966103, 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.37288135, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.43220338, 0.44067797,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5677966 , 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.60169494, 0.60169494, 0.6101695 , 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.63559324, 0.6440678 ,\n",
       "            0.6440678 , 0.65254235, 0.65254235, 0.66101694, 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.66101694, 0.66101694, 0.66101694, 0.6694915 , 0.6864407 ,\n",
       "            0.6864407 , 0.6864407 , 0.6864407 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.720339  , 0.720339  ,\n",
       "            0.7288136 , 0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7881356 , 0.7966102 , 0.7966102 , 0.7966102 , 0.8135593 ,\n",
       "            0.8220339 , 0.8220339 , 0.8220339 , 0.8220339 , 0.8220339 ,\n",
       "            0.8305085 , 0.8305085 , 0.8305085 , 0.83898306, 0.83898306,\n",
       "            0.84745765, 0.84745765, 0.8559322 , 0.86440676, 0.86440676,\n",
       "            0.87288135, 0.87288135, 0.87288135, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9491525 , 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9830508 , 0.9830508 , 0.9830508 , 0.9915254 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03787879, 0.03787879,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06818182, 0.06818182,\n",
       "            0.06818182, 0.07575758, 0.07575758, 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.09090909, 0.09090909, 0.09848485, 0.09848485,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.1969697 , 0.20454545, 0.20454545, 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25      , 0.25757575, 0.2651515 , 0.2651515 ,\n",
       "            0.27272728, 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.3560606 , 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.3939394 , 0.4090909 , 0.4090909 , 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.50757575, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.5378788 , 0.54545456, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.59090906, 0.5984849 , 0.5984849 , 0.5984849 , 0.5984849 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.68939394, 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.79545456, 0.8030303 , 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8787879 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2207 , 0.22   , 0.2195 , 0.2194 , 0.219  , 0.2189 ,\n",
       "            0.2185 , 0.2179 , 0.2172 , 0.2144 , 0.2142 , 0.214  , 0.2137 ,\n",
       "            0.2134 , 0.2128 , 0.2125 , 0.2123 , 0.2119 , 0.2115 , 0.2113 ,\n",
       "            0.2109 , 0.2106 , 0.2103 , 0.2096 , 0.2091 , 0.209  , 0.2086 ,\n",
       "            0.2085 , 0.2084 , 0.2075 , 0.207  , 0.2069 , 0.2068 , 0.206  ,\n",
       "            0.2059 , 0.2056 , 0.205  , 0.2039 , 0.2034 , 0.2017 , 0.2001 ,\n",
       "            0.1981 , 0.1965 , 0.1959 , 0.1947 , 0.1935 , 0.1906 , 0.19   ,\n",
       "            0.1884 , 0.1871 , 0.1849 , 0.1841 , 0.1815 , 0.1814 , 0.1788 ,\n",
       "            0.1787 , 0.178  , 0.1779 , 0.1752 , 0.1743 , 0.1735 , 0.1707 ,\n",
       "            0.1694 , 0.1687 , 0.1678 , 0.1676 , 0.1675 , 0.1672 , 0.1669 ,\n",
       "            0.1652 , 0.1647 , 0.1644 , 0.1636 , 0.1632 , 0.1625 , 0.1624 ,\n",
       "            0.1597 , 0.1584 , 0.1582 , 0.1575 , 0.1565 , 0.1556 , 0.1555 ,\n",
       "            0.1554 , 0.1544 , 0.1542 , 0.1533 , 0.1532 , 0.153  , 0.1517 ,\n",
       "            0.1508 , 0.15   , 0.1488 , 0.1487 , 0.1486 , 0.1484 , 0.1483 ,\n",
       "            0.1466 , 0.1465 , 0.1444 , 0.1439 , 0.1437 , 0.1433 , 0.1422 ,\n",
       "            0.1421 , 0.1415 , 0.1409 , 0.1407 , 0.1403 , 0.1401 , 0.14   ,\n",
       "            0.1399 , 0.1395 , 0.1389 , 0.1384 , 0.1377 , 0.1376 , 0.1366 ,\n",
       "            0.1359 , 0.1354 , 0.1348 , 0.1343 , 0.1339 , 0.1332 , 0.1326 ,\n",
       "            0.1324 , 0.1322 , 0.1317 , 0.1313 , 0.131  , 0.1306 , 0.1304 ,\n",
       "            0.1301 , 0.1296 , 0.1295 , 0.1292 , 0.1288 , 0.1287 , 0.1285 ,\n",
       "            0.1282 , 0.1279 , 0.1278 , 0.1274 , 0.1272 , 0.127  , 0.1267 ,\n",
       "            0.1263 , 0.1262 , 0.1261 , 0.1259 , 0.1254 , 0.1251 , 0.12476,\n",
       "            0.12463, 0.1242 , 0.12305, 0.1229 , 0.12244, 0.1217 , 0.1214 ,\n",
       "            0.1213 , 0.1207 , 0.12   , 0.1195 , 0.1192 , 0.1186 , 0.1184 ,\n",
       "            0.1178 , 0.11755, 0.11694, 0.11597, 0.11395, 0.1134 , 0.113  ,\n",
       "            0.1126 , 0.1124 , 0.1122 , 0.11163, 0.111  , 0.1101 , 0.1099 ,\n",
       "            0.1097 , 0.1093 , 0.10913, 0.1082 , 0.1076 , 0.1074 , 0.1067 ,\n",
       "            0.1052 , 0.10376, 0.1032 , 0.10266, 0.10175, 0.10156, 0.10144,\n",
       "            0.10126, 0.1007 , 0.1005 , 0.10016, 0.1    , 0.0997 , 0.09686,\n",
       "            0.0959 , 0.0955 , 0.09515, 0.0933 , 0.0927 , 0.0925 , 0.09186,\n",
       "            0.09106, 0.0899 , 0.0896 , 0.08344, 0.08136, 0.0804 , 0.07544,\n",
       "            0.0688 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.1440678 , 0.15254237, 0.16101696, 0.1779661 ,\n",
       "            0.18644068, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.37288135, 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.61864406, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.63559324, 0.63559324, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.65254235, 0.65254235, 0.65254235, 0.65254235,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.66101694, 0.66101694,\n",
       "            0.6694915 , 0.6694915 , 0.6779661 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.69491524, 0.7033898 , 0.7033898 , 0.7118644 ,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.720339  , 0.720339  ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 ,\n",
       "            0.7372881 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8135593 , 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.83898306, 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.86440676, 0.86440676, 0.87288135, 0.87288135, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.9322034 , 0.94067794, 0.94067794,\n",
       "            0.94067794, 0.9491525 , 0.9491525 , 0.9491525 , 0.9491525 ,\n",
       "            0.9491525 , 0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 ,\n",
       "            0.9745763 , 0.9745763 , 0.9830508 , 0.9830508 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.01515152,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.02272727,\n",
       "            0.02272727, 0.03030303, 0.03030303, 0.03787879, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.07575758,\n",
       "            0.07575758, 0.07575758, 0.07575758, 0.08333334, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.09090909, 0.09090909, 0.09848485,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.11363637, 0.12121212,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.13636364, 0.15151516,\n",
       "            0.1590909 , 0.1590909 , 0.16666667, 0.17424242, 0.18181819,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21212122,\n",
       "            0.21212122, 0.21969697, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.23484848, 0.24242425, 0.24242425, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.27272728, 0.28787878, 0.29545453,\n",
       "            0.3030303 , 0.3030303 , 0.3030303 , 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.5984849 , 0.6060606 , 0.6212121 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.6969697 , 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.719697  , 0.72727275, 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.74242425, 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.780303  ,\n",
       "            0.780303  , 0.780303  , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2286 , 0.2281 , 0.2278 , 0.2269 , 0.2263 , 0.2247 ,\n",
       "            0.2242 , 0.2238 , 0.2234 , 0.2233 , 0.2217 , 0.2213 , 0.2208 ,\n",
       "            0.2197 , 0.2194 , 0.2185 , 0.2168 , 0.2166 , 0.2163 , 0.2153 ,\n",
       "            0.2152 , 0.215  , 0.2145 , 0.2142 , 0.2139 , 0.2119 , 0.2096 ,\n",
       "            0.2095 , 0.2094 , 0.2089 , 0.2086 , 0.2085 , 0.2081 , 0.208  ,\n",
       "            0.2069 , 0.206  , 0.2059 , 0.2058 , 0.2054 , 0.2051 , 0.204  ,\n",
       "            0.2031 , 0.2026 , 0.2021 , 0.2009 , 0.2006 , 0.2001 , 0.1993 ,\n",
       "            0.199  , 0.195  , 0.1936 , 0.1909 , 0.1904 , 0.189  , 0.1879 ,\n",
       "            0.1863 , 0.1855 , 0.1846 , 0.1844 , 0.1837 , 0.1824 , 0.1821 ,\n",
       "            0.1812 , 0.181  , 0.179  , 0.1788 , 0.177  , 0.1754 , 0.1752 ,\n",
       "            0.1748 , 0.1746 , 0.1744 , 0.174  , 0.1737 , 0.1733 , 0.1731 ,\n",
       "            0.1718 , 0.1698 , 0.1697 , 0.1674 , 0.167  , 0.1663 , 0.165  ,\n",
       "            0.1649 , 0.1648 , 0.1641 , 0.1637 , 0.1631 , 0.163  , 0.1627 ,\n",
       "            0.1624 , 0.1622 , 0.1621 , 0.162  , 0.1602 , 0.1598 , 0.159  ,\n",
       "            0.1589 , 0.1575 , 0.1572 , 0.157  , 0.1565 , 0.1559 , 0.1555 ,\n",
       "            0.1552 , 0.1543 , 0.1536 , 0.1532 , 0.1525 , 0.1521 , 0.1517 ,\n",
       "            0.1509 , 0.1504 , 0.15   , 0.1493 , 0.1489 , 0.1487 , 0.1484 ,\n",
       "            0.1481 , 0.1473 , 0.147  , 0.1466 , 0.1461 , 0.1459 , 0.1456 ,\n",
       "            0.1454 , 0.1453 , 0.1451 , 0.1449 , 0.1447 , 0.1445 , 0.144  ,\n",
       "            0.1437 , 0.1436 , 0.1434 , 0.1428 , 0.1422 , 0.1417 , 0.1411 ,\n",
       "            0.1407 , 0.1405 , 0.1401 , 0.14   , 0.1392 , 0.139  , 0.1381 ,\n",
       "            0.138  , 0.1378 , 0.1376 , 0.1373 , 0.1372 , 0.1368 , 0.1366 ,\n",
       "            0.1359 , 0.1355 , 0.1353 , 0.1345 , 0.1334 , 0.133  , 0.1328 ,\n",
       "            0.1326 , 0.1324 , 0.1318 , 0.1313 , 0.131  , 0.1298 , 0.1293 ,\n",
       "            0.1292 , 0.1288 , 0.1284 , 0.1279 , 0.1274 , 0.1268 , 0.1261 ,\n",
       "            0.1259 , 0.1257 , 0.12463, 0.1232 , 0.12286, 0.1226 , 0.1217 ,\n",
       "            0.1214 , 0.1213 , 0.12024, 0.1201 , 0.1194 , 0.119  , 0.11816,\n",
       "            0.1174 , 0.11554, 0.11475, 0.1144 , 0.11395, 0.1138 , 0.1128 ,\n",
       "            0.1126 , 0.112  , 0.111  , 0.11084, 0.1103 , 0.1101 , 0.1095 ,\n",
       "            0.1093 , 0.1084 , 0.1078 , 0.1036 , 0.1034 , 0.10156, 0.093  ,\n",
       "            0.09283, 0.09174, 0.0903 , 0.07837], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.12711865, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.2881356 , 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5254237 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5338983 ,\n",
       "            0.5338983 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5423729 ,\n",
       "            0.5423729 , 0.5508475 , 0.5508475 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.62711865, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.62711865, 0.63559324, 0.63559324,\n",
       "            0.63559324, 0.63559324, 0.63559324, 0.6440678 , 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6779661 , 0.6779661 , 0.69491524, 0.7033898 , 0.7033898 ,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.720339  , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7457627 , 0.7457627 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7627119 , 0.7627119 , 0.7627119 ,\n",
       "            0.7627119 , 0.7627119 , 0.7627119 , 0.7711864 , 0.7711864 ,\n",
       "            0.7711864 , 0.779661  , 0.779661  , 0.779661  , 0.779661  ,\n",
       "            0.7881356 , 0.7881356 , 0.7881356 , 0.7881356 , 0.7966102 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8135593 , 0.8220339 ,\n",
       "            0.8220339 , 0.8305085 , 0.8305085 , 0.8305085 , 0.83898306,\n",
       "            0.83898306, 0.84745765, 0.86440676, 0.86440676, 0.87288135,\n",
       "            0.87288135, 0.87288135, 0.87288135, 0.87288135, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.89830506, 0.90677965,\n",
       "            0.90677965, 0.91525424, 0.91525424, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.91525424, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.94067794, 0.94067794, 0.9491525 ,\n",
       "            0.9491525 , 0.9576271 , 0.9576271 , 0.9661017 , 0.9661017 ,\n",
       "            0.9745763 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9830508 , 0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.01515152, 0.01515152, 0.01515152, 0.01515152, 0.01515152,\n",
       "            0.01515152, 0.02272727, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.02272727, 0.02272727, 0.02272727, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03787879, 0.04545455, 0.04545455, 0.04545455,\n",
       "            0.04545455, 0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 ,\n",
       "            0.0530303 , 0.06060606, 0.06060606, 0.06060606, 0.06060606,\n",
       "            0.06818182, 0.06818182, 0.06818182, 0.07575758, 0.07575758,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.08333334, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.10606061, 0.11363637,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.12878788, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18181819, 0.18939394,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.23484848, 0.25      ,\n",
       "            0.25757575, 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28030303, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.54545456, 0.54545456,\n",
       "            0.5530303 , 0.5681818 , 0.57575756, 0.57575756, 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6818182 , 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.70454544, 0.7121212 , 0.719697  , 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.7348485 , 0.74242425, 0.74242425,\n",
       "            0.75      , 0.75757575, 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.7878788 , 0.7878788 , 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.90909094, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.2411 , 0.2401 , 0.239  , 0.2383 , 0.2375 , 0.2374 ,\n",
       "            0.2367 , 0.2352 , 0.2346 , 0.2334 , 0.2325 , 0.2318 , 0.231  ,\n",
       "            0.2306 , 0.2299 , 0.2297 , 0.2285 , 0.2273 , 0.2264 , 0.2249 ,\n",
       "            0.2238 , 0.223  , 0.2225 , 0.222  , 0.2216 , 0.2212 , 0.2211 ,\n",
       "            0.2208 , 0.2197 , 0.2194 , 0.2191 , 0.2181 , 0.2179 , 0.2166 ,\n",
       "            0.2137 , 0.2134 , 0.213  , 0.2123 , 0.2108 , 0.2106 , 0.2101 ,\n",
       "            0.2096 , 0.2095 , 0.2091 , 0.2089 , 0.208  , 0.2076 , 0.207  ,\n",
       "            0.2064 , 0.206  , 0.2059 , 0.2058 , 0.2054 , 0.2047 , 0.204  ,\n",
       "            0.2035 , 0.2029 , 0.2021 , 0.2017 , 0.2007 , 0.2006 , 0.2001 ,\n",
       "            0.1993 , 0.199  , 0.1987 , 0.1971 , 0.1964 , 0.1958 , 0.1948 ,\n",
       "            0.193  , 0.1919 , 0.1918 , 0.191  , 0.1907 , 0.1906 , 0.1897 ,\n",
       "            0.1892 , 0.1891 , 0.1884 , 0.1865 , 0.1863 , 0.1853 , 0.185  ,\n",
       "            0.1848 , 0.1841 , 0.1837 , 0.1836 , 0.1827 , 0.1824 , 0.1819 ,\n",
       "            0.181  , 0.1807 , 0.1804 , 0.1799 , 0.1791 , 0.179  , 0.1788 ,\n",
       "            0.1787 , 0.1785 , 0.178  , 0.1779 , 0.1772 , 0.177  , 0.1768 ,\n",
       "            0.1766 , 0.1765 , 0.1764 , 0.1759 , 0.1757 , 0.1753 , 0.1748 ,\n",
       "            0.1746 , 0.174  , 0.1737 , 0.1736 , 0.1731 , 0.1729 , 0.1719 ,\n",
       "            0.1707 , 0.1705 , 0.1696 , 0.1692 , 0.1688 , 0.1687 , 0.1686 ,\n",
       "            0.1674 , 0.1669 , 0.1653 , 0.1649 , 0.1647 , 0.1646 , 0.1644 ,\n",
       "            0.1638 , 0.1637 , 0.1636 , 0.1622 , 0.1617 , 0.1616 , 0.1614 ,\n",
       "            0.161  , 0.1609 , 0.1608 , 0.1606 , 0.1605 , 0.1602 , 0.1599 ,\n",
       "            0.1592 , 0.1586 , 0.1582 , 0.1581 , 0.158  , 0.1575 , 0.1572 ,\n",
       "            0.1565 , 0.1564 , 0.1558 , 0.1552 , 0.155  , 0.1547 , 0.1542 ,\n",
       "            0.1539 , 0.1536 , 0.1534 , 0.1531 , 0.153  , 0.1521 , 0.1519 ,\n",
       "            0.1515 , 0.1514 , 0.1512 , 0.1508 , 0.1499 , 0.1494 , 0.1489 ,\n",
       "            0.1483 , 0.148  , 0.1472 , 0.147  , 0.1466 , 0.1461 , 0.1458 ,\n",
       "            0.1455 , 0.1454 , 0.1436 , 0.1415 , 0.1411 , 0.141  , 0.1409 ,\n",
       "            0.1405 , 0.1392 , 0.1389 , 0.1385 , 0.1384 , 0.1383 , 0.138  ,\n",
       "            0.1375 , 0.1365 , 0.1364 , 0.1362 , 0.1353 , 0.135  , 0.1335 ,\n",
       "            0.1328 , 0.1324 , 0.1312 , 0.13   , 0.1295 , 0.1279 , 0.1271 ,\n",
       "            0.1265 , 0.126  , 0.1252 , 0.1249 , 0.12445, 0.1243 , 0.1201 ,\n",
       "            0.1196 , 0.1195 , 0.119  , 0.1076 , 0.1074 , 0.1056 , 0.0937 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.13559322, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.27118644, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.29661018, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.3559322 , 0.37288135, 0.37288135, 0.3898305 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.4915254 , 0.4915254 , 0.5       ,\n",
       "            0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 ,\n",
       "            0.55932206, 0.55932206, 0.55932206, 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.60169494, 0.6101695 ,\n",
       "            0.6101695 , 0.6101695 , 0.6101695 , 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.61864406, 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.6864407 ,\n",
       "            0.69491524, 0.7118644 , 0.7118644 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.720339  , 0.720339  , 0.7288136 , 0.7288136 ,\n",
       "            0.7288136 , 0.7288136 , 0.7288136 , 0.7288136 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 , 0.7711864 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7881356 , 0.7881356 , 0.7881356 , 0.7966102 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8135593 , 0.8135593 , 0.8220339 ,\n",
       "            0.83898306, 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.87288135, 0.88135594, 0.88135594, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.91525424, 0.91525424, 0.9237288 , 0.9237288 , 0.9237288 ,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.94067794, 0.94067794,\n",
       "            0.9491525 , 0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9745763 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 0.9915254 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00757576, 0.00757576, 0.00757576, 0.00757576, 0.00757576,\n",
       "            0.01515152, 0.01515152, 0.02272727, 0.02272727, 0.02272727,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03030303, 0.03030303,\n",
       "            0.03030303, 0.03030303, 0.03030303, 0.03787879, 0.04545455,\n",
       "            0.0530303 , 0.0530303 , 0.0530303 , 0.0530303 , 0.06060606,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.06818182, 0.07575758,\n",
       "            0.07575758, 0.07575758, 0.08333334, 0.08333334, 0.09090909,\n",
       "            0.10606061, 0.11363637, 0.11363637, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.15151516,\n",
       "            0.15151516, 0.15151516, 0.1590909 , 0.1590909 , 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.17424242, 0.18181819, 0.18181819,\n",
       "            0.18181819, 0.18939394, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.23484848, 0.23484848, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25      , 0.25      , 0.25757575,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.31060606, 0.32575756, 0.3409091 , 0.34848484, 0.34848484,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.3939394 , 0.40151516, 0.4090909 , 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.4318182 ,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.59090906, 0.5984849 ,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.68939394, 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.7121212 , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75      , 0.75757575, 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.257  , 0.256  , 0.2524 , 0.2522 , 0.252  , 0.2517 ,\n",
       "            0.2505 , 0.2498 , 0.2493 , 0.247  , 0.2466 , 0.2445 , 0.2441 ,\n",
       "            0.243  , 0.2429 , 0.2417 , 0.241  , 0.2401 , 0.2378 , 0.2374 ,\n",
       "            0.237  , 0.2368 , 0.2351 , 0.235  , 0.234  , 0.2334 , 0.2325 ,\n",
       "            0.2314 , 0.2311 , 0.2303 , 0.2297 , 0.2292 , 0.228  , 0.2278 ,\n",
       "            0.2269 , 0.2263 , 0.2252 , 0.2242 , 0.2239 , 0.2235 , 0.2234 ,\n",
       "            0.223  , 0.2225 , 0.2203 , 0.2195 , 0.218  , 0.2172 , 0.217  ,\n",
       "            0.2168 , 0.2167 , 0.2166 , 0.2161 , 0.2156 , 0.2152 , 0.215  ,\n",
       "            0.2147 , 0.2135 , 0.2129 , 0.212  , 0.2119 , 0.2115 , 0.2114 ,\n",
       "            0.2113 , 0.2106 , 0.2103 , 0.21   , 0.2098 , 0.2096 , 0.2095 ,\n",
       "            0.2091 , 0.2089 , 0.2084 , 0.208  , 0.2079 , 0.2073 , 0.2065 ,\n",
       "            0.206  , 0.2059 , 0.2056 , 0.2054 , 0.205  , 0.2047 , 0.204  ,\n",
       "            0.2035 , 0.2031 , 0.202  , 0.2012 , 0.201  , 0.2007 , 0.2006 ,\n",
       "            0.2002 , 0.2001 , 0.2    , 0.1993 , 0.199  , 0.1987 , 0.1985 ,\n",
       "            0.1982 , 0.1981 , 0.1978 , 0.1974 , 0.1968 , 0.1962 , 0.1959 ,\n",
       "            0.1958 , 0.195  , 0.1948 , 0.1937 , 0.193  , 0.1924 , 0.1923 ,\n",
       "            0.1919 , 0.1918 , 0.1913 , 0.1909 , 0.19   , 0.1898 , 0.1892 ,\n",
       "            0.1884 , 0.188  , 0.1874 , 0.1873 , 0.1864 , 0.1855 , 0.1853 ,\n",
       "            0.1852 , 0.185  , 0.1843 , 0.1842 , 0.1841 , 0.1836 , 0.1824 ,\n",
       "            0.1823 , 0.182  , 0.1815 , 0.1814 , 0.1807 , 0.1805 , 0.1804 ,\n",
       "            0.1803 , 0.1798 , 0.1797 , 0.1792 , 0.1788 , 0.1787 , 0.1781 ,\n",
       "            0.1775 , 0.177  , 0.1764 , 0.1763 , 0.1755 , 0.1752 , 0.1749 ,\n",
       "            0.1744 , 0.1743 , 0.1741 , 0.1738 , 0.1736 , 0.1735 , 0.1733 ,\n",
       "            0.173  , 0.172  , 0.1716 , 0.171  , 0.1708 , 0.17   , 0.1699 ,\n",
       "            0.1694 , 0.1692 , 0.1686 , 0.1685 , 0.1677 , 0.1675 , 0.1674 ,\n",
       "            0.1663 , 0.1661 , 0.1656 , 0.1648 , 0.1646 , 0.1643 , 0.1617 ,\n",
       "            0.1616 , 0.1615 , 0.161  , 0.1597 , 0.159  , 0.1588 , 0.158  ,\n",
       "            0.1571 , 0.1567 , 0.1558 , 0.1554 , 0.1543 , 0.1539 , 0.153  ,\n",
       "            0.1516 , 0.1505 , 0.1489 , 0.1484 , 0.147  , 0.1469 , 0.1466 ,\n",
       "            0.1464 , 0.1455 , 0.145  , 0.1444 , 0.1425 , 0.1421 , 0.1393 ,\n",
       "            0.1284 , 0.1272 , 0.1262 , 0.11395], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00847458, 0.01694915, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11864407, 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.19491525, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22881356, 0.22881356, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.29661018, 0.29661018, 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.33898306, 0.34745762, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3559322 , 0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.38135594, 0.38135594, 0.3898305 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.41525424, 0.41525424,\n",
       "            0.41525424, 0.43220338, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.48305085, 0.5       ,\n",
       "            0.5       , 0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.5508475 , 0.5677966 , 0.5762712 , 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.61864406,\n",
       "            0.63559324, 0.6440678 , 0.6440678 , 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6694915 , 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7033898 , 0.7118644 , 0.7118644 ,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7542373 , 0.7627119 , 0.7627119 ,\n",
       "            0.7711864 , 0.7711864 , 0.779661  , 0.7881356 , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8135593 , 0.8220339 ,\n",
       "            0.8220339 , 0.8220339 , 0.83898306, 0.84745765, 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.88135594, 0.88135594, 0.88135594,\n",
       "            0.88135594, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.90677965, 0.90677965, 0.90677965, 0.91525424, 0.91525424,\n",
       "            0.9237288 , 0.9237288 , 0.9322034 , 0.9322034 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9830508 ,\n",
       "            0.9915254 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.01515152,\n",
       "            0.02272727, 0.02272727, 0.03030303, 0.03030303, 0.04545455,\n",
       "            0.04545455, 0.04545455, 0.04545455, 0.0530303 , 0.06060606,\n",
       "            0.06060606, 0.06060606, 0.06818182, 0.06818182, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.08333334, 0.09090909, 0.09848485,\n",
       "            0.10606061, 0.10606061, 0.10606061, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.18939394, 0.18939394, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.22727273,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.24242425, 0.24242425,\n",
       "            0.24242425, 0.25      , 0.25      , 0.25      , 0.25757575,\n",
       "            0.25757575, 0.2651515 , 0.28030303, 0.28787878, 0.3030303 ,\n",
       "            0.3030303 , 0.3181818 , 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.38636363, 0.41666666,\n",
       "            0.42424244, 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5833333 , 0.5833333 , 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.59090906, 0.6060606 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.7348485 , 0.7348485 , 0.7348485 ,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.79545456, 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8636364 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.2769, 0.2751, 0.273 , 0.2727, 0.2717, 0.2705, 0.269 ,\n",
       "            0.268 , 0.2678, 0.2673, 0.2664, 0.2656, 0.2646, 0.2627, 0.2612,\n",
       "            0.259 , 0.2583, 0.2578, 0.2573, 0.256 , 0.2556, 0.2554, 0.2551,\n",
       "            0.2544, 0.2542, 0.254 , 0.2537, 0.252 , 0.2515, 0.2512, 0.2502,\n",
       "            0.2482, 0.248 , 0.2478, 0.2473, 0.2471, 0.2467, 0.2462, 0.2452,\n",
       "            0.2451, 0.2449, 0.2445, 0.2444, 0.244 , 0.2438, 0.2433, 0.243 ,\n",
       "            0.2429, 0.2424, 0.2421, 0.2413, 0.241 , 0.2406, 0.2402, 0.2401,\n",
       "            0.2394, 0.2391, 0.2379, 0.2368, 0.2367, 0.236 , 0.2358, 0.2355,\n",
       "            0.2352, 0.2347, 0.2343, 0.234 , 0.2338, 0.2334, 0.2332, 0.2328,\n",
       "            0.2327, 0.2323, 0.2322, 0.2307, 0.2286, 0.2285, 0.2283, 0.2281,\n",
       "            0.2277, 0.2268, 0.2263, 0.2255, 0.2251, 0.2247, 0.2244, 0.2239,\n",
       "            0.2233, 0.2229, 0.2227, 0.2224, 0.2222, 0.2218, 0.2217, 0.2208,\n",
       "            0.2203, 0.2198, 0.219 , 0.2189, 0.2184, 0.2168, 0.2167, 0.2166,\n",
       "            0.2161, 0.2153, 0.2152, 0.215 , 0.2147, 0.2145, 0.2144, 0.2142,\n",
       "            0.2139, 0.2135, 0.2124, 0.212 , 0.2113, 0.211 , 0.2104, 0.2103,\n",
       "            0.2101, 0.21  , 0.2094, 0.208 , 0.2079, 0.2076, 0.2073, 0.207 ,\n",
       "            0.2068, 0.2063, 0.2059, 0.2058, 0.2048, 0.2047, 0.2043, 0.204 ,\n",
       "            0.2039, 0.2034, 0.2024, 0.2023, 0.202 , 0.2004, 0.2002, 0.1998,\n",
       "            0.1996, 0.1987, 0.1982, 0.1981, 0.1976, 0.1974, 0.1953, 0.195 ,\n",
       "            0.1946, 0.194 , 0.1936, 0.1934, 0.1929, 0.1924, 0.1918, 0.1917,\n",
       "            0.1915, 0.1901, 0.1897, 0.1896, 0.189 , 0.1876, 0.1866, 0.186 ,\n",
       "            0.1849, 0.1843, 0.1842, 0.1835, 0.182 , 0.1812, 0.1808, 0.1798,\n",
       "            0.1797, 0.1771, 0.1764, 0.1763, 0.1758, 0.1746, 0.1744, 0.1733,\n",
       "            0.1724, 0.1721, 0.172 , 0.1718, 0.1708, 0.1705, 0.1703, 0.1696,\n",
       "            0.1675, 0.165 , 0.1602, 0.1561, 0.1532, 0.1525, 0.1415],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.07627118, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.09322034, 0.11016949, 0.11016949, 0.11016949, 0.11016949,\n",
       "            0.11016949, 0.11016949, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.1779661 , 0.1779661 , 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.19491525, 0.21186441, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.2457627 , 0.2457627 , 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.26271185, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.44915253, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.4661017 , 0.47457626, 0.48305085, 0.48305085, 0.48305085,\n",
       "            0.48305085, 0.48305085, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5169492 , 0.5254237 , 0.5423729 , 0.5423729 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5677966 , 0.5677966 , 0.58474576, 0.59322035, 0.59322035,\n",
       "            0.59322035, 0.59322035, 0.60169494, 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.62711865, 0.6440678 , 0.6440678 ,\n",
       "            0.6440678 , 0.6440678 , 0.6440678 , 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.69491524, 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.83898306, 0.83898306, 0.83898306, 0.84745765,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.87288135,\n",
       "            0.88135594, 0.88135594, 0.88135594, 0.8898305 , 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9576271 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.04545455, 0.0530303 , 0.0530303 ,\n",
       "            0.06060606, 0.06818182, 0.07575758, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.12121212, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.14393939, 0.15151516,\n",
       "            0.16666667, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.28030303, 0.28787878, 0.29545453, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.3560606 , 0.36363637, 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.3939394 , 0.40151516, 0.40151516,\n",
       "            0.41666666, 0.41666666, 0.42424244, 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.46969697, 0.47727272, 0.49242425, 0.5       ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5833333 , 0.5833333 ,\n",
       "            0.59090906, 0.59090906, 0.59090906, 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.7121212 , 0.7121212 , 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.7878788 , 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.81060606, 0.8181818 ,\n",
       "            0.8181818 , 0.82575756, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3083, 0.3074, 0.3062, 0.3044, 0.304 , 0.3027, 0.3022,\n",
       "            0.3015, 0.2993, 0.299 , 0.2986, 0.2969, 0.2964, 0.2961, 0.296 ,\n",
       "            0.2957, 0.2954, 0.2944, 0.2935, 0.2932, 0.2925, 0.2922, 0.292 ,\n",
       "            0.2917, 0.2915, 0.2908, 0.2898, 0.2883, 0.2874, 0.2864, 0.2861,\n",
       "            0.2856, 0.2852, 0.2847, 0.2834, 0.283 , 0.2827, 0.2822, 0.2815,\n",
       "            0.2812, 0.2805, 0.2803, 0.2798, 0.2795, 0.2793, 0.279 , 0.2786,\n",
       "            0.2776, 0.2769, 0.2766, 0.2764, 0.2761, 0.276 , 0.2756, 0.275 ,\n",
       "            0.2747, 0.2744, 0.2742, 0.2737, 0.2734, 0.2722, 0.2715, 0.271 ,\n",
       "            0.2708, 0.2698, 0.269 , 0.2678, 0.2673, 0.2664, 0.2646, 0.2644,\n",
       "            0.2632, 0.263 , 0.2627, 0.2622, 0.2617, 0.261 , 0.2607, 0.2605,\n",
       "            0.26  , 0.2598, 0.2595, 0.2573, 0.257 , 0.2568, 0.2563, 0.2559,\n",
       "            0.255 , 0.2546, 0.2544, 0.2542, 0.2532, 0.2527, 0.252 , 0.2512,\n",
       "            0.2507, 0.2505, 0.2496, 0.2494, 0.2478, 0.2466, 0.2458, 0.2451,\n",
       "            0.2444, 0.244 , 0.2437, 0.2433, 0.2429, 0.2428, 0.2426, 0.2424,\n",
       "            0.2415, 0.241 , 0.2407, 0.2405, 0.239 , 0.2388, 0.2372, 0.237 ,\n",
       "            0.2363, 0.236 , 0.2356, 0.2352, 0.2343, 0.2339, 0.233 , 0.2325,\n",
       "            0.2318, 0.2311, 0.2306, 0.229 , 0.2281, 0.228 , 0.2274, 0.2273,\n",
       "            0.2272, 0.2269, 0.2251, 0.2247, 0.2244, 0.2242, 0.2239, 0.2234,\n",
       "            0.2229, 0.2222, 0.222 , 0.2216, 0.2212, 0.2208, 0.2203, 0.2202,\n",
       "            0.2198, 0.2197, 0.2195, 0.2186, 0.2185, 0.2175, 0.2172, 0.2168,\n",
       "            0.2166, 0.2162, 0.2147, 0.2142, 0.214 , 0.2137, 0.2134, 0.2129,\n",
       "            0.2125, 0.2123, 0.212 , 0.2113, 0.2104, 0.2094, 0.2091, 0.2085,\n",
       "            0.2075, 0.2073, 0.2063, 0.2054, 0.2048, 0.2043, 0.2028, 0.2023,\n",
       "            0.2015, 0.2007, 0.2006, 0.2001, 0.1962, 0.1909, 0.1874, 0.1865,\n",
       "            0.1836, 0.183 , 0.1766, 0.1724, 0.1674, 0.1627, 0.1549],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.1440678 , 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.18644068, 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.2881356 , 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.40677965, 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.55932206, 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.59322035, 0.59322035, 0.59322035, 0.59322035,\n",
       "            0.60169494, 0.60169494, 0.61864406, 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.7033898 ,\n",
       "            0.7118644 , 0.7118644 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7288136 , 0.7372881 , 0.7372881 , 0.7372881 , 0.7457627 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.779661  ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.8305085 , 0.8559322 , 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.12878788, 0.13636364, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.31060606,\n",
       "            0.3181818 , 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.36363637, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.4318182 , 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6136364 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.65909094, 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.6818182 , 0.6818182 , 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.72727275, 0.7348485 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.79545456, 0.79545456, 0.79545456, 0.81060606,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.356 , 0.353 , 0.3525, 0.3513, 0.351 , 0.3508, 0.3506,\n",
       "            0.3494, 0.3489, 0.3481, 0.3477, 0.3474, 0.3472, 0.3464, 0.346 ,\n",
       "            0.3457, 0.3455, 0.3445, 0.3433, 0.343 , 0.3425, 0.342 , 0.3418,\n",
       "            0.3413, 0.3408, 0.3406, 0.3403, 0.34  , 0.3396, 0.3394, 0.3386,\n",
       "            0.3384, 0.3381, 0.3376, 0.3367, 0.3362, 0.3354, 0.3347, 0.3345,\n",
       "            0.3342, 0.3335, 0.3333, 0.333 , 0.3328, 0.3325, 0.3303, 0.33  ,\n",
       "            0.327 , 0.3252, 0.3247, 0.3235, 0.323 , 0.3223, 0.3206, 0.3203,\n",
       "            0.3198, 0.3193, 0.3145, 0.314 , 0.3108, 0.3105, 0.31  , 0.3079,\n",
       "            0.3076, 0.3071, 0.3064, 0.3062, 0.306 , 0.304 , 0.3035, 0.303 ,\n",
       "            0.3022, 0.302 , 0.3013, 0.301 , 0.3005, 0.299 , 0.2988, 0.298 ,\n",
       "            0.2969, 0.2961, 0.2954, 0.2947, 0.2944, 0.2937, 0.2925, 0.2915,\n",
       "            0.2913, 0.2905, 0.29  , 0.2896, 0.2883, 0.2876, 0.2869, 0.2866,\n",
       "            0.2861, 0.286 , 0.2847, 0.2834, 0.281 , 0.2803, 0.2793, 0.2788,\n",
       "            0.2783, 0.278 , 0.2778, 0.2776, 0.277 , 0.2769, 0.276 , 0.274 ,\n",
       "            0.2737, 0.2734, 0.273 , 0.2727, 0.2717, 0.2712, 0.2708, 0.2705,\n",
       "            0.2703, 0.27  , 0.2698, 0.2695, 0.2693, 0.269 , 0.2688, 0.2683,\n",
       "            0.2678, 0.2676, 0.2673, 0.2668, 0.2666, 0.2654, 0.265 , 0.2644,\n",
       "            0.264 , 0.2637, 0.2632, 0.263 , 0.2627, 0.2607, 0.2603, 0.2598,\n",
       "            0.2595, 0.2593, 0.2576, 0.2573, 0.2563, 0.2559, 0.2554, 0.2551,\n",
       "            0.254 , 0.2537, 0.2534, 0.253 , 0.2524, 0.2515, 0.251 , 0.2507,\n",
       "            0.2502, 0.25  , 0.249 , 0.2483, 0.2478, 0.2471, 0.2449, 0.2415,\n",
       "            0.2405, 0.2402, 0.2399, 0.2394, 0.2386, 0.2374, 0.236 , 0.2318,\n",
       "            0.2289, 0.2273, 0.2246, 0.2234, 0.2233, 0.223 , 0.2218, 0.2203,\n",
       "            0.2202, 0.2172, 0.2162, 0.2158, 0.2156, 0.2152, 0.2119, 0.2059,\n",
       "            0.2015, 0.1874, 0.1819, 0.169 , 0.1633, 0.1586, 0.1504, 0.1501],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.03389831, 0.03389831,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.06779661, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.12711865, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.19491525, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.2542373 , 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.33050847, 0.33050847, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3898305 , 0.40677965, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.44915253, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.4915254 , 0.4915254 , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 , 0.5677966 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6779661 , 0.6779661 , 0.6864407 , 0.69491524, 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7542373 , 0.7542373 ,\n",
       "            0.7542373 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.06818182, 0.07575758, 0.08333334, 0.09090909,\n",
       "            0.09848485, 0.11363637, 0.12121212, 0.12878788, 0.13636364,\n",
       "            0.14393939, 0.1590909 , 0.17424242, 0.1969697 , 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.24242425, 0.25      , 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.34848484, 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.45454547, 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.530303  , 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.56060606, 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.6969697 , 0.6969697 , 0.70454544, 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.7348485 , 0.7348485 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75757575, 0.75757575, 0.7651515 , 0.7651515 ,\n",
       "            0.77272725, 0.77272725, 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.82575756, 0.8333333 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.90909094, 0.90909094, 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4172, 0.4138, 0.4128, 0.4124, 0.412 , 0.4119, 0.4114,\n",
       "            0.4094, 0.4092, 0.4087, 0.4084, 0.408 , 0.4077, 0.407 , 0.4067,\n",
       "            0.4065, 0.4058, 0.4055, 0.4048, 0.4045, 0.4043, 0.404 , 0.4036,\n",
       "            0.4033, 0.4006, 0.3997, 0.3994, 0.3977, 0.3958, 0.3904, 0.39  ,\n",
       "            0.3896, 0.3865, 0.383 , 0.3826, 0.382 , 0.381 , 0.3809, 0.378 ,\n",
       "            0.3765, 0.3762, 0.3738, 0.3708, 0.3652, 0.365 , 0.364 , 0.3638,\n",
       "            0.3591, 0.3584, 0.3547, 0.352 , 0.3508, 0.3506, 0.3503, 0.3489,\n",
       "            0.346 , 0.3433, 0.3416, 0.3413, 0.3398, 0.3389, 0.3381, 0.338 ,\n",
       "            0.3376, 0.3354, 0.3352, 0.335 , 0.3347, 0.3342, 0.332 , 0.3306,\n",
       "            0.329 , 0.3276, 0.3262, 0.3252, 0.3247, 0.3245, 0.324 , 0.3232,\n",
       "            0.3228, 0.322 , 0.3218, 0.321 , 0.3208, 0.3206, 0.32  , 0.3198,\n",
       "            0.3193, 0.3188, 0.318 , 0.317 , 0.3154, 0.3145, 0.314 , 0.3137,\n",
       "            0.313 , 0.3125, 0.3123, 0.312 , 0.3115, 0.3113, 0.3108, 0.3105,\n",
       "            0.3098, 0.3093, 0.3088, 0.3076, 0.3071, 0.3066, 0.3064, 0.3062,\n",
       "            0.306 , 0.3052, 0.305 , 0.3047, 0.3042, 0.304 , 0.3037, 0.3035,\n",
       "            0.303 , 0.3025, 0.301 , 0.3008, 0.3003, 0.2993, 0.299 , 0.2988,\n",
       "            0.2986, 0.2983, 0.298 , 0.2969, 0.2966, 0.2964, 0.2961, 0.2947,\n",
       "            0.2937, 0.2927, 0.2917, 0.2915, 0.291 , 0.2896, 0.2893, 0.289 ,\n",
       "            0.2888, 0.288 , 0.2876, 0.2856, 0.2854, 0.2852, 0.2847, 0.2827,\n",
       "            0.2825, 0.2812, 0.281 , 0.2808, 0.2805, 0.2803, 0.2798, 0.2795,\n",
       "            0.2793, 0.2786, 0.2756, 0.2744, 0.2715, 0.2637, 0.263 , 0.2625,\n",
       "            0.262 , 0.2368, 0.2325, 0.2319, 0.2277, 0.2266, 0.2263, 0.2261,\n",
       "            0.2229, 0.2225, 0.22  , 0.2179, 0.2177, 0.2173, 0.217 , 0.213 ,\n",
       "            0.2058, 0.2009, 0.1874, 0.1783, 0.1641, 0.1583, 0.1531, 0.1447,\n",
       "            0.1445], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11016949, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.1779661 , 0.18644068,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.20338982, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.22033899, 0.22881356, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2457627 , 0.2457627 ,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 , 0.2542373 ,\n",
       "            0.2542373 , 0.27966103, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.38135594, 0.3898305 ,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44915253, 0.45762712, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5169492 , 0.5169492 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.6101695 , 0.6101695 , 0.6101695 ,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.62711865, 0.63559324,\n",
       "            0.63559324, 0.6440678 , 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.8898305 , 0.89830506, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.14393939, 0.15151516, 0.1590909 , 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.25      , 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.36363637, 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.6818182 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.75      , 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.780303  , 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.81060606, 0.81060606,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.82575756, 0.82575756,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8636364 ,\n",
       "            0.8636364 , 0.8712121 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 , 0.90909094,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4976, 0.4844, 0.4841, 0.4836, 0.4817, 0.48  , 0.4792,\n",
       "            0.4778, 0.4773, 0.477 , 0.4763, 0.4756, 0.4753, 0.4705, 0.468 ,\n",
       "            0.4663, 0.4658, 0.4656, 0.4646, 0.4634, 0.4631, 0.4626, 0.462 ,\n",
       "            0.4612, 0.461 , 0.4607, 0.4587, 0.4585, 0.4575, 0.457 , 0.4568,\n",
       "            0.4548, 0.4543, 0.452 , 0.4502, 0.446 , 0.444 , 0.4438, 0.443 ,\n",
       "            0.4414, 0.438 , 0.4355, 0.4353, 0.4312, 0.4294, 0.4292, 0.4272,\n",
       "            0.4268, 0.4265, 0.4197, 0.418 , 0.417 , 0.4167, 0.4084, 0.4053,\n",
       "            0.4014, 0.401 , 0.4   , 0.3977, 0.3955, 0.3948, 0.3936, 0.3923,\n",
       "            0.3843, 0.3804, 0.379 , 0.3782, 0.3765, 0.3757, 0.3752, 0.3745,\n",
       "            0.3735, 0.3728, 0.3706, 0.37  , 0.3694, 0.3687, 0.3665, 0.3662,\n",
       "            0.3647, 0.3633, 0.3625, 0.362 , 0.3616, 0.3606, 0.3604, 0.3599,\n",
       "            0.3594, 0.3591, 0.3584, 0.358 , 0.3574, 0.3572, 0.3564, 0.356 ,\n",
       "            0.3557, 0.3552, 0.355 , 0.3523, 0.352 , 0.3518, 0.3516, 0.351 ,\n",
       "            0.3503, 0.35  , 0.3499, 0.3489, 0.3486, 0.3484, 0.3472, 0.3464,\n",
       "            0.3462, 0.3452, 0.345 , 0.344 , 0.3438, 0.343 , 0.3428, 0.3425,\n",
       "            0.3418, 0.3416, 0.3413, 0.341 , 0.3408, 0.34  , 0.3394, 0.339 ,\n",
       "            0.3389, 0.3386, 0.3376, 0.3374, 0.3372, 0.337 , 0.3367, 0.3357,\n",
       "            0.3354, 0.335 , 0.3347, 0.3345, 0.3342, 0.334 , 0.3335, 0.3333,\n",
       "            0.3325, 0.332 , 0.3313, 0.3306, 0.3303, 0.3298, 0.3289, 0.328 ,\n",
       "            0.3274, 0.3271, 0.327 , 0.3267, 0.3262, 0.3252, 0.3247, 0.3232,\n",
       "            0.3225, 0.3213, 0.3208, 0.319 , 0.3188, 0.3186, 0.3184, 0.3179,\n",
       "            0.3137, 0.305 , 0.2974, 0.295 , 0.2935, 0.293 , 0.2915, 0.2903,\n",
       "            0.2886, 0.2864, 0.2852, 0.2842, 0.284 , 0.2717, 0.2715, 0.2708,\n",
       "            0.27  , 0.2415, 0.236 , 0.2306, 0.2299, 0.2295, 0.2294, 0.2289,\n",
       "            0.2252, 0.2249, 0.2222, 0.2197, 0.2195, 0.2186, 0.2142, 0.2056,\n",
       "            0.2001, 0.1877, 0.1754, 0.1598, 0.1539, 0.1481, 0.1399, 0.1392],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.29545453, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.08474576,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11016949, 0.11016949, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.1779661 , 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.43220338, 0.43220338, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.55932206, 0.55932206, 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 , 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.62711865, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7288136 , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7711864 , 0.779661  ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06818182, 0.07575758, 0.09090909,\n",
       "            0.09848485, 0.10606061, 0.11363637, 0.12121212, 0.12878788,\n",
       "            0.13636364, 0.15151516, 0.1590909 , 0.17424242, 0.18181819,\n",
       "            0.20454545, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.4090909 , 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.47727272, 0.4848485 , 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.5       , 0.5       , 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.72727275, 0.72727275, 0.72727275, 0.7348485 , 0.7348485 ,\n",
       "            0.7348485 , 0.74242425, 0.75      , 0.7651515 , 0.77272725,\n",
       "            0.77272725, 0.77272725, 0.7878788 , 0.7878788 , 0.7878788 ,\n",
       "            0.7878788 , 0.7878788 , 0.79545456, 0.79545456, 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8484849 , 0.8484849 , 0.8484849 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.571 , 0.5493, 0.549 , 0.546 , 0.543 , 0.5425, 0.541 ,\n",
       "            0.5405, 0.5366, 0.533 , 0.531 , 0.5234, 0.5225, 0.522 , 0.5215,\n",
       "            0.5205, 0.52  , 0.5186, 0.5166, 0.514 , 0.5137, 0.513 , 0.511 ,\n",
       "            0.5093, 0.5083, 0.5063, 0.506 , 0.5054, 0.505 , 0.5034, 0.502 ,\n",
       "            0.4988, 0.4946, 0.4937, 0.4934, 0.4897, 0.4888, 0.4817, 0.4812,\n",
       "            0.479 , 0.478 , 0.4768, 0.4722, 0.4683, 0.465 , 0.4648, 0.4597,\n",
       "            0.4558, 0.4548, 0.4517, 0.4448, 0.4436, 0.4429, 0.44  , 0.4397,\n",
       "            0.436 , 0.4343, 0.4336, 0.428 , 0.4277, 0.4253, 0.4236, 0.419 ,\n",
       "            0.4177, 0.4172, 0.4143, 0.4114, 0.4111, 0.4094, 0.409 , 0.4077,\n",
       "            0.4075, 0.407 , 0.4065, 0.4038, 0.4026, 0.4019, 0.4014, 0.4011,\n",
       "            0.4006, 0.4004, 0.3987, 0.3962, 0.396 , 0.3955, 0.3943, 0.394 ,\n",
       "            0.3936, 0.393 , 0.3928, 0.3926, 0.3887, 0.3884, 0.3882, 0.3867,\n",
       "            0.3862, 0.3857, 0.3855, 0.3853, 0.385 , 0.3845, 0.384 , 0.3838,\n",
       "            0.3835, 0.3823, 0.3813, 0.3809, 0.3806, 0.3804, 0.3796, 0.379 ,\n",
       "            0.3787, 0.3784, 0.378 , 0.3772, 0.377 , 0.376 , 0.3757, 0.3748,\n",
       "            0.3745, 0.3743, 0.3735, 0.3728, 0.3726, 0.3718, 0.371 , 0.3704,\n",
       "            0.369 , 0.3687, 0.3684, 0.368 , 0.3677, 0.3674, 0.3672, 0.3667,\n",
       "            0.3665, 0.3662, 0.3657, 0.3655, 0.3652, 0.365 , 0.3647, 0.3645,\n",
       "            0.364 , 0.3638, 0.3633, 0.3618, 0.3613, 0.361 , 0.36  , 0.3599,\n",
       "            0.3582, 0.358 , 0.357 , 0.3567, 0.3562, 0.356 , 0.3552, 0.355 ,\n",
       "            0.354 , 0.353 , 0.3513, 0.351 , 0.3508, 0.3486, 0.3481, 0.3433,\n",
       "            0.3413, 0.3357, 0.3347, 0.3267, 0.3083, 0.3064, 0.3052, 0.3044,\n",
       "            0.3032, 0.3   , 0.298 , 0.2974, 0.2964, 0.2957, 0.293 , 0.28  ,\n",
       "            0.2786, 0.2783, 0.2466, 0.2406, 0.2391, 0.2338, 0.2334, 0.2327,\n",
       "            0.2323, 0.2316, 0.2274, 0.2272, 0.2255, 0.2213, 0.2212, 0.2203,\n",
       "            0.2158, 0.2059, 0.2   , 0.1877, 0.1735, 0.1569, 0.1505, 0.1449,\n",
       "            0.136 , 0.1359], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.40151516, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.03389831, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.09322034, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.18644068, 0.19491525, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.22033899, 0.22033899, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.31355932, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.34745762, 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3898305 , 0.3898305 , 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5423729 , 0.5508475 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.60169494, 0.60169494, 0.6101695 , 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.7118644 , 0.720339  , 0.7288136 , 0.7372881 ,\n",
       "            0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12121212,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.5       , 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.5681818 , 0.5681818 ,\n",
       "            0.57575756, 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.72727275, 0.72727275, 0.72727275, 0.72727275, 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.75757575, 0.75757575,\n",
       "            0.75757575, 0.75757575, 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8787879 , 0.8863636 , 0.9015151 ,\n",
       "            0.9015151 , 0.9015151 , 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.9848485 , 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.633 , 0.606 , 0.6045, 0.601 , 0.599 , 0.596 , 0.5957,\n",
       "            0.5947, 0.5894, 0.589 , 0.5835, 0.583 , 0.573 , 0.572 , 0.5713,\n",
       "            0.5693, 0.5674, 0.566 , 0.5654, 0.565 , 0.5645, 0.561 , 0.5596,\n",
       "            0.559 , 0.558 , 0.5576, 0.554 , 0.5522, 0.55  , 0.549 , 0.5474,\n",
       "            0.5454, 0.5444, 0.5435, 0.5376, 0.535 , 0.5327, 0.5317, 0.5283,\n",
       "            0.523 , 0.522 , 0.5176, 0.516 , 0.5127, 0.5054, 0.499 , 0.498 ,\n",
       "            0.4978, 0.4885, 0.488 , 0.485 , 0.4824, 0.4775, 0.476 , 0.4744,\n",
       "            0.4707, 0.4705, 0.469 , 0.4688, 0.4673, 0.4622, 0.4607, 0.4573,\n",
       "            0.4556, 0.4517, 0.4512, 0.4507, 0.4495, 0.4456, 0.4453, 0.4438,\n",
       "            0.4421, 0.4417, 0.4414, 0.4407, 0.44  , 0.4385, 0.437 , 0.4365,\n",
       "            0.4363, 0.4355, 0.4353, 0.4346, 0.434 , 0.4333, 0.4324, 0.4302,\n",
       "            0.43  , 0.4294, 0.429 , 0.428 , 0.4253, 0.4246, 0.4243, 0.4236,\n",
       "            0.4233, 0.4229, 0.4224, 0.422 , 0.4219, 0.4216, 0.421 , 0.4207,\n",
       "            0.4202, 0.42  , 0.4182, 0.4175, 0.416 , 0.4158, 0.4155, 0.4153,\n",
       "            0.4148, 0.4146, 0.414 , 0.4138, 0.4133, 0.413 , 0.4124, 0.412 ,\n",
       "            0.4106, 0.4102, 0.4094, 0.4092, 0.409 , 0.4087, 0.4082, 0.4077,\n",
       "            0.407 , 0.4067, 0.4062, 0.4058, 0.4053, 0.405 , 0.4048, 0.4045,\n",
       "            0.4038, 0.4033, 0.4028, 0.4019, 0.4014, 0.4011, 0.4006, 0.4001,\n",
       "            0.4   , 0.3977, 0.3972, 0.397 , 0.3965, 0.3962, 0.3948, 0.3936,\n",
       "            0.3933, 0.393 , 0.3918, 0.3916, 0.3909, 0.3901, 0.39  , 0.3896,\n",
       "            0.389 , 0.3887, 0.3877, 0.3872, 0.3835, 0.3828, 0.3823, 0.3813,\n",
       "            0.3804, 0.3782, 0.3767, 0.3752, 0.3748, 0.372 , 0.3694, 0.3672,\n",
       "            0.358 , 0.355 , 0.3494, 0.3477, 0.3386, 0.3188, 0.3174, 0.3164,\n",
       "            0.3152, 0.3147, 0.3108, 0.3093, 0.3071, 0.3064, 0.306 , 0.3018,\n",
       "            0.2886, 0.2883, 0.2866, 0.252 , 0.246 , 0.2429, 0.2383, 0.2367,\n",
       "            0.2362, 0.236 , 0.2346, 0.2301, 0.2297, 0.2295, 0.2238, 0.2233,\n",
       "            0.2225, 0.2181, 0.207 , 0.2009, 0.1882, 0.1729, 0.1555, 0.1482,\n",
       "            0.143 , 0.134 , 0.1333], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02542373, dtype=float32),\n",
       "    'tpr': array(0.46969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.16949153, 0.1779661 ,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.30508474, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.33050847, 0.33898306, 0.3559322 ,\n",
       "            0.37288135, 0.38135594, 0.3898305 , 0.3983051 , 0.3983051 ,\n",
       "            0.3983051 , 0.40677965, 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.41525424, 0.42372882, 0.42372882,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.45762712, 0.47457626, 0.48305085,\n",
       "            0.5       , 0.5084746 , 0.5169492 , 0.5254237 , 0.5254237 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.6101695 , 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6779661 , 0.6864407 , 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.7118644 , 0.720339  , 0.7288136 ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.2651515 , 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.65909094, 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.7121212 , 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.72727275, 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.7651515 , 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.7878788 , 0.7878788 , 0.7878788 , 0.8030303 , 0.8030303 ,\n",
       "            0.8030303 , 0.8030303 , 0.8030303 , 0.8030303 , 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8636364 , 0.8787879 , 0.8863636 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.683 , 0.653 , 0.6523, 0.6504, 0.6465, 0.6455, 0.642 ,\n",
       "            0.641 , 0.6396, 0.634 , 0.632 , 0.6265, 0.626 , 0.615 , 0.6133,\n",
       "            0.613 , 0.6104, 0.6074, 0.6064, 0.6045, 0.604 , 0.6035, 0.6   ,\n",
       "            0.5986, 0.598 , 0.5977, 0.597 , 0.596 , 0.595 , 0.592 , 0.5894,\n",
       "            0.587 , 0.5864, 0.585 , 0.5835, 0.5796, 0.579 , 0.575 , 0.5737,\n",
       "            0.565 , 0.5645, 0.562 , 0.5605, 0.5566, 0.5522, 0.5483, 0.5474,\n",
       "            0.537 , 0.5303, 0.5293, 0.527 , 0.52  , 0.5176, 0.516 , 0.51  ,\n",
       "            0.5063, 0.5044, 0.504 , 0.503 , 0.5024, 0.4993, 0.4985, 0.4949,\n",
       "            0.4944, 0.494 , 0.4915, 0.4878, 0.4836, 0.4827, 0.4817, 0.4802,\n",
       "            0.4797, 0.4788, 0.4768, 0.4753, 0.4746, 0.4734, 0.4727, 0.472 ,\n",
       "            0.4707, 0.4705, 0.4702, 0.4695, 0.4688, 0.4683, 0.467 , 0.4666,\n",
       "            0.4646, 0.4636, 0.4626, 0.4612, 0.4602, 0.4595, 0.4585, 0.4573,\n",
       "            0.457 , 0.4558, 0.4548, 0.4534, 0.4531, 0.4517, 0.4512, 0.451 ,\n",
       "            0.4504, 0.4497, 0.4495, 0.4485, 0.4482, 0.4473, 0.4458, 0.4456,\n",
       "            0.4453, 0.445 , 0.4448, 0.444 , 0.443 , 0.4417, 0.439 , 0.4385,\n",
       "            0.4377, 0.4375, 0.4373, 0.437 , 0.4363, 0.4358, 0.4355, 0.4353,\n",
       "            0.434 , 0.4333, 0.4329, 0.4326, 0.432 , 0.4314, 0.4312, 0.4302,\n",
       "            0.4297, 0.4294, 0.428 , 0.427 , 0.4263, 0.425 , 0.4243, 0.424 ,\n",
       "            0.4238, 0.4236, 0.4233, 0.422 , 0.4219, 0.4216, 0.421 , 0.4194,\n",
       "            0.419 , 0.4185, 0.4182, 0.4165, 0.4163, 0.4158, 0.4153, 0.4143,\n",
       "            0.4138, 0.4124, 0.4084, 0.4077, 0.4055, 0.405 , 0.403 , 0.4026,\n",
       "            0.4011, 0.3982, 0.3965, 0.3953, 0.3945, 0.392 , 0.391 , 0.3833,\n",
       "            0.3806, 0.3716, 0.3677, 0.3618, 0.36  , 0.35  , 0.3289, 0.3276,\n",
       "            0.3267, 0.3252, 0.325 , 0.322 , 0.3184, 0.316 , 0.3157, 0.3152,\n",
       "            0.3105, 0.2969, 0.2961, 0.2944, 0.257 , 0.2507, 0.2473, 0.2424,\n",
       "            0.2406, 0.2401, 0.2397, 0.2384, 0.2338, 0.2334, 0.2332, 0.2266,\n",
       "            0.2263, 0.2255, 0.2252, 0.2208, 0.2089, 0.2023, 0.1903, 0.1729,\n",
       "            0.1545, 0.1473, 0.1418, 0.1326, 0.1321], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.11864407, dtype=float32),\n",
       "    'tpr': array(0.57575756, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.04237288, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.06779661, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.09322034, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.12711865, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.1779661 , 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2457627 , 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 , 0.3644068 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3898305 ,\n",
       "            0.3898305 , 0.3898305 , 0.3898305 , 0.3898305 , 0.3898305 ,\n",
       "            0.3898305 , 0.40677965, 0.40677965, 0.42372882, 0.42372882,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.48305085, 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5508475 , 0.55932206, 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7118644 , 0.7118644 , 0.720339  ,\n",
       "            0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 , 0.7711864 ,\n",
       "            0.7881356 , 0.7966102 , 0.80508476, 0.8135593 , 0.8220339 ,\n",
       "            0.8305085 , 0.83898306, 0.84745765, 0.8559322 , 0.86440676,\n",
       "            0.87288135, 0.88135594, 0.8898305 , 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.1590909 , 0.17424242,\n",
       "            0.18181819, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.3030303 ,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.45454547, 0.45454547, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.5151515 , 0.5151515 ,\n",
       "            0.52272725, 0.52272725, 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.56060606, 0.5681818 , 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6136364 ,\n",
       "            0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.65909094, 0.6666667 , 0.67424244, 0.6818182 , 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.7348485 , 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.75757575, 0.75757575, 0.7651515 ,\n",
       "            0.7651515 , 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.7878788 , 0.7878788 ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8560606 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.9469697 , 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.73  , 0.697 , 0.6963, 0.694 , 0.69  , 0.6855, 0.6846,\n",
       "            0.684 , 0.682 , 0.676 , 0.6733, 0.668 , 0.6665, 0.6553, 0.6533,\n",
       "            0.6523, 0.65  , 0.646 , 0.642 , 0.641 , 0.638 , 0.6367, 0.6357,\n",
       "            0.6353, 0.635 , 0.633 , 0.632 , 0.6284, 0.6255, 0.623 , 0.6206,\n",
       "            0.6187, 0.6143, 0.614 , 0.6123, 0.612 , 0.6113, 0.597 , 0.5947,\n",
       "            0.591 , 0.5864, 0.5815, 0.5806, 0.5776, 0.569 , 0.5625, 0.559 ,\n",
       "            0.5557, 0.555 , 0.546 , 0.544 , 0.537 , 0.5356, 0.535 , 0.5347,\n",
       "            0.532 , 0.5317, 0.5303, 0.5273, 0.521 , 0.5205, 0.5186, 0.517 ,\n",
       "            0.5166, 0.513 , 0.512 , 0.5117, 0.5107, 0.5103, 0.5093, 0.509 ,\n",
       "            0.5083, 0.5073, 0.505 , 0.503 , 0.5024, 0.501 , 0.4998, 0.4988,\n",
       "            0.4983, 0.4978, 0.4973, 0.4963, 0.495 , 0.4932, 0.492 , 0.4907,\n",
       "            0.4897, 0.4883, 0.488 , 0.4858, 0.4849, 0.4844, 0.4841, 0.482 ,\n",
       "            0.4812, 0.4802, 0.4792, 0.4785, 0.478 , 0.4778, 0.4763, 0.476 ,\n",
       "            0.474 , 0.4734, 0.473 , 0.4714, 0.4712, 0.471 , 0.47  , 0.4697,\n",
       "            0.4695, 0.4675, 0.467 , 0.4668, 0.4663, 0.466 , 0.4653, 0.465 ,\n",
       "            0.4648, 0.464 , 0.4636, 0.463 , 0.4626, 0.4624, 0.462 , 0.4612,\n",
       "            0.4607, 0.46  , 0.4597, 0.4592, 0.4578, 0.4563, 0.456 , 0.4556,\n",
       "            0.455 , 0.4548, 0.4546, 0.4521, 0.452 , 0.4517, 0.4514, 0.4512,\n",
       "            0.451 , 0.4507, 0.4504, 0.4502, 0.4495, 0.4473, 0.444 , 0.4438,\n",
       "            0.4436, 0.4414, 0.4412, 0.4407, 0.4404, 0.4387, 0.4363, 0.4358,\n",
       "            0.4326, 0.4265, 0.424 , 0.4233, 0.4207, 0.4187, 0.4185, 0.414 ,\n",
       "            0.4106, 0.4104, 0.4102, 0.4092, 0.3977, 0.3945, 0.3853, 0.3806,\n",
       "            0.3745, 0.3723, 0.362 , 0.3386, 0.3376, 0.337 , 0.335 , 0.3335,\n",
       "            0.3276, 0.325 , 0.3245, 0.319 , 0.3047, 0.304 , 0.3018, 0.262 ,\n",
       "            0.255 , 0.2512, 0.2462, 0.244 , 0.2433, 0.243 , 0.2418, 0.2367,\n",
       "            0.2366, 0.2363, 0.2292, 0.229 , 0.2278, 0.2274, 0.2233, 0.2101,\n",
       "            0.2031, 0.1919, 0.1724, 0.1533, 0.1459, 0.1403, 0.1309, 0.1304],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.2457627, dtype=float32),\n",
       "    'tpr': array(0.75, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05932203, 0.06779661, 0.06779661, 0.08474576,\n",
       "            0.08474576, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22033899, 0.23728813, 0.23728813, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.31355932, 0.31355932,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.33898306, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3559322 , 0.3644068 ,\n",
       "            0.3644068 , 0.3644068 , 0.3644068 , 0.37288135, 0.37288135,\n",
       "            0.37288135, 0.37288135, 0.38135594, 0.3983051 , 0.3983051 ,\n",
       "            0.40677965, 0.40677965, 0.40677965, 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.48305085, 0.48305085, 0.4915254 , 0.5       , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.59322035, 0.60169494, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6779661 , 0.6864407 ,\n",
       "            0.69491524, 0.7033898 , 0.7118644 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.23484848, 0.24242425, 0.25      ,\n",
       "            0.25757575, 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.41666666,\n",
       "            0.42424244, 0.43939394, 0.4469697 , 0.45454547, 0.45454547,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.59090906, 0.5984849 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.6969697 , 0.6969697 , 0.70454544, 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75      ,\n",
       "            0.75757575, 0.75757575, 0.75757575, 0.75757575, 0.75757575,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.780303  , 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.81060606, 0.8181818 , 0.82575756, 0.82575756,\n",
       "            0.8333333 , 0.84090906, 0.8484849 , 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.90909094,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.772 , 0.738 , 0.7373, 0.7344, 0.7305, 0.726 , 0.725 ,\n",
       "            0.724 , 0.7217, 0.7153, 0.7124, 0.7075, 0.7046, 0.694 , 0.6914,\n",
       "            0.6904, 0.688 , 0.684 , 0.683 , 0.678 , 0.6777, 0.675 , 0.673 ,\n",
       "            0.672 , 0.671 , 0.6685, 0.667 , 0.664 , 0.6606, 0.659 , 0.658 ,\n",
       "            0.6577, 0.6553, 0.6523, 0.6475, 0.6465, 0.6313, 0.629 , 0.6284,\n",
       "            0.6265, 0.6245, 0.62  , 0.615 , 0.612 , 0.607 , 0.5996, 0.5933,\n",
       "            0.5894, 0.5884, 0.5835, 0.574 , 0.5728, 0.5713, 0.568 , 0.5664,\n",
       "            0.565 , 0.564 , 0.563 , 0.561 , 0.5605, 0.56  , 0.5596, 0.5557,\n",
       "            0.5527, 0.5503, 0.549 , 0.547 , 0.5464, 0.546 , 0.5454, 0.5435,\n",
       "            0.543 , 0.5386, 0.5347, 0.5337, 0.533 , 0.5312, 0.5303, 0.53  ,\n",
       "            0.529 , 0.5264, 0.5254, 0.5215, 0.521 , 0.519 , 0.5186, 0.518 ,\n",
       "            0.5176, 0.5146, 0.511 , 0.5107, 0.51  , 0.5093, 0.508 , 0.507 ,\n",
       "            0.506 , 0.5054, 0.505 , 0.504 , 0.5024, 0.502 , 0.5015, 0.501 ,\n",
       "            0.5005, 0.5   , 0.4998, 0.498 , 0.4976, 0.4973, 0.497 , 0.4966,\n",
       "            0.4958, 0.4946, 0.4937, 0.4927, 0.4922, 0.4912, 0.491 , 0.4907,\n",
       "            0.4895, 0.4885, 0.4873, 0.487 , 0.4863, 0.4858, 0.4854, 0.485 ,\n",
       "            0.4846, 0.4844, 0.484 , 0.4832, 0.483 , 0.4827, 0.4814, 0.4807,\n",
       "            0.4805, 0.4797, 0.479 , 0.4785, 0.4783, 0.4778, 0.4773, 0.477 ,\n",
       "            0.4766, 0.4758, 0.475 , 0.472 , 0.4714, 0.47  , 0.469 , 0.4688,\n",
       "            0.4673, 0.467 , 0.4658, 0.465 , 0.464 , 0.463 , 0.4592, 0.4573,\n",
       "            0.4517, 0.4443, 0.4412, 0.44  , 0.4355, 0.4336, 0.4297, 0.429 ,\n",
       "            0.427 , 0.426 , 0.425 , 0.4114, 0.4072, 0.3984, 0.3928, 0.3867,\n",
       "            0.3843, 0.3728, 0.3481, 0.3477, 0.347 , 0.345 , 0.3447, 0.3445,\n",
       "            0.3357, 0.3337, 0.3335, 0.333 , 0.3271, 0.3123, 0.3113, 0.3088,\n",
       "            0.266 , 0.2588, 0.2542, 0.2494, 0.2467, 0.246 , 0.2458, 0.2444,\n",
       "            0.2394, 0.239 , 0.2384, 0.2307, 0.2294, 0.2289, 0.2247, 0.2104,\n",
       "            0.2032, 0.1921, 0.1709, 0.1511, 0.1436, 0.138 , 0.1285, 0.1278],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.42372882, dtype=float32),\n",
       "    'tpr': array(0.92424244, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.22881356, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.26271185, 0.27118644,\n",
       "            0.2881356 , 0.2881356 , 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.33050847, 0.33898306, 0.33898306, 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3559322 , 0.37288135,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.41525424, 0.41525424, 0.42372882,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5169492 , 0.5254237 ,\n",
       "            0.5338983 , 0.5338983 , 0.5423729 , 0.5508475 , 0.5508475 ,\n",
       "            0.55932206, 0.5677966 , 0.5762712 , 0.58474576, 0.58474576,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.69491524,\n",
       "            0.7033898 , 0.7118644 , 0.720339  , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.3030303 , 0.31060606,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46212122, 0.46212122, 0.46969697, 0.47727272, 0.4848485 ,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.530303  , 0.530303  , 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5681818 , 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 , 0.6136364 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.65909094, 0.6666667 , 0.6818182 ,\n",
       "            0.68939394, 0.68939394, 0.68939394, 0.6969697 , 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.74242425, 0.75      , 0.75757575, 0.75757575,\n",
       "            0.75757575, 0.77272725, 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.79545456, 0.79545456, 0.79545456, 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8712121 , 0.8712121 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.804 , 0.7695, 0.7686, 0.766 , 0.762 , 0.7617, 0.758 ,\n",
       "            0.7563, 0.7554, 0.753 , 0.7466, 0.7437, 0.7383, 0.7354, 0.724 ,\n",
       "            0.722 , 0.7217, 0.7207, 0.7183, 0.714 , 0.713 , 0.7075, 0.7065,\n",
       "            0.7046, 0.7026, 0.701 , 0.7007, 0.6997, 0.697 , 0.6953, 0.693 ,\n",
       "            0.6895, 0.6885, 0.6865, 0.686 , 0.683 , 0.68  , 0.676 , 0.6753,\n",
       "            0.675 , 0.659 , 0.655 , 0.6543, 0.653 , 0.652 , 0.6475, 0.642 ,\n",
       "            0.6377, 0.6313, 0.6255, 0.6187, 0.618 , 0.6123, 0.608 , 0.606 ,\n",
       "            0.6045, 0.5977, 0.597 , 0.596 , 0.5947, 0.5933, 0.5903, 0.5884,\n",
       "            0.5864, 0.586 , 0.583 , 0.5825, 0.58  , 0.5786, 0.577 , 0.5767,\n",
       "            0.576 , 0.575 , 0.5747, 0.574 , 0.5684, 0.5635, 0.5615, 0.5605,\n",
       "            0.56  , 0.559 , 0.5586, 0.5566, 0.555 , 0.5547, 0.5537, 0.553 ,\n",
       "            0.5522, 0.55  , 0.549 , 0.548 , 0.545 , 0.5425, 0.541 , 0.5405,\n",
       "            0.5396, 0.538 , 0.537 , 0.536 , 0.535 , 0.5337, 0.5327, 0.532 ,\n",
       "            0.531 , 0.5303, 0.53  , 0.529 , 0.5283, 0.528 , 0.527 , 0.5264,\n",
       "            0.5254, 0.525 , 0.5244, 0.5234, 0.5215, 0.521 , 0.52  , 0.517 ,\n",
       "            0.5166, 0.5156, 0.514 , 0.5137, 0.513 , 0.5127, 0.5117, 0.511 ,\n",
       "            0.5107, 0.5103, 0.508 , 0.507 , 0.5063, 0.506 , 0.5054, 0.5034,\n",
       "            0.5024, 0.5015, 0.501 , 0.5005, 0.4998, 0.498 , 0.4958, 0.4956,\n",
       "            0.495 , 0.4927, 0.492 , 0.4905, 0.4897, 0.4878, 0.4873, 0.4863,\n",
       "            0.486 , 0.4854, 0.4849, 0.4846, 0.4844, 0.4792, 0.4785, 0.4736,\n",
       "            0.463 , 0.4592, 0.4568, 0.449 , 0.4473, 0.4465, 0.4438, 0.441 ,\n",
       "            0.4382, 0.4238, 0.419 , 0.4106, 0.4043, 0.3977, 0.395 , 0.383 ,\n",
       "            0.3572, 0.3567, 0.3562, 0.355 , 0.3545, 0.3538, 0.344 , 0.3423,\n",
       "            0.341 , 0.335 , 0.3196, 0.3186, 0.316 , 0.3157, 0.2708, 0.2634,\n",
       "            0.258 , 0.2534, 0.25  , 0.2494, 0.249 , 0.2477, 0.2429, 0.2418,\n",
       "            0.2415, 0.2334, 0.2319, 0.2313, 0.2272, 0.212 , 0.2045, 0.1937,\n",
       "            0.171 , 0.1508, 0.1428, 0.1372, 0.1278, 0.1268], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5254237, dtype=float32),\n",
       "    'tpr': array(0.9621212, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.04237288,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05932203, 0.05932203, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.1779661 , 0.1779661 ,\n",
       "            0.18644068, 0.18644068, 0.19491525, 0.19491525, 0.19491525,\n",
       "            0.21186441, 0.21186441, 0.22881356, 0.23728813, 0.26271185,\n",
       "            0.27966103, 0.27966103, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.29661018, 0.29661018, 0.29661018, 0.30508474,\n",
       "            0.3220339 , 0.3220339 , 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.38135594, 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5       , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5508475 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.58474576, 0.59322035,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.8898305 , 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.27272728,\n",
       "            0.28030303, 0.28787878, 0.3030303 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46212122, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.5       , 0.52272725, 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.56060606, 0.5681818 , 0.5681818 , 0.5681818 , 0.5681818 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.7348485 , 0.74242425, 0.7651515 , 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.8030303 , 0.81060606, 0.81060606, 0.81060606, 0.82575756,\n",
       "            0.84090906, 0.84090906, 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8636364 , 0.8636364 , 0.8863636 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.95454544, 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.9621212 , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.833 , 0.7993, 0.7983, 0.7954, 0.7915, 0.791 , 0.7866,\n",
       "            0.786 , 0.7847, 0.782 , 0.776 , 0.7725, 0.768 , 0.764 , 0.7534,\n",
       "            0.751 , 0.7495, 0.747 , 0.742 , 0.741 , 0.736 , 0.7354, 0.735 ,\n",
       "            0.733 , 0.7305, 0.729 , 0.7285, 0.7275, 0.7246, 0.723 , 0.7207,\n",
       "            0.717 , 0.716 , 0.714 , 0.7104, 0.7075, 0.703 , 0.702 , 0.7017,\n",
       "            0.686 , 0.68  , 0.6797, 0.678 , 0.6743, 0.669 , 0.663 , 0.6553,\n",
       "            0.6504, 0.646 , 0.644 , 0.6367, 0.636 , 0.6357, 0.633 , 0.6313,\n",
       "            0.621 , 0.6196, 0.619 , 0.616 , 0.615 , 0.614 , 0.613 , 0.612 ,\n",
       "            0.611 , 0.609 , 0.608 , 0.6064, 0.6055, 0.6045, 0.604 , 0.6035,\n",
       "            0.602 , 0.5903, 0.59  , 0.5894, 0.5884, 0.588 , 0.5874, 0.587 ,\n",
       "            0.5835, 0.583 , 0.5825, 0.578 , 0.5776, 0.5767, 0.576 , 0.572 ,\n",
       "            0.5703, 0.57  , 0.568 , 0.567 , 0.5664, 0.565 , 0.5645, 0.564 ,\n",
       "            0.5635, 0.562 , 0.5615, 0.56  , 0.559 , 0.553 , 0.5527, 0.552 ,\n",
       "            0.5513, 0.551 , 0.5503, 0.55  , 0.5493, 0.5464, 0.546 , 0.545 ,\n",
       "            0.543 , 0.5425, 0.5415, 0.541 , 0.54  , 0.5396, 0.5386, 0.538 ,\n",
       "            0.5376, 0.5366, 0.5347, 0.5327, 0.532 , 0.5312, 0.5303, 0.5283,\n",
       "            0.528 , 0.527 , 0.5264, 0.526 , 0.5244, 0.5234, 0.522 , 0.521 ,\n",
       "            0.5205, 0.52  , 0.516 , 0.515 , 0.514 , 0.5127, 0.512 , 0.5117,\n",
       "            0.5093, 0.509 , 0.5073, 0.5063, 0.505 , 0.5024, 0.502 , 0.5   ,\n",
       "            0.4954, 0.4817, 0.4788, 0.473 , 0.4644, 0.4624, 0.4604, 0.4578,\n",
       "            0.457 , 0.455 , 0.4514, 0.4363, 0.4307, 0.4229, 0.4155, 0.409 ,\n",
       "            0.406 , 0.393 , 0.3667, 0.3662, 0.3657, 0.364 , 0.3633, 0.352 ,\n",
       "            0.351 , 0.3489, 0.343 , 0.3274, 0.3262, 0.3232, 0.323 , 0.2761,\n",
       "            0.2686, 0.2617, 0.258 , 0.2534, 0.2527, 0.251 , 0.2474, 0.2449,\n",
       "            0.2445, 0.2362, 0.2358, 0.2347, 0.2343, 0.2302, 0.214 , 0.2063,\n",
       "            0.1952, 0.172 , 0.1511, 0.1425, 0.1375, 0.1279, 0.1261],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.55932206, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.06779661, 0.06779661,\n",
       "            0.06779661, 0.07627118, 0.08474576, 0.08474576, 0.08474576,\n",
       "            0.09322034, 0.09322034, 0.11016949, 0.11864407, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.19491525, 0.19491525,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.31355932, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.38135594, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.58474576, 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.83898306,\n",
       "            0.84745765, 0.8559322 , 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.23484848, 0.24242425, 0.25      , 0.25757575, 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.3030303 , 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.43939394, 0.4469697 , 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.56060606, 0.56060606,\n",
       "            0.57575756, 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.65909094, 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.6969697 , 0.6969697 , 0.6969697 , 0.6969697 ,\n",
       "            0.70454544, 0.7121212 , 0.7121212 , 0.7121212 , 0.7121212 ,\n",
       "            0.72727275, 0.7348485 , 0.75757575, 0.77272725, 0.77272725,\n",
       "            0.780303  , 0.7878788 , 0.79545456, 0.79545456, 0.79545456,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.8333333 , 0.8333333 , 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8560606 , 0.8636364 ,\n",
       "            0.8787879 , 0.8787879 , 0.8939394 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8584, 0.8257, 0.8247, 0.822 , 0.8184, 0.818 , 0.8135,\n",
       "            0.813 , 0.8115, 0.809 , 0.803 , 0.7993, 0.795 , 0.791 , 0.7803,\n",
       "            0.778 , 0.776 , 0.774 , 0.7686, 0.7676, 0.762 , 0.7617, 0.761 ,\n",
       "            0.76  , 0.7573, 0.756 , 0.7554, 0.754 , 0.751 , 0.749 , 0.747 ,\n",
       "            0.743 , 0.7417, 0.74  , 0.7397, 0.7363, 0.7334, 0.729 , 0.728 ,\n",
       "            0.7275, 0.727 , 0.7124, 0.705 , 0.704 , 0.7036, 0.703 , 0.7   ,\n",
       "            0.695 , 0.687 , 0.6787, 0.675 , 0.6733, 0.669 , 0.668 , 0.6675,\n",
       "            0.666 , 0.6587, 0.6553, 0.6484, 0.6475, 0.646 , 0.645 , 0.6445,\n",
       "            0.6426, 0.6416, 0.6396, 0.639 , 0.638 , 0.637 , 0.6357, 0.6353,\n",
       "            0.634 , 0.6333, 0.633 , 0.6304, 0.63  , 0.6294, 0.628 , 0.619 ,\n",
       "            0.6177, 0.6147, 0.6143, 0.613 , 0.6123, 0.612 , 0.6094, 0.6055,\n",
       "            0.6035, 0.6025, 0.602 , 0.5986, 0.597 , 0.595 , 0.594 , 0.593 ,\n",
       "            0.5923, 0.5913, 0.591 , 0.588 , 0.587 , 0.5864, 0.5845, 0.581 ,\n",
       "            0.5796, 0.579 , 0.5786, 0.5776, 0.5767, 0.5757, 0.5747, 0.574 ,\n",
       "            0.5737, 0.573 , 0.5728, 0.5723, 0.572 , 0.5713, 0.571 , 0.5703,\n",
       "            0.5693, 0.569 , 0.5664, 0.566 , 0.5654, 0.565 , 0.564 , 0.5635,\n",
       "            0.563 , 0.5625, 0.562 , 0.5576, 0.5566, 0.554 , 0.553 , 0.5522,\n",
       "            0.5513, 0.5503, 0.5493, 0.5483, 0.5474, 0.547 , 0.5454, 0.545 ,\n",
       "            0.543 , 0.5425, 0.541 , 0.54  , 0.5366, 0.536 , 0.5356, 0.534 ,\n",
       "            0.532 , 0.531 , 0.529 , 0.5283, 0.526 , 0.524 , 0.5215, 0.5195,\n",
       "            0.5186, 0.517 , 0.516 , 0.5005, 0.4976, 0.489 , 0.482 , 0.4766,\n",
       "            0.4749, 0.473 , 0.4724, 0.4697, 0.465 , 0.4495, 0.4434, 0.4355,\n",
       "            0.4277, 0.421 , 0.418 , 0.4045, 0.3782, 0.3765, 0.3762, 0.376 ,\n",
       "            0.3745, 0.3733, 0.3613, 0.3606, 0.3604, 0.3582, 0.3518, 0.3357,\n",
       "            0.3342, 0.3315, 0.331 , 0.282 , 0.2742, 0.2668, 0.2634, 0.258 ,\n",
       "            0.2573, 0.2556, 0.252 , 0.2493, 0.2489, 0.2401, 0.2386, 0.2382,\n",
       "            0.2339, 0.2168, 0.2089, 0.1985, 0.1733, 0.152 , 0.1432, 0.138 ,\n",
       "            0.1285, 0.1266], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5762712, dtype=float32),\n",
       "    'tpr': array(0.969697, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.11016949, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.1440678 , 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16949153, 0.16949153, 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.22033899, 0.22033899, 0.22881356, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.2881356 , 0.2881356 ,\n",
       "            0.2881356 , 0.29661018, 0.30508474, 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.33050847, 0.34745762,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3559322 , 0.37288135,\n",
       "            0.37288135, 0.37288135, 0.38135594, 0.3898305 , 0.40677965,\n",
       "            0.40677965, 0.41525424, 0.41525424, 0.42372882, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5254237 , 0.5254237 ,\n",
       "            0.5338983 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.38636363, 0.3939394 , 0.40151516, 0.4090909 ,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.43939394, 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.45454547, 0.45454547, 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.52272725, 0.530303  ,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.59090906, 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.68939394, 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.70454544, 0.70454544, 0.7121212 , 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.72727275, 0.72727275, 0.74242425,\n",
       "            0.74242425, 0.75757575, 0.7651515 , 0.77272725, 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.8030303 , 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.82575756, 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.9015151 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.9469697 , 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.881 , 0.8496, 0.8486, 0.8457, 0.8423, 0.842 , 0.8374,\n",
       "            0.8354, 0.8335, 0.8276, 0.8237, 0.8193, 0.8154, 0.805 , 0.8027,\n",
       "            0.8013, 0.799 , 0.793 , 0.7925, 0.7866, 0.786 , 0.7856, 0.7847,\n",
       "            0.782 , 0.781 , 0.78  , 0.7783, 0.7754, 0.7734, 0.7715, 0.7676,\n",
       "            0.766 , 0.7646, 0.7607, 0.7573, 0.7534, 0.7524, 0.752 , 0.751 ,\n",
       "            0.7373, 0.7285, 0.7275, 0.7266, 0.7246, 0.7197, 0.71  , 0.701 ,\n",
       "            0.7007, 0.6997, 0.698 , 0.695 , 0.6934, 0.681 , 0.68  , 0.678 ,\n",
       "            0.675 , 0.674 , 0.673 , 0.67  , 0.668 , 0.6675, 0.6655, 0.665 ,\n",
       "            0.6636, 0.663 , 0.661 , 0.6597, 0.659 , 0.658 , 0.6562, 0.652 ,\n",
       "            0.65  , 0.648 , 0.6465, 0.642 , 0.6416, 0.641 , 0.6406, 0.64  ,\n",
       "            0.636 , 0.6357, 0.6353, 0.635 , 0.634 , 0.6323, 0.6304, 0.626 ,\n",
       "            0.6255, 0.625 , 0.6235, 0.6196, 0.618 , 0.6177, 0.616 , 0.6147,\n",
       "            0.6123, 0.6113, 0.611 , 0.6104, 0.609 , 0.608 , 0.6074, 0.605 ,\n",
       "            0.6045, 0.6025, 0.602 , 0.6016, 0.6   , 0.5986, 0.598 , 0.5977,\n",
       "            0.597 , 0.5967, 0.596 , 0.5957, 0.5947, 0.594 , 0.5938, 0.5933,\n",
       "            0.5923, 0.592 , 0.5903, 0.5894, 0.589 , 0.588 , 0.5835, 0.5825,\n",
       "            0.582 , 0.5786, 0.578 , 0.577 , 0.5757, 0.5747, 0.5723, 0.572 ,\n",
       "            0.5713, 0.57  , 0.5693, 0.5684, 0.568 , 0.5674, 0.565 , 0.5645,\n",
       "            0.561 , 0.5596, 0.559 , 0.557 , 0.556 , 0.5522, 0.5503, 0.55  ,\n",
       "            0.543 , 0.5425, 0.5386, 0.536 , 0.5347, 0.5317, 0.5186, 0.516 ,\n",
       "            0.505 , 0.499 , 0.4902, 0.4885, 0.4863, 0.484 , 0.4778, 0.462 ,\n",
       "            0.4553, 0.4478, 0.4392, 0.4321, 0.429 , 0.415 , 0.3882, 0.3857,\n",
       "            0.3855, 0.3853, 0.3838, 0.3823, 0.3696, 0.3694, 0.369 , 0.3662,\n",
       "            0.3596, 0.343 , 0.3413, 0.3386, 0.338 , 0.2861, 0.278 , 0.27  ,\n",
       "            0.2668, 0.2612, 0.2598, 0.2583, 0.255 , 0.252 , 0.2512, 0.2421,\n",
       "            0.2406, 0.2399, 0.2358, 0.2177, 0.2091, 0.1996, 0.1726, 0.1506,\n",
       "            0.1417, 0.1365, 0.127 , 0.1249], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59322035, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05084746, 0.05084746, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.09322034,\n",
       "            0.09322034, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.18644068, 0.18644068,\n",
       "            0.18644068, 0.18644068, 0.18644068, 0.20338982, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.23728813, 0.2542373 , 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.34745762, 0.34745762,\n",
       "            0.34745762, 0.3644068 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.37288135, 0.3898305 , 0.3983051 , 0.40677965, 0.41525424,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.3030303 , 0.31060606, 0.3181818 , 0.32575756, 0.33333334,\n",
       "            0.3409091 , 0.34848484, 0.3560606 , 0.36363637, 0.37121212,\n",
       "            0.37878788, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.4469697 , 0.45454547, 0.45454547, 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.49242425, 0.49242425,\n",
       "            0.5       , 0.5151515 , 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6439394 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.68939394,\n",
       "            0.6969697 , 0.6969697 , 0.70454544, 0.70454544, 0.719697  ,\n",
       "            0.72727275, 0.72727275, 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.75      , 0.7651515 , 0.780303  , 0.79545456, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.84090906, 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.92424244, 0.9318182 ,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9004, 0.871 , 0.87  , 0.867 , 0.864 , 0.8633, 0.859 ,\n",
       "            0.8574, 0.8555, 0.8496, 0.846 , 0.842 , 0.838 , 0.8286, 0.8257,\n",
       "            0.824 , 0.8223, 0.8154, 0.81  , 0.809 , 0.8086, 0.808 , 0.8057,\n",
       "            0.804 , 0.803 , 0.802 , 0.7983, 0.7964, 0.795 , 0.7905, 0.7886,\n",
       "            0.7876, 0.784 , 0.7803, 0.777 , 0.776 , 0.7754, 0.774 , 0.761 ,\n",
       "            0.7515, 0.7505, 0.75  , 0.7495, 0.748 , 0.743 , 0.7324, 0.727 ,\n",
       "            0.7256, 0.723 , 0.7227, 0.721 , 0.717 , 0.7104, 0.704 , 0.7026,\n",
       "            0.702 , 0.701 , 0.6973, 0.6963, 0.6943, 0.693 , 0.6914, 0.69  ,\n",
       "            0.6885, 0.688 , 0.687 , 0.684 , 0.6836, 0.682 , 0.6816, 0.681 ,\n",
       "            0.6763, 0.675 , 0.674 , 0.6714, 0.671 , 0.668 , 0.6665, 0.6655,\n",
       "            0.661 , 0.66  , 0.657 , 0.654 , 0.653 , 0.6523, 0.651 , 0.65  ,\n",
       "            0.649 , 0.648 , 0.6465, 0.6436, 0.6426, 0.642 , 0.641 , 0.6387,\n",
       "            0.638 , 0.6367, 0.636 , 0.6357, 0.6353, 0.635 , 0.6313, 0.631 ,\n",
       "            0.6304, 0.63  , 0.629 , 0.6274, 0.627 , 0.623 , 0.6226, 0.621 ,\n",
       "            0.6206, 0.62  , 0.619 , 0.6187, 0.618 , 0.6167, 0.615 , 0.6143,\n",
       "            0.614 , 0.6133, 0.613 , 0.6123, 0.6084, 0.6074, 0.6035, 0.603 ,\n",
       "            0.602 , 0.5996, 0.599 , 0.5977, 0.596 , 0.5947, 0.594 , 0.5938,\n",
       "            0.593 , 0.592 , 0.591 , 0.5903, 0.5894, 0.588 , 0.5874, 0.587 ,\n",
       "            0.586 , 0.583 , 0.582 , 0.5815, 0.579 , 0.576 , 0.574 , 0.5723,\n",
       "            0.5674, 0.5645, 0.564 , 0.5625, 0.56  , 0.5596, 0.5537, 0.5513,\n",
       "            0.548 , 0.5376, 0.5366, 0.521 , 0.517 , 0.505 , 0.5044, 0.5034,\n",
       "            0.501 , 0.4988, 0.4915, 0.475 , 0.468 , 0.4604, 0.4517, 0.444 ,\n",
       "            0.441 , 0.4263, 0.3997, 0.3958, 0.3955, 0.395 , 0.394 , 0.3923,\n",
       "            0.3787, 0.3784, 0.3782, 0.375 , 0.3684, 0.351 , 0.349 , 0.347 ,\n",
       "            0.3455, 0.2915, 0.2832, 0.2744, 0.2712, 0.2654, 0.2646, 0.2634,\n",
       "            0.262 , 0.2588, 0.2554, 0.255 , 0.2451, 0.2449, 0.2434, 0.2429,\n",
       "            0.2386, 0.2195, 0.2106, 0.2017, 0.1727, 0.1503, 0.1411, 0.1359,\n",
       "            0.1262, 0.1241], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6101695, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.04237288, 0.04237288, 0.05084746, 0.05932203,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.06779661, 0.06779661,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16949153, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.1779661 , 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.22033899, 0.22033899,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.26271185, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.29661018, 0.30508474, 0.31355932, 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.3559322 , 0.3644068 , 0.3644068 , 0.37288135,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.44067797, 0.44067797, 0.44067797, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5169492 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.59322035, 0.60169494, 0.6101695 ,\n",
       "            0.61864406, 0.62711865, 0.63559324, 0.6440678 , 0.65254235,\n",
       "            0.66101694, 0.6694915 , 0.6694915 , 0.6864407 , 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.89830506, 0.90677965, 0.91525424, 0.9237288 ,\n",
       "            0.9322034 , 0.94067794, 0.9491525 , 0.9576271 , 0.9661017 ,\n",
       "            0.9745763 , 0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.43939394, 0.4469697 , 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.530303  , 0.5378788 , 0.5378788 ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6515151 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.70454544, 0.7121212 , 0.7121212 , 0.719697  , 0.719697  ,\n",
       "            0.719697  , 0.72727275, 0.72727275, 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.74242425, 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.8030303 , 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84090906, 0.84090906, 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.9318182 , 0.9318182 ,\n",
       "            0.9318182 , 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.917 , 0.89  , 0.889 , 0.8867, 0.8833, 0.8823, 0.8784,\n",
       "            0.8774, 0.8755, 0.87  , 0.8667, 0.8623, 0.8584, 0.849 , 0.8467,\n",
       "            0.846 , 0.8457, 0.8433, 0.837 , 0.831 , 0.8306, 0.83  , 0.8296,\n",
       "            0.827 , 0.8257, 0.8247, 0.823 , 0.8203, 0.8184, 0.817 , 0.8125,\n",
       "            0.8105, 0.8096, 0.806 , 0.8022, 0.799 , 0.7983, 0.7974, 0.796 ,\n",
       "            0.7837, 0.773 , 0.7725, 0.7715, 0.771 , 0.7705, 0.765 , 0.762 ,\n",
       "            0.7544, 0.754 , 0.7505, 0.749 , 0.744 , 0.743 , 0.7393, 0.7334,\n",
       "            0.732 , 0.7295, 0.724 , 0.723 , 0.721 , 0.719 , 0.7183, 0.718 ,\n",
       "            0.715 , 0.7144, 0.7114, 0.71  , 0.7085, 0.708 , 0.7075, 0.7065,\n",
       "            0.7036, 0.703 , 0.7026, 0.6987, 0.696 , 0.6953, 0.695 , 0.694 ,\n",
       "            0.6924, 0.6914, 0.688 , 0.686 , 0.685 , 0.6836, 0.683 , 0.68  ,\n",
       "            0.677 , 0.6753, 0.6743, 0.6733, 0.673 , 0.672 , 0.671 , 0.669 ,\n",
       "            0.668 , 0.6665, 0.6646, 0.6636, 0.663 , 0.6616, 0.661 , 0.66  ,\n",
       "            0.659 , 0.6587, 0.657 , 0.6567, 0.6562, 0.656 , 0.655 , 0.6533,\n",
       "            0.6523, 0.6504, 0.6484, 0.648 , 0.6475, 0.646 , 0.6455, 0.645 ,\n",
       "            0.6436, 0.643 , 0.6426, 0.642 , 0.6406, 0.64  , 0.6387, 0.638 ,\n",
       "            0.6377, 0.637 , 0.6367, 0.636 , 0.6333, 0.6323, 0.628 , 0.6274,\n",
       "            0.627 , 0.624 , 0.623 , 0.6206, 0.62  , 0.619 , 0.6187, 0.6167,\n",
       "            0.616 , 0.6157, 0.615 , 0.6123, 0.6113, 0.6094, 0.609 , 0.6084,\n",
       "            0.608 , 0.6074, 0.6064, 0.605 , 0.602 , 0.601 , 0.597 , 0.5967,\n",
       "            0.5947, 0.594 , 0.587 , 0.586 , 0.5854, 0.582 , 0.5815, 0.5767,\n",
       "            0.5713, 0.5684, 0.564 , 0.558 , 0.5576, 0.538 , 0.536 , 0.5225,\n",
       "            0.5186, 0.516 , 0.514 , 0.5054, 0.4888, 0.4807, 0.4739, 0.464 ,\n",
       "            0.4565, 0.4534, 0.4373, 0.4136, 0.4067, 0.4053, 0.403 , 0.3892,\n",
       "            0.3882, 0.3877, 0.384 , 0.3777, 0.3604, 0.3582, 0.3562, 0.354 ,\n",
       "            0.2979, 0.2898, 0.279 , 0.2776, 0.2703, 0.2693, 0.268 , 0.266 ,\n",
       "            0.2646, 0.259 , 0.2588, 0.2485, 0.2473, 0.2467, 0.2426, 0.2222,\n",
       "            0.2133, 0.2039, 0.1744, 0.1514, 0.1414, 0.1366, 0.1271, 0.124 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.61864406, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.05932203, 0.05932203, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.1779661 , 0.1779661 , 0.1779661 , 0.18644068,\n",
       "            0.20338982, 0.21186441, 0.21186441, 0.21186441, 0.21186441,\n",
       "            0.22033899, 0.22881356, 0.23728813, 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.27966103, 0.27966103,\n",
       "            0.2881356 , 0.2881356 , 0.2881356 , 0.29661018, 0.29661018,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.3220339 , 0.33898306,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3559322 , 0.3559322 ,\n",
       "            0.3559322 , 0.3644068 , 0.38135594, 0.3898305 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.1590909 ,\n",
       "            0.16666667, 0.18181819, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.2651515 , 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.41666666, 0.41666666, 0.42424244, 0.4318182 ,\n",
       "            0.43939394, 0.43939394, 0.4469697 , 0.4469697 , 0.45454547,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.47727272, 0.4848485 , 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.530303  , 0.530303  , 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.5530303 , 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.65909094,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.67424244, 0.68939394,\n",
       "            0.68939394, 0.70454544, 0.70454544, 0.70454544, 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75757575, 0.75757575, 0.77272725, 0.7878788 ,\n",
       "            0.79545456, 0.8030303 , 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8560606 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.90909094, 0.9166667 , 0.9318182 ,\n",
       "            0.9318182 , 0.9318182 , 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9287, 0.904 , 0.9033, 0.901 , 0.8975, 0.8965, 0.893 ,\n",
       "            0.892 , 0.89  , 0.8853, 0.882 , 0.8774, 0.874 , 0.865 , 0.863 ,\n",
       "            0.862 , 0.8613, 0.8594, 0.853 , 0.8477, 0.8467, 0.846 , 0.8438,\n",
       "            0.8423, 0.8413, 0.84  , 0.837 , 0.835 , 0.8335, 0.8296, 0.827 ,\n",
       "            0.8267, 0.8228, 0.8193, 0.816 , 0.815 , 0.8145, 0.814 , 0.8125,\n",
       "            0.801 , 0.79  , 0.7896, 0.7886, 0.788 , 0.7876, 0.785 , 0.7827,\n",
       "            0.776 , 0.771 , 0.7705, 0.7695, 0.762 , 0.761 , 0.7603, 0.7573,\n",
       "            0.7563, 0.754 , 0.7505, 0.7456, 0.7407, 0.74  , 0.7397, 0.7393,\n",
       "            0.737 , 0.736 , 0.7354, 0.7334, 0.729 , 0.728 , 0.726 , 0.7256,\n",
       "            0.725 , 0.7246, 0.721 , 0.7207, 0.72  , 0.7163, 0.7144, 0.7124,\n",
       "            0.7114, 0.7095, 0.709 , 0.706 , 0.705 , 0.7046, 0.703 , 0.7017,\n",
       "            0.6978, 0.6973, 0.6943, 0.693 , 0.692 , 0.6914, 0.6904, 0.69  ,\n",
       "            0.6895, 0.688 , 0.687 , 0.686 , 0.685 , 0.683 , 0.6816, 0.681 ,\n",
       "            0.6807, 0.68  , 0.679 , 0.6787, 0.678 , 0.6772, 0.676 , 0.6753,\n",
       "            0.673 , 0.6714, 0.67  , 0.669 , 0.667 , 0.6665, 0.666 , 0.6655,\n",
       "            0.663 , 0.6626, 0.662 , 0.661 , 0.659 , 0.658 , 0.6577, 0.657 ,\n",
       "            0.654 , 0.6533, 0.6523, 0.6504, 0.6484, 0.6475, 0.647 , 0.6426,\n",
       "            0.641 , 0.6396, 0.6377, 0.637 , 0.6367, 0.6353, 0.635 , 0.6343,\n",
       "            0.631 , 0.628 , 0.6274, 0.626 , 0.625 , 0.6245, 0.6235, 0.622 ,\n",
       "            0.6196, 0.619 , 0.615 , 0.6133, 0.613 , 0.612 , 0.605 , 0.6025,\n",
       "            0.601 , 0.5996, 0.5977, 0.591 , 0.586 , 0.582 , 0.5776, 0.575 ,\n",
       "            0.5522, 0.552 , 0.5366, 0.5317, 0.5312, 0.5293, 0.527 , 0.5176,\n",
       "            0.501 , 0.4924, 0.4856, 0.4756, 0.4678, 0.4644, 0.448 , 0.4255,\n",
       "            0.417 , 0.4167, 0.4155, 0.415 , 0.413 , 0.3987, 0.3977, 0.3967,\n",
       "            0.393 , 0.3867, 0.369 , 0.3667, 0.365 , 0.3623, 0.3044, 0.2969,\n",
       "            0.2847, 0.2837, 0.276 , 0.2747, 0.2732, 0.2715, 0.2708, 0.2642,\n",
       "            0.2637, 0.2534, 0.252 , 0.2512, 0.2473, 0.226 , 0.2168, 0.2079,\n",
       "            0.1771, 0.1536, 0.1432, 0.1387, 0.129 , 0.1254], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.62711865, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.07627118, 0.07627118, 0.07627118, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.19491525, 0.20338982, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 , 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3559322 , 0.3644068 , 0.37288135, 0.38135594,\n",
       "            0.3898305 , 0.3983051 , 0.41525424, 0.42372882, 0.43220338,\n",
       "            0.43220338, 0.43220338, 0.44067797, 0.44067797, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.59322035, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.86440676, 0.87288135, 0.88135594,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.1590909 , 0.16666667, 0.18939394, 0.1969697 , 0.20454545,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.34848484, 0.3560606 , 0.37121212, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.42424244, 0.4318182 , 0.4469697 ,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.46969697,\n",
       "            0.47727272, 0.4848485 , 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.49242425, 0.49242425, 0.5       , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6363636 ,\n",
       "            0.6439394 , 0.65909094, 0.65909094, 0.65909094, 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.6818182 , 0.68939394,\n",
       "            0.68939394, 0.70454544, 0.7121212 , 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.7878788 , 0.79545456,\n",
       "            0.79545456, 0.79545456, 0.81060606, 0.8181818 , 0.8181818 ,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8560606 , 0.8560606 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.9318182 , 0.9318182 , 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9395, 0.9165, 0.9155, 0.9136, 0.9106, 0.9097, 0.9062,\n",
       "            0.906 , 0.9053, 0.9033, 0.899 , 0.8955, 0.891 , 0.888 , 0.8794,\n",
       "            0.8774, 0.877 , 0.8765, 0.874 , 0.868 , 0.863 , 0.862 , 0.8594,\n",
       "            0.8574, 0.857 , 0.8555, 0.8525, 0.8506, 0.849 , 0.845 , 0.8433,\n",
       "            0.843 , 0.839 , 0.8354, 0.832 , 0.831 , 0.8306, 0.83  , 0.829 ,\n",
       "            0.8174, 0.8066, 0.806 , 0.8047, 0.8037, 0.799 , 0.7964, 0.7896,\n",
       "            0.789 , 0.787 , 0.7837, 0.7783, 0.7773, 0.777 , 0.775 , 0.771 ,\n",
       "            0.7666, 0.7607, 0.7603, 0.759 , 0.758 , 0.756 , 0.7554, 0.755 ,\n",
       "            0.752 , 0.7476, 0.747 , 0.7466, 0.746 , 0.7456, 0.743 , 0.7427,\n",
       "            0.7417, 0.738 , 0.7373, 0.7344, 0.731 , 0.73  , 0.729 , 0.726 ,\n",
       "            0.7256, 0.725 , 0.7246, 0.72  , 0.719 , 0.718 , 0.716 , 0.7144,\n",
       "            0.71  , 0.709 , 0.7085, 0.708 , 0.706 , 0.705 , 0.7046, 0.703 ,\n",
       "            0.701 , 0.7007, 0.7   , 0.6997, 0.699 , 0.6987, 0.6973, 0.6963,\n",
       "            0.6934, 0.692 , 0.6914, 0.689 , 0.688 , 0.687 , 0.6865, 0.686 ,\n",
       "            0.685 , 0.684 , 0.6836, 0.6826, 0.682 , 0.6807, 0.6797, 0.679 ,\n",
       "            0.678 , 0.6777, 0.6772, 0.677 , 0.676 , 0.6743, 0.673 , 0.67  ,\n",
       "            0.6694, 0.6685, 0.667 , 0.662 , 0.6587, 0.658 , 0.6577, 0.657 ,\n",
       "            0.6567, 0.6553, 0.654 , 0.6533, 0.6523, 0.649 , 0.6455, 0.6445,\n",
       "            0.6426, 0.6416, 0.641 , 0.6396, 0.6377, 0.637 , 0.636 , 0.6333,\n",
       "            0.631 , 0.6304, 0.63  , 0.623 , 0.62  , 0.617 , 0.6157, 0.6133,\n",
       "            0.6055, 0.6   , 0.596 , 0.5923, 0.592 , 0.567 , 0.566 , 0.551 ,\n",
       "            0.546 , 0.544 , 0.542 , 0.54  , 0.53  , 0.5127, 0.5044, 0.4976,\n",
       "            0.487 , 0.479 , 0.4758, 0.459 , 0.4373, 0.4272, 0.427 , 0.4258,\n",
       "            0.425 , 0.4233, 0.4084, 0.4072, 0.4062, 0.4023, 0.396 , 0.3777,\n",
       "            0.3752, 0.3738, 0.3708, 0.311 , 0.3035, 0.2903, 0.2898, 0.2815,\n",
       "            0.2798, 0.278 , 0.2766, 0.269 , 0.2686, 0.2578, 0.2563, 0.2559,\n",
       "            0.252 , 0.2297, 0.2202, 0.2118, 0.1797, 0.1556, 0.1448, 0.1405,\n",
       "            0.1309, 0.1267], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.63559324, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.03389831, 0.04237288,\n",
       "            0.04237288, 0.05084746, 0.05932203, 0.05932203, 0.05932203,\n",
       "            0.07627118, 0.08474576, 0.09322034, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.16949153, 0.16949153, 0.16949153, 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.22881356,\n",
       "            0.2457627 , 0.2457627 , 0.2457627 , 0.2457627 , 0.2542373 ,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.27966103, 0.30508474, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33898306, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3559322 , 0.3644068 , 0.38135594, 0.3898305 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.43220338, 0.43220338, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.13636364, 0.14393939, 0.1590909 , 0.16666667,\n",
       "            0.18939394, 0.1969697 , 0.20454545, 0.21212122, 0.21969697,\n",
       "            0.22727273, 0.23484848, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.2651515 , 0.27272728, 0.28030303, 0.28787878, 0.29545453,\n",
       "            0.31060606, 0.3181818 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.4469697 , 0.45454547, 0.46969697, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.49242425, 0.5       ,\n",
       "            0.5       , 0.5       , 0.50757575, 0.50757575, 0.5151515 ,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.5530303 , 0.56060606, 0.5681818 , 0.57575756,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.6666667 , 0.67424244,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.7121212 , 0.7121212 ,\n",
       "            0.7121212 , 0.719697  , 0.7348485 , 0.74242425, 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.7878788 , 0.79545456, 0.79545456,\n",
       "            0.81060606, 0.8181818 , 0.8181818 , 0.8181818 , 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8484849 , 0.8560606 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.90909094, 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.948 , 0.9272, 0.927 , 0.925 , 0.9224, 0.9214, 0.918 ,\n",
       "            0.917 , 0.9155, 0.911 , 0.9077, 0.904 , 0.901 , 0.8926, 0.8906,\n",
       "            0.89  , 0.8877, 0.8823, 0.877 , 0.876 , 0.874 , 0.872 , 0.8716,\n",
       "            0.87  , 0.8667, 0.865 , 0.8643, 0.8604, 0.8584, 0.858 , 0.8574,\n",
       "            0.854 , 0.85  , 0.8477, 0.8457, 0.845 , 0.844 , 0.833 , 0.8267,\n",
       "            0.8223, 0.822 , 0.8203, 0.8193, 0.8154, 0.8145, 0.808 , 0.807 ,\n",
       "            0.8037, 0.803 , 0.799 , 0.7944, 0.7935, 0.7925, 0.7915, 0.79  ,\n",
       "            0.786 , 0.78  , 0.776 , 0.775 , 0.774 , 0.7725, 0.771 , 0.77  ,\n",
       "            0.7666, 0.766 , 0.765 , 0.764 , 0.7637, 0.7627, 0.762 , 0.76  ,\n",
       "            0.758 , 0.757 , 0.7544, 0.7534, 0.751 , 0.75  , 0.7456, 0.745 ,\n",
       "            0.7446, 0.744 , 0.743 , 0.742 , 0.7397, 0.7373, 0.736 , 0.735 ,\n",
       "            0.73  , 0.7295, 0.7285, 0.728 , 0.727 , 0.7266, 0.726 , 0.725 ,\n",
       "            0.7246, 0.7236, 0.7227, 0.7217, 0.719 , 0.718 , 0.7173, 0.717 ,\n",
       "            0.716 , 0.713 , 0.712 , 0.7085, 0.7075, 0.7065, 0.705 , 0.704 ,\n",
       "            0.7036, 0.702 , 0.7017, 0.6987, 0.6978, 0.6973, 0.697 , 0.6963,\n",
       "            0.696 , 0.695 , 0.694 , 0.693 , 0.692 , 0.6875, 0.6865, 0.686 ,\n",
       "            0.685 , 0.683 , 0.681 , 0.6772, 0.6763, 0.676 , 0.6743, 0.673 ,\n",
       "            0.671 , 0.6704, 0.67  , 0.6685, 0.665 , 0.6636, 0.661 , 0.66  ,\n",
       "            0.6577, 0.6553, 0.655 , 0.653 , 0.651 , 0.649 , 0.648 , 0.646 ,\n",
       "            0.6406, 0.637 , 0.6343, 0.6304, 0.6284, 0.6196, 0.6147, 0.6104,\n",
       "            0.6094, 0.609 , 0.6055, 0.582 , 0.58  , 0.5654, 0.56  , 0.557 ,\n",
       "            0.556 , 0.554 , 0.543 , 0.5254, 0.5166, 0.5103, 0.4993, 0.4912,\n",
       "            0.4878, 0.4705, 0.4512, 0.4385, 0.4382, 0.4373, 0.436 , 0.4343,\n",
       "            0.4192, 0.418 , 0.4163, 0.412 , 0.4058, 0.3875, 0.3848, 0.3838,\n",
       "            0.3801, 0.3186, 0.3115, 0.2974, 0.2969, 0.288 , 0.2861, 0.2844,\n",
       "            0.2837, 0.2827, 0.2751, 0.2744, 0.2634, 0.2622, 0.2615, 0.2576,\n",
       "            0.2344, 0.2247, 0.2166, 0.1833, 0.1587, 0.1472, 0.1434, 0.1339,\n",
       "            0.1288], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.66101694, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.04237288, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.05932203, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.10169491, 0.10169491, 0.11016949, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.13559322, 0.13559322, 0.1440678 , 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16949153, 0.16949153,\n",
       "            0.1779661 , 0.18644068, 0.18644068, 0.18644068, 0.19491525,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.2457627 , 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.2881356 , 0.2881356 ,\n",
       "            0.29661018, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.3898305 , 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.42372882, 0.43220338, 0.44067797, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.44915253, 0.45762712,\n",
       "            0.4661017 , 0.4661017 , 0.4661017 , 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.23484848,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.31060606, 0.3181818 , 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.3560606 , 0.36363637,\n",
       "            0.37121212, 0.37878788, 0.38636363, 0.3939394 , 0.40151516,\n",
       "            0.4090909 , 0.4090909 , 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.4318182 , 0.4469697 , 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.54545456, 0.54545456, 0.54545456, 0.5530303 ,\n",
       "            0.5530303 , 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6060606 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6287879 ,\n",
       "            0.6287879 , 0.6287879 , 0.6363636 , 0.6515151 , 0.6515151 ,\n",
       "            0.65909094, 0.65909094, 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.75      , 0.75757575,\n",
       "            0.77272725, 0.7878788 , 0.79545456, 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.8181818 , 0.82575756, 0.8333333 , 0.84090906,\n",
       "            0.8484849 , 0.8560606 , 0.8560606 , 0.8712121 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.956 , 0.937 , 0.9365, 0.9346, 0.932 , 0.9316, 0.9287,\n",
       "            0.928 , 0.9277, 0.9263, 0.922 , 0.919 , 0.9155, 0.9126, 0.905 ,\n",
       "            0.903 , 0.9023, 0.9   , 0.8955, 0.895 , 0.89  , 0.889 , 0.8887,\n",
       "            0.887 , 0.8853, 0.885 , 0.8833, 0.8804, 0.8784, 0.878 , 0.874 ,\n",
       "            0.872 , 0.8716, 0.8677, 0.8643, 0.862 , 0.86  , 0.859 , 0.858 ,\n",
       "            0.848 , 0.845 , 0.837 , 0.8364, 0.8354, 0.835 , 0.8335, 0.833 ,\n",
       "            0.8296, 0.8257, 0.824 , 0.8228, 0.8184, 0.818 , 0.813 , 0.8086,\n",
       "            0.808 , 0.8076, 0.8047, 0.7983, 0.798 , 0.793 , 0.7896, 0.789 ,\n",
       "            0.787 , 0.786 , 0.7856, 0.785 , 0.7847, 0.784 , 0.7827, 0.7812,\n",
       "            0.7793, 0.7783, 0.7764, 0.776 , 0.7734, 0.772 , 0.771 , 0.7705,\n",
       "            0.768 , 0.7676, 0.7656, 0.7637, 0.762 , 0.761 , 0.76  , 0.758 ,\n",
       "            0.756 , 0.7554, 0.755 , 0.7544, 0.75  , 0.749 , 0.748 , 0.7466,\n",
       "            0.746 , 0.7456, 0.745 , 0.7446, 0.743 , 0.742 , 0.7417, 0.7397,\n",
       "            0.739 , 0.7383, 0.738 , 0.737 , 0.7363, 0.736 , 0.7354, 0.7344,\n",
       "            0.734 , 0.7334, 0.732 , 0.7314, 0.728 , 0.7275, 0.726 , 0.724 ,\n",
       "            0.723 , 0.7227, 0.7207, 0.7163, 0.716 , 0.7153, 0.715 , 0.7144,\n",
       "            0.713 , 0.7124, 0.7114, 0.7095, 0.7065, 0.705 , 0.7026, 0.701 ,\n",
       "            0.6997, 0.6987, 0.696 , 0.6953, 0.6943, 0.694 , 0.6904, 0.69  ,\n",
       "            0.6885, 0.6875, 0.687 , 0.6865, 0.684 , 0.6807, 0.6797, 0.6777,\n",
       "            0.6772, 0.6743, 0.674 , 0.673 , 0.67  , 0.6694, 0.6685, 0.6665,\n",
       "            0.665 , 0.6626, 0.658 , 0.655 , 0.652 , 0.6455, 0.6436, 0.635 ,\n",
       "            0.63  , 0.626 , 0.6255, 0.625 , 0.6206, 0.5977, 0.595 , 0.5806,\n",
       "            0.575 , 0.5713, 0.5703, 0.569 , 0.557 , 0.539 , 0.5303, 0.5244,\n",
       "            0.5127, 0.5044, 0.5015, 0.484 , 0.466 , 0.4514, 0.451 , 0.4502,\n",
       "            0.4485, 0.4468, 0.4316, 0.43  , 0.428 , 0.4238, 0.4175, 0.3992,\n",
       "            0.3962, 0.3955, 0.391 , 0.3281, 0.3213, 0.3066, 0.3054, 0.2964,\n",
       "            0.2944, 0.2927, 0.2925, 0.2908, 0.283 , 0.2822, 0.2708, 0.2695,\n",
       "            0.269 , 0.2651, 0.2407, 0.231 , 0.2235, 0.1886, 0.1635, 0.1512,\n",
       "            0.1478, 0.1382, 0.1323], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.66101694, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.08474576, 0.09322034,\n",
       "            0.10169491, 0.10169491, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.12711865, 0.13559322, 0.13559322,\n",
       "            0.13559322, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.16949153, 0.18644068, 0.18644068,\n",
       "            0.19491525, 0.19491525, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.23728813, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2542373 , 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.31355932, 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.37288135, 0.38135594, 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44067797, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.4915254 , 0.4915254 , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 ,\n",
       "            0.5423729 , 0.5508475 , 0.55932206, 0.5677966 , 0.5677966 ,\n",
       "            0.5762712 , 0.5762712 , 0.5762712 , 0.58474576, 0.59322035,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6779661 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.83898306,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.17424242, 0.18939394, 0.1969697 ,\n",
       "            0.21212122, 0.21969697, 0.22727273, 0.23484848, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.31060606, 0.3181818 , 0.32575756, 0.3409091 ,\n",
       "            0.34848484, 0.3560606 , 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.4090909 , 0.41666666,\n",
       "            0.42424244, 0.42424244, 0.43939394, 0.45454547, 0.46212122,\n",
       "            0.46969697, 0.46969697, 0.47727272, 0.47727272, 0.47727272,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.5530303 , 0.5530303 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5833333 , 0.59090906,\n",
       "            0.5984849 , 0.5984849 , 0.6060606 , 0.6136364 , 0.6136364 ,\n",
       "            0.6212121 , 0.6212121 , 0.6287879 , 0.6287879 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6439394 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.67424244, 0.68939394,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.7121212 , 0.719697  ,\n",
       "            0.72727275, 0.7348485 , 0.74242425, 0.75      , 0.75757575,\n",
       "            0.7651515 , 0.77272725, 0.780303  , 0.79545456, 0.81060606,\n",
       "            0.81060606, 0.81060606, 0.8181818 , 0.82575756, 0.8333333 ,\n",
       "            0.84090906, 0.8484849 , 0.8484849 , 0.8560606 , 0.8560606 ,\n",
       "            0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.9318182 , 0.93939394,\n",
       "            0.9469697 , 0.9469697 , 0.95454544, 0.95454544, 0.95454544,\n",
       "            0.9621212 , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.97727275,\n",
       "            0.97727275, 0.9848485 , 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.963 , 0.946 , 0.9453, 0.9434, 0.9414, 0.941 , 0.938 ,\n",
       "            0.9375, 0.937 , 0.936 , 0.9316, 0.929 , 0.926 , 0.923 , 0.916 ,\n",
       "            0.914 , 0.9136, 0.911 , 0.907 , 0.9062, 0.902 , 0.901 , 0.9004,\n",
       "            0.899 , 0.897 , 0.8955, 0.8926, 0.8906, 0.89  , 0.8867, 0.885 ,\n",
       "            0.8843, 0.8804, 0.877 , 0.875 , 0.873 , 0.872 , 0.871 , 0.8623,\n",
       "            0.8506, 0.85  , 0.849 , 0.8486, 0.8477, 0.8433, 0.842 , 0.8403,\n",
       "            0.8354, 0.8325, 0.83  , 0.825 , 0.8228, 0.8223, 0.816 , 0.8154,\n",
       "            0.8105, 0.81  , 0.8086, 0.805 , 0.8047, 0.8037, 0.803 , 0.801 ,\n",
       "            0.799 , 0.798 , 0.795 , 0.794 , 0.7935, 0.7925, 0.79  , 0.7896,\n",
       "            0.7886, 0.7856, 0.785 , 0.7847, 0.7817, 0.7793, 0.779 , 0.7783,\n",
       "            0.7764, 0.774 , 0.7734, 0.773 , 0.771 , 0.769 , 0.7676, 0.767 ,\n",
       "            0.765 , 0.7646, 0.7637, 0.763 , 0.7627, 0.7617, 0.7607, 0.76  ,\n",
       "            0.759 , 0.757 , 0.756 , 0.755 , 0.754 , 0.7534, 0.752 , 0.751 ,\n",
       "            0.75  , 0.747 , 0.746 , 0.7446, 0.744 , 0.742 , 0.7417, 0.7407,\n",
       "            0.7393, 0.7383, 0.734 , 0.7334, 0.733 , 0.7324, 0.732 , 0.7314,\n",
       "            0.7295, 0.729 , 0.7266, 0.726 , 0.725 , 0.7236, 0.723 , 0.7183,\n",
       "            0.718 , 0.7163, 0.7144, 0.714 , 0.7124, 0.712 , 0.707 , 0.7065,\n",
       "            0.706 , 0.7056, 0.704 , 0.7026, 0.701 , 0.698 , 0.6973, 0.6943,\n",
       "            0.6934, 0.6904, 0.69  , 0.686 , 0.6855, 0.6846, 0.6836, 0.682 ,\n",
       "            0.678 , 0.676 , 0.673 , 0.67  , 0.6597, 0.658 , 0.6484, 0.6436,\n",
       "            0.642 , 0.6406, 0.638 , 0.635 , 0.613 , 0.6084, 0.594 , 0.589 ,\n",
       "            0.5835, 0.5825, 0.5815, 0.569 , 0.551 , 0.542 , 0.5356, 0.5234,\n",
       "            0.515 , 0.512 , 0.495 , 0.4758, 0.4607, 0.4602, 0.4595, 0.4578,\n",
       "            0.456 , 0.4404, 0.4387, 0.4368, 0.4324, 0.426 , 0.4067, 0.4038,\n",
       "            0.4033, 0.3987, 0.333 , 0.3262, 0.3108, 0.31  , 0.3005, 0.2986,\n",
       "            0.2966, 0.295 , 0.2869, 0.2864, 0.2747, 0.2742, 0.2727, 0.2722,\n",
       "            0.268 , 0.2429, 0.2327, 0.2268, 0.1893, 0.1636, 0.1515, 0.1477,\n",
       "            0.138 , 0.1324], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6694915, dtype=float32),\n",
       "    'tpr': array(0.99242425, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.03389831, 0.04237288, 0.04237288,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.18644068, 0.19491525, 0.20338982,\n",
       "            0.21186441, 0.21186441, 0.21186441, 0.21186441, 0.22033899,\n",
       "            0.22881356, 0.23728813, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.2542373 , 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27966103, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.29661018, 0.30508474, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.31355932, 0.31355932, 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.33050847, 0.33050847,\n",
       "            0.33898306, 0.34745762, 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.3898305 , 0.3983051 , 0.3983051 , 0.40677965, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.47457626, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.59322035, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6694915 , 0.6779661 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.8305085 , 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.89830506,\n",
       "            0.90677965, 0.91525424, 0.9237288 , 0.9322034 , 0.94067794,\n",
       "            0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 ,\n",
       "            0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12878788, 0.13636364, 0.14393939, 0.15151516, 0.1590909 ,\n",
       "            0.16666667, 0.17424242, 0.18939394, 0.1969697 , 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.24242425, 0.25      , 0.2651515 ,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.40151516, 0.4090909 , 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.47727272, 0.4848485 ,\n",
       "            0.4848485 , 0.49242425, 0.49242425, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.52272725, 0.530303  ,\n",
       "            0.5378788 , 0.5378788 , 0.54545456, 0.5530303 , 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6060606 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6363636 , 0.6439394 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.6666667 , 0.67424244, 0.6818182 , 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.70454544, 0.7121212 , 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.7878788 ,\n",
       "            0.79545456, 0.81060606, 0.81060606, 0.8181818 , 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.84090906, 0.8484849 , 0.8484849 ,\n",
       "            0.8560606 , 0.8636364 , 0.8712121 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 , 0.90909094,\n",
       "            0.9166667 , 0.9166667 , 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.9469697 , 0.9469697 , 0.9469697 , 0.95454544,\n",
       "            0.95454544, 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9688, 0.953 , 0.9526, 0.951 , 0.949 , 0.9463, 0.946 ,\n",
       "            0.9453, 0.9443, 0.9404, 0.938 , 0.935 , 0.9326, 0.926 , 0.924 ,\n",
       "            0.9233, 0.9214, 0.918 , 0.917 , 0.9126, 0.9116, 0.911 , 0.9097,\n",
       "            0.908 , 0.9062, 0.904 , 0.902 , 0.8984, 0.8965, 0.896 , 0.8926,\n",
       "            0.889 , 0.887 , 0.8853, 0.8843, 0.8833, 0.8774, 0.875 , 0.8647,\n",
       "            0.8633, 0.863 , 0.8623, 0.8613, 0.8604, 0.8564, 0.855 , 0.8525,\n",
       "            0.846 , 0.8457, 0.841 , 0.839 , 0.837 , 0.8364, 0.8354, 0.832 ,\n",
       "            0.831 , 0.8267, 0.8237, 0.8228, 0.8223, 0.821 , 0.82  , 0.8184,\n",
       "            0.817 , 0.8145, 0.814 , 0.811 , 0.8096, 0.808 , 0.807 , 0.806 ,\n",
       "            0.8027, 0.8022, 0.8013, 0.8003, 0.799 , 0.7964, 0.796 , 0.7944,\n",
       "            0.7915, 0.791 , 0.7905, 0.7876, 0.7866, 0.7856, 0.7847, 0.783 ,\n",
       "            0.7817, 0.7812, 0.781 , 0.78  , 0.779 , 0.778 , 0.7754, 0.775 ,\n",
       "            0.7744, 0.773 , 0.7725, 0.772 , 0.7715, 0.7705, 0.769 , 0.7676,\n",
       "            0.766 , 0.7656, 0.7646, 0.7637, 0.7627, 0.762 , 0.76  , 0.7593,\n",
       "            0.758 , 0.756 , 0.7554, 0.753 , 0.7515, 0.7505, 0.75  , 0.749 ,\n",
       "            0.7485, 0.748 , 0.7476, 0.7456, 0.7427, 0.7417, 0.741 , 0.7407,\n",
       "            0.74  , 0.7354, 0.734 , 0.7324, 0.7314, 0.7305, 0.73  , 0.7295,\n",
       "            0.7285, 0.724 , 0.7236, 0.722 , 0.7207, 0.7188, 0.7183, 0.715 ,\n",
       "            0.7104, 0.71  , 0.7065, 0.706 , 0.702 , 0.7017, 0.7   , 0.699 ,\n",
       "            0.6987, 0.698 , 0.6943, 0.6924, 0.6895, 0.687 , 0.674 , 0.672 ,\n",
       "            0.6616, 0.6577, 0.657 , 0.656 , 0.6514, 0.6475, 0.6284, 0.621 ,\n",
       "            0.608 , 0.601 , 0.5957, 0.5947, 0.594 , 0.5806, 0.562 , 0.5527,\n",
       "            0.5474, 0.534 , 0.526 , 0.5225, 0.505 , 0.489 , 0.471 , 0.4702,\n",
       "            0.4675, 0.466 , 0.45  , 0.4482, 0.445 , 0.4407, 0.4346, 0.4155,\n",
       "            0.4124, 0.4067, 0.3396, 0.3333, 0.3174, 0.315 , 0.3062, 0.3032,\n",
       "            0.3015, 0.2996, 0.2913, 0.2905, 0.2786, 0.277 , 0.2766, 0.2727,\n",
       "            0.2466, 0.236 , 0.2297, 0.1919, 0.1659, 0.1528, 0.1499, 0.1403,\n",
       "            0.1333], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6694915, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00847458, 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.03389831, 0.04237288, 0.05084746, 0.05932203, 0.05932203,\n",
       "            0.06779661, 0.06779661, 0.06779661, 0.07627118, 0.08474576,\n",
       "            0.09322034, 0.10169491, 0.10169491, 0.11016949, 0.11016949,\n",
       "            0.11864407, 0.11864407, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.15254237, 0.15254237, 0.16101696, 0.16101696,\n",
       "            0.16949153, 0.16949153, 0.18644068, 0.19491525, 0.21186441,\n",
       "            0.21186441, 0.21186441, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27118644, 0.27118644, 0.27966103, 0.27966103, 0.2881356 ,\n",
       "            0.29661018, 0.30508474, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.33050847, 0.33050847, 0.33898306, 0.34745762, 0.3644068 ,\n",
       "            0.37288135, 0.3898305 , 0.3983051 , 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.48305085, 0.48305085,\n",
       "            0.4915254 , 0.4915254 , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.55932206, 0.5677966 , 0.5677966 , 0.5762712 ,\n",
       "            0.5762712 , 0.5762712 , 0.58474576, 0.59322035, 0.60169494,\n",
       "            0.6101695 , 0.61864406, 0.62711865, 0.63559324, 0.6440678 ,\n",
       "            0.65254235, 0.66101694, 0.6694915 , 0.6694915 , 0.6779661 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.779661  , 0.7881356 , 0.7966102 , 0.80508476, 0.8135593 ,\n",
       "            0.8220339 , 0.8305085 , 0.83898306, 0.84745765, 0.8559322 ,\n",
       "            0.86440676, 0.87288135, 0.88135594, 0.89830506, 0.90677965,\n",
       "            0.91525424, 0.9237288 , 0.9322034 , 0.94067794, 0.9491525 ,\n",
       "            0.9576271 , 0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.04545455,\n",
       "            0.0530303 , 0.06060606, 0.06818182, 0.07575758, 0.08333334,\n",
       "            0.09090909, 0.09848485, 0.10606061, 0.11363637, 0.12878788,\n",
       "            0.13636364, 0.14393939, 0.15151516, 0.1590909 , 0.16666667,\n",
       "            0.17424242, 0.18939394, 0.1969697 , 0.20454545, 0.21212122,\n",
       "            0.21969697, 0.22727273, 0.24242425, 0.25      , 0.25757575,\n",
       "            0.27272728, 0.28030303, 0.28787878, 0.29545453, 0.31060606,\n",
       "            0.3181818 , 0.32575756, 0.33333334, 0.3409091 , 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.38636363,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.4090909 ,\n",
       "            0.41666666, 0.42424244, 0.42424244, 0.4318182 , 0.43939394,\n",
       "            0.4469697 , 0.45454547, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.49242425, 0.5       , 0.50757575, 0.50757575, 0.50757575,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.5151515 , 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.54545456, 0.54545456, 0.56060606,\n",
       "            0.5681818 , 0.57575756, 0.57575756, 0.5833333 , 0.59090906,\n",
       "            0.59090906, 0.5984849 , 0.6136364 , 0.6136364 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6363636 , 0.6363636 ,\n",
       "            0.6515151 , 0.65909094, 0.65909094, 0.65909094, 0.6666667 ,\n",
       "            0.67424244, 0.6818182 , 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.7121212 , 0.719697  , 0.72727275,\n",
       "            0.7348485 , 0.7348485 , 0.74242425, 0.75      , 0.7651515 ,\n",
       "            0.77272725, 0.780303  , 0.780303  , 0.7878788 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.95454544, 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.97727275, 0.97727275,\n",
       "            0.9848485 , 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9736, 0.9595, 0.958 , 0.956 , 0.954 , 0.953 , 0.9526,\n",
       "            0.9517, 0.948 , 0.946 , 0.9434, 0.941 , 0.9346, 0.933 , 0.932 ,\n",
       "            0.9307, 0.9277, 0.927 , 0.9224, 0.9214, 0.921 , 0.9194, 0.9185,\n",
       "            0.918 , 0.9165, 0.914 , 0.912 , 0.9087, 0.907 , 0.9067, 0.9033,\n",
       "            0.9   , 0.899 , 0.8965, 0.8955, 0.8945, 0.8916, 0.887 , 0.8784,\n",
       "            0.8755, 0.875 , 0.8745, 0.8735, 0.8726, 0.871 , 0.8706, 0.869 ,\n",
       "            0.8687, 0.868 , 0.8613, 0.8584, 0.8555, 0.8535, 0.85  , 0.849 ,\n",
       "            0.8486, 0.8477, 0.846 , 0.842 , 0.84  , 0.839 , 0.838 , 0.837 ,\n",
       "            0.8364, 0.834 , 0.833 , 0.8325, 0.832 , 0.829 , 0.8286, 0.8276,\n",
       "            0.827 , 0.825 , 0.8237, 0.822 , 0.8213, 0.8193, 0.817 , 0.8164,\n",
       "            0.8154, 0.814 , 0.813 , 0.811 , 0.81  , 0.809 , 0.8076, 0.805 ,\n",
       "            0.8027, 0.802 , 0.8013, 0.801 , 0.8   , 0.7993, 0.7983, 0.796 ,\n",
       "            0.793 , 0.7915, 0.791 , 0.7905, 0.79  , 0.789 , 0.788 , 0.7866,\n",
       "            0.786 , 0.784 , 0.7837, 0.7827, 0.782 , 0.781 , 0.7803, 0.78  ,\n",
       "            0.7793, 0.779 , 0.776 , 0.7744, 0.7725, 0.772 , 0.7705, 0.768 ,\n",
       "            0.767 , 0.7666, 0.7656, 0.764 , 0.7637, 0.761 , 0.7593, 0.7583,\n",
       "            0.758 , 0.757 , 0.7534, 0.752 , 0.7495, 0.7485, 0.7476, 0.746 ,\n",
       "            0.745 , 0.744 , 0.7417, 0.7393, 0.738 , 0.737 , 0.7363, 0.7354,\n",
       "            0.734 , 0.732 , 0.731 , 0.7256, 0.7227, 0.7217, 0.721 , 0.7183,\n",
       "            0.717 , 0.715 , 0.7134, 0.713 , 0.709 , 0.7085, 0.7056, 0.7036,\n",
       "            0.6875, 0.685 , 0.676 , 0.6733, 0.671 , 0.6704, 0.665 , 0.6626,\n",
       "            0.6436, 0.6353, 0.622 , 0.616 , 0.6094, 0.6084, 0.608 , 0.594 ,\n",
       "            0.5757, 0.5664, 0.561 , 0.5474, 0.539 , 0.5356, 0.519 , 0.5024,\n",
       "            0.4834, 0.4827, 0.4824, 0.4797, 0.4783, 0.4622, 0.4602, 0.457 ,\n",
       "            0.4524, 0.4463, 0.427 , 0.4236, 0.4177, 0.3489, 0.3425, 0.3262,\n",
       "            0.324 , 0.3145, 0.312 , 0.3115, 0.3098, 0.3079, 0.2996, 0.2988,\n",
       "            0.2864, 0.2847, 0.284 , 0.28  , 0.253 , 0.2422, 0.2375, 0.1971,\n",
       "            0.1705, 0.157 , 0.1543, 0.1447, 0.1371], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6694915, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00847458, 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.08474576, 0.09322034, 0.10169491,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.12711865, 0.12711865, 0.13559322, 0.13559322, 0.13559322,\n",
       "            0.1440678 , 0.1440678 , 0.15254237, 0.15254237, 0.15254237,\n",
       "            0.16101696, 0.16101696, 0.16101696, 0.16101696, 0.18644068,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.21186441, 0.21186441,\n",
       "            0.22881356, 0.23728813, 0.2457627 , 0.2457627 , 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.2542373 , 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27118644, 0.27118644, 0.27118644, 0.27118644,\n",
       "            0.27966103, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.30508474, 0.30508474, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.43220338, 0.44067797,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.45762712, 0.45762712,\n",
       "            0.4661017 , 0.47457626, 0.47457626, 0.47457626, 0.48305085,\n",
       "            0.4915254 , 0.5       , 0.5084746 , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5254237 , 0.5338983 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.24242425, 0.25      , 0.25757575, 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.3181818 ,\n",
       "            0.32575756, 0.33333334, 0.3409091 , 0.34848484, 0.3560606 ,\n",
       "            0.36363637, 0.37121212, 0.37878788, 0.38636363, 0.3939394 ,\n",
       "            0.3939394 , 0.40151516, 0.4090909 , 0.41666666, 0.42424244,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.45454547,\n",
       "            0.46969697, 0.47727272, 0.4848485 , 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.5       , 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.52272725, 0.52272725, 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.56060606, 0.5681818 , 0.57575756, 0.5833333 ,\n",
       "            0.5833333 , 0.59090906, 0.59090906, 0.5984849 , 0.6060606 ,\n",
       "            0.6060606 , 0.6136364 , 0.6212121 , 0.6287879 , 0.6287879 ,\n",
       "            0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 , 0.6515151 ,\n",
       "            0.6515151 , 0.65909094, 0.6666667 , 0.67424244, 0.6818182 ,\n",
       "            0.6818182 , 0.68939394, 0.6969697 , 0.6969697 , 0.70454544,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75      , 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.7878788 , 0.8030303 , 0.8030303 , 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.84090906, 0.84090906,\n",
       "            0.8484849 , 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.9015151 , 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.92424244, 0.9318182 , 0.93939394, 0.93939394,\n",
       "            0.9469697 , 0.95454544, 0.95454544, 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9775, 0.9653, 0.965 , 0.964 , 0.9624, 0.962 , 0.9604,\n",
       "            0.9595, 0.959 , 0.958 , 0.955 , 0.953 , 0.9507, 0.948 , 0.9424,\n",
       "            0.9414, 0.941 , 0.9404, 0.939 , 0.936 , 0.935 , 0.931 , 0.93  ,\n",
       "            0.9297, 0.9287, 0.9277, 0.9272, 0.926 , 0.9233, 0.9214, 0.9185,\n",
       "            0.9175, 0.9165, 0.913 , 0.91  , 0.909 , 0.907 , 0.9067, 0.9062,\n",
       "            0.905 , 0.9043, 0.898 , 0.891 , 0.8867, 0.886 , 0.8857, 0.885 ,\n",
       "            0.8843, 0.884 , 0.8823, 0.8813, 0.8804, 0.875 , 0.87  , 0.869 ,\n",
       "            0.8677, 0.863 , 0.862 , 0.861 , 0.8604, 0.856 , 0.8555, 0.8545,\n",
       "            0.8525, 0.8516, 0.851 , 0.8477, 0.8467, 0.846 , 0.8447, 0.8433,\n",
       "            0.843 , 0.8423, 0.841 , 0.84  , 0.837 , 0.8364, 0.835 , 0.8345,\n",
       "            0.8315, 0.831 , 0.829 , 0.827 , 0.8257, 0.825 , 0.8247, 0.8237,\n",
       "            0.823 , 0.8213, 0.819 , 0.8184, 0.818 , 0.8174, 0.816 , 0.8154,\n",
       "            0.8145, 0.814 , 0.8125, 0.812 , 0.8076, 0.807 , 0.806 , 0.805 ,\n",
       "            0.8047, 0.804 , 0.803 , 0.8027, 0.8003, 0.7983, 0.7974, 0.7964,\n",
       "            0.796 , 0.7954, 0.795 , 0.7935, 0.7925, 0.792 , 0.7905, 0.7886,\n",
       "            0.788 , 0.785 , 0.784 , 0.783 , 0.7827, 0.782 , 0.781 , 0.7803,\n",
       "            0.7793, 0.779 , 0.7764, 0.7754, 0.7744, 0.774 , 0.772 , 0.768 ,\n",
       "            0.7666, 0.766 , 0.7646, 0.7637, 0.763 , 0.762 , 0.7607, 0.7593,\n",
       "            0.7583, 0.755 , 0.7534, 0.752 , 0.7515, 0.749 , 0.748 , 0.746 ,\n",
       "            0.7407, 0.7383, 0.737 , 0.7363, 0.734 , 0.7324, 0.732 , 0.73  ,\n",
       "            0.727 , 0.724 , 0.721 , 0.72  , 0.7017, 0.698 , 0.6895, 0.688 ,\n",
       "            0.685 , 0.6787, 0.6772, 0.659 , 0.6494, 0.6367, 0.6313, 0.6235,\n",
       "            0.6226, 0.6084, 0.59  , 0.5806, 0.575 , 0.561 , 0.553 , 0.55  ,\n",
       "            0.534 , 0.5186, 0.4973, 0.4968, 0.496 , 0.4934, 0.492 , 0.4756,\n",
       "            0.4736, 0.4705, 0.4656, 0.4592, 0.44  , 0.4368, 0.4363, 0.4304,\n",
       "            0.36  , 0.3542, 0.3374, 0.3347, 0.325 , 0.3232, 0.322 , 0.32  ,\n",
       "            0.3184, 0.3096, 0.309 , 0.2964, 0.296 , 0.2942, 0.2935, 0.2893,\n",
       "            0.2615, 0.2505, 0.2477, 0.2047, 0.1774, 0.1632, 0.1609, 0.1512,\n",
       "            0.1428], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7118644, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.00847458, 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.03389831,\n",
       "            0.04237288, 0.05084746, 0.05084746, 0.05932203, 0.06779661,\n",
       "            0.07627118, 0.07627118, 0.07627118, 0.08474576, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.11864407, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.12711865, 0.12711865, 0.13559322,\n",
       "            0.13559322, 0.1440678 , 0.1440678 , 0.15254237, 0.15254237,\n",
       "            0.15254237, 0.16101696, 0.16101696, 0.16101696, 0.16949153,\n",
       "            0.19491525, 0.20338982, 0.21186441, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.22881356, 0.23728813, 0.23728813, 0.23728813,\n",
       "            0.2457627 , 0.2457627 , 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.2881356 , 0.29661018,\n",
       "            0.30508474, 0.30508474, 0.30508474, 0.30508474, 0.31355932,\n",
       "            0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.33050847, 0.33898306, 0.34745762, 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.38135594, 0.3898305 ,\n",
       "            0.3983051 , 0.40677965, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.4661017 , 0.47457626, 0.47457626, 0.47457626,\n",
       "            0.48305085, 0.5       , 0.5       , 0.5       , 0.5084746 ,\n",
       "            0.5084746 , 0.5169492 , 0.5254237 , 0.5338983 , 0.5423729 ,\n",
       "            0.5508475 , 0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 ,\n",
       "            0.5762712 , 0.58474576, 0.60169494, 0.6101695 , 0.61864406,\n",
       "            0.62711865, 0.63559324, 0.6440678 , 0.65254235, 0.66101694,\n",
       "            0.6694915 , 0.6694915 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.02272727, 0.03030303, 0.03787879,\n",
       "            0.04545455, 0.0530303 , 0.06060606, 0.06818182, 0.07575758,\n",
       "            0.08333334, 0.09090909, 0.09848485, 0.10606061, 0.11363637,\n",
       "            0.12121212, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.29545453, 0.3030303 , 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.34848484, 0.3560606 , 0.37878788, 0.37878788,\n",
       "            0.38636363, 0.3939394 , 0.40151516, 0.4090909 , 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46969697, 0.47727272, 0.47727272,\n",
       "            0.4848485 , 0.4848485 , 0.49242425, 0.49242425, 0.49242425,\n",
       "            0.5       , 0.50757575, 0.5151515 , 0.5151515 , 0.5151515 ,\n",
       "            0.5151515 , 0.5151515 , 0.52272725, 0.530303  , 0.5378788 ,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5681818 , 0.5681818 , 0.5833333 , 0.5833333 , 0.5984849 ,\n",
       "            0.6060606 , 0.6060606 , 0.6136364 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6287879 , 0.6287879 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.65909094, 0.6666667 ,\n",
       "            0.6666667 , 0.67424244, 0.67424244, 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75      , 0.75757575, 0.7651515 , 0.77272725,\n",
       "            0.780303  , 0.780303  , 0.79545456, 0.8030303 , 0.8030303 ,\n",
       "            0.81060606, 0.8181818 , 0.82575756, 0.84090906, 0.84090906,\n",
       "            0.84090906, 0.8484849 , 0.8560606 , 0.8636364 , 0.8712121 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.9318182 , 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.95454544, 0.9621212 , 0.9621212 ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.97727275, 0.97727275, 0.9848485 ,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9814, 0.97  , 0.9688, 0.968 , 0.9673, 0.966 , 0.9653,\n",
       "            0.965 , 0.964 , 0.961 , 0.959 , 0.957 , 0.9546, 0.9497, 0.9487,\n",
       "            0.948 , 0.9478, 0.9463, 0.944 , 0.943 , 0.939 , 0.938 , 0.9375,\n",
       "            0.9365, 0.936 , 0.9355, 0.934 , 0.9316, 0.93  , 0.9272, 0.9263,\n",
       "            0.9253, 0.9224, 0.9194, 0.919 , 0.9165, 0.916 , 0.914 , 0.908 ,\n",
       "            0.9033, 0.8975, 0.897 , 0.8965, 0.8955, 0.895 , 0.8945, 0.893 ,\n",
       "            0.891 , 0.8877, 0.882 , 0.8813, 0.881 , 0.875 , 0.8745, 0.8735,\n",
       "            0.8726, 0.872 , 0.87  , 0.869 , 0.8687, 0.8667, 0.8657, 0.8643,\n",
       "            0.86  , 0.8594, 0.8574, 0.857 , 0.856 , 0.8555, 0.8516, 0.8506,\n",
       "            0.8496, 0.849 , 0.8477, 0.8467, 0.8457, 0.845 , 0.8447, 0.8438,\n",
       "            0.8413, 0.8403, 0.84  , 0.839 , 0.8384, 0.837 , 0.8345, 0.8335,\n",
       "            0.833 , 0.832 , 0.831 , 0.8296, 0.829 , 0.828 , 0.827 , 0.8267,\n",
       "            0.823 , 0.8228, 0.8213, 0.821 , 0.8203, 0.82  , 0.8193, 0.819 ,\n",
       "            0.818 , 0.8154, 0.814 , 0.8115, 0.811 , 0.8105, 0.81  , 0.809 ,\n",
       "            0.808 , 0.807 , 0.806 , 0.804 , 0.803 , 0.7993, 0.799 , 0.7983,\n",
       "            0.798 , 0.7974, 0.796 , 0.794 , 0.7935, 0.791 , 0.7905, 0.79  ,\n",
       "            0.7896, 0.786 , 0.7837, 0.7827, 0.781 , 0.7793, 0.7783, 0.7773,\n",
       "            0.777 , 0.776 , 0.7744, 0.7734, 0.7725, 0.7695, 0.7686, 0.7666,\n",
       "            0.7656, 0.764 , 0.7637, 0.7617, 0.756 , 0.7554, 0.7534, 0.751 ,\n",
       "            0.749 , 0.7476, 0.7466, 0.745 , 0.7407, 0.7383, 0.7363, 0.736 ,\n",
       "            0.715 , 0.712 , 0.703 , 0.7026, 0.699 , 0.698 , 0.6924, 0.675 ,\n",
       "            0.663 , 0.651 , 0.6465, 0.6377, 0.636 , 0.6226, 0.604 , 0.595 ,\n",
       "            0.5894, 0.575 , 0.568 , 0.564 , 0.5493, 0.535 , 0.511 , 0.51  ,\n",
       "            0.5073, 0.506 , 0.4895, 0.4873, 0.4841, 0.479 , 0.473 , 0.4531,\n",
       "            0.4502, 0.4495, 0.4434, 0.3716, 0.3665, 0.3489, 0.3464, 0.336 ,\n",
       "            0.3352, 0.333 , 0.3308, 0.3293, 0.3208, 0.32  , 0.3074, 0.3064,\n",
       "            0.3042, 0.3037, 0.2993, 0.2708, 0.2595, 0.2588, 0.2129, 0.1849,\n",
       "            0.17  , 0.1682, 0.1587, 0.1493], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.720339, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05932203, 0.06779661, 0.07627118, 0.07627118, 0.07627118,\n",
       "            0.08474576, 0.09322034, 0.10169491, 0.11016949, 0.11864407,\n",
       "            0.11864407, 0.11864407, 0.13559322, 0.13559322, 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16101696, 0.16949153, 0.1779661 , 0.19491525,\n",
       "            0.20338982, 0.20338982, 0.20338982, 0.21186441, 0.21186441,\n",
       "            0.21186441, 0.22033899, 0.22881356, 0.23728813, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.2542373 , 0.2542373 , 0.2542373 ,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.27118644, 0.27966103, 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.30508474, 0.31355932, 0.3220339 , 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33898306, 0.34745762,\n",
       "            0.3559322 , 0.3644068 , 0.38135594, 0.3898305 , 0.3983051 ,\n",
       "            0.40677965, 0.41525424, 0.42372882, 0.42372882, 0.43220338,\n",
       "            0.44067797, 0.44915253, 0.44915253, 0.44915253, 0.44915253,\n",
       "            0.45762712, 0.45762712, 0.4661017 , 0.47457626, 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.4915254 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6779661 , 0.6864407 , 0.69491524, 0.7033898 ,\n",
       "            0.7118644 , 0.720339  , 0.7288136 , 0.7372881 , 0.7457627 ,\n",
       "            0.7542373 , 0.7627119 , 0.7711864 , 0.779661  , 0.7881356 ,\n",
       "            0.7966102 , 0.80508476, 0.8135593 , 0.8220339 , 0.8305085 ,\n",
       "            0.83898306, 0.84745765, 0.8559322 , 0.86440676, 0.87288135,\n",
       "            0.88135594, 0.8898305 , 0.89830506, 0.90677965, 0.91525424,\n",
       "            0.9237288 , 0.9322034 , 0.94067794, 0.9491525 , 0.9576271 ,\n",
       "            0.9661017 , 0.9745763 , 0.9830508 , 0.9915254 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.34848484, 0.3560606 ,\n",
       "            0.3560606 , 0.36363637, 0.37121212, 0.37878788, 0.3939394 ,\n",
       "            0.40151516, 0.4090909 , 0.41666666, 0.41666666, 0.42424244,\n",
       "            0.4318182 , 0.43939394, 0.45454547, 0.46212122, 0.46969697,\n",
       "            0.47727272, 0.47727272, 0.4848485 , 0.4848485 , 0.49242425,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.5       , 0.50757575,\n",
       "            0.50757575, 0.5151515 , 0.5151515 , 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.54545456, 0.5530303 , 0.56060606, 0.56060606,\n",
       "            0.5833333 , 0.59090906, 0.5984849 , 0.6060606 , 0.6060606 ,\n",
       "            0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6212121 , 0.6287879 , 0.6363636 , 0.6363636 , 0.6439394 ,\n",
       "            0.6515151 , 0.6515151 , 0.6515151 , 0.6515151 , 0.65909094,\n",
       "            0.6666667 , 0.67424244, 0.6818182 , 0.68939394, 0.6969697 ,\n",
       "            0.6969697 , 0.70454544, 0.719697  , 0.72727275, 0.7348485 ,\n",
       "            0.74242425, 0.75757575, 0.7651515 , 0.77272725, 0.780303  ,\n",
       "            0.780303  , 0.780303  , 0.79545456, 0.81060606, 0.8181818 ,\n",
       "            0.82575756, 0.8333333 , 0.84090906, 0.8560606 , 0.8636364 ,\n",
       "            0.8712121 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 ,\n",
       "            0.8939394 , 0.8939394 , 0.9015151 , 0.90909094, 0.9166667 ,\n",
       "            0.9166667 , 0.92424244, 0.92424244, 0.92424244, 0.9318182 ,\n",
       "            0.93939394, 0.93939394, 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.95454544, 0.9621212 , 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9844, 0.9746, 0.974 , 0.973 , 0.9727, 0.972 , 0.9707,\n",
       "            0.97  , 0.969 , 0.9688, 0.9663, 0.9644, 0.963 , 0.9604, 0.956 ,\n",
       "            0.955 , 0.954 , 0.953 , 0.9507, 0.9497, 0.946 , 0.9453, 0.945 ,\n",
       "            0.944 , 0.9434, 0.9424, 0.9414, 0.9395, 0.9375, 0.935 , 0.9346,\n",
       "            0.9336, 0.933 , 0.9307, 0.9277, 0.9272, 0.9263, 0.9253, 0.925 ,\n",
       "            0.923 , 0.9175, 0.914 , 0.909 , 0.9077, 0.907 , 0.9067, 0.9062,\n",
       "            0.906 , 0.9043, 0.904 , 0.9014, 0.899 , 0.893 , 0.8926, 0.8916,\n",
       "            0.8867, 0.8853, 0.8833, 0.883 , 0.8823, 0.882 , 0.881 , 0.88  ,\n",
       "            0.879 , 0.8765, 0.8726, 0.8716, 0.871 , 0.8706, 0.869 , 0.868 ,\n",
       "            0.8677, 0.8633, 0.863 , 0.862 , 0.8594, 0.858 , 0.8574, 0.8545,\n",
       "            0.8525, 0.852 , 0.8516, 0.851 , 0.848 , 0.8477, 0.847 , 0.8467,\n",
       "            0.8457, 0.845 , 0.8438, 0.8433, 0.843 , 0.842 , 0.841 , 0.839 ,\n",
       "            0.8384, 0.8374, 0.837 , 0.8354, 0.8345, 0.834 , 0.8335, 0.832 ,\n",
       "            0.8315, 0.8296, 0.829 , 0.8257, 0.825 , 0.824 , 0.823 , 0.8223,\n",
       "            0.8213, 0.821 , 0.8184, 0.818 , 0.8174, 0.814 , 0.8125, 0.812 ,\n",
       "            0.8105, 0.808 , 0.806 , 0.8047, 0.804 , 0.8   , 0.7983, 0.798 ,\n",
       "            0.796 , 0.794 , 0.792 , 0.7905, 0.79  , 0.787 , 0.7856, 0.7847,\n",
       "            0.7837, 0.7827, 0.7812, 0.7793, 0.779 , 0.7783, 0.776 , 0.77  ,\n",
       "            0.7695, 0.768 , 0.765 , 0.7646, 0.7637, 0.7627, 0.7607, 0.76  ,\n",
       "            0.756 , 0.7544, 0.7534, 0.7524, 0.7515, 0.751 , 0.7275, 0.725 ,\n",
       "            0.7163, 0.716 , 0.714 , 0.7114, 0.7065, 0.7056, 0.689 , 0.6763,\n",
       "            0.664 , 0.6616, 0.6514, 0.6494, 0.636 , 0.617 , 0.609 , 0.6025,\n",
       "            0.5884, 0.581 , 0.577 , 0.564 , 0.5483, 0.524 , 0.5234, 0.5225,\n",
       "            0.5195, 0.518 , 0.5015, 0.499 , 0.4966, 0.4912, 0.4849, 0.4646,\n",
       "            0.4617, 0.4607, 0.4546, 0.3806, 0.3755, 0.3577, 0.3557, 0.3445,\n",
       "            0.344 , 0.3418, 0.3396, 0.3381, 0.3296, 0.3289, 0.3162, 0.3145,\n",
       "            0.312 , 0.3115, 0.3066, 0.2773, 0.268 , 0.2656, 0.218 , 0.1896,\n",
       "            0.1747, 0.1726, 0.1631, 0.1534], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7457627, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00847458, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.02542373,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.03389831, 0.03389831, 0.03389831, 0.04237288, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.07627118, 0.07627118,\n",
       "            0.07627118, 0.08474576, 0.10169491, 0.10169491, 0.10169491,\n",
       "            0.11016949, 0.11864407, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.13559322, 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.16101696, 0.16949153,\n",
       "            0.1779661 , 0.19491525, 0.20338982, 0.20338982, 0.20338982,\n",
       "            0.20338982, 0.21186441, 0.22033899, 0.22881356, 0.23728813,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.2457627 , 0.2542373 ,\n",
       "            0.2542373 , 0.2542373 , 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.27118644, 0.27966103,\n",
       "            0.27966103, 0.2881356 , 0.2881356 , 0.30508474, 0.30508474,\n",
       "            0.31355932, 0.3220339 , 0.3220339 , 0.3220339 , 0.33050847,\n",
       "            0.33050847, 0.33898306, 0.34745762, 0.3559322 , 0.3559322 ,\n",
       "            0.3644068 , 0.37288135, 0.38135594, 0.3983051 , 0.40677965,\n",
       "            0.41525424, 0.42372882, 0.42372882, 0.43220338, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.44915253, 0.45762712, 0.4661017 ,\n",
       "            0.47457626, 0.47457626, 0.47457626, 0.48305085, 0.4915254 ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5084746 , 0.5084746 ,\n",
       "            0.5169492 , 0.5338983 , 0.5423729 , 0.5508475 , 0.55932206,\n",
       "            0.5677966 , 0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 ,\n",
       "            0.58474576, 0.60169494, 0.6101695 , 0.61864406, 0.62711865,\n",
       "            0.63559324, 0.6440678 , 0.65254235, 0.66101694, 0.6694915 ,\n",
       "            0.6694915 , 0.6864407 , 0.69491524, 0.7033898 , 0.7118644 ,\n",
       "            0.720339  , 0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 ,\n",
       "            0.7627119 , 0.7711864 , 0.779661  , 0.7881356 , 0.7966102 ,\n",
       "            0.80508476, 0.8135593 , 0.8220339 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12121212, 0.12878788, 0.13636364, 0.14393939,\n",
       "            0.15151516, 0.1590909 , 0.16666667, 0.18181819, 0.18939394,\n",
       "            0.1969697 , 0.20454545, 0.21212122, 0.21969697, 0.22727273,\n",
       "            0.24242425, 0.25757575, 0.27272728, 0.28030303, 0.28787878,\n",
       "            0.3030303 , 0.31060606, 0.32575756, 0.33333334, 0.3409091 ,\n",
       "            0.34848484, 0.34848484, 0.3560606 , 0.36363637, 0.37878788,\n",
       "            0.38636363, 0.40151516, 0.4090909 , 0.41666666, 0.41666666,\n",
       "            0.42424244, 0.4318182 , 0.43939394, 0.4469697 , 0.46212122,\n",
       "            0.46212122, 0.46969697, 0.47727272, 0.4848485 , 0.4848485 ,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.49242425, 0.5       ,\n",
       "            0.50757575, 0.50757575, 0.50757575, 0.5151515 , 0.52272725,\n",
       "            0.52272725, 0.530303  , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.56060606, 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.5833333 , 0.6060606 , 0.6136364 , 0.6212121 ,\n",
       "            0.6212121 , 0.6212121 , 0.6212121 , 0.6287879 , 0.6363636 ,\n",
       "            0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6515151 , 0.6666667 , 0.67424244, 0.67424244, 0.6818182 ,\n",
       "            0.68939394, 0.6969697 , 0.6969697 , 0.70454544, 0.7121212 ,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.77272725, 0.780303  , 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.82575756,\n",
       "            0.8333333 , 0.8333333 , 0.84090906, 0.8636364 , 0.8636364 ,\n",
       "            0.8787879 , 0.8787879 , 0.8787879 , 0.8787879 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8939394 , 0.8939394 , 0.8939394 ,\n",
       "            0.9015151 , 0.90909094, 0.9166667 , 0.9166667 , 0.92424244,\n",
       "            0.92424244, 0.9318182 , 0.93939394, 0.93939394, 0.93939394,\n",
       "            0.93939394, 0.9469697 , 0.9621212 , 0.9621212 , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.97727275, 0.97727275, 0.9848485 , 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.987 , 0.9785, 0.978 , 0.977 , 0.9766, 0.976 , 0.975 ,\n",
       "            0.9746, 0.9736, 0.973 , 0.9707, 0.969 , 0.9683, 0.966 , 0.962 ,\n",
       "            0.961 , 0.9604, 0.96  , 0.959 , 0.957 , 0.9556, 0.9526, 0.9517,\n",
       "            0.951 , 0.9507, 0.95  , 0.949 , 0.948 , 0.9463, 0.945 , 0.9424,\n",
       "            0.941 , 0.938 , 0.936 , 0.9355, 0.9336, 0.9326, 0.931 , 0.9263,\n",
       "            0.9243, 0.9194, 0.918 , 0.9155, 0.915 , 0.914 , 0.9136, 0.9106,\n",
       "            0.9097, 0.9043, 0.9033, 0.9014, 0.898 , 0.8965, 0.8955, 0.894 ,\n",
       "            0.893 , 0.8926, 0.892 , 0.8916, 0.891 , 0.8877, 0.8843, 0.8833,\n",
       "            0.883 , 0.8823, 0.882 , 0.8794, 0.879 , 0.877 , 0.875 , 0.8735,\n",
       "            0.8726, 0.871 , 0.8706, 0.87  , 0.8696, 0.869 , 0.8677, 0.866 ,\n",
       "            0.8657, 0.8647, 0.864 , 0.862 , 0.861 , 0.86  , 0.8584, 0.857 ,\n",
       "            0.8564, 0.855 , 0.8545, 0.854 , 0.8525, 0.851 , 0.8506, 0.85  ,\n",
       "            0.8486, 0.8477, 0.847 , 0.8467, 0.8457, 0.844 , 0.8438, 0.843 ,\n",
       "            0.84  , 0.8394, 0.8384, 0.838 , 0.8364, 0.836 , 0.8354, 0.8345,\n",
       "            0.8325, 0.832 , 0.8296, 0.828 , 0.8276, 0.8267, 0.826 , 0.8247,\n",
       "            0.822 , 0.8203, 0.8193, 0.8184, 0.813 , 0.8125, 0.811 , 0.808 ,\n",
       "            0.806 , 0.805 , 0.804 , 0.803 , 0.802 , 0.8003, 0.7983, 0.798 ,\n",
       "            0.7964, 0.795 , 0.7935, 0.7925, 0.79  , 0.7837, 0.783 , 0.7827,\n",
       "            0.779 , 0.7783, 0.7773, 0.7744, 0.774 , 0.771 , 0.767 , 0.7666,\n",
       "            0.766 , 0.765 , 0.7407, 0.7383, 0.7295, 0.729 , 0.7246, 0.721 ,\n",
       "            0.7183, 0.704 , 0.69  , 0.6777, 0.6763, 0.665 , 0.663 , 0.65  ,\n",
       "            0.631 , 0.623 , 0.616 , 0.602 , 0.5947, 0.591 , 0.579 , 0.564 ,\n",
       "            0.5376, 0.536 , 0.533 , 0.5317, 0.515 , 0.5127, 0.5103, 0.5044,\n",
       "            0.4983, 0.4775, 0.475 , 0.4736, 0.4673, 0.3918, 0.3872, 0.369 ,\n",
       "            0.3672, 0.3552, 0.3525, 0.35  , 0.3489, 0.3403, 0.3394, 0.3267,\n",
       "            0.3245, 0.3218, 0.3213, 0.3164, 0.2861, 0.2795, 0.2742, 0.2256,\n",
       "            0.1965, 0.1813, 0.1794, 0.1699, 0.1598], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7542373, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00847458, 0.01694915,\n",
       "            0.01694915, 0.01694915, 0.01694915, 0.01694915, 0.01694915,\n",
       "            0.02542373, 0.02542373, 0.02542373, 0.02542373, 0.02542373,\n",
       "            0.02542373, 0.03389831, 0.04237288, 0.05084746, 0.05084746,\n",
       "            0.05084746, 0.05932203, 0.06779661, 0.06779661, 0.07627118,\n",
       "            0.08474576, 0.08474576, 0.10169491, 0.10169491, 0.11016949,\n",
       "            0.11016949, 0.11016949, 0.11864407, 0.12711865, 0.12711865,\n",
       "            0.13559322, 0.13559322, 0.1440678 , 0.1440678 , 0.1440678 ,\n",
       "            0.15254237, 0.15254237, 0.15254237, 0.15254237, 0.16101696,\n",
       "            0.16101696, 0.16949153, 0.1779661 , 0.19491525, 0.20338982,\n",
       "            0.20338982, 0.20338982, 0.21186441, 0.22033899, 0.22881356,\n",
       "            0.23728813, 0.23728813, 0.23728813, 0.23728813, 0.2457627 ,\n",
       "            0.2542373 , 0.2542373 , 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.26271185,\n",
       "            0.26271185, 0.26271185, 0.26271185, 0.26271185, 0.27118644,\n",
       "            0.27118644, 0.2881356 , 0.2881356 , 0.29661018, 0.30508474,\n",
       "            0.30508474, 0.30508474, 0.31355932, 0.3220339 , 0.3220339 ,\n",
       "            0.3220339 , 0.3220339 , 0.33050847, 0.33050847, 0.33898306,\n",
       "            0.34745762, 0.3559322 , 0.3559322 , 0.3644068 , 0.37288135,\n",
       "            0.38135594, 0.3983051 , 0.40677965, 0.41525424, 0.42372882,\n",
       "            0.42372882, 0.43220338, 0.44067797, 0.44915253, 0.44915253,\n",
       "            0.44915253, 0.44915253, 0.45762712, 0.4661017 , 0.47457626,\n",
       "            0.47457626, 0.48305085, 0.48305085, 0.4915254 , 0.4915254 ,\n",
       "            0.5       , 0.5084746 , 0.5084746 , 0.5084746 , 0.5169492 ,\n",
       "            0.5254237 , 0.5423729 , 0.5508475 , 0.55932206, 0.5677966 ,\n",
       "            0.5677966 , 0.5762712 , 0.5762712 , 0.5762712 , 0.58474576,\n",
       "            0.60169494, 0.6101695 , 0.61864406, 0.62711865, 0.63559324,\n",
       "            0.6440678 , 0.65254235, 0.66101694, 0.6694915 , 0.6694915 ,\n",
       "            0.6864407 , 0.69491524, 0.7033898 , 0.7118644 , 0.720339  ,\n",
       "            0.7288136 , 0.7372881 , 0.7457627 , 0.7542373 , 0.7627119 ,\n",
       "            0.7711864 , 0.779661  , 0.7881356 , 0.7966102 , 0.80508476,\n",
       "            0.8135593 , 0.8220339 , 0.8305085 , 0.83898306, 0.84745765,\n",
       "            0.8559322 , 0.86440676, 0.87288135, 0.88135594, 0.8898305 ,\n",
       "            0.89830506, 0.90677965, 0.91525424, 0.9237288 , 0.9322034 ,\n",
       "            0.94067794, 0.9491525 , 0.9576271 , 0.9661017 , 0.9745763 ,\n",
       "            0.9830508 , 0.9915254 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00757576, 0.01515152, 0.02272727, 0.03030303,\n",
       "            0.03787879, 0.04545455, 0.0530303 , 0.06060606, 0.06818182,\n",
       "            0.07575758, 0.08333334, 0.09090909, 0.09848485, 0.10606061,\n",
       "            0.11363637, 0.12878788, 0.13636364, 0.14393939, 0.15151516,\n",
       "            0.1590909 , 0.16666667, 0.18181819, 0.18939394, 0.1969697 ,\n",
       "            0.20454545, 0.21212122, 0.21969697, 0.22727273, 0.24242425,\n",
       "            0.25      , 0.25757575, 0.2651515 , 0.27272728, 0.28030303,\n",
       "            0.28787878, 0.29545453, 0.3030303 , 0.31060606, 0.32575756,\n",
       "            0.33333334, 0.3409091 , 0.34848484, 0.34848484, 0.34848484,\n",
       "            0.3560606 , 0.36363637, 0.38636363, 0.40151516, 0.41666666,\n",
       "            0.41666666, 0.42424244, 0.4318182 , 0.43939394, 0.4469697 ,\n",
       "            0.45454547, 0.46212122, 0.46212122, 0.46969697, 0.47727272,\n",
       "            0.49242425, 0.49242425, 0.49242425, 0.5       , 0.5       ,\n",
       "            0.5       , 0.50757575, 0.50757575, 0.52272725, 0.52272725,\n",
       "            0.530303  , 0.5378788 , 0.5378788 , 0.5378788 , 0.54545456,\n",
       "            0.54545456, 0.5530303 , 0.5530303 , 0.56060606, 0.5681818 ,\n",
       "            0.5681818 , 0.57575756, 0.5833333 , 0.5984849 , 0.6060606 ,\n",
       "            0.6136364 , 0.6136364 , 0.6212121 , 0.6212121 , 0.6212121 ,\n",
       "            0.6287879 , 0.6363636 , 0.6439394 , 0.6439394 , 0.6439394 ,\n",
       "            0.6439394 , 0.6515151 , 0.6666667 , 0.67424244, 0.67424244,\n",
       "            0.67424244, 0.68939394, 0.68939394, 0.6969697 , 0.70454544,\n",
       "            0.719697  , 0.72727275, 0.7348485 , 0.74242425, 0.75      ,\n",
       "            0.75757575, 0.7651515 , 0.77272725, 0.780303  , 0.780303  ,\n",
       "            0.7878788 , 0.79545456, 0.8030303 , 0.81060606, 0.81060606,\n",
       "            0.8181818 , 0.82575756, 0.8333333 , 0.8333333 , 0.84090906,\n",
       "            0.8560606 , 0.8636364 , 0.8636364 , 0.8712121 , 0.8787879 ,\n",
       "            0.8787879 , 0.8787879 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 , 0.8863636 ,\n",
       "            0.8939394 , 0.8939394 , 0.8939394 , 0.8939394 , 0.9015151 ,\n",
       "            0.90909094, 0.9166667 , 0.9166667 , 0.92424244, 0.92424244,\n",
       "            0.9318182 , 0.9318182 , 0.93939394, 0.93939394, 0.9469697 ,\n",
       "            0.9469697 , 0.95454544, 0.9621212 , 0.969697  , 0.969697  ,\n",
       "            0.969697  , 0.969697  , 0.969697  , 0.969697  , 0.969697  ,\n",
       "            0.97727275, 0.97727275, 0.9848485 , 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 0.99242425,\n",
       "            0.99242425, 0.99242425, 0.99242425, 0.99242425, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9893, 0.982 , 0.9814, 0.9805, 0.98  , 0.9795, 0.979 ,\n",
       "            0.978 , 0.9775, 0.9766, 0.975 , 0.9736, 0.9727, 0.97  , 0.967 ,\n",
       "            0.966 , 0.965 , 0.9644, 0.9624, 0.961 , 0.958 , 0.9575, 0.957 ,\n",
       "            0.9565, 0.956 , 0.955 , 0.954 , 0.952 , 0.951 , 0.949 , 0.9487,\n",
       "            0.9478, 0.9473, 0.945 , 0.9443, 0.943 , 0.9424, 0.941 , 0.94  ,\n",
       "            0.938 , 0.934 , 0.9336, 0.929 , 0.9277, 0.9272, 0.924 , 0.9233,\n",
       "            0.922 , 0.9194, 0.914 , 0.9136, 0.91  , 0.908 , 0.907 , 0.9062,\n",
       "            0.9053, 0.9033, 0.903 , 0.9023, 0.902 , 0.8984, 0.895 , 0.8945,\n",
       "            0.894 , 0.8936, 0.8926, 0.89  , 0.889 , 0.886 , 0.885 , 0.8843,\n",
       "            0.884 , 0.8833, 0.882 , 0.8813, 0.881 , 0.88  , 0.8794, 0.879 ,\n",
       "            0.878 , 0.8774, 0.8765, 0.875 , 0.8745, 0.874 , 0.8735, 0.873 ,\n",
       "            0.871 , 0.8696, 0.869 , 0.8667, 0.8657, 0.865 , 0.864 , 0.8633,\n",
       "            0.862 , 0.8613, 0.861 , 0.86  , 0.859 , 0.8584, 0.857 , 0.8564,\n",
       "            0.856 , 0.8525, 0.851 , 0.85  , 0.8496, 0.8486, 0.8477, 0.847 ,\n",
       "            0.8467, 0.8457, 0.845 , 0.8413, 0.841 , 0.84  , 0.8394, 0.839 ,\n",
       "            0.8384, 0.837 , 0.835 , 0.834 , 0.833 , 0.832 , 0.83  , 0.827 ,\n",
       "            0.826 , 0.825 , 0.822 , 0.82  , 0.8193, 0.818 , 0.8154, 0.815 ,\n",
       "            0.8125, 0.811 , 0.8105, 0.81  , 0.8086, 0.8076, 0.8057, 0.8047,\n",
       "            0.8037, 0.7974, 0.797 , 0.7964, 0.7925, 0.792 , 0.791 , 0.788 ,\n",
       "            0.7876, 0.7856, 0.781 , 0.78  , 0.7793, 0.779 , 0.7534, 0.7515,\n",
       "            0.743 , 0.742 , 0.7373, 0.7344, 0.731 , 0.7188, 0.7026, 0.6914,\n",
       "            0.6904, 0.6777, 0.676 , 0.663 , 0.644 , 0.6357, 0.6294, 0.6147,\n",
       "            0.608 , 0.6035, 0.593 , 0.579 , 0.5503, 0.549 , 0.546 , 0.5444,\n",
       "            0.528 , 0.525 , 0.5225, 0.5166, 0.5103, 0.4895, 0.4873, 0.4854,\n",
       "            0.4788, 0.402 , 0.3977, 0.3787, 0.3772, 0.3655, 0.3647, 0.362 ,\n",
       "            0.3594, 0.3584, 0.3499, 0.3489, 0.336 , 0.333 , 0.3306, 0.3298,\n",
       "            0.3247, 0.2937, 0.2893, 0.2812, 0.2319, 0.2023, 0.1866, 0.185 ,\n",
       "            0.1757, 0.1647], dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9916667, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.11666667, 0.125     , 0.125     , 0.13333334, 0.15      ,\n",
       "            0.15      , 0.15      , 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.24166666, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.36666667, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.51666665, 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.575     , 0.5833333 ,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.64166665, 0.64166665, 0.64166665, 0.65833336,\n",
       "            0.6666667 , 0.69166666, 0.7       , 0.71666664, 0.725     ,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.8333333 ,\n",
       "            0.84166664, 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.95      , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13076924, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.15384616, 0.16153847, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.18461539, 0.1923077 , 0.1923077 ,\n",
       "            0.1923077 , 0.20769231, 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23846154, 0.23846154, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.31538463, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.3923077 , 0.4       , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.73846155, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7846154 , 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.765 , 0.76  , 0.7383, 0.7363, 0.735 , 0.7324, 0.7314,\n",
       "            0.7285, 0.7275, 0.726 , 0.725 , 0.7246, 0.721 , 0.72  , 0.7183,\n",
       "            0.717 , 0.716 , 0.714 , 0.713 , 0.7104, 0.709 , 0.7075, 0.707 ,\n",
       "            0.706 , 0.7056, 0.704 , 0.7036, 0.7026, 0.702 , 0.7007, 0.6997,\n",
       "            0.699 , 0.6987, 0.6963, 0.6943, 0.6934, 0.6924, 0.6904, 0.6895,\n",
       "            0.689 , 0.6885, 0.688 , 0.6875, 0.6865, 0.686 , 0.685 , 0.6846,\n",
       "            0.684 , 0.6836, 0.6826, 0.6816, 0.681 , 0.6807, 0.68  , 0.679 ,\n",
       "            0.6753, 0.675 , 0.674 , 0.6733, 0.67  , 0.6685, 0.667 , 0.6665,\n",
       "            0.6655, 0.665 , 0.663 , 0.6626, 0.662 , 0.661 , 0.6597, 0.6587,\n",
       "            0.658 , 0.657 , 0.656 , 0.6543, 0.654 , 0.6514, 0.649 , 0.6475,\n",
       "            0.647 , 0.6455, 0.6445, 0.644 , 0.6436, 0.643 , 0.642 , 0.6416,\n",
       "            0.6396, 0.639 , 0.6387, 0.6343, 0.633 , 0.6323, 0.6313, 0.629 ,\n",
       "            0.6265, 0.626 , 0.6177, 0.6133, 0.6123, 0.6113, 0.6104, 0.61  ,\n",
       "            0.605 , 0.604 , 0.6035, 0.603 , 0.601 , 0.5996, 0.598 , 0.597 ,\n",
       "            0.596 , 0.5947, 0.5923, 0.5884, 0.5864, 0.586 , 0.585 , 0.5845,\n",
       "            0.582 , 0.58  , 0.579 , 0.5776, 0.576 , 0.5747, 0.5737, 0.573 ,\n",
       "            0.5728, 0.5723, 0.5713, 0.571 , 0.5693, 0.569 , 0.566 , 0.5654,\n",
       "            0.5645, 0.564 , 0.562 , 0.5615, 0.561 , 0.5605, 0.56  , 0.5576,\n",
       "            0.557 , 0.5566, 0.556 , 0.555 , 0.554 , 0.5537, 0.553 , 0.5522,\n",
       "            0.552 , 0.5513, 0.551 , 0.5503, 0.55  , 0.5493, 0.5483, 0.548 ,\n",
       "            0.547 , 0.5464, 0.546 , 0.544 , 0.543 , 0.5425, 0.542 , 0.5415,\n",
       "            0.541 , 0.54  , 0.5396, 0.538 , 0.5376, 0.537 , 0.536 , 0.5356,\n",
       "            0.5347, 0.5317, 0.53  , 0.529 , 0.5264, 0.5205, 0.518 , 0.515 ,\n",
       "            0.514 , 0.5117, 0.5093, 0.5024, 0.5015, 0.501 , 0.4927, 0.492 ,\n",
       "            0.4773], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.9916667, dtype=float32),\n",
       "    'tpr': array(0.9230769, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.075     , 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.2       ,\n",
       "            0.2       , 0.20833333, 0.225     , 0.23333333, 0.23333333,\n",
       "            0.24166666, 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.29166666, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55      ,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.65      , 0.6666667 , 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.7416667 , 0.75      , 0.7583333 , 0.775     ,\n",
       "            0.78333336, 0.8       , 0.8       , 0.8333333 , 0.84166664,\n",
       "            0.8666667 , 0.8833333 , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06923077, 0.06923077,\n",
       "            0.07692308, 0.09230769, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13076924, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.16923077, 0.17692308, 0.17692308, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.26923078,\n",
       "            0.26923078, 0.26923078, 0.2769231 , 0.2846154 , 0.2846154 ,\n",
       "            0.3       , 0.31538463, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.37692308, 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.43846154, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.46153846, 0.46923077, 0.47692308, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.5       , 0.5153846 , 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7       , 0.7076923 ,\n",
       "            0.7076923 , 0.7076923 , 0.7076923 , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.73846155, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.76153845, 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8153846 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7393, 0.7344, 0.7124, 0.71  , 0.709 , 0.7085, 0.705 ,\n",
       "            0.7046, 0.703 , 0.701 , 0.7   , 0.698 , 0.6963, 0.6953, 0.6934,\n",
       "            0.691 , 0.688 , 0.6875, 0.687 , 0.6865, 0.685 , 0.684 , 0.683 ,\n",
       "            0.682 , 0.6816, 0.681 , 0.6807, 0.68  , 0.6797, 0.679 , 0.678 ,\n",
       "            0.676 , 0.6753, 0.675 , 0.6733, 0.672 , 0.6714, 0.671 , 0.67  ,\n",
       "            0.6694, 0.669 , 0.668 , 0.666 , 0.665 , 0.6646, 0.663 , 0.6626,\n",
       "            0.662 , 0.661 , 0.6606, 0.6562, 0.6553, 0.6543, 0.653 , 0.6523,\n",
       "            0.652 , 0.6514, 0.65  , 0.6484, 0.646 , 0.644 , 0.6436, 0.6416,\n",
       "            0.6406, 0.6396, 0.639 , 0.638 , 0.6377, 0.6353, 0.6343, 0.633 ,\n",
       "            0.6313, 0.6304, 0.6294, 0.628 , 0.627 , 0.6265, 0.625 , 0.6245,\n",
       "            0.623 , 0.6216, 0.621 , 0.6206, 0.62  , 0.6196, 0.617 , 0.6167,\n",
       "            0.6157, 0.6147, 0.614 , 0.6094, 0.6055, 0.6045, 0.601 , 0.5986,\n",
       "            0.592 , 0.587 , 0.5864, 0.5854, 0.5845, 0.5825, 0.5806, 0.5796,\n",
       "            0.579 , 0.5786, 0.575 , 0.5747, 0.5737, 0.572 , 0.57  , 0.5693,\n",
       "            0.569 , 0.568 , 0.5654, 0.565 , 0.564 , 0.563 , 0.5625, 0.562 ,\n",
       "            0.5615, 0.561 , 0.5596, 0.558 , 0.557 , 0.5566, 0.556 , 0.555 ,\n",
       "            0.554 , 0.5537, 0.553 , 0.5522, 0.5513, 0.551 , 0.55  , 0.549 ,\n",
       "            0.547 , 0.5464, 0.546 , 0.5454, 0.545 , 0.5444, 0.544 , 0.5435,\n",
       "            0.543 , 0.5425, 0.542 , 0.5415, 0.541 , 0.5405, 0.539 , 0.5386,\n",
       "            0.538 , 0.5366, 0.5356, 0.534 , 0.5317, 0.5293, 0.529 , 0.5283,\n",
       "            0.528 , 0.527 , 0.526 , 0.524 , 0.5234, 0.5225, 0.5215, 0.517 ,\n",
       "            0.5166, 0.515 , 0.5146, 0.514 , 0.5117, 0.5083, 0.508 , 0.506 ,\n",
       "            0.505 , 0.499 , 0.4966, 0.488 , 0.487 , 0.4854, 0.477 , 0.4734,\n",
       "            0.47  , 0.465 , 0.46  , 0.4575], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.96666664, dtype=float32),\n",
       "    'tpr': array(0.8230769, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.15833333,\n",
       "            0.16666667, 0.175     , 0.175     , 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.2       , 0.225     , 0.23333333, 0.25      , 0.25      ,\n",
       "            0.25833333, 0.275     , 0.275     , 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35      , 0.36666667,\n",
       "            0.36666667, 0.375     , 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.425     ,\n",
       "            0.43333334, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.46666667, 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.525     , 0.525     , 0.53333336, 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.56666666, 0.575     , 0.59166664,\n",
       "            0.60833335, 0.625     , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.64166665, 0.64166665, 0.65833336, 0.6666667 ,\n",
       "            0.68333334, 0.68333334, 0.7       , 0.7083333 , 0.73333335,\n",
       "            0.7416667 , 0.7416667 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.8       , 0.80833334, 0.825     , 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.02307692, 0.03846154, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.07692308, 0.08461539, 0.1       , 0.10769231,\n",
       "            0.10769231, 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.15384616, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.16923077, 0.16923077, 0.17692308,\n",
       "            0.17692308, 0.17692308, 0.18461539, 0.18461539, 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2846154 ,\n",
       "            0.2846154 , 0.2846154 , 0.2923077 , 0.30769232, 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.4846154 , 0.4923077 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.6076923 ,\n",
       "            0.6076923 , 0.61538464, 0.61538464, 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7076923 , 0.7076923 ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.7153846 , 0.7153846 ,\n",
       "            0.72307694, 0.72307694, 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.74615383, 0.74615383, 0.76153845, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.77692306, 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.712 , 0.708 , 0.686 , 0.6836, 0.682 , 0.681 , 0.6772,\n",
       "            0.676 , 0.6743, 0.674 , 0.672 , 0.6714, 0.67  , 0.6675, 0.665 ,\n",
       "            0.6646, 0.664 , 0.662 , 0.661 , 0.66  , 0.659 , 0.6587, 0.658 ,\n",
       "            0.6577, 0.657 , 0.6567, 0.6562, 0.656 , 0.655 , 0.6543, 0.654 ,\n",
       "            0.6514, 0.651 , 0.6504, 0.65  , 0.6484, 0.648 , 0.6475, 0.647 ,\n",
       "            0.646 , 0.6455, 0.645 , 0.6445, 0.6426, 0.6416, 0.641 , 0.6406,\n",
       "            0.6396, 0.6367, 0.636 , 0.635 , 0.6343, 0.6323, 0.631 , 0.6294,\n",
       "            0.6284, 0.626 , 0.6255, 0.624 , 0.6177, 0.6157, 0.615 , 0.6143,\n",
       "            0.613 , 0.6123, 0.612 , 0.611 , 0.6104, 0.61  , 0.609 , 0.6084,\n",
       "            0.6074, 0.607 , 0.6064, 0.606 , 0.605 , 0.6045, 0.602 , 0.6006,\n",
       "            0.6   , 0.5996, 0.598 , 0.597 , 0.5967, 0.5947, 0.5923, 0.584 ,\n",
       "            0.5835, 0.5825, 0.5786, 0.575 , 0.5703, 0.567 , 0.5654, 0.564 ,\n",
       "            0.5615, 0.561 , 0.558 , 0.557 , 0.5557, 0.553 , 0.5522, 0.552 ,\n",
       "            0.551 , 0.5503, 0.55  , 0.549 , 0.548 , 0.546 , 0.5454, 0.545 ,\n",
       "            0.5444, 0.543 , 0.5425, 0.542 , 0.5415, 0.541 , 0.5405, 0.54  ,\n",
       "            0.5396, 0.5386, 0.5376, 0.5366, 0.536 , 0.5347, 0.534 , 0.5337,\n",
       "            0.5327, 0.532 , 0.5317, 0.531 , 0.53  , 0.529 , 0.5273, 0.5264,\n",
       "            0.526 , 0.5254, 0.525 , 0.5244, 0.5234, 0.522 , 0.5215, 0.521 ,\n",
       "            0.5205, 0.52  , 0.5195, 0.5156, 0.515 , 0.5146, 0.514 , 0.5137,\n",
       "            0.513 , 0.511 , 0.5107, 0.5103, 0.509 , 0.5083, 0.5073, 0.507 ,\n",
       "            0.5063, 0.503 , 0.5   , 0.498 , 0.4978, 0.4976, 0.4966, 0.496 ,\n",
       "            0.4944, 0.4922, 0.49  , 0.4868, 0.4866, 0.4849, 0.4822, 0.4812,\n",
       "            0.4795, 0.4775, 0.4731, 0.4644, 0.4617, 0.4585, 0.4521, 0.4443,\n",
       "            0.4385, 0.4373, 0.437 , 0.4275], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.925, dtype=float32),\n",
       "    'tpr': array(0.72307694, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05833333,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.23333333,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.35      , 0.35      , 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.48333332, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.5416667 , 0.55      , 0.56666666,\n",
       "            0.575     , 0.59166664, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7083333 , 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.75      , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.925     , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.1       , 0.1       , 0.10769231,\n",
       "            0.11538462, 0.11538462, 0.12307692, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.16153847, 0.16153847, 0.16153847, 0.16923077,\n",
       "            0.18461539, 0.18461539, 0.1923077 , 0.20769231, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.26923078, 0.26923078,\n",
       "            0.2846154 , 0.3       , 0.3       , 0.30769232, 0.30769232,\n",
       "            0.30769232, 0.31538463, 0.31538463, 0.31538463, 0.31538463,\n",
       "            0.33076924, 0.34615386, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.37692308, 0.3923077 , 0.4076923 , 0.41538462, 0.42307693,\n",
       "            0.42307693, 0.42307693, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.5307692 , 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.6076923 , 0.6076923 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.64615387, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.66923076, 0.6769231 , 0.6923077 , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7076923 , 0.7076923 ,\n",
       "            0.7076923 , 0.72307694, 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.75384617, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6846, 0.68  , 0.659 , 0.658 , 0.6562, 0.6543, 0.654 ,\n",
       "            0.653 , 0.6514, 0.6504, 0.65  , 0.649 , 0.6475, 0.647 , 0.6465,\n",
       "            0.646 , 0.6445, 0.642 , 0.6406, 0.64  , 0.6396, 0.6387, 0.637 ,\n",
       "            0.6367, 0.636 , 0.6357, 0.6353, 0.635 , 0.6333, 0.633 , 0.6323,\n",
       "            0.632 , 0.63  , 0.6294, 0.6284, 0.6274, 0.6265, 0.626 , 0.625 ,\n",
       "            0.6245, 0.6235, 0.622 , 0.621 , 0.6206, 0.62  , 0.619 , 0.617 ,\n",
       "            0.6157, 0.6147, 0.6133, 0.612 , 0.6113, 0.6104, 0.6094, 0.607 ,\n",
       "            0.6064, 0.606 , 0.6055, 0.605 , 0.604 , 0.5957, 0.594 , 0.5923,\n",
       "            0.592 , 0.5903, 0.5884, 0.588 , 0.587 , 0.5864, 0.5854, 0.5845,\n",
       "            0.5835, 0.583 , 0.582 , 0.5815, 0.581 , 0.5806, 0.58  , 0.578 ,\n",
       "            0.5767, 0.576 , 0.575 , 0.574 , 0.5737, 0.5728, 0.57  , 0.567 ,\n",
       "            0.5625, 0.5605, 0.5576, 0.553 , 0.549 , 0.548 , 0.5454, 0.544 ,\n",
       "            0.5435, 0.5415, 0.5405, 0.5386, 0.5376, 0.5366, 0.5356, 0.5337,\n",
       "            0.532 , 0.5317, 0.5312, 0.5303, 0.53  , 0.528 , 0.527 , 0.5264,\n",
       "            0.5254, 0.525 , 0.524 , 0.5234, 0.5225, 0.522 , 0.521 , 0.5205,\n",
       "            0.5195, 0.519 , 0.5186, 0.517 , 0.516 , 0.5156, 0.515 , 0.5146,\n",
       "            0.514 , 0.5137, 0.513 , 0.5107, 0.5103, 0.5093, 0.509 , 0.508 ,\n",
       "            0.5073, 0.503 , 0.5024, 0.502 , 0.5015, 0.501 , 0.5005, 0.5   ,\n",
       "            0.4995, 0.4983, 0.498 , 0.4973, 0.4966, 0.495 , 0.494 , 0.4934,\n",
       "            0.4907, 0.4902, 0.49  , 0.4873, 0.4856, 0.4834, 0.4827, 0.4814,\n",
       "            0.4812, 0.481 , 0.4773, 0.477 , 0.4692, 0.4678, 0.4673, 0.4653,\n",
       "            0.465 , 0.4648, 0.4646, 0.4602, 0.4587, 0.4583, 0.4568, 0.456 ,\n",
       "            0.451 , 0.442 , 0.4417, 0.4353, 0.432 , 0.4272, 0.4172, 0.4155,\n",
       "            0.4094, 0.4075, 0.3958], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.825, dtype=float32),\n",
       "    'tpr': array(0.6, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.04166667, 0.05      ,\n",
       "            0.05833333, 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.125     , 0.125     ,\n",
       "            0.15      , 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.175     , 0.175     , 0.175     , 0.18333334,\n",
       "            0.19166666, 0.20833333, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.25833333, 0.26666668,\n",
       "            0.275     , 0.275     , 0.28333333, 0.28333333, 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.30833334, 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.425     ,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.56666666, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.7       , 0.7083333 , 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.825     , 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.89166665, 0.89166665, 0.9166667 , 0.925     , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.95      , 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.05384615, 0.06153846, 0.06153846,\n",
       "            0.06153846, 0.06153846, 0.06153846, 0.06153846, 0.07692308,\n",
       "            0.08461539, 0.1       , 0.10769231, 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.14615385, 0.16923077, 0.16923077, 0.16923077, 0.18461539,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.21538462, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.24615385, 0.26153848, 0.26153848, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2769231 , 0.2846154 , 0.2923077 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.30769232, 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.33846155, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.3923077 , 0.3923077 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.50769234, 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.6       , 0.6       , 0.6       ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.61538464, 0.61538464, 0.61538464, 0.61538464, 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7076923 , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.656 , 0.6514, 0.6333, 0.631 , 0.63  , 0.628 , 0.6255,\n",
       "            0.6245, 0.6235, 0.6226, 0.6206, 0.6196, 0.619 , 0.6187, 0.618 ,\n",
       "            0.617 , 0.616 , 0.6157, 0.614 , 0.613 , 0.612 , 0.6104, 0.6094,\n",
       "            0.6084, 0.6074, 0.607 , 0.6064, 0.606 , 0.6055, 0.605 , 0.6035,\n",
       "            0.6025, 0.602 , 0.6016, 0.6006, 0.6   , 0.5996, 0.599 , 0.5986,\n",
       "            0.5977, 0.5967, 0.5957, 0.594 , 0.5938, 0.5933, 0.5923, 0.5913,\n",
       "            0.59  , 0.588 , 0.5874, 0.587 , 0.586 , 0.585 , 0.584 , 0.581 ,\n",
       "            0.5786, 0.575 , 0.5737, 0.573 , 0.5693, 0.5684, 0.568 , 0.5674,\n",
       "            0.565 , 0.5645, 0.563 , 0.5615, 0.561 , 0.5605, 0.56  , 0.5596,\n",
       "            0.5576, 0.556 , 0.554 , 0.5513, 0.55  , 0.5493, 0.547 , 0.5444,\n",
       "            0.541 , 0.5405, 0.5376, 0.5366, 0.5347, 0.534 , 0.5312, 0.531 ,\n",
       "            0.53  , 0.5273, 0.527 , 0.5254, 0.5244, 0.5234, 0.523 , 0.5225,\n",
       "            0.5215, 0.52  , 0.5195, 0.5186, 0.517 , 0.516 , 0.5156, 0.515 ,\n",
       "            0.5137, 0.513 , 0.5127, 0.512 , 0.5117, 0.511 , 0.51  , 0.5093,\n",
       "            0.509 , 0.508 , 0.5073, 0.507 , 0.506 , 0.505 , 0.504 , 0.503 ,\n",
       "            0.502 , 0.501 , 0.4993, 0.4983, 0.4978, 0.497 , 0.4968, 0.496 ,\n",
       "            0.4956, 0.4954, 0.494 , 0.4937, 0.492 , 0.4912, 0.4907, 0.4902,\n",
       "            0.4888, 0.4885, 0.4878, 0.4868, 0.4866, 0.4844, 0.484 , 0.483 ,\n",
       "            0.482 , 0.4812, 0.481 , 0.4807, 0.4788, 0.4744, 0.474 , 0.4739,\n",
       "            0.4734, 0.472 , 0.471 , 0.4705, 0.466 , 0.4653, 0.465 , 0.4648,\n",
       "            0.4644, 0.4634, 0.46  , 0.4517, 0.4502, 0.4492, 0.447 , 0.4436,\n",
       "            0.4424, 0.441 , 0.4407, 0.4397, 0.4395, 0.4382, 0.436 , 0.4343,\n",
       "            0.433 , 0.4321, 0.4272, 0.4268, 0.4204, 0.419 , 0.4104, 0.4092,\n",
       "            0.4053, 0.4026, 0.3975, 0.387 , 0.382 , 0.3767, 0.3643],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7, dtype=float32),\n",
       "    'tpr': array(0.52307695, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.05      , 0.05833333, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.23333333, 0.23333333,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.26666668,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.425     , 0.425     ,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.525     ,\n",
       "            0.525     , 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.59166664, 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.65833336, 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.8       , 0.80833334, 0.81666666,\n",
       "            0.81666666, 0.825     , 0.825     , 0.825     , 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.8833333 , 0.89166665, 0.89166665, 0.90833336,\n",
       "            0.925     , 0.925     , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.04615385, 0.04615385, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.07692308, 0.08461539,\n",
       "            0.08461539, 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13846155, 0.13846155, 0.16153847, 0.16153847,\n",
       "            0.16153847, 0.17692308, 0.18461539, 0.20769231, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.22307692, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.25384617, 0.26153848,\n",
       "            0.2769231 , 0.2769231 , 0.2769231 , 0.2769231 , 0.2846154 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.2923077 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.3       , 0.31538463, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43076923,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46153846, 0.46153846, 0.46923077, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.47692308, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.5307692 , 0.5307692 , 0.5307692 , 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.61538464, 0.61538464,\n",
       "            0.63076925, 0.63846153, 0.63846153, 0.63846153, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6265, 0.621 , 0.6074, 0.6055, 0.6025, 0.6006, 0.5996,\n",
       "            0.598 , 0.597 , 0.5967, 0.596 , 0.5947, 0.594 , 0.5933, 0.593 ,\n",
       "            0.5923, 0.591 , 0.59  , 0.5894, 0.589 , 0.588 , 0.586 , 0.5854,\n",
       "            0.584 , 0.5835, 0.582 , 0.5815, 0.5806, 0.58  , 0.5796, 0.579 ,\n",
       "            0.578 , 0.577 , 0.5767, 0.576 , 0.5757, 0.575 , 0.574 , 0.5737,\n",
       "            0.573 , 0.5723, 0.5713, 0.571 , 0.5684, 0.5674, 0.567 , 0.5664,\n",
       "            0.565 , 0.5645, 0.564 , 0.5605, 0.56  , 0.5576, 0.5566, 0.5547,\n",
       "            0.553 , 0.5513, 0.5503, 0.5483, 0.546 , 0.544 , 0.5425, 0.5415,\n",
       "            0.541 , 0.5405, 0.539 , 0.5386, 0.538 , 0.5366, 0.5347, 0.534 ,\n",
       "            0.5337, 0.533 , 0.5312, 0.5303, 0.53  , 0.5283, 0.5273, 0.524 ,\n",
       "            0.5225, 0.5215, 0.521 , 0.52  , 0.5195, 0.519 , 0.5186, 0.5166,\n",
       "            0.5156, 0.5146, 0.514 , 0.512 , 0.511 , 0.5103, 0.5093, 0.509 ,\n",
       "            0.5073, 0.507 , 0.5063, 0.5054, 0.505 , 0.5044, 0.5034, 0.5024,\n",
       "            0.502 , 0.5015, 0.501 , 0.5   , 0.4985, 0.4983, 0.498 , 0.4976,\n",
       "            0.497 , 0.4963, 0.4958, 0.4956, 0.493 , 0.4922, 0.4912, 0.4902,\n",
       "            0.4883, 0.488 , 0.4878, 0.4875, 0.487 , 0.4866, 0.4844, 0.4841,\n",
       "            0.484 , 0.4834, 0.4832, 0.4805, 0.4785, 0.4783, 0.4753, 0.475 ,\n",
       "            0.4734, 0.4712, 0.4705, 0.4695, 0.4678, 0.4675, 0.4673, 0.4666,\n",
       "            0.4631, 0.4607, 0.4602, 0.46  , 0.4587, 0.4585, 0.4583, 0.4546,\n",
       "            0.451 , 0.4485, 0.4478, 0.447 , 0.4456, 0.4448, 0.4412, 0.4392,\n",
       "            0.4387, 0.4373, 0.4348, 0.432 , 0.4302, 0.4258, 0.422 , 0.4211,\n",
       "            0.421 , 0.42  , 0.4177, 0.4172, 0.4143, 0.4126, 0.4106, 0.4087,\n",
       "            0.4077, 0.407 , 0.4016, 0.3987, 0.397 , 0.3965, 0.3901, 0.3835,\n",
       "            0.3794, 0.3792, 0.3782, 0.3774, 0.359 , 0.3552, 0.3467, 0.334 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5, dtype=float32),\n",
       "    'tpr': array(0.43076923, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.06666667, 0.075     , 0.09166667, 0.1       ,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.35      , 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.425     ,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.575     , 0.59166664, 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65      , 0.6666667 , 0.675     , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.80833334, 0.81666666, 0.81666666, 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.8666667 , 0.875     , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.06923077, 0.07692308, 0.08461539,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.12307692, 0.12307692,\n",
       "            0.13076924, 0.13076924, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.17692308,\n",
       "            0.1923077 , 0.2       , 0.21538462, 0.22307692, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.2846154 , 0.2846154 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.2923077 , 0.3       ,\n",
       "            0.3       , 0.31538463, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3846154 , 0.3923077 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.44615385, 0.45384616, 0.45384616,\n",
       "            0.45384616, 0.45384616, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.46153846, 0.46153846, 0.46153846, 0.46153846, 0.46153846,\n",
       "            0.46923077, 0.46923077, 0.47692308, 0.4846154 , 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.4923077 , 0.4923077 , 0.4923077 ,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "            0.50769234, 0.50769234, 0.5153846 , 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.56153846, 0.56153846, 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.59  , 0.584 , 0.575 , 0.5737, 0.572 , 0.5684, 0.568 ,\n",
       "            0.567 , 0.566 , 0.5654, 0.5645, 0.5635, 0.563 , 0.5625, 0.562 ,\n",
       "            0.5615, 0.561 , 0.5605, 0.5596, 0.559 , 0.5586, 0.558 , 0.5576,\n",
       "            0.557 , 0.556 , 0.5557, 0.555 , 0.5547, 0.5537, 0.5527, 0.5522,\n",
       "            0.552 , 0.5513, 0.5503, 0.55  , 0.5493, 0.549 , 0.5483, 0.5474,\n",
       "            0.547 , 0.5454, 0.5444, 0.544 , 0.543 , 0.542 , 0.5405, 0.54  ,\n",
       "            0.5396, 0.539 , 0.5376, 0.537 , 0.5366, 0.536 , 0.5347, 0.5312,\n",
       "            0.53  , 0.5283, 0.527 , 0.525 , 0.5244, 0.524 , 0.5234, 0.5225,\n",
       "            0.52  , 0.519 , 0.518 , 0.516 , 0.5156, 0.5127, 0.512 , 0.5093,\n",
       "            0.509 , 0.508 , 0.5073, 0.507 , 0.506 , 0.5054, 0.505 , 0.5044,\n",
       "            0.504 , 0.5034, 0.502 , 0.5015, 0.5005, 0.5   , 0.4993, 0.499 ,\n",
       "            0.4988, 0.4978, 0.497 , 0.4968, 0.4956, 0.4949, 0.4932, 0.493 ,\n",
       "            0.4927, 0.4924, 0.4917, 0.4915, 0.4905, 0.4897, 0.489 , 0.4888,\n",
       "            0.4885, 0.4878, 0.4866, 0.4856, 0.4854, 0.485 , 0.4846, 0.484 ,\n",
       "            0.4834, 0.483 , 0.4827, 0.4824, 0.481 , 0.4795, 0.4783, 0.478 ,\n",
       "            0.4775, 0.4766, 0.4731, 0.473 , 0.47  , 0.4692, 0.4688, 0.468 ,\n",
       "            0.4644, 0.4639, 0.4636, 0.4626, 0.4624, 0.461 , 0.46  , 0.4597,\n",
       "            0.4592, 0.4543, 0.4531, 0.4524, 0.4517, 0.4507, 0.4502, 0.446 ,\n",
       "            0.443 , 0.4429, 0.4407, 0.4397, 0.4395, 0.439 , 0.4375, 0.4368,\n",
       "            0.4353, 0.428 , 0.427 , 0.4258, 0.4248, 0.4202, 0.4194, 0.4177,\n",
       "            0.417 , 0.4163, 0.4155, 0.415 , 0.4048, 0.4026, 0.4004, 0.3997,\n",
       "            0.3987, 0.3984, 0.3975, 0.3962, 0.3958, 0.3945, 0.3892, 0.3855,\n",
       "            0.385 , 0.3833, 0.381 , 0.3806, 0.38  , 0.375 , 0.3743, 0.3706,\n",
       "            0.3665, 0.3635, 0.3562, 0.3547, 0.3542, 0.3506, 0.3496, 0.3447,\n",
       "            0.3276, 0.3252, 0.3137, 0.3005], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.375, dtype=float32),\n",
       "    'tpr': array(0.3, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.1       , 0.11666667, 0.14166667, 0.15      ,\n",
       "            0.175     , 0.175     , 0.18333334, 0.18333334, 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.23333333, 0.24166666, 0.24166666, 0.25      ,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.325     , 0.325     , 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.375     , 0.375     , 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.65833336,\n",
       "            0.65833336, 0.6666667 , 0.6666667 , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.73333335, 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.7583333 , 0.775     ,\n",
       "            0.7916667 , 0.80833334, 0.80833334, 0.80833334, 0.81666666,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85      , 0.85833335, 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.925     , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.96666664, 0.96666664, 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.06923077,\n",
       "            0.06923077, 0.08461539, 0.08461539, 0.08461539, 0.1       ,\n",
       "            0.11538462, 0.13076924, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.20769231, 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23076923, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.25384617, 0.26153848, 0.26153848, 0.26923078,\n",
       "            0.26923078, 0.26923078, 0.2769231 , 0.2769231 , 0.2846154 ,\n",
       "            0.2846154 , 0.2846154 , 0.2923077 , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36153847, 0.36153847,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.36923078, 0.36923078, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.3846154 , 0.3923077 , 0.3923077 ,\n",
       "            0.3923077 , 0.3923077 , 0.3923077 , 0.3923077 , 0.3923077 ,\n",
       "            0.3923077 , 0.3923077 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.41538462, 0.43076923, 0.43846154, 0.43846154,\n",
       "            0.43846154, 0.43846154, 0.43846154, 0.43846154, 0.44615385,\n",
       "            0.44615385, 0.45384616, 0.45384616, 0.46153846, 0.46153846,\n",
       "            0.46153846, 0.46153846, 0.46923077, 0.47692308, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.4923077 , 0.4923077 , 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5527, 0.546 , 0.543 , 0.542 , 0.5405, 0.5386, 0.537 ,\n",
       "            0.5366, 0.5356, 0.535 , 0.5347, 0.534 , 0.533 , 0.532 , 0.5317,\n",
       "            0.5312, 0.531 , 0.5303, 0.53  , 0.5293, 0.528 , 0.5273, 0.527 ,\n",
       "            0.5264, 0.5254, 0.5244, 0.524 , 0.523 , 0.5225, 0.522 , 0.521 ,\n",
       "            0.5205, 0.5195, 0.519 , 0.5186, 0.5176, 0.5166, 0.5156, 0.515 ,\n",
       "            0.5146, 0.514 , 0.5137, 0.5127, 0.512 , 0.5117, 0.5107, 0.5103,\n",
       "            0.509 , 0.5063, 0.5034, 0.5024, 0.502 , 0.5015, 0.5   , 0.4998,\n",
       "            0.498 , 0.4968, 0.496 , 0.4956, 0.4949, 0.4946, 0.4941, 0.494 ,\n",
       "            0.4932, 0.4922, 0.4917, 0.4915, 0.4902, 0.49  , 0.4888, 0.4883,\n",
       "            0.4868, 0.4866, 0.4856, 0.4841, 0.484 , 0.4834, 0.4827, 0.4824,\n",
       "            0.4822, 0.4812, 0.4805, 0.4797, 0.4792, 0.479 , 0.4788, 0.4783,\n",
       "            0.4778, 0.4775, 0.4773, 0.4766, 0.4763, 0.4753, 0.4749, 0.474 ,\n",
       "            0.4731, 0.473 , 0.4724, 0.4707, 0.4697, 0.4695, 0.4692, 0.4688,\n",
       "            0.4683, 0.4673, 0.4666, 0.4656, 0.4653, 0.464 , 0.4639, 0.4626,\n",
       "            0.4624, 0.461 , 0.4604, 0.4602, 0.4595, 0.4592, 0.4578, 0.4543,\n",
       "            0.454 , 0.4531, 0.453 , 0.4526, 0.4521, 0.4492, 0.4487, 0.4482,\n",
       "            0.4446, 0.444 , 0.4434, 0.4421, 0.4414, 0.4392, 0.4382, 0.4373,\n",
       "            0.437 , 0.4353, 0.434 , 0.4326, 0.4277, 0.4229, 0.421 , 0.419 ,\n",
       "            0.4175, 0.415 , 0.4136, 0.4133, 0.4124, 0.4116, 0.409 , 0.4084,\n",
       "            0.4082, 0.408 , 0.4067, 0.3987, 0.396 , 0.3945, 0.394 , 0.3914,\n",
       "            0.391 , 0.3906, 0.3867, 0.386 , 0.3833, 0.382 , 0.3772, 0.3765,\n",
       "            0.3735, 0.3733, 0.368 , 0.3677, 0.3672, 0.3625, 0.3618, 0.3616,\n",
       "            0.3586, 0.3577, 0.357 , 0.3528, 0.3513, 0.3508, 0.3499, 0.346 ,\n",
       "            0.3457, 0.3428, 0.3425, 0.3354, 0.3328, 0.3325, 0.3313, 0.3262,\n",
       "            0.324 , 0.3235, 0.3213, 0.3115, 0.2976, 0.2966, 0.2822, 0.269 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.13333334, dtype=float32),\n",
       "    'tpr': array(0.13076924, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.06666667, 0.06666667,\n",
       "            0.08333334, 0.1       , 0.11666667, 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.13333334, 0.13333334, 0.15      , 0.15      ,\n",
       "            0.15      , 0.15      , 0.15      , 0.15833333, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.2       , 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.23333333, 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25833333, 0.26666668, 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.4       , 0.41666666,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.46666667, 0.475     , 0.48333332,\n",
       "            0.5       , 0.51666665, 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.625     ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.71666664, 0.71666664, 0.73333335, 0.75      , 0.7583333 ,\n",
       "            0.775     , 0.775     , 0.775     , 0.775     , 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.8       , 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85833335, 0.85833335, 0.8666667 , 0.875     , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.07692308, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.13076924, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16153847, 0.16153847,\n",
       "            0.16153847, 0.16153847, 0.16153847, 0.16923077, 0.18461539,\n",
       "            0.18461539, 0.2       , 0.20769231, 0.21538462, 0.21538462,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.24615385, 0.24615385, 0.25384617,\n",
       "            0.25384617, 0.25384617, 0.26153848, 0.26923078, 0.26923078,\n",
       "            0.26923078, 0.26923078, 0.2846154 , 0.2923077 , 0.2923077 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.31538463, 0.31538463,\n",
       "            0.31538463, 0.32307693, 0.32307693, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.34615386, 0.34615386, 0.34615386,\n",
       "            0.34615386, 0.34615386, 0.34615386, 0.34615386, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.35384616, 0.35384616, 0.35384616,\n",
       "            0.35384616, 0.35384616, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.36923078, 0.36923078,\n",
       "            0.36923078, 0.36923078, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.3923077 , 0.3923077 , 0.3923077 ,\n",
       "            0.3923077 , 0.4       , 0.41538462, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.44615385, 0.44615385,\n",
       "            0.44615385, 0.45384616, 0.45384616, 0.45384616, 0.45384616,\n",
       "            0.45384616, 0.46153846, 0.46153846, 0.46153846, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.4923077 , 0.50769234, 0.50769234,\n",
       "            0.50769234, 0.50769234, 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.5153846 , 0.52307695, 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5923077 , 0.6       ,\n",
       "            0.61538464, 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8076923 , 0.8230769 , 0.83076924,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.515 , 0.51  , 0.5093, 0.5083, 0.508 , 0.507 , 0.5063,\n",
       "            0.506 , 0.5054, 0.5044, 0.5034, 0.503 , 0.5024, 0.502 , 0.5015,\n",
       "            0.501 , 0.5005, 0.5   , 0.4998, 0.4995, 0.4993, 0.499 , 0.4988,\n",
       "            0.4978, 0.497 , 0.4958, 0.4954, 0.4949, 0.4946, 0.4941, 0.494 ,\n",
       "            0.4937, 0.4934, 0.492 , 0.4902, 0.4897, 0.4893, 0.489 , 0.488 ,\n",
       "            0.4858, 0.4854, 0.4841, 0.484 , 0.4836, 0.4814, 0.4805, 0.4802,\n",
       "            0.4797, 0.4792, 0.479 , 0.4788, 0.4785, 0.478 , 0.4778, 0.4768,\n",
       "            0.4766, 0.4758, 0.4756, 0.4749, 0.4739, 0.4734, 0.4722, 0.472 ,\n",
       "            0.4717, 0.4712, 0.471 , 0.4705, 0.4695, 0.4692, 0.4688, 0.4683,\n",
       "            0.4675, 0.467 , 0.466 , 0.4658, 0.4656, 0.4653, 0.4648, 0.4644,\n",
       "            0.4639, 0.4631, 0.462 , 0.4617, 0.4604, 0.4597, 0.4595, 0.4587,\n",
       "            0.4575, 0.457 , 0.4563, 0.455 , 0.4534, 0.4531, 0.4524, 0.452 ,\n",
       "            0.4517, 0.45  , 0.4492, 0.4487, 0.4478, 0.4463, 0.446 , 0.4456,\n",
       "            0.4453, 0.445 , 0.4448, 0.4443, 0.4429, 0.4424, 0.4417, 0.4402,\n",
       "            0.4397, 0.4395, 0.4392, 0.4375, 0.4365, 0.4363, 0.4338, 0.4324,\n",
       "            0.432 , 0.4312, 0.4307, 0.4302, 0.429 , 0.4287, 0.4275, 0.4268,\n",
       "            0.4253, 0.4236, 0.422 , 0.421 , 0.4187, 0.4177, 0.4167, 0.4148,\n",
       "            0.414 , 0.4128, 0.4124, 0.4055, 0.402 , 0.4   , 0.3938, 0.3933,\n",
       "            0.3894, 0.3892, 0.3884, 0.3862, 0.3833, 0.3816, 0.3762, 0.3757,\n",
       "            0.374 , 0.3699, 0.368 , 0.3677, 0.3628, 0.3625, 0.362 , 0.3596,\n",
       "            0.3584, 0.356 , 0.3538, 0.3533, 0.3486, 0.3447, 0.3406, 0.3396,\n",
       "            0.336 , 0.3354, 0.3315, 0.33  , 0.3262, 0.3254, 0.325 , 0.3184,\n",
       "            0.3176, 0.3174, 0.316 , 0.3113, 0.3064, 0.3047, 0.3037, 0.2996,\n",
       "            0.2988, 0.2866, 0.2756, 0.2595, 0.2466], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.08333334, 0.08333334,\n",
       "            0.1       , 0.1       , 0.1       , 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.175     , 0.175     , 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.20833333, 0.225     , 0.225     , 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.29166666, 0.31666666, 0.325     , 0.34166667, 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.60833335, 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.6666667 , 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.7583333 , 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.825     ,\n",
       "            0.8333333 , 0.8333333 , 0.84166664, 0.84166664, 0.85      ,\n",
       "            0.85      , 0.85      , 0.85      , 0.85      , 0.8666667 ,\n",
       "            0.875     , 0.875     , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.89166665, 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.00769231, 0.02307692,\n",
       "            0.02307692, 0.03846154, 0.04615385, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.07692308, 0.08461539,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.1       , 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.15384616, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.18461539, 0.18461539, 0.18461539, 0.2       , 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.21538462, 0.21538462, 0.22307692,\n",
       "            0.22307692, 0.22307692, 0.22307692, 0.22307692, 0.22307692,\n",
       "            0.22307692, 0.23076923, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.23846154, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.26153848, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.2846154 , 0.2846154 ,\n",
       "            0.2846154 , 0.2846154 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.31538463, 0.32307693, 0.32307693, 0.32307693, 0.32307693,\n",
       "            0.32307693, 0.33076924, 0.33076924, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.34615386, 0.34615386, 0.35384616,\n",
       "            0.35384616, 0.35384616, 0.35384616, 0.36153847, 0.36153847,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36153847, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.3846154 , 0.3846154 ,\n",
       "            0.3846154 , 0.3846154 , 0.3923077 , 0.3923077 , 0.3923077 ,\n",
       "            0.3923077 , 0.4       , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.45384616, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.46923077, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.47692308, 0.47692308, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.64615387, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.478 , 0.4778, 0.4773, 0.477 , 0.4768, 0.4766, 0.4763,\n",
       "            0.476 , 0.4758, 0.4756, 0.4753, 0.4749, 0.4746, 0.474 , 0.4736,\n",
       "            0.4731, 0.473 , 0.4727, 0.4722, 0.472 , 0.4714, 0.471 , 0.4705,\n",
       "            0.4702, 0.47  , 0.4695, 0.4692, 0.4688, 0.4685, 0.4683, 0.4673,\n",
       "            0.4666, 0.466 , 0.4653, 0.4648, 0.4646, 0.464 , 0.4636, 0.463 ,\n",
       "            0.462 , 0.4614, 0.4612, 0.4592, 0.4583, 0.458 , 0.4578, 0.4573,\n",
       "            0.457 , 0.4568, 0.4565, 0.456 , 0.4558, 0.4556, 0.4553, 0.455 ,\n",
       "            0.4548, 0.4546, 0.4539, 0.4536, 0.4534, 0.4531, 0.453 , 0.4524,\n",
       "            0.452 , 0.4512, 0.4504, 0.4492, 0.4487, 0.4485, 0.448 , 0.4473,\n",
       "            0.447 , 0.4465, 0.4463, 0.446 , 0.4458, 0.4448, 0.444 , 0.4438,\n",
       "            0.4426, 0.4417, 0.4414, 0.439 , 0.4377, 0.4365, 0.4363, 0.4358,\n",
       "            0.4355, 0.4353, 0.435 , 0.433 , 0.4321, 0.4316, 0.4314, 0.4297,\n",
       "            0.4282, 0.4268, 0.4258, 0.4253, 0.4248, 0.4246, 0.424 , 0.4238,\n",
       "            0.422 , 0.4219, 0.4214, 0.4207, 0.4194, 0.419 , 0.4185, 0.4177,\n",
       "            0.4167, 0.4165, 0.4163, 0.4155, 0.4143, 0.414 , 0.4138, 0.413 ,\n",
       "            0.4124, 0.412 , 0.4116, 0.41  , 0.4094, 0.4092, 0.409 , 0.4065,\n",
       "            0.4062, 0.4045, 0.4026, 0.4011, 0.4004, 0.4   , 0.3997, 0.3977,\n",
       "            0.396 , 0.3953, 0.3901, 0.3875, 0.3853, 0.3838, 0.3806, 0.3782,\n",
       "            0.3728, 0.3699, 0.3667, 0.3662, 0.366 , 0.3643, 0.3633, 0.3618,\n",
       "            0.3606, 0.3582, 0.355 , 0.3494, 0.3486, 0.344 , 0.3416, 0.341 ,\n",
       "            0.3408, 0.3396, 0.3384, 0.3376, 0.3342, 0.3335, 0.3284, 0.3237,\n",
       "            0.3235, 0.321 , 0.3171, 0.3145, 0.3137, 0.313 , 0.311 , 0.3096,\n",
       "            0.3093, 0.306 , 0.3018, 0.3013, 0.3005, 0.2996, 0.2986, 0.298 ,\n",
       "            0.2927, 0.292 , 0.2908, 0.2869, 0.283 , 0.2825, 0.2812, 0.28  ,\n",
       "            0.2773, 0.2737, 0.2615, 0.254 , 0.2532, 0.2363, 0.2235],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.10833333, 0.11666667,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.2       , 0.2       , 0.20833333,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.275     , 0.28333333, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.35      , 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.4       , 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.44166666,\n",
       "            0.45      , 0.45      , 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.49166667, 0.5083333 ,\n",
       "            0.525     , 0.525     , 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.65833336,\n",
       "            0.6666667 , 0.68333334, 0.68333334, 0.68333334, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.76666665, 0.775     , 0.78333336, 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85      , 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.90833336, 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.10769231, 0.11538462, 0.12307692, 0.12307692,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.13846155, 0.13846155,\n",
       "            0.14615385, 0.14615385, 0.14615385, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.16153847, 0.18461539, 0.1923077 , 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.20769231, 0.21538462, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.22307692, 0.22307692, 0.23076923,\n",
       "            0.23076923, 0.23846154, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.25384617, 0.25384617, 0.25384617, 0.25384617,\n",
       "            0.26153848, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.2923077 , 0.2923077 , 0.3       , 0.3       ,\n",
       "            0.3       , 0.3       , 0.30769232, 0.30769232, 0.30769232,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.33846155, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.34615386, 0.34615386, 0.35384616, 0.35384616, 0.35384616,\n",
       "            0.35384616, 0.36153847, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.36923078, 0.36923078, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.3846154 , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4076923 , 0.42307693, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.43846154, 0.44615385, 0.45384616, 0.45384616,\n",
       "            0.46153846, 0.46153846, 0.46923077, 0.46923077, 0.47692308,\n",
       "            0.47692308, 0.4846154 , 0.4846154 , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.53846157, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5769231 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.7       , 0.7076923 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.455 , 0.454 , 0.4524, 0.4521, 0.4517, 0.4514, 0.451 ,\n",
       "            0.4507, 0.4504, 0.4502, 0.45  , 0.4497, 0.4495, 0.4492, 0.449 ,\n",
       "            0.4487, 0.4485, 0.4482, 0.4475, 0.447 , 0.4465, 0.446 , 0.4456,\n",
       "            0.4446, 0.4443, 0.444 , 0.4438, 0.4436, 0.4434, 0.4429, 0.4424,\n",
       "            0.4421, 0.4414, 0.4412, 0.4407, 0.4404, 0.4402, 0.44  , 0.4392,\n",
       "            0.439 , 0.4387, 0.4385, 0.4382, 0.4377, 0.4375, 0.437 , 0.4363,\n",
       "            0.436 , 0.4355, 0.4348, 0.4346, 0.4343, 0.4336, 0.433 , 0.4329,\n",
       "            0.4326, 0.4324, 0.4321, 0.4314, 0.4307, 0.4297, 0.4285, 0.4282,\n",
       "            0.428 , 0.4263, 0.426 , 0.4255, 0.425 , 0.424 , 0.4238, 0.4229,\n",
       "            0.4226, 0.4219, 0.4214, 0.4204, 0.4194, 0.4192, 0.4185, 0.4177,\n",
       "            0.4175, 0.4167, 0.4163, 0.416 , 0.4155, 0.4153, 0.4148, 0.4133,\n",
       "            0.4126, 0.4124, 0.412 , 0.4116, 0.4104, 0.41  , 0.4092, 0.408 ,\n",
       "            0.407 , 0.4067, 0.4062, 0.4058, 0.405 , 0.4043, 0.4033, 0.4023,\n",
       "            0.401 , 0.3994, 0.3987, 0.3984, 0.398 , 0.3972, 0.3965, 0.3962,\n",
       "            0.3958, 0.3955, 0.3943, 0.3936, 0.3933, 0.3916, 0.3914, 0.3909,\n",
       "            0.3906, 0.3904, 0.3901, 0.3894, 0.3887, 0.3884, 0.3867, 0.3865,\n",
       "            0.3848, 0.3845, 0.3806, 0.3762, 0.3757, 0.3735, 0.3726, 0.3713,\n",
       "            0.3704, 0.3684, 0.3655, 0.3635, 0.3633, 0.3616, 0.355 , 0.3542,\n",
       "            0.351 , 0.3464, 0.3462, 0.3457, 0.3435, 0.343 , 0.3413, 0.3386,\n",
       "            0.3372, 0.3367, 0.3362, 0.336 , 0.3325, 0.3303, 0.3286, 0.3262,\n",
       "            0.324 , 0.3186, 0.3176, 0.3171, 0.3167, 0.3123, 0.31  , 0.3052,\n",
       "            0.3025, 0.3018, 0.299 , 0.2986, 0.2966, 0.2942, 0.2917, 0.2915,\n",
       "            0.2896, 0.2876, 0.2874, 0.2837, 0.2805, 0.2786, 0.2773, 0.277 ,\n",
       "            0.2766, 0.2722, 0.2712, 0.268 , 0.2673, 0.266 , 0.265 , 0.261 ,\n",
       "            0.2595, 0.2588, 0.2534, 0.2417, 0.2368, 0.2355, 0.2184, 0.2059],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.19166666, 0.2       , 0.2       , 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.23333333,\n",
       "            0.24166666, 0.26666668, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.3       , 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.575     , 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.6       , 0.60833335, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.725     , 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 ,\n",
       "            0.7583333 , 0.775     , 0.78333336, 0.80833334, 0.81666666,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.89166665, 0.9       , 0.90833336, 0.90833336,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.925     , 0.925     ,\n",
       "            0.925     , 0.93333334, 0.93333334, 0.94166666, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.95      , 0.95      , 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.03076923, 0.03846154,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.05384615, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.07692308, 0.07692308, 0.07692308, 0.07692308, 0.08461539,\n",
       "            0.08461539, 0.09230769, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.11538462, 0.11538462, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.14615385, 0.14615385, 0.14615385, 0.15384616,\n",
       "            0.16153847, 0.16153847, 0.16923077, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.20769231, 0.21538462, 0.21538462,\n",
       "            0.21538462, 0.23076923, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.25384617, 0.25384617, 0.26153848,\n",
       "            0.26153848, 0.26153848, 0.26923078, 0.26923078, 0.26923078,\n",
       "            0.26923078, 0.26923078, 0.26923078, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.2923077 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.30769232, 0.30769232, 0.32307693,\n",
       "            0.32307693, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.36153847, 0.36153847, 0.36153847, 0.36153847, 0.36153847,\n",
       "            0.36923078, 0.36923078, 0.36923078, 0.36923078, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.43846154, 0.45384616,\n",
       "            0.46153846, 0.46923077, 0.46923077, 0.47692308, 0.4846154 ,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5692308 , 0.5692308 ,\n",
       "            0.5769231 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4421, 0.442 , 0.4392, 0.4387, 0.4368, 0.436 , 0.435 ,\n",
       "            0.4348, 0.4338, 0.4336, 0.432 , 0.4316, 0.431 , 0.4307, 0.4304,\n",
       "            0.4302, 0.4297, 0.429 , 0.4287, 0.4285, 0.4277, 0.4272, 0.427 ,\n",
       "            0.4265, 0.4263, 0.426 , 0.4258, 0.425 , 0.424 , 0.4236, 0.4233,\n",
       "            0.4229, 0.4226, 0.4224, 0.422 , 0.4219, 0.4216, 0.4214, 0.421 ,\n",
       "            0.4207, 0.4202, 0.4197, 0.4194, 0.4187, 0.4185, 0.4182, 0.4175,\n",
       "            0.417 , 0.4163, 0.416 , 0.4158, 0.4153, 0.4148, 0.4146, 0.4143,\n",
       "            0.414 , 0.4136, 0.413 , 0.4128, 0.4119, 0.4116, 0.4114, 0.4111,\n",
       "            0.4104, 0.41  , 0.4097, 0.4092, 0.4084, 0.408 , 0.4072, 0.4065,\n",
       "            0.406 , 0.405 , 0.4048, 0.4043, 0.4038, 0.403 , 0.4014, 0.401 ,\n",
       "            0.4006, 0.4001, 0.3997, 0.3994, 0.3992, 0.398 , 0.3977, 0.3965,\n",
       "            0.396 , 0.3958, 0.3955, 0.395 , 0.3948, 0.3943, 0.3916, 0.3909,\n",
       "            0.3896, 0.3894, 0.3887, 0.388 , 0.3877, 0.3872, 0.3867, 0.3862,\n",
       "            0.3853, 0.384 , 0.3838, 0.3835, 0.3833, 0.382 , 0.3813, 0.3809,\n",
       "            0.3804, 0.378 , 0.3772, 0.3765, 0.3755, 0.3748, 0.3743, 0.3733,\n",
       "            0.3728, 0.3713, 0.3708, 0.37  , 0.3696, 0.3691, 0.369 , 0.3687,\n",
       "            0.3682, 0.368 , 0.3677, 0.3674, 0.3652, 0.365 , 0.3647, 0.3613,\n",
       "            0.3606, 0.3586, 0.3564, 0.3562, 0.3528, 0.3523, 0.35  , 0.3486,\n",
       "            0.3477, 0.347 , 0.346 , 0.3457, 0.3452, 0.3435, 0.3386, 0.3381,\n",
       "            0.3376, 0.3367, 0.3325, 0.33  , 0.3271, 0.3254, 0.325 , 0.323 ,\n",
       "            0.319 , 0.3188, 0.3154, 0.3145, 0.3115, 0.311 , 0.31  , 0.3096,\n",
       "            0.3093, 0.3079, 0.3071, 0.3032, 0.299 , 0.2966, 0.2961, 0.2954,\n",
       "            0.2944, 0.2856, 0.2825, 0.2815, 0.2808, 0.2793, 0.278 , 0.275 ,\n",
       "            0.2742, 0.273 , 0.2722, 0.2693, 0.2688, 0.2651, 0.2637, 0.2595,\n",
       "            0.2568, 0.2551, 0.2532, 0.2512, 0.251 , 0.2498, 0.2485, 0.2467,\n",
       "            0.2466, 0.2456, 0.2413, 0.2402, 0.2372, 0.2328, 0.2211, 0.2191,\n",
       "            0.217 , 0.1998, 0.1879], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25833333, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.53333336, 0.5416667 ,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.65833336, 0.65833336,\n",
       "            0.675     , 0.675     , 0.68333334, 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.80833334, 0.81666666, 0.81666666,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.85      , 0.85833335, 0.8666667 , 0.8833333 ,\n",
       "            0.8833333 , 0.8833333 , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.925     , 0.93333334, 0.93333334, 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.94166666, 0.94166666, 0.94166666, 0.94166666,\n",
       "            0.95      , 0.95      , 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.98333335, 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03846154, 0.05384615,\n",
       "            0.05384615, 0.05384615, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.08461539, 0.09230769, 0.09230769, 0.1       , 0.1       ,\n",
       "            0.10769231, 0.10769231, 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.14615385, 0.14615385,\n",
       "            0.14615385, 0.15384616, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.2       , 0.2       , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.22307692, 0.23076923, 0.23076923,\n",
       "            0.23846154, 0.23846154, 0.24615385, 0.24615385, 0.26153848,\n",
       "            0.26153848, 0.26923078, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2769231 , 0.2769231 , 0.2846154 , 0.2923077 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.3       , 0.30769232, 0.30769232,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.31538463, 0.31538463,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.34615386, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.36923078, 0.37692308, 0.37692308, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4297, 0.429 , 0.4265, 0.425 , 0.4248, 0.4233, 0.423 ,\n",
       "            0.4224, 0.4216, 0.4202, 0.4197, 0.4194, 0.418 , 0.4177, 0.4175,\n",
       "            0.4163, 0.4155, 0.4153, 0.415 , 0.4148, 0.4146, 0.413 , 0.4128,\n",
       "            0.4119, 0.4106, 0.4104, 0.4092, 0.409 , 0.408 , 0.4077, 0.4067,\n",
       "            0.4065, 0.4062, 0.406 , 0.4038, 0.4036, 0.4033, 0.4019, 0.4016,\n",
       "            0.4014, 0.4011, 0.4001, 0.3987, 0.3984, 0.3977, 0.3972, 0.397 ,\n",
       "            0.3967, 0.3962, 0.396 , 0.3958, 0.395 , 0.3945, 0.3943, 0.394 ,\n",
       "            0.3936, 0.3933, 0.3923, 0.392 , 0.3918, 0.3901, 0.39  , 0.3896,\n",
       "            0.389 , 0.3887, 0.3882, 0.388 , 0.3877, 0.3875, 0.3872, 0.3853,\n",
       "            0.385 , 0.3845, 0.384 , 0.3838, 0.3835, 0.3833, 0.383 , 0.382 ,\n",
       "            0.3816, 0.3813, 0.381 , 0.3809, 0.3806, 0.3804, 0.3801, 0.3794,\n",
       "            0.379 , 0.3784, 0.378 , 0.3765, 0.3755, 0.3752, 0.375 , 0.3743,\n",
       "            0.3738, 0.3718, 0.3716, 0.3708, 0.3706, 0.3691, 0.369 , 0.3684,\n",
       "            0.3682, 0.3674, 0.3657, 0.3655, 0.3652, 0.365 , 0.3638, 0.3635,\n",
       "            0.363 , 0.3623, 0.3618, 0.3608, 0.36  , 0.3591, 0.3584, 0.3582,\n",
       "            0.358 , 0.3577, 0.3572, 0.356 , 0.3542, 0.3533, 0.3528, 0.3525,\n",
       "            0.3516, 0.35  , 0.3496, 0.349 , 0.346 , 0.3457, 0.3452, 0.344 ,\n",
       "            0.3435, 0.3423, 0.342 , 0.3418, 0.3403, 0.34  , 0.3396, 0.3386,\n",
       "            0.3381, 0.3347, 0.3345, 0.3337, 0.3323, 0.331 , 0.3303, 0.3284,\n",
       "            0.3281, 0.3257, 0.325 , 0.3223, 0.3188, 0.3186, 0.318 , 0.3162,\n",
       "            0.3145, 0.3108, 0.3093, 0.3088, 0.3086, 0.3071, 0.3052, 0.3015,\n",
       "            0.3003, 0.2988, 0.2979, 0.297 , 0.2961, 0.292 , 0.2915, 0.291 ,\n",
       "            0.2878, 0.2866, 0.284 , 0.281 , 0.2805, 0.2783, 0.2769, 0.2676,\n",
       "            0.2673, 0.2656, 0.2654, 0.2644, 0.2612, 0.2607, 0.2605, 0.2603,\n",
       "            0.2593, 0.2559, 0.2534, 0.2494, 0.2467, 0.2452, 0.2418, 0.2399,\n",
       "            0.2374, 0.237 , 0.2362, 0.2352, 0.2346, 0.2332, 0.233 , 0.2301,\n",
       "            0.2295, 0.2263, 0.2227, 0.2191, 0.2085, 0.2079, 0.2058, 0.1886,\n",
       "            0.1772], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.325     , 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.59166664, 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.675     , 0.69166666, 0.69166666, 0.7       , 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.71666664, 0.71666664,\n",
       "            0.71666664, 0.725     , 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.80833334, 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.8333333 , 0.8333333 ,\n",
       "            0.8333333 , 0.84166664, 0.84166664, 0.84166664, 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.9       , 0.90833336,\n",
       "            0.90833336, 0.90833336, 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.9583333 ,\n",
       "            0.9583333 , 0.9583333 , 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.02307692, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.04615385, 0.06923077,\n",
       "            0.07692308, 0.07692308, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.09230769, 0.09230769, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.10769231, 0.10769231, 0.12307692, 0.12307692,\n",
       "            0.12307692, 0.12307692, 0.12307692, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.13846155, 0.14615385, 0.16153847, 0.16153847,\n",
       "            0.16923077, 0.16923077, 0.17692308, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.1923077 , 0.2       ,\n",
       "            0.21538462, 0.21538462, 0.21538462, 0.21538462, 0.23076923,\n",
       "            0.23846154, 0.23846154, 0.24615385, 0.24615385, 0.25384617,\n",
       "            0.25384617, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2923077 , 0.2923077 , 0.2923077 , 0.2923077 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.3       , 0.3       , 0.30769232,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4076923 , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.45384616, 0.46153846, 0.46923077, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.56153846, 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.99230766, 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4175, 0.416 , 0.4136, 0.4124, 0.4114, 0.4111, 0.4106,\n",
       "            0.4097, 0.4094, 0.4077, 0.4075, 0.4067, 0.406 , 0.4048, 0.4045,\n",
       "            0.404 , 0.4023, 0.402 , 0.4011, 0.4006, 0.4004, 0.3994, 0.3975,\n",
       "            0.3962, 0.396 , 0.395 , 0.3943, 0.3938, 0.3928, 0.392 , 0.3906,\n",
       "            0.39  , 0.3887, 0.3882, 0.3848, 0.3828, 0.381 , 0.3809, 0.3806,\n",
       "            0.3801, 0.3782, 0.378 , 0.377 , 0.3765, 0.376 , 0.3755, 0.375 ,\n",
       "            0.3738, 0.3735, 0.3723, 0.3718, 0.3706, 0.3704, 0.3687, 0.3684,\n",
       "            0.3677, 0.3674, 0.3672, 0.367 , 0.3667, 0.3665, 0.366 , 0.3657,\n",
       "            0.3655, 0.3652, 0.365 , 0.3638, 0.363 , 0.362 , 0.3618, 0.3616,\n",
       "            0.3608, 0.3606, 0.3599, 0.3596, 0.3591, 0.3584, 0.358 , 0.3574,\n",
       "            0.357 , 0.3557, 0.3552, 0.3545, 0.3542, 0.3538, 0.3535, 0.3533,\n",
       "            0.353 , 0.3525, 0.3523, 0.352 , 0.3518, 0.3516, 0.3513, 0.35  ,\n",
       "            0.3499, 0.348 , 0.3474, 0.3447, 0.3445, 0.344 , 0.343 , 0.3428,\n",
       "            0.342 , 0.3418, 0.3416, 0.341 , 0.3389, 0.338 , 0.3374, 0.336 ,\n",
       "            0.335 , 0.3345, 0.333 , 0.3315, 0.3308, 0.3303, 0.3298, 0.3296,\n",
       "            0.3293, 0.327 , 0.3267, 0.3242, 0.3235, 0.3232, 0.3228, 0.322 ,\n",
       "            0.3213, 0.321 , 0.3198, 0.3193, 0.3179, 0.3171, 0.3164, 0.3162,\n",
       "            0.316 , 0.3142, 0.3137, 0.3118, 0.3108, 0.3105, 0.3103, 0.3088,\n",
       "            0.3079, 0.3071, 0.3066, 0.3015, 0.301 , 0.2996, 0.298 , 0.2976,\n",
       "            0.2969, 0.2932, 0.2925, 0.292 , 0.2917, 0.2915, 0.2908, 0.2905,\n",
       "            0.2903, 0.29  , 0.286 , 0.2832, 0.283 , 0.2825, 0.281 , 0.2805,\n",
       "            0.28  , 0.278 , 0.2737, 0.2727, 0.2725, 0.2717, 0.2708, 0.2637,\n",
       "            0.2634, 0.26  , 0.2598, 0.258 , 0.2512, 0.251 , 0.2505, 0.2483,\n",
       "            0.2482, 0.2477, 0.2474, 0.2463, 0.2458, 0.2456, 0.2367, 0.2363,\n",
       "            0.236 , 0.2322, 0.2292, 0.2281, 0.2252, 0.2242, 0.2229, 0.2208,\n",
       "            0.2207, 0.219 , 0.2179, 0.2177, 0.2157, 0.2137, 0.2129, 0.2106,\n",
       "            0.2063, 0.2037, 0.1956, 0.1927, 0.1925, 0.1754, 0.1647],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.34166667, 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.425     , 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45833334, 0.46666667, 0.46666667, 0.49166667, 0.5       ,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.525     , 0.525     ,\n",
       "            0.55      , 0.55      , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.5833333 , 0.5833333 , 0.59166664, 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.6333333 , 0.64166665, 0.65      , 0.65      ,\n",
       "            0.65833336, 0.65833336, 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.71666664, 0.725     , 0.73333335, 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.775     , 0.775     ,\n",
       "            0.775     , 0.775     , 0.78333336, 0.78333336, 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.84166664, 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.8666667 , 0.8666667 ,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.9       , 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.925     , 0.925     , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.98333335, 0.98333335,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.06923077, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.07692308, 0.07692308, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.11538462, 0.13076924, 0.13846155, 0.13846155, 0.14615385,\n",
       "            0.14615385, 0.14615385, 0.15384616, 0.15384616, 0.15384616,\n",
       "            0.16153847, 0.16153847, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.2       , 0.2       , 0.2       , 0.20769231,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.22307692, 0.22307692,\n",
       "            0.23076923, 0.23076923, 0.23076923, 0.23846154, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.24615385, 0.24615385, 0.25384617,\n",
       "            0.25384617, 0.25384617, 0.25384617, 0.26923078, 0.26923078,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.36923078, 0.37692308, 0.3846154 , 0.3846154 ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.44615385, 0.45384616, 0.46153846, 0.46153846,\n",
       "            0.47692308, 0.4846154 , 0.4846154 , 0.4846154 , 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.52307695, 0.52307695,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.54615384, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.61538464, 0.63076925,\n",
       "            0.63846153, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.75384617, 0.76153845, 0.7692308 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4055, 0.4028, 0.401 , 0.4006, 0.4   , 0.3982, 0.3977,\n",
       "            0.397 , 0.3965, 0.3955, 0.394 , 0.3936, 0.3923, 0.3916, 0.39  ,\n",
       "            0.3896, 0.3892, 0.389 , 0.388 , 0.387 , 0.386 , 0.3857, 0.3838,\n",
       "            0.3833, 0.383 , 0.3828, 0.3823, 0.3801, 0.3796, 0.378 , 0.3752,\n",
       "            0.373 , 0.3706, 0.3699, 0.3677, 0.3672, 0.3635, 0.362 , 0.3591,\n",
       "            0.3584, 0.358 , 0.3564, 0.355 , 0.3538, 0.3523, 0.3518, 0.3516,\n",
       "            0.351 , 0.3508, 0.3506, 0.3499, 0.3496, 0.3484, 0.348 , 0.3474,\n",
       "            0.347 , 0.3457, 0.3455, 0.3452, 0.3447, 0.3438, 0.3435, 0.343 ,\n",
       "            0.3425, 0.3418, 0.3413, 0.341 , 0.3408, 0.3403, 0.3389, 0.3386,\n",
       "            0.3384, 0.3381, 0.337 , 0.336 , 0.3357, 0.335 , 0.3347, 0.3345,\n",
       "            0.3335, 0.3333, 0.3318, 0.3315, 0.3298, 0.3296, 0.3293, 0.3289,\n",
       "            0.3286, 0.3284, 0.328 , 0.3271, 0.3267, 0.3264, 0.3262, 0.326 ,\n",
       "            0.3257, 0.3252, 0.325 , 0.3247, 0.3232, 0.3228, 0.3225, 0.3213,\n",
       "            0.3203, 0.3188, 0.3184, 0.3167, 0.3164, 0.316 , 0.3154, 0.3137,\n",
       "            0.3127, 0.3123, 0.3103, 0.3098, 0.3086, 0.308 , 0.3064, 0.3052,\n",
       "            0.305 , 0.3044, 0.3032, 0.3025, 0.3022, 0.3013, 0.3   , 0.2996,\n",
       "            0.2983, 0.298 , 0.2979, 0.2976, 0.2974, 0.297 , 0.2954, 0.2944,\n",
       "            0.294 , 0.2937, 0.2927, 0.2917, 0.291 , 0.29  , 0.2886, 0.2878,\n",
       "            0.2866, 0.2852, 0.2842, 0.2837, 0.2825, 0.2815, 0.2805, 0.28  ,\n",
       "            0.2798, 0.2793, 0.278 , 0.2761, 0.2756, 0.275 , 0.2747, 0.274 ,\n",
       "            0.2722, 0.2705, 0.269 , 0.2688, 0.2676, 0.2666, 0.2659, 0.2656,\n",
       "            0.2646, 0.2637, 0.2632, 0.2617, 0.2595, 0.2573, 0.2542, 0.2527,\n",
       "            0.2522, 0.2478, 0.2456, 0.2422, 0.2418, 0.2413, 0.2399, 0.2372,\n",
       "            0.237 , 0.2355, 0.2335, 0.2251, 0.2235, 0.2213, 0.2203, 0.2195,\n",
       "            0.2173, 0.2166, 0.2152, 0.2133, 0.2125, 0.2114, 0.2094, 0.2089,\n",
       "            0.2084, 0.2063, 0.2026, 0.2017, 0.1968, 0.1952, 0.1893, 0.1859,\n",
       "            0.1846, 0.1692, 0.1588], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.525     , 0.525     , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.65833336, 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.7416667 , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.775     , 0.775     , 0.775     , 0.775     ,\n",
       "            0.775     , 0.775     , 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.8       , 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.8333333 , 0.8333333 , 0.85      , 0.85      ,\n",
       "            0.85      , 0.85      , 0.85833335, 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.8666667 , 0.8666667 , 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.8833333 , 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.90833336, 0.90833336, 0.90833336, 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.04615385,\n",
       "            0.04615385, 0.05384615, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.08461539, 0.08461539,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.1       , 0.10769231,\n",
       "            0.11538462, 0.11538462, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13846155, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.15384616, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.17692308, 0.18461539, 0.1923077 , 0.2       ,\n",
       "            0.2       , 0.2       , 0.21538462, 0.21538462, 0.21538462,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26153848,\n",
       "            0.26923078, 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.31538463, 0.32307693, 0.33076924, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.4076923 , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43076923, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.46923077, 0.47692308, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.50769234, 0.52307695, 0.53846157, 0.54615384, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.56153846, 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5846154 , 0.5846154 , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.65384614, 0.6615385 , 0.66923076, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3936, 0.3896, 0.3884, 0.3882, 0.388 , 0.3857, 0.3848,\n",
       "            0.3845, 0.384 , 0.3835, 0.382 , 0.3804, 0.38  , 0.379 , 0.3777,\n",
       "            0.3772, 0.3762, 0.3757, 0.3755, 0.373 , 0.3728, 0.3716, 0.3708,\n",
       "            0.3704, 0.37  , 0.3696, 0.3691, 0.3677, 0.3667, 0.3657, 0.3625,\n",
       "            0.3572, 0.3547, 0.3542, 0.3538, 0.3513, 0.3506, 0.3486, 0.348 ,\n",
       "            0.344 , 0.343 , 0.3408, 0.3403, 0.3381, 0.3376, 0.337 , 0.3364,\n",
       "            0.3362, 0.3357, 0.3333, 0.333 , 0.3325, 0.332 , 0.3306, 0.3303,\n",
       "            0.3289, 0.3286, 0.328 , 0.3271, 0.3264, 0.3262, 0.326 , 0.3247,\n",
       "            0.324 , 0.3237, 0.3232, 0.3228, 0.3223, 0.3218, 0.3213, 0.321 ,\n",
       "            0.3206, 0.3203, 0.32  , 0.3196, 0.3193, 0.3184, 0.3174, 0.3171,\n",
       "            0.3152, 0.3132, 0.3127, 0.3123, 0.3113, 0.3108, 0.3105, 0.3096,\n",
       "            0.3093, 0.309 , 0.3083, 0.3079, 0.3076, 0.3074, 0.305 , 0.3044,\n",
       "            0.304 , 0.3032, 0.303 , 0.3015, 0.3013, 0.3005, 0.2998, 0.299 ,\n",
       "            0.2961, 0.2944, 0.2937, 0.2935, 0.293 , 0.2927, 0.292 , 0.291 ,\n",
       "            0.2908, 0.2903, 0.2886, 0.2876, 0.286 , 0.2856, 0.2837, 0.2825,\n",
       "            0.282 , 0.2815, 0.2795, 0.2793, 0.279 , 0.2773, 0.277 , 0.2769,\n",
       "            0.2761, 0.2756, 0.2751, 0.2737, 0.273 , 0.2722, 0.272 , 0.2712,\n",
       "            0.271 , 0.2708, 0.2698, 0.2686, 0.2673, 0.267 , 0.2664, 0.2646,\n",
       "            0.2644, 0.263 , 0.2622, 0.2612, 0.261 , 0.2607, 0.259 , 0.2588,\n",
       "            0.2585, 0.2576, 0.2573, 0.2568, 0.256 , 0.253 , 0.2527, 0.2515,\n",
       "            0.25  , 0.249 , 0.2477, 0.246 , 0.2458, 0.2448, 0.2444, 0.2428,\n",
       "            0.2424, 0.2417, 0.2411, 0.2394, 0.2378, 0.2356, 0.2355, 0.2352,\n",
       "            0.2299, 0.2297, 0.2295, 0.2274, 0.2273, 0.2261, 0.2257, 0.2251,\n",
       "            0.222 , 0.2217, 0.2202, 0.2167, 0.2161, 0.2156, 0.2076, 0.2047,\n",
       "            0.2042, 0.2035, 0.2034, 0.1989, 0.1985, 0.1981, 0.1958, 0.1954,\n",
       "            0.1941, 0.1931, 0.193 , 0.1884, 0.1858, 0.1857, 0.183 , 0.1805,\n",
       "            0.1796, 0.1758, 0.172 , 0.1694, 0.1555, 0.1456], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.15      , 0.15833333, 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.225     , 0.23333333, 0.24166666,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45      , 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.49166667, 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.6       , 0.60833335,\n",
       "            0.60833335, 0.60833335, 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.6666667 , 0.6666667 , 0.68333334, 0.68333334,\n",
       "            0.69166666, 0.69166666, 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7       , 0.71666664, 0.725     , 0.725     ,\n",
       "            0.73333335, 0.73333335, 0.75      , 0.7583333 , 0.7583333 ,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.825     , 0.825     , 0.825     , 0.825     , 0.8333333 ,\n",
       "            0.8333333 , 0.8333333 , 0.8333333 , 0.8333333 , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.89166665, 0.89166665, 0.89166665, 0.89166665, 0.89166665,\n",
       "            0.9       , 0.9       , 0.9166667 , 0.9166667 , 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.9166667 , 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.9583333 , 0.9583333 , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 0.9916667 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.04615385, 0.04615385,\n",
       "            0.05384615, 0.06153846, 0.06153846, 0.06923077, 0.07692308,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.09230769, 0.09230769,\n",
       "            0.09230769, 0.1       , 0.10769231, 0.10769231, 0.10769231,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.12307692, 0.13076924,\n",
       "            0.13076924, 0.13076924, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.16923077, 0.16923077,\n",
       "            0.17692308, 0.17692308, 0.17692308, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.1923077 , 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26153848, 0.26153848, 0.2846154 ,\n",
       "            0.2846154 , 0.3       , 0.3       , 0.31538463, 0.32307693,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6076923 , 0.61538464, 0.6230769 , 0.63076925, 0.63076925,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.6615385 , 0.6769231 , 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.382 , 0.378 , 0.377 , 0.3767, 0.375 , 0.3748, 0.3738,\n",
       "            0.373 , 0.3728, 0.3726, 0.3713, 0.3696, 0.3682, 0.3665, 0.3662,\n",
       "            0.3655, 0.3647, 0.3635, 0.3625, 0.361 , 0.3608, 0.3596, 0.3594,\n",
       "            0.3591, 0.3572, 0.3535, 0.3503, 0.3442, 0.3413, 0.3406, 0.3389,\n",
       "            0.3374, 0.3372, 0.337 , 0.335 , 0.3345, 0.3303, 0.3264, 0.3245,\n",
       "            0.3242, 0.3232, 0.3228, 0.3223, 0.3213, 0.3193, 0.3186, 0.318 ,\n",
       "            0.3171, 0.316 , 0.3154, 0.3127, 0.3123, 0.3113, 0.311 , 0.3108,\n",
       "            0.3103, 0.31  , 0.3086, 0.3079, 0.3074, 0.3066, 0.306 , 0.3057,\n",
       "            0.3042, 0.3032, 0.3022, 0.302 , 0.3018, 0.3008, 0.3005, 0.2998,\n",
       "            0.2996, 0.2993, 0.299 , 0.2986, 0.298 , 0.2976, 0.2969, 0.2961,\n",
       "            0.2957, 0.2954, 0.2944, 0.294 , 0.293 , 0.2922, 0.2915, 0.291 ,\n",
       "            0.2908, 0.2905, 0.2898, 0.289 , 0.2888, 0.287 , 0.2869, 0.2847,\n",
       "            0.2844, 0.2842, 0.2832, 0.282 , 0.2808, 0.2798, 0.2786, 0.2773,\n",
       "            0.277 , 0.2769, 0.2766, 0.2761, 0.2756, 0.2727, 0.2722, 0.272 ,\n",
       "            0.2703, 0.2678, 0.2668, 0.2664, 0.2659, 0.2654, 0.2642, 0.264 ,\n",
       "            0.2637, 0.263 , 0.2607, 0.2595, 0.2588, 0.258 , 0.2576, 0.2573,\n",
       "            0.2563, 0.2554, 0.2551, 0.255 , 0.2546, 0.2544, 0.2542, 0.2537,\n",
       "            0.2534, 0.253 , 0.2527, 0.252 , 0.2517, 0.2512, 0.25  , 0.2482,\n",
       "            0.2466, 0.2463, 0.2462, 0.2449, 0.2448, 0.2424, 0.2421, 0.2415,\n",
       "            0.2411, 0.239 , 0.2386, 0.2374, 0.2362, 0.2355, 0.2334, 0.2332,\n",
       "            0.2322, 0.2316, 0.2314, 0.2307, 0.2297, 0.2294, 0.229 , 0.2289,\n",
       "            0.2285, 0.2266, 0.224 , 0.2235, 0.2234, 0.2229, 0.2222, 0.2213,\n",
       "            0.2203, 0.2202, 0.2186, 0.2184, 0.2175, 0.2173, 0.2144, 0.212 ,\n",
       "            0.2101, 0.2094, 0.2089, 0.2064, 0.202 , 0.2018, 0.199 , 0.1989,\n",
       "            0.1974, 0.1964, 0.1958, 0.1937, 0.1925, 0.1919, 0.1912, 0.1907,\n",
       "            0.1896, 0.1887, 0.188 , 0.1829, 0.1821, 0.1808, 0.1766, 0.1765,\n",
       "            0.1763, 0.1748, 0.1707, 0.1665, 0.1543, 0.145 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.16666667, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.425     , 0.425     , 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.5416667 , 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.5833333 , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.6333333 , 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.675     , 0.68333334, 0.68333334, 0.68333334,\n",
       "            0.69166666, 0.69166666, 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7       , 0.7       , 0.7       , 0.71666664,\n",
       "            0.725     , 0.725     , 0.73333335, 0.73333335, 0.75      ,\n",
       "            0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.76666665, 0.775     , 0.775     , 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.7916667 , 0.8       , 0.8       ,\n",
       "            0.80833334, 0.80833334, 0.80833334, 0.81666666, 0.81666666,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.8333333 , 0.84166664,\n",
       "            0.84166664, 0.84166664, 0.85      , 0.85      , 0.85833335,\n",
       "            0.85833335, 0.85833335, 0.8666667 , 0.8666667 , 0.875     ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.89166665, 0.9       ,\n",
       "            0.9       , 0.9       , 0.90833336, 0.9166667 , 0.9166667 ,\n",
       "            0.925     , 0.925     , 0.925     , 0.925     , 0.925     ,\n",
       "            0.925     , 0.925     , 0.925     , 0.925     , 0.925     ,\n",
       "            0.93333334, 0.93333334, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 0.9916667 , 0.9916667 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.03076923, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03846154, 0.03846154, 0.03846154, 0.04615385,\n",
       "            0.04615385, 0.06153846, 0.06923077, 0.06923077, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.09230769, 0.09230769, 0.09230769,\n",
       "            0.1       , 0.1       , 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.14615385, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.15384616, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.17692308, 0.18461539, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.30769232,\n",
       "            0.30769232, 0.31538463, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.4076923 , 0.41538462, 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4846154 , 0.4923077 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.54615384, 0.54615384, 0.5538462 , 0.5538462 ,\n",
       "            0.56153846, 0.5769231 , 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.6230769 , 0.63076925, 0.63076925, 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.72307694, 0.72307694,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.7692308 , 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.95384616, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3726, 0.37  , 0.3699, 0.3684, 0.367 , 0.3667, 0.3652,\n",
       "            0.3645, 0.3643, 0.363 , 0.362 , 0.3606, 0.36  , 0.3591, 0.3584,\n",
       "            0.3567, 0.356 , 0.3555, 0.3552, 0.3538, 0.3533, 0.3528, 0.3525,\n",
       "            0.352 , 0.3516, 0.3494, 0.3486, 0.3474, 0.3457, 0.3452, 0.3418,\n",
       "            0.3376, 0.3335, 0.3318, 0.331 , 0.3289, 0.327 , 0.3254, 0.3245,\n",
       "            0.3242, 0.3235, 0.3228, 0.3186, 0.316 , 0.3135, 0.3132, 0.3125,\n",
       "            0.3096, 0.3093, 0.3088, 0.3071, 0.3054, 0.3052, 0.3047, 0.3037,\n",
       "            0.3032, 0.303 , 0.2996, 0.2988, 0.2983, 0.2976, 0.2969, 0.296 ,\n",
       "            0.2957, 0.294 , 0.2932, 0.2925, 0.292 , 0.2915, 0.2898, 0.289 ,\n",
       "            0.2886, 0.2883, 0.2866, 0.2861, 0.2856, 0.2852, 0.2847, 0.2844,\n",
       "            0.2842, 0.284 , 0.2837, 0.2827, 0.2822, 0.2808, 0.2805, 0.2803,\n",
       "            0.2788, 0.278 , 0.2778, 0.2776, 0.277 , 0.2764, 0.276 , 0.2751,\n",
       "            0.275 , 0.2732, 0.273 , 0.2727, 0.2708, 0.2705, 0.2698, 0.2688,\n",
       "            0.2673, 0.2668, 0.2664, 0.2654, 0.2644, 0.2642, 0.2632, 0.263 ,\n",
       "            0.2625, 0.2622, 0.2617, 0.2612, 0.26  , 0.259 , 0.2588, 0.2578,\n",
       "            0.2563, 0.2556, 0.255 , 0.2534, 0.2524, 0.2517, 0.2515, 0.2512,\n",
       "            0.251 , 0.2507, 0.2493, 0.249 , 0.2487, 0.2483, 0.248 , 0.2478,\n",
       "            0.244 , 0.2434, 0.2433, 0.243 , 0.2422, 0.2421, 0.2406, 0.2401,\n",
       "            0.2399, 0.2397, 0.2395, 0.2394, 0.2388, 0.2383, 0.2382, 0.237 ,\n",
       "            0.2362, 0.2358, 0.2352, 0.2351, 0.2347, 0.2344, 0.234 , 0.2328,\n",
       "            0.2322, 0.231 , 0.2306, 0.2301, 0.2281, 0.2272, 0.2261, 0.2257,\n",
       "            0.2255, 0.2252, 0.2247, 0.2235, 0.2229, 0.2227, 0.2208, 0.2203,\n",
       "            0.2195, 0.219 , 0.2184, 0.2177, 0.2175, 0.2167, 0.2158, 0.2156,\n",
       "            0.2153, 0.2142, 0.2137, 0.2129, 0.2123, 0.21  , 0.208 , 0.2074,\n",
       "            0.2063, 0.2042, 0.2028, 0.202 , 0.2009, 0.2004, 0.1984, 0.1978,\n",
       "            0.1965, 0.1959, 0.1952, 0.1935, 0.193 , 0.1921, 0.1915, 0.1909,\n",
       "            0.1901, 0.1893, 0.1884, 0.1858, 0.1821, 0.182 , 0.1804, 0.1799,\n",
       "            0.1764, 0.1758, 0.1715, 0.1671, 0.1556, 0.1467], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01666667, 0.025     , 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.325     , 0.33333334, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.38333333,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.43333334, 0.45      , 0.45      , 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.525     , 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.59166664, 0.6       , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.65      , 0.65833336, 0.65833336, 0.65833336, 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.675     , 0.675     , 0.675     ,\n",
       "            0.675     , 0.675     , 0.675     , 0.675     , 0.69166666,\n",
       "            0.69166666, 0.69166666, 0.69166666, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.7583333 , 0.76666665, 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.775     , 0.775     , 0.775     , 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.80833334, 0.80833334,\n",
       "            0.80833334, 0.80833334, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.825     , 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85      , 0.85833335, 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.93333334, 0.94166666, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.96666664, 0.96666664, 0.96666664,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.975     , 0.975     , 0.98333335,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 0.9916667 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06153846, 0.06923077, 0.06923077, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.11538462,\n",
       "            0.12307692, 0.12307692, 0.13076924, 0.13076924, 0.13076924,\n",
       "            0.13076924, 0.13846155, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.15384616, 0.16923077, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.2       , 0.2       ,\n",
       "            0.2       , 0.20769231, 0.20769231, 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.24615385, 0.24615385, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.30769232, 0.31538463, 0.32307693,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.4076923 , 0.41538462, 0.41538462, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.46923077, 0.47692308, 0.4846154 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.52307695, 0.52307695,\n",
       "            0.52307695, 0.54615384, 0.5538462 , 0.56153846, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.6076923 , 0.61538464, 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63846153, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.66923076, 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7076923 , 0.7076923 , 0.7076923 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3647, 0.3643, 0.3625, 0.3618, 0.3606, 0.3584, 0.3577,\n",
       "            0.3557, 0.3555, 0.3552, 0.3542, 0.3538, 0.3528, 0.352 , 0.3518,\n",
       "            0.3513, 0.35  , 0.3489, 0.3452, 0.3445, 0.3442, 0.342 , 0.3418,\n",
       "            0.3413, 0.3406, 0.3372, 0.335 , 0.3342, 0.3335, 0.3328, 0.332 ,\n",
       "            0.329 , 0.325 , 0.3208, 0.318 , 0.317 , 0.316 , 0.3157, 0.3147,\n",
       "            0.3123, 0.3096, 0.3093, 0.3088, 0.3052, 0.3037, 0.3018, 0.2986,\n",
       "            0.2966, 0.2954, 0.2942, 0.2937, 0.2935, 0.293 , 0.2908, 0.2898,\n",
       "            0.2893, 0.289 , 0.2886, 0.2883, 0.2864, 0.286 , 0.2852, 0.2847,\n",
       "            0.2842, 0.284 , 0.283 , 0.2815, 0.2795, 0.2793, 0.2788, 0.278 ,\n",
       "            0.2776, 0.2769, 0.2761, 0.276 , 0.2754, 0.275 , 0.2744, 0.2742,\n",
       "            0.2737, 0.2734, 0.2732, 0.273 , 0.2722, 0.272 , 0.2708, 0.2705,\n",
       "            0.2703, 0.2695, 0.2688, 0.2676, 0.2668, 0.2656, 0.2654, 0.2651,\n",
       "            0.264 , 0.2637, 0.2634, 0.2627, 0.2622, 0.2615, 0.2612, 0.2603,\n",
       "            0.26  , 0.2595, 0.2593, 0.2588, 0.2585, 0.258 , 0.257 , 0.2559,\n",
       "            0.255 , 0.2534, 0.2532, 0.253 , 0.2522, 0.251 , 0.2505, 0.2502,\n",
       "            0.2498, 0.2496, 0.2494, 0.2487, 0.2485, 0.2477, 0.2456, 0.2434,\n",
       "            0.2433, 0.2428, 0.2422, 0.2421, 0.2394, 0.2386, 0.2383, 0.2367,\n",
       "            0.2362, 0.2351, 0.2344, 0.2334, 0.2332, 0.233 , 0.2327, 0.231 ,\n",
       "            0.2303, 0.2301, 0.2289, 0.2283, 0.228 , 0.2277, 0.2274, 0.2268,\n",
       "            0.2255, 0.2238, 0.2234, 0.223 , 0.2229, 0.222 , 0.2216, 0.2211,\n",
       "            0.2194, 0.218 , 0.2173, 0.2172, 0.2166, 0.2161, 0.2152, 0.2142,\n",
       "            0.214 , 0.2135, 0.2114, 0.2094, 0.2091, 0.209 , 0.2085, 0.2084,\n",
       "            0.2075, 0.2063, 0.2047, 0.2042, 0.204 , 0.2028, 0.2024, 0.2023,\n",
       "            0.2018, 0.2013, 0.201 , 0.2006, 0.1998, 0.1985, 0.1979, 0.1962,\n",
       "            0.1958, 0.1941, 0.1935, 0.1931, 0.1921, 0.1904, 0.1887, 0.1886,\n",
       "            0.1885, 0.1884, 0.1871, 0.1865, 0.1849, 0.1844, 0.1838, 0.1797,\n",
       "            0.178 , 0.1763, 0.172 , 0.1692, 0.1617, 0.1604], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.15      , 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.48333332, 0.5083333 , 0.51666665, 0.51666665, 0.51666665,\n",
       "            0.51666665, 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.575     , 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.59166664, 0.6       , 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.6333333 , 0.6333333 , 0.64166665, 0.64166665,\n",
       "            0.64166665, 0.65      , 0.65      , 0.65833336, 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.68333334, 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.7       , 0.7       , 0.7083333 , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.7583333 , 0.7583333 , 0.76666665, 0.76666665, 0.76666665,\n",
       "            0.775     , 0.775     , 0.78333336, 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.78333336, 0.78333336,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.8       , 0.8       , 0.80833334, 0.80833334,\n",
       "            0.81666666, 0.81666666, 0.825     , 0.825     , 0.825     ,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.85833335, 0.85833335, 0.85833335, 0.8666667 ,\n",
       "            0.8666667 , 0.8666667 , 0.875     , 0.875     , 0.8833333 ,\n",
       "            0.8833333 , 0.8833333 , 0.8833333 , 0.89166665, 0.89166665,\n",
       "            0.89166665, 0.9       , 0.9       , 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.925     , 0.925     ,\n",
       "            0.925     , 0.925     , 0.93333334, 0.93333334, 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.975     , 0.975     ,\n",
       "            0.975     , 0.975     , 0.98333335, 0.9916667 , 0.9916667 ,\n",
       "            0.9916667 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00769231, 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.07692308, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.09230769, 0.1       , 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.14615385, 0.14615385, 0.14615385, 0.14615385, 0.15384616,\n",
       "            0.15384616, 0.15384616, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.18461539, 0.1923077 , 0.1923077 ,\n",
       "            0.1923077 , 0.1923077 , 0.20769231, 0.21538462, 0.23076923,\n",
       "            0.23076923, 0.23846154, 0.25384617, 0.26153848, 0.26153848,\n",
       "            0.26923078, 0.2846154 , 0.3       , 0.3       , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.33846155,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.36923078, 0.3923077 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.42307693, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.46923077, 0.47692308, 0.47692308, 0.4846154 , 0.4846154 ,\n",
       "            0.4846154 , 0.4846154 , 0.4923077 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.5153846 , 0.5153846 , 0.52307695, 0.5307692 ,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.6230769 , 0.6230769 , 0.63076925,\n",
       "            0.63076925, 0.64615387, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7       , 0.7153846 , 0.7307692 , 0.74615383, 0.75384617,\n",
       "            0.7692308 , 0.77692306, 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.8384615 , 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86923075, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3582, 0.358 , 0.356 , 0.3555, 0.355 , 0.3545, 0.352 ,\n",
       "            0.3508, 0.35  , 0.3499, 0.3489, 0.3486, 0.348 , 0.3477, 0.3445,\n",
       "            0.344 , 0.342 , 0.3406, 0.3394, 0.338 , 0.3345, 0.3337, 0.333 ,\n",
       "            0.3315, 0.3306, 0.33  , 0.3298, 0.3284, 0.3281, 0.3262, 0.3223,\n",
       "            0.3213, 0.3203, 0.317 , 0.3147, 0.3145, 0.3137, 0.3123, 0.311 ,\n",
       "            0.3093, 0.3074, 0.3071, 0.3022, 0.3013, 0.2988, 0.297 , 0.2966,\n",
       "            0.296 , 0.2952, 0.2942, 0.2925, 0.289 , 0.2888, 0.2864, 0.2856,\n",
       "            0.2854, 0.2852, 0.2844, 0.2832, 0.2815, 0.281 , 0.2805, 0.2786,\n",
       "            0.278 , 0.277 , 0.2769, 0.2761, 0.276 , 0.275 , 0.274 , 0.2737,\n",
       "            0.2734, 0.2732, 0.273 , 0.2717, 0.2712, 0.271 , 0.269 , 0.2688,\n",
       "            0.2683, 0.268 , 0.2673, 0.2668, 0.2666, 0.2664, 0.2659, 0.2654,\n",
       "            0.2642, 0.264 , 0.2637, 0.2634, 0.2632, 0.263 , 0.262 , 0.2615,\n",
       "            0.2612, 0.2605, 0.2595, 0.2588, 0.2578, 0.2573, 0.257 , 0.2568,\n",
       "            0.2551, 0.255 , 0.2544, 0.254 , 0.2534, 0.2527, 0.2524, 0.2522,\n",
       "            0.252 , 0.2515, 0.251 , 0.2502, 0.25  , 0.2496, 0.248 , 0.2466,\n",
       "            0.2462, 0.246 , 0.2452, 0.2451, 0.2438, 0.2434, 0.2429, 0.2426,\n",
       "            0.2421, 0.2417, 0.2411, 0.241 , 0.2406, 0.2405, 0.2399, 0.2395,\n",
       "            0.239 , 0.2386, 0.2384, 0.2374, 0.2366, 0.2363, 0.2362, 0.2358,\n",
       "            0.2335, 0.2334, 0.2332, 0.2322, 0.2313, 0.231 , 0.2302, 0.2294,\n",
       "            0.2263, 0.2256, 0.2252, 0.2216, 0.2211, 0.2208, 0.2179, 0.2177,\n",
       "            0.2168, 0.2156, 0.2145, 0.214 , 0.2135, 0.2128, 0.2125, 0.2115,\n",
       "            0.2114, 0.2113, 0.2109, 0.2106, 0.2089, 0.2085, 0.2074, 0.2068,\n",
       "            0.2058, 0.2056, 0.2054, 0.2051, 0.2048, 0.2043, 0.202 , 0.2013,\n",
       "            0.2006, 0.1989, 0.1987, 0.1981, 0.197 , 0.1968, 0.1962, 0.1953,\n",
       "            0.1937, 0.1936, 0.1934, 0.1923, 0.1918, 0.1909, 0.1901, 0.1897,\n",
       "            0.1892, 0.186 , 0.1859, 0.185 , 0.1846, 0.1833, 0.183 , 0.1808,\n",
       "            0.177 , 0.1753, 0.1748, 0.1731, 0.1719, 0.1718, 0.1664, 0.1658,\n",
       "            0.1636, 0.1588, 0.1475], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.075     , 0.08333334, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15833333, 0.16666667, 0.175     , 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.3       , 0.30833334, 0.31666666,\n",
       "            0.325     , 0.33333334, 0.33333334, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35      , 0.35      , 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.41666666, 0.41666666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.53333336, 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.59166664, 0.6       , 0.60833335,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.675     , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.68333334, 0.69166666, 0.69166666,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.71666664, 0.725     , 0.725     , 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.7583333 , 0.7583333 , 0.7583333 , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.775     , 0.775     , 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8       , 0.80833334,\n",
       "            0.80833334, 0.80833334, 0.80833334, 0.80833334, 0.80833334,\n",
       "            0.80833334, 0.80833334, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.825     , 0.825     , 0.8333333 , 0.8333333 , 0.84166664,\n",
       "            0.84166664, 0.84166664, 0.85      , 0.85      , 0.85833335,\n",
       "            0.85833335, 0.8666667 , 0.8666667 , 0.8666667 , 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.8833333 , 0.8833333 ,\n",
       "            0.8833333 , 0.89166665, 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.925     , 0.93333334, 0.93333334,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.9583333 ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.98333335,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.01538462, 0.01538462, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03076923, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.06153846, 0.06923077, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.11538462, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16153847, 0.16923077, 0.16923077,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.24615385, 0.26153848, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2846154 , 0.2923077 , 0.2923077 , 0.2923077 , 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36153847, 0.36153847,\n",
       "            0.36923078, 0.3846154 , 0.3923077 , 0.4       , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.43846154, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.47692308, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.5       , 0.50769234, 0.50769234, 0.5153846 ,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5692308 , 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.6076923 , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.9461538 ,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3586, 0.3574, 0.3567, 0.3564, 0.355 , 0.354 , 0.3538,\n",
       "            0.3528, 0.3525, 0.351 , 0.35  , 0.3494, 0.3464, 0.339 , 0.3372,\n",
       "            0.3354, 0.334 , 0.3325, 0.3313, 0.3281, 0.328 , 0.3267, 0.3252,\n",
       "            0.325 , 0.3242, 0.322 , 0.321 , 0.3208, 0.319 , 0.318 , 0.3137,\n",
       "            0.3123, 0.312 , 0.311 , 0.3093, 0.3086, 0.306 , 0.3047, 0.3044,\n",
       "            0.299 , 0.2988, 0.2983, 0.298 , 0.2974, 0.297 , 0.2944, 0.2937,\n",
       "            0.292 , 0.291 , 0.2908, 0.2903, 0.2893, 0.2888, 0.2883, 0.2874,\n",
       "            0.2869, 0.2864, 0.286 , 0.2854, 0.284 , 0.2832, 0.2827, 0.2825,\n",
       "            0.2822, 0.282 , 0.2817, 0.2815, 0.281 , 0.2805, 0.28  , 0.2798,\n",
       "            0.2793, 0.2786, 0.2776, 0.2773, 0.277 , 0.2769, 0.2764, 0.276 ,\n",
       "            0.2742, 0.2737, 0.2734, 0.2722, 0.272 , 0.2712, 0.27  , 0.2698,\n",
       "            0.2693, 0.2686, 0.268 , 0.2678, 0.2676, 0.2673, 0.267 , 0.2656,\n",
       "            0.2646, 0.2637, 0.263 , 0.2627, 0.2625, 0.2612, 0.261 , 0.2603,\n",
       "            0.2598, 0.2595, 0.2588, 0.2583, 0.2576, 0.257 , 0.2568, 0.256 ,\n",
       "            0.2556, 0.2551, 0.2534, 0.2527, 0.2517, 0.2515, 0.251 , 0.2507,\n",
       "            0.2505, 0.2502, 0.25  , 0.2498, 0.2494, 0.2487, 0.2482, 0.2478,\n",
       "            0.2474, 0.2473, 0.247 , 0.2467, 0.2462, 0.2452, 0.2448, 0.2437,\n",
       "            0.2426, 0.2422, 0.2413, 0.241 , 0.2399, 0.2379, 0.2362, 0.2356,\n",
       "            0.2355, 0.234 , 0.2335, 0.2334, 0.2328, 0.2327, 0.2325, 0.2294,\n",
       "            0.2283, 0.228 , 0.2272, 0.2261, 0.226 , 0.2256, 0.2244, 0.224 ,\n",
       "            0.2239, 0.2213, 0.2207, 0.22  , 0.219 , 0.2184, 0.2179, 0.2166,\n",
       "            0.2153, 0.2142, 0.214 , 0.2139, 0.2137, 0.2134, 0.2129, 0.2118,\n",
       "            0.2114, 0.2109, 0.2106, 0.2101, 0.2091, 0.2089, 0.2076, 0.2054,\n",
       "            0.205 , 0.2039, 0.2034, 0.2031, 0.2029, 0.2026, 0.2023, 0.1982,\n",
       "            0.1943, 0.1936, 0.1931, 0.1929, 0.1904, 0.187 , 0.1859, 0.1853,\n",
       "            0.1848, 0.1836, 0.1792, 0.1774, 0.1764, 0.1752, 0.1727, 0.1726,\n",
       "            0.1721, 0.1681, 0.1597, 0.1436], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.025     , 0.03333334, 0.05833333,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.10833333, 0.11666667,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.2       , 0.21666667,\n",
       "            0.21666667, 0.225     , 0.24166666, 0.25      , 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.275     ,\n",
       "            0.275     , 0.275     , 0.275     , 0.28333333, 0.28333333,\n",
       "            0.29166666, 0.3       , 0.3       , 0.3       , 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.325     , 0.33333334, 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.425     ,\n",
       "            0.425     , 0.44166666, 0.44166666, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.525     , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55      , 0.55      , 0.56666666,\n",
       "            0.56666666, 0.56666666, 0.575     , 0.59166664, 0.6       ,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.64166665, 0.64166665,\n",
       "            0.65      , 0.65833336, 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.675     , 0.675     , 0.675     , 0.68333334,\n",
       "            0.68333334, 0.68333334, 0.68333334, 0.68333334, 0.68333334,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.75      , 0.7583333 , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.7916667 , 0.7916667 , 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.84166664,\n",
       "            0.84166664, 0.85      , 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.90833336, 0.90833336, 0.9166667 ,\n",
       "            0.9166667 , 0.9166667 , 0.925     , 0.925     , 0.93333334,\n",
       "            0.93333334, 0.94166666, 0.94166666, 0.95      , 0.95      ,\n",
       "            0.96666664, 0.96666664, 0.96666664, 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.98333335, 0.9916667 , 0.9916667 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00769231, 0.01538462, 0.01538462,\n",
       "            0.01538462, 0.02307692, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.02307692, 0.02307692, 0.03076923, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.03846154, 0.03846154, 0.03846154, 0.03846154,\n",
       "            0.04615385, 0.05384615, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.09230769, 0.1       ,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.14615385, 0.15384616, 0.15384616,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.17692308, 0.1923077 ,\n",
       "            0.2       , 0.2       , 0.20769231, 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2769231 , 0.2769231 , 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.34615386, 0.35384616, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3846154 , 0.3923077 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.41538462, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.45384616, 0.46153846, 0.46153846, 0.46153846, 0.46153846,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.56153846, 0.5692308 , 0.5692308 , 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.61538464, 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.63846153, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6923077 , 0.7       , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.8769231 ,\n",
       "            0.8769231 , 0.8769231 , 0.88461536, 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.367 , 0.3665, 0.3655, 0.3652, 0.3638, 0.3635, 0.3623,\n",
       "            0.3594, 0.357 , 0.3555, 0.351 , 0.346 , 0.3428, 0.3425, 0.3403,\n",
       "            0.3398, 0.339 , 0.336 , 0.3357, 0.3347, 0.3315, 0.3306, 0.3298,\n",
       "            0.3289, 0.3286, 0.3276, 0.3262, 0.3254, 0.3235, 0.323 , 0.3225,\n",
       "            0.3223, 0.3215, 0.3198, 0.3196, 0.319 , 0.3186, 0.3176, 0.3174,\n",
       "            0.3171, 0.3157, 0.3137, 0.3135, 0.3132, 0.3125, 0.3123, 0.3115,\n",
       "            0.3113, 0.3108, 0.31  , 0.309 , 0.3074, 0.307 , 0.3066, 0.3064,\n",
       "            0.306 , 0.3052, 0.3044, 0.304 , 0.3037, 0.3035, 0.3032, 0.3027,\n",
       "            0.3025, 0.3018, 0.301 , 0.3005, 0.2993, 0.299 , 0.298 , 0.2979,\n",
       "            0.2974, 0.2961, 0.2947, 0.292 , 0.291 , 0.2903, 0.29  , 0.289 ,\n",
       "            0.2886, 0.2883, 0.2874, 0.2856, 0.2854, 0.285 , 0.2837, 0.2827,\n",
       "            0.2825, 0.2822, 0.2815, 0.2805, 0.28  , 0.2793, 0.2786, 0.2776,\n",
       "            0.277 , 0.2766, 0.2761, 0.276 , 0.2754, 0.2751, 0.275 , 0.2747,\n",
       "            0.2742, 0.274 , 0.2737, 0.2732, 0.2722, 0.2715, 0.2712, 0.2703,\n",
       "            0.2688, 0.2686, 0.2683, 0.268 , 0.2673, 0.267 , 0.2668, 0.2666,\n",
       "            0.266 , 0.2646, 0.2642, 0.263 , 0.2622, 0.262 , 0.2612, 0.2595,\n",
       "            0.2578, 0.2573, 0.2568, 0.2566, 0.2551, 0.2544, 0.254 , 0.2534,\n",
       "            0.2512, 0.251 , 0.2507, 0.25  , 0.2498, 0.2493, 0.2478, 0.2473,\n",
       "            0.2467, 0.2466, 0.2462, 0.2451, 0.2445, 0.243 , 0.2407, 0.2397,\n",
       "            0.2394, 0.239 , 0.237 , 0.2367, 0.2366, 0.2358, 0.2351, 0.234 ,\n",
       "            0.2339, 0.2316, 0.2311, 0.231 , 0.2294, 0.2292, 0.2286, 0.2281,\n",
       "            0.2252, 0.2239, 0.222 , 0.22  , 0.2197, 0.2194, 0.2185, 0.2184,\n",
       "            0.2181, 0.218 , 0.2157, 0.2139, 0.2133, 0.2128, 0.212 , 0.2054,\n",
       "            0.2043, 0.204 , 0.2035, 0.2034, 0.1978, 0.1942, 0.1918, 0.1892,\n",
       "            0.183 , 0.1823, 0.1821, 0.1813, 0.1796, 0.1763, 0.1678, 0.1665,\n",
       "            0.1449], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.125     , 0.13333334, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.175     , 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.20833333, 0.21666667,\n",
       "            0.225     , 0.225     , 0.225     , 0.225     , 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.275     , 0.29166666, 0.3       , 0.31666666,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.34166667, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.375     , 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.525     , 0.53333336, 0.53333336, 0.53333336,\n",
       "            0.53333336, 0.5416667 , 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.625     , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.6666667 , 0.675     , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.7416667 , 0.7416667 ,\n",
       "            0.75      , 0.75      , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.78333336, 0.7916667 ,\n",
       "            0.80833334, 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.8833333 , 0.9       ,\n",
       "            0.90833336, 0.90833336, 0.9166667 , 0.925     , 0.925     ,\n",
       "            0.94166666, 0.95      , 0.95      , 0.95      , 0.95      ,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.975     ,\n",
       "            0.975     , 0.98333335, 0.98333335, 0.9916667 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00769231, 0.00769231,\n",
       "            0.00769231, 0.01538462, 0.02307692, 0.02307692, 0.02307692,\n",
       "            0.03076923, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.08461539,\n",
       "            0.09230769, 0.1       , 0.1       , 0.10769231, 0.11538462,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16923077, 0.17692308, 0.17692308, 0.17692308,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.23846154, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.2769231 , 0.2769231 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.30769232, 0.31538463, 0.32307693, 0.33846155,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4076923 , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.5       ,\n",
       "            0.5       , 0.50769234, 0.52307695, 0.52307695, 0.5307692 ,\n",
       "            0.53846157, 0.5538462 , 0.5538462 , 0.5769231 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6       , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7076923 ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.75384617, 0.75384617, 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.8769231 , 0.8769231 , 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3792, 0.3782, 0.3774, 0.3772, 0.377 , 0.3765, 0.3743,\n",
       "            0.374 , 0.3733, 0.3713, 0.3706, 0.3687, 0.3662, 0.365 , 0.3618,\n",
       "            0.3608, 0.3604, 0.3594, 0.3577, 0.3567, 0.3533, 0.351 , 0.3486,\n",
       "            0.3484, 0.3467, 0.3464, 0.3457, 0.3452, 0.3447, 0.3442, 0.3435,\n",
       "            0.3433, 0.343 , 0.3425, 0.3416, 0.341 , 0.3408, 0.3403, 0.3389,\n",
       "            0.3386, 0.3364, 0.3362, 0.335 , 0.3347, 0.3345, 0.334 , 0.3333,\n",
       "            0.3325, 0.3306, 0.33  , 0.3296, 0.329 , 0.3289, 0.3286, 0.3281,\n",
       "            0.328 , 0.3274, 0.3271, 0.327 , 0.3267, 0.3264, 0.325 , 0.3245,\n",
       "            0.3232, 0.3228, 0.3223, 0.3218, 0.3215, 0.3203, 0.3193, 0.3186,\n",
       "            0.318 , 0.316 , 0.3154, 0.3152, 0.3145, 0.3142, 0.3137, 0.313 ,\n",
       "            0.3115, 0.3108, 0.3098, 0.309 , 0.3086, 0.3083, 0.3074, 0.3064,\n",
       "            0.3057, 0.3052, 0.305 , 0.3042, 0.3037, 0.3035, 0.3032, 0.3027,\n",
       "            0.3025, 0.3018, 0.3013, 0.3005, 0.2998, 0.2986, 0.297 , 0.2961,\n",
       "            0.2957, 0.2954, 0.2952, 0.295 , 0.2947, 0.2944, 0.2932, 0.2927,\n",
       "            0.2925, 0.2913, 0.2903, 0.2898, 0.2896, 0.289 , 0.2888, 0.2886,\n",
       "            0.288 , 0.2878, 0.2874, 0.2869, 0.2864, 0.2861, 0.286 , 0.285 ,\n",
       "            0.2847, 0.2844, 0.2834, 0.2815, 0.2812, 0.281 , 0.28  , 0.2793,\n",
       "            0.279 , 0.277 , 0.2766, 0.2754, 0.2722, 0.2705, 0.27  , 0.269 ,\n",
       "            0.2676, 0.2664, 0.2654, 0.2646, 0.264 , 0.2617, 0.2605, 0.2583,\n",
       "            0.2573, 0.2556, 0.2551, 0.2534, 0.251 , 0.2502, 0.2496, 0.2478,\n",
       "            0.2473, 0.2445, 0.2444, 0.2433, 0.2421, 0.2415, 0.2399, 0.2384,\n",
       "            0.2383, 0.2382, 0.2372, 0.2367, 0.2358, 0.2344, 0.2322, 0.2316,\n",
       "            0.2314, 0.2297, 0.2292, 0.2281, 0.2249, 0.2244, 0.224 , 0.2218,\n",
       "            0.2212, 0.2203, 0.219 , 0.2158, 0.2104, 0.2086, 0.2075, 0.2037,\n",
       "            0.2001, 0.1937, 0.1931, 0.1901, 0.1836, 0.18  , 0.1696, 0.1588,\n",
       "            0.15  ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.08333334, 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "            0.1       , 0.1       , 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.24166666, 0.25      , 0.25      ,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.275     , 0.275     , 0.275     , 0.275     , 0.275     ,\n",
       "            0.275     , 0.28333333, 0.28333333, 0.29166666, 0.29166666,\n",
       "            0.29166666, 0.29166666, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.3       , 0.3       , 0.30833334, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.39166668, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45      , 0.45833334, 0.46666667,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.49166667, 0.49166667, 0.49166667, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.525     , 0.53333336,\n",
       "            0.55      , 0.55      , 0.55      , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7083333 , 0.71666664,\n",
       "            0.71666664, 0.71666664, 0.725     , 0.725     , 0.725     ,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.81666666, 0.825     , 0.825     , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.85833335, 0.85833335, 0.8666667 , 0.8666667 ,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.975     , 0.975     , 0.975     ,\n",
       "            0.98333335, 0.9916667 , 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.00769231,\n",
       "            0.00769231, 0.00769231, 0.00769231, 0.00769231, 0.01538462,\n",
       "            0.01538462, 0.01538462, 0.02307692, 0.03076923, 0.03076923,\n",
       "            0.03846154, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.07692308, 0.08461539, 0.08461539, 0.08461539, 0.1       ,\n",
       "            0.10769231, 0.10769231, 0.10769231, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16153847, 0.16153847, 0.16923077, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.18461539, 0.2       , 0.2       , 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.23846154, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.3       , 0.3       , 0.30769232, 0.32307693,\n",
       "            0.33076924, 0.33846155, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.37692308, 0.37692308,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.43846154, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4923077 , 0.5       , 0.5153846 , 0.52307695,\n",
       "            0.52307695, 0.5307692 , 0.53846157, 0.53846157, 0.53846157,\n",
       "            0.5538462 , 0.56153846, 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.61538464, 0.61538464, 0.6230769 , 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63846153, 0.64615387, 0.64615387,\n",
       "            0.65384614, 0.66923076, 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7153846 , 0.7153846 , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.7846154 , 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3975, 0.3965, 0.396 , 0.3945, 0.394 , 0.3938, 0.393 ,\n",
       "            0.3918, 0.3914, 0.391 , 0.389 , 0.3882, 0.388 , 0.3875, 0.387 ,\n",
       "            0.3865, 0.3862, 0.3857, 0.3855, 0.385 , 0.3843, 0.384 , 0.3838,\n",
       "            0.3833, 0.3823, 0.382 , 0.381 , 0.3804, 0.3792, 0.3784, 0.3772,\n",
       "            0.377 , 0.3765, 0.3743, 0.3735, 0.372 , 0.3718, 0.3704, 0.37  ,\n",
       "            0.3691, 0.369 , 0.3674, 0.3667, 0.3662, 0.366 , 0.3657, 0.3655,\n",
       "            0.365 , 0.3647, 0.364 , 0.3638, 0.3635, 0.363 , 0.362 , 0.3613,\n",
       "            0.361 , 0.3608, 0.3606, 0.3591, 0.3564, 0.3562, 0.356 , 0.355 ,\n",
       "            0.3542, 0.3538, 0.3533, 0.3525, 0.3516, 0.3506, 0.3503, 0.3499,\n",
       "            0.348 , 0.3467, 0.3455, 0.3442, 0.3428, 0.3425, 0.3418, 0.3416,\n",
       "            0.3408, 0.3403, 0.3396, 0.3394, 0.3386, 0.338 , 0.3376, 0.3372,\n",
       "            0.3362, 0.3357, 0.3354, 0.3352, 0.335 , 0.3347, 0.334 , 0.3325,\n",
       "            0.3323, 0.3313, 0.331 , 0.3308, 0.3306, 0.3298, 0.3296, 0.3293,\n",
       "            0.3289, 0.3286, 0.328 , 0.3274, 0.3271, 0.327 , 0.3267, 0.3254,\n",
       "            0.3252, 0.3247, 0.3245, 0.3242, 0.3235, 0.3225, 0.3223, 0.322 ,\n",
       "            0.3218, 0.3213, 0.321 , 0.3208, 0.32  , 0.3184, 0.318 , 0.317 ,\n",
       "            0.3164, 0.316 , 0.3147, 0.3137, 0.3127, 0.311 , 0.309 , 0.3086,\n",
       "            0.308 , 0.3079, 0.307 , 0.3066, 0.3064, 0.3042, 0.304 , 0.3025,\n",
       "            0.3008, 0.3003, 0.2998, 0.2996, 0.2988, 0.2983, 0.297 , 0.2957,\n",
       "            0.2944, 0.2925, 0.292 , 0.2917, 0.2903, 0.2898, 0.2844, 0.282 ,\n",
       "            0.2805, 0.28  , 0.278 , 0.2769, 0.2761, 0.2747, 0.2742, 0.2727,\n",
       "            0.2722, 0.2703, 0.27  , 0.268 , 0.2678, 0.2673, 0.266 , 0.2654,\n",
       "            0.2646, 0.2642, 0.263 , 0.2625, 0.2546, 0.253 , 0.2522, 0.2498,\n",
       "            0.249 , 0.2489, 0.2463, 0.2458, 0.2451, 0.2424, 0.2418, 0.2407,\n",
       "            0.2391, 0.2355, 0.2325, 0.2283, 0.2281, 0.228 , 0.2274, 0.2247,\n",
       "            0.2238, 0.2224, 0.2203, 0.2175, 0.2144, 0.2133, 0.2104, 0.2096,\n",
       "            0.2068, 0.1995, 0.1765, 0.1641, 0.1594, 0.1521], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05      , 0.06666667, 0.06666667,\n",
       "            0.075     , 0.08333334, 0.08333334, 0.09166667, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.1       , 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.16666667, 0.16666667, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.18333334, 0.18333334,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.23333333, 0.23333333,\n",
       "            0.24166666, 0.24166666, 0.24166666, 0.25      , 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.25833333, 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.26666668, 0.26666668, 0.275     , 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.35      , 0.36666667,\n",
       "            0.36666667, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.475     , 0.48333332, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.525     , 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65      , 0.65      , 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.71666664, 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.78333336, 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.84166664, 0.85      , 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.90833336, 0.90833336, 0.90833336, 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.01538462, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.07692308, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.15384616, 0.16153847,\n",
       "            0.16153847, 0.16153847, 0.17692308, 0.17692308, 0.1923077 ,\n",
       "            0.20769231, 0.20769231, 0.21538462, 0.21538462, 0.21538462,\n",
       "            0.22307692, 0.22307692, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.2769231 , 0.2846154 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.30769232, 0.32307693, 0.33076924,\n",
       "            0.33076924, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4076923 , 0.42307693,\n",
       "            0.42307693, 0.43076923, 0.43076923, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5692308 , 0.5769231 , 0.5846154 ,\n",
       "            0.5923077 , 0.5923077 , 0.6       , 0.6076923 , 0.6230769 ,\n",
       "            0.63076925, 0.63076925, 0.63076925, 0.63846153, 0.65384614,\n",
       "            0.6615385 , 0.6615385 , 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.7       , 0.7       ,\n",
       "            0.7153846 , 0.73846155, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.86923075, 0.86923075,\n",
       "            0.86923075, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9       , 0.9       ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.436 , 0.4355, 0.4321, 0.4316, 0.431 , 0.4307, 0.4304,\n",
       "            0.4297, 0.4287, 0.4272, 0.4255, 0.4246, 0.4243, 0.4219, 0.4214,\n",
       "            0.4202, 0.4197, 0.4187, 0.4182, 0.4177, 0.416 , 0.4158, 0.4148,\n",
       "            0.4146, 0.414 , 0.4128, 0.412 , 0.4116, 0.4111, 0.408 , 0.4077,\n",
       "            0.4067, 0.406 , 0.4058, 0.4053, 0.405 , 0.4048, 0.4045, 0.4043,\n",
       "            0.4036, 0.403 , 0.4028, 0.4026, 0.4023, 0.4019, 0.4011, 0.401 ,\n",
       "            0.4006, 0.4004, 0.4001, 0.3997, 0.3992, 0.399 , 0.3984, 0.3967,\n",
       "            0.3962, 0.396 , 0.3955, 0.3943, 0.3933, 0.3928, 0.3923, 0.3918,\n",
       "            0.3916, 0.391 , 0.3904, 0.3901, 0.3892, 0.3884, 0.388 , 0.3867,\n",
       "            0.3857, 0.3843, 0.384 , 0.3833, 0.3828, 0.3823, 0.382 , 0.3818,\n",
       "            0.3813, 0.3806, 0.3804, 0.38  , 0.379 , 0.3782, 0.378 , 0.3772,\n",
       "            0.3762, 0.376 , 0.375 , 0.3748, 0.3745, 0.3735, 0.3733, 0.373 ,\n",
       "            0.371 , 0.3708, 0.37  , 0.3699, 0.3696, 0.3694, 0.368 , 0.366 ,\n",
       "            0.365 , 0.3647, 0.3645, 0.3628, 0.3625, 0.362 , 0.3616, 0.361 ,\n",
       "            0.3606, 0.3604, 0.3596, 0.3591, 0.356 , 0.3557, 0.3552, 0.355 ,\n",
       "            0.354 , 0.3533, 0.351 , 0.3481, 0.3477, 0.3472, 0.344 , 0.3438,\n",
       "            0.343 , 0.3425, 0.3418, 0.341 , 0.3408, 0.339 , 0.3381, 0.3372,\n",
       "            0.336 , 0.3345, 0.3333, 0.3315, 0.3313, 0.3303, 0.3298, 0.328 ,\n",
       "            0.327 , 0.3242, 0.3235, 0.323 , 0.3228, 0.318 , 0.3176, 0.3154,\n",
       "            0.315 , 0.314 , 0.3137, 0.3135, 0.312 , 0.3118, 0.3115, 0.3105,\n",
       "            0.308 , 0.3079, 0.3076, 0.3062, 0.306 , 0.3057, 0.305 , 0.3008,\n",
       "            0.2969, 0.2964, 0.2932, 0.287 , 0.2866, 0.2864, 0.2834, 0.281 ,\n",
       "            0.2808, 0.28  , 0.2766, 0.2756, 0.2744, 0.2722, 0.268 , 0.2678,\n",
       "            0.2666, 0.266 , 0.2644, 0.2625, 0.2588, 0.2585, 0.2563, 0.2502,\n",
       "            0.2452, 0.2438, 0.2424, 0.2368, 0.2347, 0.233 , 0.2327, 0.2286,\n",
       "            0.2257, 0.2233, 0.2207, 0.2203, 0.2191, 0.219 , 0.2133, 0.2026,\n",
       "            0.1765, 0.1729, 0.1625, 0.149 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.075     , 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.1       , 0.10833333, 0.125     , 0.125     , 0.125     ,\n",
       "            0.125     , 0.125     , 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15      , 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.175     , 0.18333334,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.26666668, 0.26666668, 0.275     , 0.275     ,\n",
       "            0.275     , 0.275     , 0.28333333, 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.3       , 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.325     , 0.325     , 0.325     ,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.34166667, 0.35833332,\n",
       "            0.36666667, 0.375     , 0.38333333, 0.39166668, 0.40833333,\n",
       "            0.41666666, 0.425     , 0.425     , 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.78333336, 0.7916667 , 0.7916667 , 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.85833335, 0.85833335,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.11538462, 0.11538462, 0.12307692,\n",
       "            0.13076924, 0.13846155, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.17692308, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.24615385, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.32307693, 0.33076924, 0.33846155, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.3923077 , 0.4076923 ,\n",
       "            0.41538462, 0.41538462, 0.41538462, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46923077, 0.46923077,\n",
       "            0.46923077, 0.46923077, 0.47692308, 0.4846154 , 0.4846154 ,\n",
       "            0.4923077 , 0.5       , 0.50769234, 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.53846157, 0.54615384, 0.56153846, 0.5692308 ,\n",
       "            0.5692308 , 0.5692308 , 0.5846154 , 0.5923077 , 0.5923077 ,\n",
       "            0.5923077 , 0.5923077 , 0.6076923 , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7076923 , 0.7153846 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.75384617,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.497 , 0.4963, 0.4924, 0.4868, 0.485 , 0.4844, 0.483 ,\n",
       "            0.4824, 0.4814, 0.4778, 0.4766, 0.4746, 0.4736, 0.4727, 0.4722,\n",
       "            0.472 , 0.4702, 0.4695, 0.4688, 0.4666, 0.4656, 0.4648, 0.4636,\n",
       "            0.4634, 0.4622, 0.4617, 0.4597, 0.4585, 0.4583, 0.4573, 0.457 ,\n",
       "            0.456 , 0.4558, 0.4548, 0.4543, 0.454 , 0.4524, 0.4521, 0.4514,\n",
       "            0.4512, 0.451 , 0.4504, 0.45  , 0.4495, 0.4492, 0.4487, 0.4485,\n",
       "            0.4482, 0.4478, 0.4475, 0.4473, 0.447 , 0.4465, 0.4463, 0.446 ,\n",
       "            0.4458, 0.445 , 0.4448, 0.4443, 0.4438, 0.4436, 0.443 , 0.4421,\n",
       "            0.4417, 0.4414, 0.44  , 0.4385, 0.4377, 0.4375, 0.437 , 0.4368,\n",
       "            0.4365, 0.436 , 0.4358, 0.4355, 0.435 , 0.4348, 0.4333, 0.4329,\n",
       "            0.4326, 0.4304, 0.4302, 0.4294, 0.4275, 0.427 , 0.4263, 0.4243,\n",
       "            0.424 , 0.4238, 0.4236, 0.4224, 0.422 , 0.4219, 0.421 , 0.4197,\n",
       "            0.419 , 0.4187, 0.4185, 0.4175, 0.4172, 0.4163, 0.416 , 0.4155,\n",
       "            0.4153, 0.4143, 0.4124, 0.412 , 0.4119, 0.4116, 0.4104, 0.4102,\n",
       "            0.4097, 0.409 , 0.4082, 0.4077, 0.4065, 0.4058, 0.405 , 0.4048,\n",
       "            0.4038, 0.4036, 0.4014, 0.4011, 0.4004, 0.4001, 0.3975, 0.397 ,\n",
       "            0.396 , 0.3955, 0.3936, 0.391 , 0.3896, 0.3855, 0.385 , 0.3838,\n",
       "            0.3804, 0.3796, 0.3794, 0.3777, 0.3728, 0.3716, 0.3691, 0.3684,\n",
       "            0.3677, 0.367 , 0.3662, 0.3652, 0.3618, 0.3613, 0.3606, 0.3594,\n",
       "            0.3582, 0.358 , 0.3574, 0.3567, 0.3545, 0.354 , 0.3538, 0.3523,\n",
       "            0.3506, 0.3499, 0.3496, 0.3484, 0.346 , 0.3452, 0.3433, 0.342 ,\n",
       "            0.3418, 0.3398, 0.3345, 0.334 , 0.3328, 0.3296, 0.3293, 0.328 ,\n",
       "            0.3247, 0.324 , 0.3235, 0.32  , 0.3198, 0.319 , 0.3176, 0.3164,\n",
       "            0.3098, 0.3088, 0.3086, 0.3054, 0.3052, 0.305 , 0.304 , 0.3015,\n",
       "            0.3005, 0.3003, 0.297 , 0.2964, 0.2905, 0.2847, 0.2825, 0.279 ,\n",
       "            0.2744, 0.27  , 0.2695, 0.266 , 0.2656, 0.2646, 0.2605, 0.2598,\n",
       "            0.2517, 0.25  , 0.2474, 0.2375, 0.2346, 0.2224, 0.2186, 0.218 ,\n",
       "            0.2163, 0.213 , 0.2119, 0.2096, 0.1978, 0.1947, 0.1687, 0.1606,\n",
       "            0.1455], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.04166667, dtype=float32),\n",
       "    'tpr': array(0.2846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.06666667, 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.1       , 0.1       , 0.1       , 0.1       , 0.10833333,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.125     , 0.13333334,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15833333, 0.15833333, 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "            0.2       , 0.2       , 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.25      , 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.29166666, 0.3       , 0.3       , 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.40833333, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.525     , 0.53333336, 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.69166666, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.81666666, 0.81666666, 0.81666666, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.9166667 , 0.925     , 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.26923078, 0.26923078, 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.32307693, 0.33846155, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.42307693, 0.43076923, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.45384616, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.47692308, 0.4846154 , 0.4923077 , 0.4923077 ,\n",
       "            0.4923077 , 0.50769234, 0.50769234, 0.5153846 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.56153846, 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.5923077 , 0.6       , 0.6       ,\n",
       "            0.6230769 , 0.63076925, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.6769231 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.7692308 , 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8       , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86153847, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.567 , 0.5557, 0.5483, 0.5405, 0.5366, 0.5347, 0.533 ,\n",
       "            0.532 , 0.5303, 0.53  , 0.5283, 0.528 , 0.527 , 0.526 , 0.5244,\n",
       "            0.5234, 0.523 , 0.522 , 0.5195, 0.518 , 0.5176, 0.517 , 0.516 ,\n",
       "            0.515 , 0.5127, 0.511 , 0.5103, 0.51  , 0.509 , 0.5083, 0.5073,\n",
       "            0.507 , 0.506 , 0.5044, 0.5015, 0.501 , 0.5005, 0.5   , 0.498 ,\n",
       "            0.4976, 0.497 , 0.4968, 0.496 , 0.4956, 0.4944, 0.494 , 0.4937,\n",
       "            0.4934, 0.4927, 0.4924, 0.4922, 0.492 , 0.4915, 0.491 , 0.4907,\n",
       "            0.4897, 0.4888, 0.488 , 0.4875, 0.4873, 0.4868, 0.4856, 0.485 ,\n",
       "            0.4834, 0.4812, 0.4805, 0.4802, 0.4795, 0.4788, 0.4778, 0.4753,\n",
       "            0.475 , 0.4736, 0.4724, 0.4717, 0.471 , 0.4705, 0.47  , 0.469 ,\n",
       "            0.468 , 0.4668, 0.4656, 0.4644, 0.4639, 0.463 , 0.4624, 0.4617,\n",
       "            0.461 , 0.4602, 0.4595, 0.4592, 0.459 , 0.4585, 0.4573, 0.4565,\n",
       "            0.4563, 0.456 , 0.4558, 0.4543, 0.4534, 0.4526, 0.4492, 0.4485,\n",
       "            0.4473, 0.447 , 0.4446, 0.4438, 0.4424, 0.4417, 0.441 , 0.4387,\n",
       "            0.4382, 0.4363, 0.435 , 0.4343, 0.4314, 0.4297, 0.4292, 0.4263,\n",
       "            0.426 , 0.4238, 0.4236, 0.4216, 0.421 , 0.4202, 0.4192, 0.418 ,\n",
       "            0.417 , 0.4146, 0.413 , 0.409 , 0.4075, 0.4058, 0.4053, 0.4048,\n",
       "            0.4038, 0.4036, 0.4023, 0.3997, 0.3994, 0.399 , 0.3975, 0.3972,\n",
       "            0.397 , 0.392 , 0.3914, 0.3857, 0.3796, 0.3767, 0.3765, 0.3762,\n",
       "            0.37  , 0.365 , 0.3647, 0.361 , 0.3608, 0.3596, 0.3591, 0.3564,\n",
       "            0.353 , 0.3523, 0.349 , 0.3462, 0.344 , 0.3372, 0.3362, 0.333 ,\n",
       "            0.3308, 0.3303, 0.3298, 0.328 , 0.327 , 0.3262, 0.3257, 0.322 ,\n",
       "            0.3196, 0.3193, 0.316 , 0.3137, 0.31  , 0.308 , 0.3074, 0.3013,\n",
       "            0.298 , 0.2969, 0.2964, 0.2913, 0.2908, 0.2896, 0.286 , 0.276 ,\n",
       "            0.2708, 0.2676, 0.264 , 0.2544, 0.2502, 0.2458, 0.2405, 0.2278,\n",
       "            0.2266, 0.217 , 0.2129, 0.2123, 0.208 , 0.206 , 0.2021, 0.1971,\n",
       "            0.1831, 0.1605, 0.1544, 0.138 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.19166666, dtype=float32),\n",
       "    'tpr': array(0.7307692, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.06666667, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.06666667, 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.1       , 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.10833333, 0.10833333, 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.175     , 0.175     ,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.20833333, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.30833334, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.36666667, 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.43333334, 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.60833335, 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.73333335,\n",
       "            0.7416667 , 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.775     , 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.08461539, 0.09230769, 0.1       , 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.18461539, 0.1923077 ,\n",
       "            0.2       , 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26153848, 0.26923078,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.32307693, 0.33846155, 0.34615386, 0.36153847,\n",
       "            0.36923078, 0.36923078, 0.3923077 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.44615385, 0.45384616, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.50769234, 0.5153846 ,\n",
       "            0.5307692 , 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.56153846, 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.7307692 , 0.7307692 , 0.7307692 , 0.7307692 ,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 ,\n",
       "            0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.8230769 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9       , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6323, 0.6113, 0.601 , 0.5938, 0.5923, 0.588 , 0.585 ,\n",
       "            0.584 , 0.5835, 0.5815, 0.58  , 0.5796, 0.578 , 0.5757, 0.575 ,\n",
       "            0.574 , 0.5723, 0.571 , 0.5703, 0.569 , 0.568 , 0.567 , 0.5664,\n",
       "            0.565 , 0.564 , 0.5625, 0.562 , 0.561 , 0.56  , 0.5596, 0.5566,\n",
       "            0.5557, 0.5547, 0.5537, 0.553 , 0.5527, 0.5522, 0.551 , 0.5503,\n",
       "            0.55  , 0.5493, 0.549 , 0.5474, 0.546 , 0.5425, 0.542 , 0.5415,\n",
       "            0.541 , 0.5405, 0.538 , 0.5376, 0.5366, 0.536 , 0.535 , 0.5347,\n",
       "            0.534 , 0.5337, 0.533 , 0.5327, 0.532 , 0.531 , 0.5293, 0.528 ,\n",
       "            0.5273, 0.5264, 0.526 , 0.5254, 0.525 , 0.524 , 0.5215, 0.52  ,\n",
       "            0.519 , 0.5186, 0.518 , 0.517 , 0.5166, 0.516 , 0.5146, 0.5127,\n",
       "            0.5117, 0.51  , 0.509 , 0.5083, 0.508 , 0.507 , 0.5063, 0.5054,\n",
       "            0.5034, 0.5024, 0.502 , 0.5015, 0.4976, 0.4963, 0.4949, 0.4941,\n",
       "            0.4932, 0.4922, 0.4912, 0.491 , 0.4902, 0.4897, 0.4885, 0.4883,\n",
       "            0.4875, 0.4873, 0.487 , 0.4868, 0.485 , 0.484 , 0.4802, 0.4778,\n",
       "            0.4775, 0.4763, 0.475 , 0.4749, 0.4739, 0.4724, 0.4722, 0.472 ,\n",
       "            0.4685, 0.4658, 0.463 , 0.4624, 0.4607, 0.458 , 0.4546, 0.453 ,\n",
       "            0.4526, 0.4524, 0.4514, 0.4502, 0.4482, 0.4478, 0.4465, 0.4463,\n",
       "            0.445 , 0.444 , 0.4407, 0.4375, 0.4368, 0.4326, 0.431 , 0.43  ,\n",
       "            0.4263, 0.4238, 0.4216, 0.4207, 0.42  , 0.4197, 0.4172, 0.4167,\n",
       "            0.4158, 0.4065, 0.404 , 0.3933, 0.3843, 0.3828, 0.3826, 0.3752,\n",
       "            0.3713, 0.3708, 0.3691, 0.369 , 0.368 , 0.3647, 0.3643, 0.3623,\n",
       "            0.3604, 0.3572, 0.3555, 0.3516, 0.351 , 0.35  , 0.3484, 0.3464,\n",
       "            0.344 , 0.337 , 0.3347, 0.334 , 0.3335, 0.331 , 0.3303, 0.3281,\n",
       "            0.327 , 0.3257, 0.325 , 0.3245, 0.3167, 0.3147, 0.3088, 0.2996,\n",
       "            0.2974, 0.2927, 0.2915, 0.2864, 0.2825, 0.269 , 0.2678, 0.2515,\n",
       "            0.2482, 0.2429, 0.2355, 0.2335, 0.2246, 0.2185, 0.2153, 0.2103,\n",
       "            0.204 , 0.2031, 0.2006, 0.1946, 0.188 , 0.1752, 0.156 , 0.1519,\n",
       "            0.134 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.35, dtype=float32),\n",
       "    'tpr': array(0.8230769, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.075     , 0.075     , 0.08333334, 0.09166667, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.1       , 0.10833333, 0.10833333,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.125     , 0.125     , 0.13333334, 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15      , 0.15      , 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.16666667, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.18333334, 0.19166666, 0.19166666, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.225     , 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.25      , 0.25      ,\n",
       "            0.25      , 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "            0.26666668, 0.275     , 0.275     , 0.28333333, 0.29166666,\n",
       "            0.31666666, 0.325     , 0.325     , 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.375     , 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.46666667, 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.5833333 , 0.59166664, 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.675     , 0.68333334, 0.7       , 0.7       , 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.32307693, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.35384616, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3846154 , 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.41538462, 0.41538462, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.45384616, 0.45384616, 0.46153846,\n",
       "            0.47692308, 0.47692308, 0.4846154 , 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.5       , 0.50769234, 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.53846157, 0.54615384, 0.5538462 , 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6230769 , 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.64615387, 0.6615385 , 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.72307694, 0.72307694, 0.72307694, 0.72307694,\n",
       "            0.7307692 , 0.7307692 , 0.73846155, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8       , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.8230769 , 0.83076924, 0.8384615 ,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.84615386, 0.84615386,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.86923075, 0.8769231 , 0.8769231 , 0.88461536,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.8923077 , 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.95384616, 0.95384616,\n",
       "            0.95384616, 0.95384616, 0.95384616, 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.6885, 0.6606, 0.6484, 0.648 , 0.6387, 0.6357, 0.6343,\n",
       "            0.6323, 0.628 , 0.6265, 0.626 , 0.625 , 0.6216, 0.621 , 0.618 ,\n",
       "            0.6177, 0.6167, 0.615 , 0.6143, 0.6133, 0.613 , 0.6113, 0.611 ,\n",
       "            0.6104, 0.61  , 0.609 , 0.6084, 0.6045, 0.602 , 0.6016, 0.5996,\n",
       "            0.5986, 0.598 , 0.5977, 0.5967, 0.596 , 0.5947, 0.5938, 0.5933,\n",
       "            0.593 , 0.5913, 0.591 , 0.5903, 0.5884, 0.588 , 0.587 , 0.5864,\n",
       "            0.5854, 0.585 , 0.584 , 0.583 , 0.5815, 0.5806, 0.58  , 0.5796,\n",
       "            0.5786, 0.577 , 0.5747, 0.574 , 0.5737, 0.5728, 0.571 , 0.57  ,\n",
       "            0.5693, 0.569 , 0.5684, 0.5674, 0.5664, 0.566 , 0.5654, 0.565 ,\n",
       "            0.5645, 0.564 , 0.563 , 0.5625, 0.5615, 0.5605, 0.56  , 0.5566,\n",
       "            0.556 , 0.5557, 0.554 , 0.5537, 0.553 , 0.551 , 0.5503, 0.55  ,\n",
       "            0.549 , 0.5483, 0.5474, 0.5464, 0.546 , 0.545 , 0.5435, 0.5415,\n",
       "            0.54  , 0.539 , 0.536 , 0.533 , 0.5293, 0.529 , 0.5283, 0.528 ,\n",
       "            0.5264, 0.526 , 0.5254, 0.525 , 0.523 , 0.52  , 0.517 , 0.5156,\n",
       "            0.515 , 0.5146, 0.5137, 0.5127, 0.511 , 0.5107, 0.5103, 0.51  ,\n",
       "            0.502 , 0.5015, 0.4998, 0.4993, 0.498 , 0.4968, 0.4966, 0.4958,\n",
       "            0.4956, 0.494 , 0.4912, 0.4905, 0.4893, 0.4841, 0.483 , 0.4795,\n",
       "            0.479 , 0.4785, 0.4739, 0.4714, 0.4675, 0.4668, 0.4653, 0.4622,\n",
       "            0.4617, 0.4573, 0.4539, 0.4531, 0.4526, 0.4512, 0.4492, 0.4404,\n",
       "            0.4358, 0.4343, 0.4314, 0.4268, 0.4243, 0.4172, 0.4097, 0.4058,\n",
       "            0.4048, 0.4033, 0.393 , 0.3918, 0.3882, 0.388 , 0.3865, 0.3848,\n",
       "            0.378 , 0.3762, 0.376 , 0.375 , 0.3718, 0.3713, 0.3657, 0.3643,\n",
       "            0.364 , 0.361 , 0.3574, 0.3557, 0.3484, 0.3481, 0.3367, 0.3342,\n",
       "            0.334 , 0.3333, 0.331 , 0.3276, 0.3247, 0.3206, 0.317 , 0.3098,\n",
       "            0.2993, 0.2986, 0.2974, 0.2964, 0.2957, 0.293 , 0.27  , 0.2646,\n",
       "            0.2573, 0.2498, 0.2482, 0.236 , 0.2268, 0.2212, 0.2133, 0.2108,\n",
       "            0.208 , 0.2017, 0.1982, 0.1936, 0.1873, 0.1794, 0.1675, 0.1515,\n",
       "            0.1493, 0.1302], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.44166666, dtype=float32),\n",
       "    'tpr': array(0.88461536, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.11666667, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15      , 0.15      ,\n",
       "            0.15      , 0.15      , 0.15      , 0.15      , 0.15      ,\n",
       "            0.15833333, 0.175     , 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.23333333,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.275     , 0.275     ,\n",
       "            0.275     , 0.275     , 0.28333333, 0.28333333, 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.3       , 0.3       , 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.43333334, 0.43333334, 0.43333334, 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.45      , 0.45      , 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.6       , 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.8333333 , 0.84166664,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.11538462,\n",
       "            0.12307692, 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16923077, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.26923078, 0.2846154 , 0.2923077 , 0.3       ,\n",
       "            0.30769232, 0.32307693, 0.33076924, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3846154 ,\n",
       "            0.3846154 , 0.3846154 , 0.3923077 , 0.4076923 , 0.41538462,\n",
       "            0.43076923, 0.43846154, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.46153846, 0.46153846, 0.47692308, 0.47692308, 0.4846154 ,\n",
       "            0.4923077 , 0.50769234, 0.5153846 , 0.5153846 , 0.5307692 ,\n",
       "            0.53846157, 0.53846157, 0.54615384, 0.54615384, 0.56153846,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 , 0.5923077 ,\n",
       "            0.6076923 , 0.61538464, 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.6615385 , 0.66923076, 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7       , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.72307694, 0.7307692 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.8       , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.8769231 ,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7334, 0.701 , 0.694 , 0.6875, 0.678 , 0.6763, 0.6724,\n",
       "            0.669 , 0.667 , 0.6646, 0.664 , 0.6626, 0.661 , 0.658 , 0.657 ,\n",
       "            0.6567, 0.6553, 0.6533, 0.653 , 0.6523, 0.652 , 0.6514, 0.651 ,\n",
       "            0.6484, 0.647 , 0.646 , 0.6455, 0.645 , 0.643 , 0.642 , 0.64  ,\n",
       "            0.637 , 0.635 , 0.6343, 0.6333, 0.6323, 0.632 , 0.6313, 0.63  ,\n",
       "            0.6284, 0.628 , 0.6265, 0.6255, 0.625 , 0.623 , 0.6216, 0.621 ,\n",
       "            0.62  , 0.6167, 0.6157, 0.615 , 0.6143, 0.614 , 0.6123, 0.611 ,\n",
       "            0.6084, 0.607 , 0.606 , 0.6055, 0.605 , 0.604 , 0.6035, 0.6025,\n",
       "            0.6016, 0.599 , 0.5986, 0.5977, 0.5967, 0.596 , 0.5957, 0.595 ,\n",
       "            0.5947, 0.5938, 0.5923, 0.5913, 0.589 , 0.588 , 0.5864, 0.586 ,\n",
       "            0.584 , 0.5835, 0.583 , 0.582 , 0.581 , 0.5806, 0.58  , 0.5796,\n",
       "            0.577 , 0.5767, 0.5737, 0.573 , 0.57  , 0.5674, 0.567 , 0.5625,\n",
       "            0.562 , 0.5615, 0.56  , 0.5596, 0.5586, 0.558 , 0.5566, 0.554 ,\n",
       "            0.5537, 0.553 , 0.5527, 0.55  , 0.5493, 0.548 , 0.5454, 0.5435,\n",
       "            0.542 , 0.5415, 0.541 , 0.5386, 0.538 , 0.5376, 0.5356, 0.535 ,\n",
       "            0.5347, 0.5337, 0.5317, 0.5312, 0.5303, 0.526 , 0.5254, 0.5166,\n",
       "            0.5137, 0.513 , 0.512 , 0.5117, 0.511 , 0.5083, 0.5063, 0.5024,\n",
       "            0.4985, 0.4949, 0.494 , 0.491 , 0.4902, 0.4875, 0.4873, 0.4805,\n",
       "            0.4797, 0.4795, 0.4685, 0.4658, 0.4653, 0.4648, 0.4492, 0.4487,\n",
       "            0.4456, 0.4453, 0.438 , 0.4355, 0.4329, 0.432 , 0.4253, 0.4238,\n",
       "            0.4214, 0.4211, 0.4192, 0.413 , 0.4016, 0.3958, 0.393 , 0.3926,\n",
       "            0.388 , 0.386 , 0.385 , 0.3828, 0.3813, 0.379 , 0.3784, 0.3772,\n",
       "            0.366 , 0.3647, 0.361 , 0.3499, 0.3394, 0.3376, 0.335 , 0.3345,\n",
       "            0.333 , 0.3274, 0.3262, 0.324 , 0.3174, 0.3154, 0.3108, 0.3044,\n",
       "            0.3042, 0.2957, 0.2944, 0.2783, 0.2712, 0.2617, 0.252 , 0.2456,\n",
       "            0.2302, 0.2213, 0.2186, 0.2119, 0.2064, 0.2045, 0.2001, 0.1946,\n",
       "            0.188 , 0.1815, 0.1726, 0.1616, 0.1482, 0.1476, 0.1276],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.49166667, dtype=float32),\n",
       "    'tpr': array(0.9153846, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.1       , 0.1       ,\n",
       "            0.10833333, 0.10833333, 0.10833333, 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.13333334, 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15      , 0.15      ,\n",
       "            0.15      , 0.15      , 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.25833333, 0.26666668, 0.26666668, 0.26666668,\n",
       "            0.26666668, 0.275     , 0.275     , 0.275     , 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.3       , 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.34166667, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.51666665, 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.5833333 , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.60833335, 0.6166667 , 0.6166667 ,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.04615385, 0.05384615, 0.06153846, 0.07692308,\n",
       "            0.08461539, 0.09230769, 0.1       , 0.10769231, 0.12307692,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.17692308,\n",
       "            0.1923077 , 0.20769231, 0.21538462, 0.23076923, 0.23846154,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.30769232, 0.31538463, 0.33076924, 0.33846155,\n",
       "            0.33846155, 0.34615386, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.3846154 , 0.3923077 , 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.45384616, 0.46153846, 0.47692308,\n",
       "            0.47692308, 0.4923077 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5923077 , 0.6       , 0.61538464, 0.61538464,\n",
       "            0.61538464, 0.61538464, 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.72307694, 0.72307694,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.7846154 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8230769 , 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.8384615 , 0.84615386, 0.84615386, 0.84615386, 0.84615386,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.8769231 , 0.88461536, 0.88461536, 0.88461536, 0.88461536,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9153846 , 0.9153846 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 , 0.9307692 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.771 , 0.7363, 0.7314, 0.721 , 0.7144, 0.7134, 0.706 ,\n",
       "            0.705 , 0.7017, 0.6973, 0.697 , 0.695 , 0.693 , 0.6924, 0.6885,\n",
       "            0.6865, 0.686 , 0.6855, 0.6846, 0.683 , 0.6826, 0.681 , 0.6797,\n",
       "            0.679 , 0.678 , 0.6772, 0.676 , 0.6743, 0.674 , 0.6724, 0.6704,\n",
       "            0.6694, 0.666 , 0.6636, 0.6626, 0.6616, 0.6597, 0.6587, 0.658 ,\n",
       "            0.6567, 0.656 , 0.654 , 0.6533, 0.653 , 0.6514, 0.65  , 0.6475,\n",
       "            0.647 , 0.645 , 0.644 , 0.6436, 0.6416, 0.6406, 0.639 , 0.6387,\n",
       "            0.638 , 0.637 , 0.6367, 0.636 , 0.635 , 0.6333, 0.6323, 0.632 ,\n",
       "            0.628 , 0.6274, 0.627 , 0.6265, 0.626 , 0.625 , 0.6235, 0.623 ,\n",
       "            0.622 , 0.6216, 0.621 , 0.62  , 0.6187, 0.6177, 0.617 , 0.616 ,\n",
       "            0.6157, 0.615 , 0.6147, 0.612 , 0.611 , 0.6104, 0.6094, 0.608 ,\n",
       "            0.6055, 0.603 , 0.6025, 0.601 , 0.6006, 0.6   , 0.598 , 0.595 ,\n",
       "            0.594 , 0.593 , 0.5913, 0.591 , 0.5903, 0.59  , 0.589 , 0.5864,\n",
       "            0.586 , 0.5835, 0.5825, 0.5786, 0.578 , 0.5767, 0.576 , 0.5737,\n",
       "            0.5723, 0.572 , 0.5713, 0.571 , 0.5703, 0.567 , 0.5664, 0.562 ,\n",
       "            0.5605, 0.5596, 0.557 , 0.5566, 0.5557, 0.553 , 0.552 , 0.5396,\n",
       "            0.538 , 0.5376, 0.535 , 0.5337, 0.532 , 0.5293, 0.5283, 0.5254,\n",
       "            0.525 , 0.521 , 0.519 , 0.509 , 0.5083, 0.5073, 0.501 , 0.5   ,\n",
       "            0.495 , 0.4932, 0.483 , 0.4822, 0.4802, 0.4783, 0.4763, 0.473 ,\n",
       "            0.4646, 0.4617, 0.4592, 0.4583, 0.4543, 0.4526, 0.452 , 0.447 ,\n",
       "            0.4458, 0.4404, 0.4302, 0.4297, 0.4216, 0.4182, 0.4043, 0.4011,\n",
       "            0.3987, 0.3962, 0.3945, 0.3904, 0.3877, 0.3833, 0.3767, 0.3735,\n",
       "            0.3706, 0.354 , 0.345 , 0.3442, 0.3418, 0.3376, 0.3352, 0.3347,\n",
       "            0.3298, 0.326 , 0.321 , 0.317 , 0.315 , 0.313 , 0.304 , 0.2993,\n",
       "            0.298 , 0.2969, 0.2761, 0.2612, 0.2573, 0.247 , 0.228 , 0.2198,\n",
       "            0.2197, 0.2145, 0.2086, 0.2023, 0.202 , 0.1946, 0.1863, 0.1797,\n",
       "            0.1696, 0.1594, 0.1495, 0.1486, 0.1283], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.51666665, dtype=float32),\n",
       "    'tpr': array(0.93846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.1       , 0.1       ,\n",
       "            0.1       , 0.1       , 0.10833333, 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.16666667, 0.18333334,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.2       , 0.2       , 0.20833333, 0.225     ,\n",
       "            0.225     , 0.225     , 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.29166666, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.45      , 0.45833334, 0.475     , 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.56666666,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.59166664,\n",
       "            0.6       , 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.16923077, 0.18461539,\n",
       "            0.2       , 0.21538462, 0.22307692, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26923078, 0.2769231 , 0.2769231 , 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.33076924, 0.33076924,\n",
       "            0.33846155, 0.34615386, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.3846154 , 0.3923077 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.42307693, 0.43076923, 0.43076923, 0.43076923, 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.5153846 , 0.5153846 ,\n",
       "            0.52307695, 0.5307692 , 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.5538462 , 0.5538462 , 0.5538462 ,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.6       , 0.61538464,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.74615383, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.805 , 0.769 , 0.7666, 0.7534, 0.748 , 0.7476, 0.746 ,\n",
       "            0.739 , 0.7383, 0.7363, 0.735 , 0.734 , 0.729 , 0.728 , 0.7275,\n",
       "            0.725 , 0.723 , 0.722 , 0.7197, 0.7188, 0.7183, 0.717 , 0.7163,\n",
       "            0.715 , 0.7144, 0.7134, 0.713 , 0.7124, 0.7114, 0.7104, 0.71  ,\n",
       "            0.7085, 0.708 , 0.7075, 0.706 , 0.7036, 0.702 , 0.6987, 0.6973,\n",
       "            0.6934, 0.6914, 0.69  , 0.6895, 0.6885, 0.688 , 0.6865, 0.684 ,\n",
       "            0.681 , 0.6807, 0.678 , 0.6777, 0.6753, 0.675 , 0.6743, 0.674 ,\n",
       "            0.6733, 0.672 , 0.6714, 0.671 , 0.6704, 0.6694, 0.6685, 0.6675,\n",
       "            0.667 , 0.666 , 0.6655, 0.6616, 0.6606, 0.66  , 0.659 , 0.658 ,\n",
       "            0.6577, 0.6567, 0.6562, 0.6553, 0.654 , 0.6523, 0.6514, 0.6504,\n",
       "            0.65  , 0.649 , 0.6484, 0.647 , 0.6436, 0.6426, 0.642 , 0.6416,\n",
       "            0.6406, 0.637 , 0.635 , 0.6343, 0.633 , 0.6323, 0.632 , 0.631 ,\n",
       "            0.6284, 0.628 , 0.6274, 0.6265, 0.6255, 0.6245, 0.624 , 0.622 ,\n",
       "            0.6216, 0.6206, 0.6177, 0.617 , 0.6157, 0.615 , 0.613 , 0.6123,\n",
       "            0.6094, 0.6064, 0.606 , 0.6035, 0.6016, 0.601 , 0.6006, 0.5977,\n",
       "            0.597 , 0.5967, 0.5947, 0.5938, 0.5894, 0.587 , 0.583 , 0.576 ,\n",
       "            0.5713, 0.57  , 0.568 , 0.5664, 0.565 , 0.5645, 0.5615, 0.559 ,\n",
       "            0.554 , 0.548 , 0.5474, 0.5454, 0.544 , 0.538 , 0.5356, 0.534 ,\n",
       "            0.525 , 0.5234, 0.5225, 0.52  , 0.515 , 0.5127, 0.5073, 0.506 ,\n",
       "            0.4988, 0.4956, 0.492 , 0.4912, 0.4905, 0.489 , 0.4873, 0.4836,\n",
       "            0.4822, 0.4702, 0.4688, 0.468 , 0.464 , 0.4573, 0.4553, 0.455 ,\n",
       "            0.4504, 0.4482, 0.425 , 0.4092, 0.409 , 0.405 , 0.4036, 0.398 ,\n",
       "            0.3953, 0.391 , 0.3887, 0.38  , 0.3755, 0.357 , 0.3538, 0.349 ,\n",
       "            0.3489, 0.347 , 0.3418, 0.3394, 0.3357, 0.3308, 0.3286, 0.3274,\n",
       "            0.3262, 0.3228, 0.3203, 0.3176, 0.3027, 0.299 , 0.2969, 0.2793,\n",
       "            0.2612, 0.259 , 0.2462, 0.224 , 0.2191, 0.2162, 0.2152, 0.209 ,\n",
       "            0.2026, 0.1978, 0.1927, 0.1827, 0.1761, 0.1649, 0.1555, 0.1495,\n",
       "            0.1471, 0.1272], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.55833334, dtype=float32),\n",
       "    'tpr': array(0.96153843, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.09166667, 0.09166667, 0.09166667, 0.09166667,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.125     , 0.14166667,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.16666667, 0.175     ,\n",
       "            0.175     , 0.175     , 0.175     , 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "            0.2       , 0.2       , 0.2       , 0.2       , 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.23333333, 0.25833333,\n",
       "            0.25833333, 0.25833333, 0.25833333, 0.26666668, 0.26666668,\n",
       "            0.275     , 0.275     , 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.3       , 0.3       , 0.3       ,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.375     , 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45833334, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.5416667 , 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.55833334, 0.56666666, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.00769231, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.05384615, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13846155,\n",
       "            0.14615385, 0.15384616, 0.16153847, 0.16923077, 0.17692308,\n",
       "            0.18461539, 0.1923077 , 0.20769231, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2923077 , 0.30769232, 0.31538463, 0.31538463,\n",
       "            0.33076924, 0.33846155, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36923078, 0.3846154 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.43076923, 0.43846154, 0.44615385, 0.44615385,\n",
       "            0.45384616, 0.46153846, 0.47692308, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.50769234, 0.5153846 , 0.5307692 ,\n",
       "            0.5307692 , 0.5307692 , 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5692308 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9       , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.96153843, 0.9692308 , 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8354, 0.7993, 0.7983, 0.7837, 0.7803, 0.779 , 0.7773,\n",
       "            0.7705, 0.7695, 0.7686, 0.768 , 0.7646, 0.7603, 0.759 , 0.7573,\n",
       "            0.756 , 0.7544, 0.754 , 0.752 , 0.7515, 0.751 , 0.75  , 0.7476,\n",
       "            0.747 , 0.746 , 0.745 , 0.7446, 0.7437, 0.7427, 0.742 , 0.741 ,\n",
       "            0.7407, 0.7397, 0.7383, 0.738 , 0.7373, 0.737 , 0.7324, 0.731 ,\n",
       "            0.73  , 0.723 , 0.7217, 0.7207, 0.7197, 0.719 , 0.718 , 0.714 ,\n",
       "            0.7095, 0.708 , 0.7075, 0.707 , 0.706 , 0.7056, 0.7046, 0.702 ,\n",
       "            0.7017, 0.701 , 0.7007, 0.6987, 0.698 , 0.6978, 0.6973, 0.6963,\n",
       "            0.695 , 0.6943, 0.693 , 0.6914, 0.6904, 0.69  , 0.689 , 0.688 ,\n",
       "            0.687 , 0.6855, 0.684 , 0.6836, 0.682 , 0.681 , 0.68  , 0.679 ,\n",
       "            0.678 , 0.6777, 0.6772, 0.6763, 0.675 , 0.672 , 0.6704, 0.6694,\n",
       "            0.669 , 0.6685, 0.667 , 0.6636, 0.663 , 0.6606, 0.6597, 0.6587,\n",
       "            0.658 , 0.657 , 0.656 , 0.6553, 0.655 , 0.6543, 0.653 , 0.6523,\n",
       "            0.65  , 0.649 , 0.645 , 0.6436, 0.641 , 0.64  , 0.639 , 0.6387,\n",
       "            0.637 , 0.6357, 0.6294, 0.629 , 0.6284, 0.628 , 0.6274, 0.626 ,\n",
       "            0.6206, 0.6157, 0.6104, 0.608 , 0.6045, 0.598 , 0.5957, 0.595 ,\n",
       "            0.594 , 0.5923, 0.5913, 0.589 , 0.5835, 0.5757, 0.57  , 0.5664,\n",
       "            0.5635, 0.561 , 0.559 , 0.5557, 0.554 , 0.5503, 0.548 , 0.542 ,\n",
       "            0.5376, 0.536 , 0.5356, 0.5293, 0.527 , 0.5244, 0.524 , 0.5186,\n",
       "            0.515 , 0.5127, 0.5034, 0.502 , 0.4985, 0.4973, 0.4897, 0.4893,\n",
       "            0.4856, 0.4841, 0.4822, 0.4778, 0.464 , 0.4558, 0.4465, 0.4246,\n",
       "            0.4158, 0.4143, 0.408 , 0.4065, 0.406 , 0.4036, 0.393 , 0.3865,\n",
       "            0.3801, 0.3738, 0.3599, 0.3555, 0.3545, 0.3535, 0.3528, 0.3496,\n",
       "            0.341 , 0.3394, 0.3362, 0.3318, 0.3284, 0.3267, 0.325 , 0.3206,\n",
       "            0.3066, 0.3   , 0.2969, 0.283 , 0.2659, 0.2568, 0.246 , 0.2205,\n",
       "            0.2191, 0.2167, 0.213 , 0.2103, 0.2039, 0.1941, 0.1917, 0.1797,\n",
       "            0.173 , 0.1609, 0.1523, 0.1506, 0.1466, 0.1272], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5833333, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00833333, 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "            0.1       , 0.11666667, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "            0.175     , 0.18333334, 0.18333334, 0.19166666, 0.2       ,\n",
       "            0.2       , 0.2       , 0.2       , 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25      , 0.25833333, 0.25833333, 0.25833333, 0.26666668,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.3       , 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.375     , 0.375     , 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.475     , 0.475     , 0.48333332, 0.49166667,\n",
       "            0.49166667, 0.5083333 , 0.51666665, 0.525     , 0.525     ,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.5416667 , 0.5416667 ,\n",
       "            0.55      , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7       , 0.7083333 , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.02307692, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.18461539, 0.2       ,\n",
       "            0.20769231, 0.20769231, 0.21538462, 0.22307692, 0.23846154,\n",
       "            0.25384617, 0.26153848, 0.26923078, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.30769232, 0.30769232, 0.31538463,\n",
       "            0.33076924, 0.33846155, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36923078, 0.37692308, 0.3846154 , 0.3846154 , 0.3923077 ,\n",
       "            0.4       , 0.41538462, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.44615385, 0.45384616, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.50769234, 0.50769234, 0.50769234, 0.5153846 ,\n",
       "            0.5307692 , 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.56153846, 0.56153846,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.63076925, 0.63846153, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.6923077 , 0.7076923 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.7307692 , 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.77692306, 0.7846154 ,\n",
       "            0.7846154 , 0.7923077 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.859 , 0.823 , 0.8076, 0.805 , 0.8037, 0.802 , 0.797 ,\n",
       "            0.7954, 0.7944, 0.792 , 0.789 , 0.786 , 0.7827, 0.7812, 0.781 ,\n",
       "            0.7803, 0.7793, 0.778 , 0.776 , 0.7754, 0.775 , 0.772 , 0.7715,\n",
       "            0.771 , 0.7705, 0.77  , 0.768 , 0.767 , 0.7666, 0.766 , 0.765 ,\n",
       "            0.7646, 0.763 , 0.7627, 0.7617, 0.761 , 0.7607, 0.758 , 0.757 ,\n",
       "            0.755 , 0.7495, 0.747 , 0.7466, 0.7446, 0.743 , 0.7417, 0.741 ,\n",
       "            0.7383, 0.7363, 0.736 , 0.7324, 0.7314, 0.731 , 0.73  , 0.729 ,\n",
       "            0.7285, 0.728 , 0.7275, 0.726 , 0.725 , 0.7236, 0.723 , 0.722 ,\n",
       "            0.7217, 0.721 , 0.7207, 0.72  , 0.7197, 0.719 , 0.7188, 0.7183,\n",
       "            0.718 , 0.7153, 0.7144, 0.714 , 0.7134, 0.711 , 0.7104, 0.709 ,\n",
       "            0.7085, 0.7075, 0.7065, 0.7056, 0.704 , 0.7036, 0.702 , 0.7017,\n",
       "            0.6997, 0.699 , 0.6978, 0.6953, 0.693 , 0.6924, 0.691 , 0.689 ,\n",
       "            0.688 , 0.6875, 0.687 , 0.686 , 0.6846, 0.684 , 0.683 , 0.6826,\n",
       "            0.6816, 0.6807, 0.6797, 0.679 , 0.678 , 0.6777, 0.6772, 0.677 ,\n",
       "            0.6763, 0.6743, 0.674 , 0.673 , 0.67  , 0.6694, 0.6685, 0.666 ,\n",
       "            0.664 , 0.663 , 0.66  , 0.6587, 0.657 , 0.656 , 0.6553, 0.653 ,\n",
       "            0.6523, 0.652 , 0.649 , 0.6406, 0.6333, 0.633 , 0.6304, 0.629 ,\n",
       "            0.6284, 0.619 , 0.614 , 0.6113, 0.6084, 0.604 , 0.5996, 0.5986,\n",
       "            0.5913, 0.5854, 0.584 , 0.5796, 0.5767, 0.576 , 0.574 , 0.572 ,\n",
       "            0.5713, 0.5664, 0.5625, 0.5615, 0.554 , 0.5503, 0.5483, 0.542 ,\n",
       "            0.539 , 0.535 , 0.5293, 0.5283, 0.519 , 0.513 , 0.5127, 0.512 ,\n",
       "            0.51  , 0.508 , 0.5063, 0.493 , 0.486 , 0.472 , 0.465 , 0.4626,\n",
       "            0.438 , 0.4226, 0.4216, 0.42  , 0.4128, 0.412 , 0.4104, 0.3972,\n",
       "            0.392 , 0.391 , 0.3845, 0.3792, 0.3623, 0.3591, 0.3577, 0.3572,\n",
       "            0.3562, 0.3496, 0.3423, 0.3367, 0.3354, 0.3325, 0.327 , 0.3267,\n",
       "            0.323 , 0.3098, 0.301 , 0.2966, 0.2861, 0.2698, 0.2544, 0.2456,\n",
       "            0.2189, 0.2177, 0.217 , 0.211 , 0.2101, 0.2047, 0.1904, 0.177 ,\n",
       "            0.17  , 0.1571, 0.1512, 0.1492, 0.1458, 0.1268], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.59166664, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.00833333, 0.00833333, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.075     , 0.08333334,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.09166667, 0.09166667,\n",
       "            0.1       , 0.10833333, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.13333334, 0.14166667, 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.175     , 0.175     , 0.175     ,\n",
       "            0.175     , 0.175     , 0.19166666, 0.2       , 0.2       ,\n",
       "            0.2       , 0.20833333, 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.21666667, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25      , 0.25      ,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.3       , 0.3       , 0.3       ,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.325     , 0.325     ,\n",
       "            0.325     , 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.375     , 0.375     , 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.43333334, 0.44166666,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.5083333 , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.525     , 0.525     , 0.53333336,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.68333334,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.12307692, 0.13076924, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.17692308, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.24615385, 0.25384617, 0.26153848, 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.3       , 0.30769232, 0.30769232,\n",
       "            0.31538463, 0.32307693, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3846154 , 0.3923077 , 0.4076923 , 0.4076923 , 0.4076923 ,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.43846154, 0.44615385,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46923077, 0.47692308,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.50769234, 0.50769234,\n",
       "            0.5153846 , 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.5692308 , 0.5769231 ,\n",
       "            0.5923077 , 0.5923077 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.63846153, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.7923077 , 0.7923077 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 ,\n",
       "            0.83076924, 0.83076924, 0.83076924, 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.95384616, 0.96153843,\n",
       "            0.96153843, 0.96153843, 0.9692308 , 0.97692305, 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8794, 0.846 , 0.8447, 0.8296, 0.8286, 0.826 , 0.824 ,\n",
       "            0.8223, 0.8184, 0.818 , 0.8145, 0.812 , 0.81  , 0.806 , 0.805 ,\n",
       "            0.803 , 0.8022, 0.8003, 0.7993, 0.7983, 0.798 , 0.7974, 0.796 ,\n",
       "            0.7954, 0.7944, 0.7935, 0.793 , 0.7925, 0.7915, 0.789 , 0.7886,\n",
       "            0.788 , 0.7876, 0.787 , 0.7866, 0.784 , 0.7837, 0.783 , 0.7827,\n",
       "            0.7803, 0.7793, 0.779 , 0.774 , 0.771 , 0.7666, 0.7656, 0.765 ,\n",
       "            0.764 , 0.7637, 0.761 , 0.7607, 0.758 , 0.757 , 0.7554, 0.755 ,\n",
       "            0.7544, 0.754 , 0.7534, 0.752 , 0.7515, 0.751 , 0.75  , 0.7495,\n",
       "            0.748 , 0.7476, 0.7466, 0.7446, 0.744 , 0.7437, 0.7427, 0.7417,\n",
       "            0.741 , 0.7407, 0.74  , 0.7393, 0.7383, 0.736 , 0.734 , 0.733 ,\n",
       "            0.732 , 0.7314, 0.729 , 0.7275, 0.727 , 0.7256, 0.7236, 0.721 ,\n",
       "            0.719 , 0.7183, 0.718 , 0.716 , 0.7153, 0.714 , 0.7134, 0.713 ,\n",
       "            0.7124, 0.7114, 0.71  , 0.7075, 0.706 , 0.7056, 0.705 , 0.7036,\n",
       "            0.703 , 0.7026, 0.702 , 0.7007, 0.6997, 0.6978, 0.6973, 0.696 ,\n",
       "            0.692 , 0.691 , 0.6875, 0.6855, 0.684 , 0.682 , 0.678 , 0.6772,\n",
       "            0.6763, 0.676 , 0.675 , 0.669 , 0.6606, 0.6597, 0.657 , 0.6514,\n",
       "            0.65  , 0.645 , 0.6426, 0.642 , 0.6416, 0.6357, 0.632 , 0.628 ,\n",
       "            0.6255, 0.623 , 0.6196, 0.6147, 0.614 , 0.6064, 0.6045, 0.603 ,\n",
       "            0.599 , 0.596 , 0.593 , 0.591 , 0.588 , 0.5854, 0.582 , 0.58  ,\n",
       "            0.5757, 0.5684, 0.565 , 0.563 , 0.56  , 0.557 , 0.548 , 0.5464,\n",
       "            0.541 , 0.5405, 0.5337, 0.526 , 0.5234, 0.523 , 0.516 , 0.503 ,\n",
       "            0.4944, 0.4834, 0.4795, 0.4695, 0.451 , 0.4326, 0.4302, 0.4287,\n",
       "            0.4194, 0.417 , 0.4165, 0.4082, 0.402 , 0.4019, 0.3975, 0.3884,\n",
       "            0.3645, 0.3635, 0.3623, 0.362 , 0.3606, 0.3591, 0.3435, 0.3416,\n",
       "            0.337 , 0.3335, 0.3281, 0.3267, 0.325 , 0.3125, 0.3015, 0.2961,\n",
       "            0.2883, 0.2727, 0.2524, 0.2448, 0.218 , 0.2179, 0.2137, 0.2109,\n",
       "            0.207 , 0.2045, 0.1885, 0.1866, 0.1737, 0.1669, 0.1532, 0.1509,\n",
       "            0.1459, 0.1442, 0.1257], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.60833335, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.00833333, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.06666667, 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.10833333, 0.10833333,\n",
       "            0.11666667, 0.11666667, 0.125     , 0.13333334, 0.14166667,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.16666667, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.2       , 0.2       ,\n",
       "            0.2       , 0.2       , 0.2       , 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.225     , 0.225     , 0.225     ,\n",
       "            0.24166666, 0.25      , 0.25      , 0.25      , 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.28333333,\n",
       "            0.29166666, 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.44166666, 0.44166666, 0.45      , 0.45      , 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5       , 0.5       , 0.5083333 ,\n",
       "            0.5083333 , 0.5083333 , 0.51666665, 0.525     , 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.65833336, 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13076924, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.17692308, 0.18461539, 0.1923077 , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23846154, 0.26923078, 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.2846154 , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.34615386, 0.35384616,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.3846154 , 0.3923077 ,\n",
       "            0.3923077 , 0.4       , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.42307693, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.45384616, 0.46153846, 0.46153846, 0.46153846, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.4923077 , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.54615384,\n",
       "            0.54615384, 0.56153846, 0.56153846, 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.61538464, 0.63076925, 0.63846153, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6923077 , 0.7       , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.72307694, 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.86153847, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9076923 , 0.9076923 , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.97692305, 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.8975, 0.8667, 0.865 , 0.85  , 0.847 , 0.8457, 0.8403,\n",
       "            0.84  , 0.836 , 0.8335, 0.8325, 0.8306, 0.8267, 0.8257, 0.825 ,\n",
       "            0.8247, 0.8213, 0.821 , 0.8203, 0.819 , 0.8184, 0.8174, 0.817 ,\n",
       "            0.8154, 0.815 , 0.814 , 0.8105, 0.8096, 0.809 , 0.8076, 0.8066,\n",
       "            0.8057, 0.8047, 0.8022, 0.802 , 0.8013, 0.798 , 0.7944, 0.788 ,\n",
       "            0.787 , 0.7866, 0.786 , 0.785 , 0.7847, 0.783 , 0.7812, 0.781 ,\n",
       "            0.7793, 0.779 , 0.7773, 0.777 , 0.7764, 0.776 , 0.7744, 0.7734,\n",
       "            0.773 , 0.7725, 0.772 , 0.7715, 0.771 , 0.7705, 0.77  , 0.768 ,\n",
       "            0.766 , 0.7656, 0.7637, 0.763 , 0.7627, 0.762 , 0.7617, 0.761 ,\n",
       "            0.76  , 0.7583, 0.758 , 0.7573, 0.7563, 0.755 , 0.754 , 0.751 ,\n",
       "            0.75  , 0.7495, 0.7485, 0.7456, 0.744 , 0.742 , 0.7417, 0.7407,\n",
       "            0.74  , 0.7393, 0.738 , 0.7363, 0.735 , 0.7344, 0.7334, 0.7305,\n",
       "            0.7295, 0.7285, 0.727 , 0.726 , 0.7256, 0.7246, 0.724 , 0.7236,\n",
       "            0.72  , 0.719 , 0.7188, 0.718 , 0.7173, 0.7124, 0.7114, 0.7104,\n",
       "            0.709 , 0.7085, 0.708 , 0.707 , 0.701 , 0.699 , 0.6978, 0.6973,\n",
       "            0.689 , 0.686 , 0.68  , 0.671 , 0.67  , 0.669 , 0.6655, 0.6646,\n",
       "            0.6577, 0.656 , 0.654 , 0.647 , 0.644 , 0.6436, 0.6406, 0.6357,\n",
       "            0.632 , 0.6313, 0.631 , 0.629 , 0.6284, 0.6265, 0.613 , 0.6094,\n",
       "            0.6055, 0.602 , 0.5996, 0.5977, 0.5933, 0.5894, 0.589 , 0.58  ,\n",
       "            0.5767, 0.5737, 0.5728, 0.561 , 0.558 , 0.553 , 0.547 , 0.5347,\n",
       "            0.527 , 0.5156, 0.505 , 0.5044, 0.4895, 0.4783, 0.4668, 0.4487,\n",
       "            0.4407, 0.4363, 0.4307, 0.4294, 0.4287, 0.4265, 0.4229, 0.4082,\n",
       "            0.4055, 0.395 , 0.372 , 0.3716, 0.3704, 0.3694, 0.3667, 0.3508,\n",
       "            0.3472, 0.3396, 0.3367, 0.3325, 0.3298, 0.3293, 0.3184, 0.3047,\n",
       "            0.2983, 0.294 , 0.279 , 0.2527, 0.2467, 0.2212, 0.22  , 0.214 ,\n",
       "            0.2128, 0.2075, 0.2064, 0.1896, 0.1855, 0.1731, 0.1661, 0.1536,\n",
       "            0.1516, 0.1454, 0.1449, 0.1271], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.60833335, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.075     ,\n",
       "            0.09166667, 0.1       , 0.1       , 0.10833333, 0.11666667,\n",
       "            0.125     , 0.125     , 0.125     , 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.175     , 0.19166666, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.2       , 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.225     ,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25833333, 0.25833333, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.44166666, 0.44166666,\n",
       "            0.45      , 0.45      , 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5       , 0.5       , 0.5083333 , 0.51666665,\n",
       "            0.525     , 0.53333336, 0.5416667 , 0.55      , 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.64166665, 0.65      , 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.03076923,\n",
       "            0.03846154, 0.04615385, 0.06153846, 0.06923077, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.16153847, 0.16923077, 0.18461539,\n",
       "            0.1923077 , 0.2       , 0.20769231, 0.21538462, 0.22307692,\n",
       "            0.23076923, 0.23846154, 0.24615385, 0.26923078, 0.2769231 ,\n",
       "            0.2769231 , 0.2846154 , 0.2846154 , 0.30769232, 0.31538463,\n",
       "            0.32307693, 0.33076924, 0.33846155, 0.33846155, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.36923078, 0.37692308, 0.3846154 ,\n",
       "            0.3923077 , 0.3923077 , 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.44615385, 0.45384616, 0.46153846, 0.46153846, 0.4846154 ,\n",
       "            0.4923077 , 0.4923077 , 0.5       , 0.5       , 0.5       ,\n",
       "            0.50769234, 0.5153846 , 0.52307695, 0.5307692 , 0.53846157,\n",
       "            0.5538462 , 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5923077 , 0.5923077 , 0.6076923 , 0.61538464,\n",
       "            0.6230769 , 0.63076925, 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.66923076, 0.66923076, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.7153846 , 0.72307694, 0.7307692 ,\n",
       "            0.7307692 , 0.74615383, 0.75384617, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.77692306, 0.7846154 , 0.7923077 ,\n",
       "            0.8       , 0.8       , 0.8       , 0.8       , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.8384615 , 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86153847, 0.86923075, 0.88461536, 0.8923077 ,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9153846 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.9692308 ,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.914 , 0.8853, 0.8833, 0.869 , 0.8667, 0.8657, 0.86  ,\n",
       "            0.856 , 0.853 , 0.8467, 0.846 , 0.8457, 0.8447, 0.844 , 0.8423,\n",
       "            0.842 , 0.841 , 0.84  , 0.8384, 0.8374, 0.8364, 0.836 , 0.8354,\n",
       "            0.834 , 0.832 , 0.8306, 0.83  , 0.8296, 0.829 , 0.8286, 0.8276,\n",
       "            0.826 , 0.8247, 0.823 , 0.8228, 0.8223, 0.82  , 0.8164, 0.816 ,\n",
       "            0.8105, 0.8086, 0.8076, 0.8066, 0.806 , 0.8057, 0.8037, 0.803 ,\n",
       "            0.8027, 0.8022, 0.802 , 0.8013, 0.799 , 0.7983, 0.798 , 0.797 ,\n",
       "            0.796 , 0.795 , 0.794 , 0.7915, 0.791 , 0.7905, 0.788 , 0.7876,\n",
       "            0.787 , 0.7866, 0.7856, 0.785 , 0.7847, 0.784 , 0.783 , 0.7827,\n",
       "            0.7817, 0.7803, 0.78  , 0.7793, 0.7773, 0.7754, 0.772 , 0.7705,\n",
       "            0.77  , 0.769 , 0.7676, 0.766 , 0.7656, 0.7646, 0.7627, 0.762 ,\n",
       "            0.7607, 0.76  , 0.7593, 0.759 , 0.7583, 0.758 , 0.7573, 0.7554,\n",
       "            0.7544, 0.7534, 0.7524, 0.75  , 0.7495, 0.7485, 0.746 , 0.745 ,\n",
       "            0.744 , 0.743 , 0.7417, 0.7393, 0.7383, 0.7373, 0.736 , 0.7334,\n",
       "            0.7314, 0.73  , 0.7295, 0.7275, 0.7246, 0.7217, 0.7197, 0.717 ,\n",
       "            0.713 , 0.712 , 0.7085, 0.699 , 0.6953, 0.6904, 0.6895, 0.6885,\n",
       "            0.6865, 0.6855, 0.6816, 0.679 , 0.6777, 0.673 , 0.67  , 0.6655,\n",
       "            0.6606, 0.659 , 0.6587, 0.6577, 0.657 , 0.654 , 0.652 , 0.643 ,\n",
       "            0.6367, 0.6265, 0.621 , 0.6196, 0.619 , 0.6167, 0.614 , 0.6104,\n",
       "            0.6035, 0.603 , 0.591 , 0.588 , 0.587 , 0.571 , 0.568 , 0.5654,\n",
       "            0.547 , 0.5464, 0.5376, 0.5283, 0.527 , 0.515 , 0.5   , 0.4878,\n",
       "            0.4834, 0.4653, 0.4597, 0.4517, 0.4512, 0.4448, 0.4385, 0.4365,\n",
       "            0.4302, 0.4153, 0.4143, 0.402 , 0.386 , 0.3813, 0.3782, 0.3774,\n",
       "            0.375 , 0.3735, 0.361 , 0.3518, 0.3433, 0.3406, 0.3376, 0.3354,\n",
       "            0.3325, 0.3247, 0.3088, 0.3013, 0.3003, 0.2864, 0.2537, 0.2494,\n",
       "            0.2255, 0.2229, 0.2179, 0.2128, 0.2113, 0.2068, 0.1913, 0.1852,\n",
       "            0.1735, 0.1664, 0.157 , 0.151 , 0.1473, 0.1448, 0.1294],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6166667, dtype=float32),\n",
       "    'tpr': array(0.9846154, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.00833333,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.08333334, 0.09166667, 0.1       , 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.125     , 0.125     ,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.15      ,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.18333334,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.2       , 0.2       , 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.225     ,\n",
       "            0.225     , 0.225     , 0.225     , 0.23333333, 0.23333333,\n",
       "            0.25      , 0.26666668, 0.26666668, 0.275     , 0.275     ,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.31666666, 0.325     , 0.325     , 0.325     ,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35      , 0.35833332,\n",
       "            0.36666667, 0.375     , 0.375     , 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.39166668, 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.43333334, 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.48333332, 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.02307692,\n",
       "            0.03076923, 0.03846154, 0.04615385, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.11538462,\n",
       "            0.12307692, 0.13076924, 0.13846155, 0.14615385, 0.15384616,\n",
       "            0.16923077, 0.1923077 , 0.20769231, 0.20769231, 0.21538462,\n",
       "            0.23076923, 0.23846154, 0.23846154, 0.26153848, 0.2769231 ,\n",
       "            0.2846154 , 0.2846154 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.33076924, 0.33846155, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.3923077 ,\n",
       "            0.4       , 0.4       , 0.41538462, 0.41538462, 0.41538462,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.43076923, 0.44615385,\n",
       "            0.46153846, 0.46153846, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.5       ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.5538462 , 0.56153846, 0.5692308 , 0.5769231 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.5923077 , 0.5923077 ,\n",
       "            0.6       , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.63846153, 0.64615387, 0.65384614, 0.65384614, 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.6923077 , 0.7       ,\n",
       "            0.72307694, 0.7307692 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.74615383, 0.75384617, 0.75384617, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8       , 0.8076923 , 0.8076923 , 0.8153846 , 0.8153846 ,\n",
       "            0.8230769 , 0.8230769 , 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9153846 , 0.9153846 ,\n",
       "            0.9230769 , 0.9230769 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.928 , 0.902 , 0.9   , 0.8867, 0.886 , 0.8843, 0.8833,\n",
       "            0.878 , 0.8735, 0.873 , 0.8716, 0.871 , 0.8657, 0.8643, 0.8633,\n",
       "            0.863 , 0.862 , 0.8604, 0.8594, 0.859 , 0.857 , 0.856 , 0.8555,\n",
       "            0.854 , 0.852 , 0.85  , 0.849 , 0.848 , 0.8477, 0.846 , 0.845 ,\n",
       "            0.8438, 0.8433, 0.843 , 0.842 , 0.8403, 0.8364, 0.836 , 0.834 ,\n",
       "            0.8286, 0.8276, 0.827 , 0.826 , 0.8257, 0.8247, 0.824 , 0.823 ,\n",
       "            0.8228, 0.822 , 0.8193, 0.8184, 0.818 , 0.8174, 0.8164, 0.8154,\n",
       "            0.815 , 0.8135, 0.813 , 0.812 , 0.8115, 0.811 , 0.8105, 0.81  ,\n",
       "            0.807 , 0.806 , 0.8057, 0.805 , 0.8047, 0.8037, 0.803 , 0.8027,\n",
       "            0.802 , 0.8013, 0.801 , 0.7993, 0.798 , 0.797 , 0.796 , 0.795 ,\n",
       "            0.7925, 0.792 , 0.791 , 0.79  , 0.7896, 0.7886, 0.788 , 0.786 ,\n",
       "            0.784 , 0.783 , 0.782 , 0.78  , 0.7773, 0.777 , 0.776 , 0.7744,\n",
       "            0.774 , 0.771 , 0.7705, 0.7686, 0.7666, 0.765 , 0.764 , 0.763 ,\n",
       "            0.762 , 0.76  , 0.759 , 0.7573, 0.7563, 0.756 , 0.7534, 0.7495,\n",
       "            0.748 , 0.7476, 0.7466, 0.743 , 0.7407, 0.738 , 0.736 , 0.735 ,\n",
       "            0.7275, 0.7183, 0.718 , 0.71  , 0.7075, 0.706 , 0.7036, 0.7   ,\n",
       "            0.6987, 0.6904, 0.689 , 0.688 , 0.687 , 0.6855, 0.685 , 0.6807,\n",
       "            0.677 , 0.675 , 0.6714, 0.6675, 0.6626, 0.6523, 0.6484, 0.647 ,\n",
       "            0.6396, 0.634 , 0.6323, 0.6304, 0.6274, 0.616 , 0.613 , 0.6035,\n",
       "            0.599 , 0.5874, 0.5825, 0.577 , 0.558 , 0.5566, 0.548 , 0.5474,\n",
       "            0.54  , 0.525 , 0.5093, 0.4985, 0.4963, 0.4873, 0.4807, 0.4717,\n",
       "            0.4614, 0.4526, 0.4473, 0.4456, 0.4365, 0.4219, 0.4084, 0.3984,\n",
       "            0.3901, 0.385 , 0.3845, 0.38  , 0.3794, 0.37  , 0.3555, 0.3462,\n",
       "            0.3438, 0.3416, 0.34  , 0.3352, 0.3303, 0.312 , 0.3054, 0.3035,\n",
       "            0.2925, 0.2542, 0.2512, 0.2285, 0.2247, 0.2207, 0.2142, 0.212 ,\n",
       "            0.2064, 0.1924, 0.1843, 0.173 , 0.1659, 0.1594, 0.1498, 0.1486,\n",
       "            0.144 , 0.1309], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6333333, dtype=float32),\n",
       "    'tpr': array(0.99230766, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.025     , 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.04166667, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.06666667, 0.08333334,\n",
       "            0.08333334, 0.09166667, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.18333334, 0.18333334, 0.18333334,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.19166666, 0.20833333,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.225     , 0.225     , 0.23333333, 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25833333, 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.275     , 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.325     , 0.325     , 0.325     , 0.33333334,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35833332, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.43333334,\n",
       "            0.44166666, 0.45      , 0.45      , 0.45833334, 0.46666667,\n",
       "            0.475     , 0.475     , 0.475     , 0.475     , 0.475     ,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.5833333 , 0.59166664,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13846155, 0.14615385,\n",
       "            0.16153847, 0.16923077, 0.17692308, 0.18461539, 0.20769231,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23076923,\n",
       "            0.23846154, 0.25384617, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.30769232, 0.31538463, 0.33076924, 0.33846155, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.3923077 , 0.4       , 0.4076923 , 0.41538462,\n",
       "            0.41538462, 0.41538462, 0.41538462, 0.42307693, 0.43846154,\n",
       "            0.45384616, 0.46923077, 0.46923077, 0.46923077, 0.47692308,\n",
       "            0.4846154 , 0.4923077 , 0.5       , 0.50769234, 0.5153846 ,\n",
       "            0.52307695, 0.52307695, 0.5307692 , 0.53846157, 0.54615384,\n",
       "            0.56153846, 0.5692308 , 0.5692308 , 0.5769231 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.63076925, 0.63076925, 0.63846153, 0.65384614,\n",
       "            0.6615385 , 0.6615385 , 0.66923076, 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.73846155, 0.73846155, 0.74615383, 0.74615383, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.77692306, 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8076923 ,\n",
       "            0.8153846 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.94  , 0.9165, 0.914 , 0.903 , 0.9023, 0.9014, 0.9   ,\n",
       "            0.8994, 0.894 , 0.891 , 0.89  , 0.888 , 0.887 , 0.883 , 0.8813,\n",
       "            0.881 , 0.88  , 0.8794, 0.8774, 0.8765, 0.8755, 0.8745, 0.874 ,\n",
       "            0.8735, 0.873 , 0.871 , 0.8706, 0.869 , 0.868 , 0.8677, 0.8657,\n",
       "            0.865 , 0.8647, 0.8633, 0.861 , 0.8604, 0.86  , 0.8594, 0.8555,\n",
       "            0.854 , 0.8486, 0.848 , 0.846 , 0.845 , 0.8447, 0.8438, 0.8433,\n",
       "            0.843 , 0.842 , 0.8413, 0.84  , 0.8374, 0.836 , 0.8354, 0.835 ,\n",
       "            0.8345, 0.832 , 0.831 , 0.83  , 0.8296, 0.8286, 0.828 , 0.826 ,\n",
       "            0.8257, 0.824 , 0.8237, 0.823 , 0.8223, 0.822 , 0.8213, 0.821 ,\n",
       "            0.82  , 0.819 , 0.8184, 0.818 , 0.8154, 0.815 , 0.8135, 0.8125,\n",
       "            0.812 , 0.811 , 0.8086, 0.808 , 0.806 , 0.805 , 0.803 , 0.8027,\n",
       "            0.8022, 0.8013, 0.8003, 0.8   , 0.799 , 0.797 , 0.7954, 0.795 ,\n",
       "            0.794 , 0.793 , 0.7925, 0.791 , 0.7896, 0.788 , 0.7876, 0.7847,\n",
       "            0.7837, 0.783 , 0.7827, 0.782 , 0.7817, 0.78  , 0.7773, 0.775 ,\n",
       "            0.7744, 0.769 , 0.7686, 0.7676, 0.766 , 0.7637, 0.762 , 0.761 ,\n",
       "            0.7593, 0.753 , 0.7456, 0.7407, 0.7363, 0.7324, 0.731 , 0.7295,\n",
       "            0.728 , 0.727 , 0.726 , 0.7207, 0.719 , 0.7183, 0.7173, 0.716 ,\n",
       "            0.712 , 0.711 , 0.7104, 0.7085, 0.704 , 0.699 , 0.6963, 0.693 ,\n",
       "            0.6885, 0.6836, 0.6787, 0.6772, 0.6733, 0.669 , 0.661 , 0.649 ,\n",
       "            0.6455, 0.642 , 0.639 , 0.6304, 0.618 , 0.6133, 0.6084, 0.596 ,\n",
       "            0.591 , 0.572 , 0.57  , 0.5693, 0.5605, 0.553 , 0.536 , 0.5215,\n",
       "            0.518 , 0.5166, 0.5073, 0.499 , 0.495 , 0.474 , 0.4634, 0.459 ,\n",
       "            0.4573, 0.4458, 0.4326, 0.4312, 0.418 , 0.4148, 0.402 , 0.395 ,\n",
       "            0.3948, 0.3884, 0.3877, 0.3826, 0.3623, 0.3523, 0.35  , 0.349 ,\n",
       "            0.3481, 0.341 , 0.339 , 0.3186, 0.3142, 0.309 , 0.3022, 0.258 ,\n",
       "            0.2566, 0.2352, 0.2302, 0.2269, 0.2203, 0.2147, 0.2095, 0.1967,\n",
       "            0.1866, 0.1758, 0.1685, 0.1653, 0.153 , 0.1516, 0.1465, 0.1355],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.64166665, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.04166667, 0.05      , 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.08333334, 0.09166667, 0.09166667, 0.09166667, 0.09166667,\n",
       "            0.1       , 0.11666667, 0.11666667, 0.125     , 0.13333334,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.14166667, 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.16666667, 0.175     , 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.2       , 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.225     , 0.225     ,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.28333333, 0.28333333, 0.28333333,\n",
       "            0.28333333, 0.29166666, 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.33333334, 0.34166667, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45      , 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.46666667, 0.475     , 0.475     ,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.14615385, 0.15384616, 0.16153847, 0.16923077,\n",
       "            0.18461539, 0.1923077 , 0.2       , 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.22307692, 0.23076923, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.2769231 , 0.2846154 , 0.2923077 ,\n",
       "            0.31538463, 0.32307693, 0.33846155, 0.33846155, 0.33846155,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36153847, 0.36153847,\n",
       "            0.36153847, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.41538462, 0.41538462, 0.42307693, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.43846154, 0.45384616, 0.46923077, 0.46923077,\n",
       "            0.47692308, 0.4846154 , 0.4923077 , 0.5       , 0.5153846 ,\n",
       "            0.5153846 , 0.5153846 , 0.52307695, 0.53846157, 0.54615384,\n",
       "            0.54615384, 0.5538462 , 0.5692308 , 0.5692308 , 0.5846154 ,\n",
       "            0.5846154 , 0.5846154 , 0.5923077 , 0.5923077 , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6769231 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.75384617, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.8       , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9       , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9507, 0.929 , 0.9272, 0.918 , 0.9165, 0.9155, 0.914 ,\n",
       "            0.9136, 0.909 , 0.9087, 0.907 , 0.905 , 0.904 , 0.9023, 0.899 ,\n",
       "            0.897 , 0.896 , 0.8955, 0.895 , 0.8945, 0.893 , 0.8926, 0.892 ,\n",
       "            0.8906, 0.89  , 0.8896, 0.889 , 0.8887, 0.887 , 0.8867, 0.8853,\n",
       "            0.885 , 0.8843, 0.882 , 0.8813, 0.881 , 0.8804, 0.879 , 0.878 ,\n",
       "            0.877 , 0.8765, 0.876 , 0.875 , 0.8726, 0.871 , 0.868 , 0.8667,\n",
       "            0.866 , 0.8657, 0.8643, 0.862 , 0.8613, 0.861 , 0.8604, 0.8594,\n",
       "            0.859 , 0.8564, 0.856 , 0.855 , 0.8535, 0.853 , 0.8525, 0.8516,\n",
       "            0.8496, 0.8477, 0.847 , 0.846 , 0.845 , 0.8447, 0.8433, 0.843 ,\n",
       "            0.842 , 0.841 , 0.8403, 0.84  , 0.839 , 0.8384, 0.8374, 0.8364,\n",
       "            0.836 , 0.8345, 0.834 , 0.8335, 0.8325, 0.832 , 0.831 , 0.83  ,\n",
       "            0.829 , 0.828 , 0.8257, 0.824 , 0.823 , 0.8228, 0.822 , 0.821 ,\n",
       "            0.82  , 0.8184, 0.814 , 0.8125, 0.8115, 0.811 , 0.8105, 0.81  ,\n",
       "            0.8057, 0.8037, 0.8027, 0.8013, 0.8003, 0.799 , 0.7954, 0.7944,\n",
       "            0.7925, 0.7915, 0.7896, 0.7876, 0.786 , 0.7856, 0.7837, 0.783 ,\n",
       "            0.7817, 0.781 , 0.77  , 0.763 , 0.7627, 0.756 , 0.7534, 0.752 ,\n",
       "            0.7515, 0.7476, 0.7456, 0.744 , 0.7437, 0.742 , 0.7397, 0.7373,\n",
       "            0.737 , 0.7363, 0.734 , 0.731 , 0.729 , 0.726 , 0.7256, 0.716 ,\n",
       "            0.712 , 0.7085, 0.704 , 0.703 , 0.698 , 0.6973, 0.6963, 0.688 ,\n",
       "            0.6636, 0.663 , 0.659 , 0.6553, 0.6436, 0.6313, 0.6274, 0.626 ,\n",
       "            0.608 , 0.6025, 0.59  , 0.5835, 0.5796, 0.571 , 0.5645, 0.546 ,\n",
       "            0.5454, 0.5317, 0.5303, 0.516 , 0.5156, 0.5146, 0.484 , 0.4717,\n",
       "            0.4678, 0.466 , 0.4524, 0.4402, 0.4377, 0.4275, 0.4243, 0.4111,\n",
       "            0.402 , 0.4019, 0.3945, 0.3926, 0.392 , 0.3665, 0.3555, 0.3538,\n",
       "            0.3535, 0.3533, 0.345 , 0.344 , 0.322 , 0.3198, 0.3115, 0.3086,\n",
       "            0.2595, 0.259 , 0.2388, 0.2327, 0.2303, 0.2238, 0.2148, 0.2098,\n",
       "            0.1982, 0.1864, 0.1761, 0.1686, 0.1547, 0.1511, 0.1464, 0.1376],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.64166665, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.025     , 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.03333334, 0.04166667, 0.04166667, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15833333, 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.16666667, 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.19166666, 0.2       , 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.23333333, 0.23333333, 0.23333333, 0.23333333,\n",
       "            0.24166666, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.275     , 0.28333333,\n",
       "            0.28333333, 0.28333333, 0.3       , 0.3       , 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35      , 0.35      , 0.35      , 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.39166668, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.39166668, 0.4       , 0.40833333, 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.44166666, 0.45      , 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.46666667, 0.46666667,\n",
       "            0.475     , 0.475     , 0.48333332, 0.49166667, 0.5       ,\n",
       "            0.5083333 , 0.51666665, 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.625     , 0.6333333 , 0.64166665, 0.65      ,\n",
       "            0.65833336, 0.6666667 , 0.675     , 0.68333334, 0.69166666,\n",
       "            0.7       , 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.7916667 , 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.04615385, 0.05384615, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13076924, 0.13846155, 0.15384616, 0.16153847,\n",
       "            0.16923077, 0.18461539, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.22307692, 0.23846154, 0.24615385,\n",
       "            0.25384617, 0.26153848, 0.2769231 , 0.2846154 , 0.3       ,\n",
       "            0.31538463, 0.32307693, 0.33846155, 0.33846155, 0.34615386,\n",
       "            0.35384616, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.3846154 , 0.4       , 0.4076923 , 0.42307693, 0.42307693,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.45384616, 0.46153846,\n",
       "            0.46923077, 0.46923077, 0.46923077, 0.4846154 , 0.4923077 ,\n",
       "            0.5       , 0.50769234, 0.5153846 , 0.5153846 , 0.5153846 ,\n",
       "            0.5153846 , 0.53846157, 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.63846153, 0.64615387, 0.64615387, 0.65384614, 0.6615385 ,\n",
       "            0.66923076, 0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.75384617, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.83076924, 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.8923077 , 0.8923077 , 0.9       , 0.9       ,\n",
       "            0.9076923 , 0.9153846 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.958 , 0.939 , 0.9365, 0.929 , 0.927 , 0.926 , 0.9243,\n",
       "            0.92  , 0.9194, 0.916 , 0.915 , 0.9136, 0.9106, 0.9087, 0.9077,\n",
       "            0.907 , 0.9062, 0.905 , 0.904 , 0.903 , 0.9023, 0.902 , 0.9014,\n",
       "            0.9004, 0.8994, 0.899 , 0.8984, 0.8965, 0.894 , 0.8936, 0.893 ,\n",
       "            0.8926, 0.8916, 0.8906, 0.8896, 0.889 , 0.8887, 0.8857, 0.8843,\n",
       "            0.884 , 0.882 , 0.8804, 0.8784, 0.876 , 0.875 , 0.8735, 0.873 ,\n",
       "            0.8726, 0.872 , 0.8687, 0.867 , 0.8667, 0.8657, 0.865 , 0.8647,\n",
       "            0.8643, 0.8633, 0.861 , 0.86  , 0.8594, 0.859 , 0.8584, 0.8574,\n",
       "            0.857 , 0.8564, 0.8555, 0.855 , 0.854 , 0.853 , 0.852 , 0.851 ,\n",
       "            0.8506, 0.8496, 0.848 , 0.8477, 0.8467, 0.8447, 0.8438, 0.843 ,\n",
       "            0.8413, 0.84  , 0.8384, 0.8374, 0.837 , 0.8364, 0.836 , 0.8354,\n",
       "            0.835 , 0.8335, 0.832 , 0.8296, 0.828 , 0.8267, 0.8257, 0.825 ,\n",
       "            0.824 , 0.821 , 0.82  , 0.818 , 0.8174, 0.8164, 0.8154, 0.8145,\n",
       "            0.813 , 0.8105, 0.809 , 0.8066, 0.806 , 0.8057, 0.803 , 0.8027,\n",
       "            0.8013, 0.8   , 0.7993, 0.7974, 0.796 , 0.7837, 0.78  , 0.7773,\n",
       "            0.774 , 0.772 , 0.768 , 0.7676, 0.7656, 0.7637, 0.763 , 0.7627,\n",
       "            0.7617, 0.7583, 0.7563, 0.756 , 0.753 , 0.7505, 0.747 , 0.7466,\n",
       "            0.745 , 0.743 , 0.733 , 0.7324, 0.7266, 0.7236, 0.7217, 0.7188,\n",
       "            0.7173, 0.712 , 0.7104, 0.684 , 0.6763, 0.6724, 0.668 , 0.6562,\n",
       "            0.645 , 0.6436, 0.6377, 0.62  , 0.6143, 0.609 , 0.595 , 0.591 ,\n",
       "            0.582 , 0.576 , 0.5713, 0.556 , 0.547 , 0.541 , 0.5356, 0.5303,\n",
       "            0.526 , 0.495 , 0.4814, 0.4783, 0.4768, 0.4612, 0.45  , 0.4465,\n",
       "            0.4417, 0.4329, 0.4219, 0.4114, 0.4111, 0.4036, 0.403 , 0.4   ,\n",
       "            0.373 , 0.3613, 0.3606, 0.3604, 0.3596, 0.3533, 0.3496, 0.3281,\n",
       "            0.328 , 0.3176, 0.317 , 0.2642, 0.2632, 0.2451, 0.2378, 0.2363,\n",
       "            0.2295, 0.2177, 0.2128, 0.2024, 0.189 , 0.1788, 0.174 , 0.1714,\n",
       "            0.1587, 0.1532, 0.1488, 0.1417], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.65, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05833333, 0.05833333, 0.06666667,\n",
       "            0.06666667, 0.075     , 0.08333334, 0.08333334, 0.09166667,\n",
       "            0.09166667, 0.09166667, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15833333, 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.18333334, 0.18333334, 0.19166666,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.2       , 0.20833333,\n",
       "            0.21666667, 0.225     , 0.225     , 0.23333333, 0.23333333,\n",
       "            0.23333333, 0.23333333, 0.24166666, 0.24166666, 0.25      ,\n",
       "            0.25      , 0.26666668, 0.275     , 0.275     , 0.28333333,\n",
       "            0.28333333, 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.325     , 0.33333334, 0.33333334, 0.33333334,\n",
       "            0.34166667, 0.34166667, 0.35      , 0.35      , 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.36666667, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.46666667, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.55      , 0.55833334, 0.56666666, 0.575     ,\n",
       "            0.5833333 , 0.5833333 , 0.59166664, 0.6       , 0.60833335,\n",
       "            0.6166667 , 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7083333 , 0.71666664, 0.725     , 0.73333335,\n",
       "            0.7416667 , 0.75      , 0.7583333 , 0.76666665, 0.775     ,\n",
       "            0.78333336, 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.04615385, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.13076924, 0.13846155, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.18461539, 0.2       , 0.20769231, 0.21538462, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.24615385, 0.25384617,\n",
       "            0.26153848, 0.2769231 , 0.2769231 , 0.2923077 , 0.3       ,\n",
       "            0.32307693, 0.33846155, 0.33846155, 0.34615386, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.37692308, 0.3923077 , 0.3923077 , 0.4076923 , 0.41538462,\n",
       "            0.42307693, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.46153846, 0.46923077, 0.46923077, 0.4846154 ,\n",
       "            0.4923077 , 0.50769234, 0.50769234, 0.50769234, 0.5153846 ,\n",
       "            0.5153846 , 0.52307695, 0.5307692 , 0.53846157, 0.53846157,\n",
       "            0.54615384, 0.5538462 , 0.56153846, 0.5846154 , 0.5846154 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.65384614, 0.65384614, 0.6846154 , 0.6846154 ,\n",
       "            0.6923077 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.74615383, 0.75384617,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9230769 , 0.9307692 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9644, 0.9473, 0.9453, 0.939 , 0.9365, 0.935 , 0.934 ,\n",
       "            0.93  , 0.929 , 0.9263, 0.9253, 0.924 , 0.9214, 0.9194, 0.918 ,\n",
       "            0.917 , 0.916 , 0.9155, 0.915 , 0.9136, 0.913 , 0.9116, 0.911 ,\n",
       "            0.91  , 0.9097, 0.908 , 0.9077, 0.9053, 0.905 , 0.9043, 0.904 ,\n",
       "            0.9033, 0.903 , 0.9023, 0.901 , 0.9004, 0.898 , 0.8975, 0.8965,\n",
       "            0.896 , 0.8936, 0.892 , 0.889 , 0.8887, 0.888 , 0.887 , 0.8867,\n",
       "            0.8857, 0.8853, 0.885 , 0.8813, 0.881 , 0.8804, 0.88  , 0.8784,\n",
       "            0.878 , 0.8774, 0.876 , 0.874 , 0.8735, 0.873 , 0.8726, 0.8716,\n",
       "            0.871 , 0.87  , 0.8696, 0.869 , 0.8687, 0.868 , 0.8667, 0.866 ,\n",
       "            0.8657, 0.865 , 0.8647, 0.864 , 0.8633, 0.863 , 0.8613, 0.861 ,\n",
       "            0.8594, 0.859 , 0.8574, 0.8564, 0.853 , 0.852 , 0.8516, 0.851 ,\n",
       "            0.8506, 0.8477, 0.8457, 0.8447, 0.844 , 0.8403, 0.84  , 0.839 ,\n",
       "            0.8374, 0.837 , 0.8345, 0.834 , 0.832 , 0.831 , 0.829 , 0.828 ,\n",
       "            0.8267, 0.8257, 0.823 , 0.8223, 0.821 , 0.8203, 0.8193, 0.8174,\n",
       "            0.816 , 0.8145, 0.811 , 0.798 , 0.7964, 0.7915, 0.7866, 0.7837,\n",
       "            0.783 , 0.782 , 0.7793, 0.778 , 0.7773, 0.7754, 0.772 , 0.7715,\n",
       "            0.769 , 0.7676, 0.7646, 0.762 , 0.761 , 0.76  , 0.7515, 0.7495,\n",
       "            0.7485, 0.743 , 0.7407, 0.7373, 0.735 , 0.7324, 0.725 , 0.705 ,\n",
       "            0.69  , 0.6855, 0.6807, 0.6694, 0.6626, 0.6562, 0.65  , 0.633 ,\n",
       "            0.628 , 0.6265, 0.6084, 0.6025, 0.597 , 0.5947, 0.589 , 0.5674,\n",
       "            0.563 , 0.556 , 0.5527, 0.547 , 0.537 , 0.5073, 0.4924, 0.4897,\n",
       "            0.4885, 0.4712, 0.461 , 0.4568, 0.4426, 0.434 , 0.422 , 0.4214,\n",
       "            0.4163, 0.4126, 0.4084, 0.3809, 0.3694, 0.3687, 0.3672, 0.3625,\n",
       "            0.3567, 0.3372, 0.3354, 0.3276, 0.3235, 0.2703, 0.2688, 0.2524,\n",
       "            0.244 , 0.2434, 0.2366, 0.2218, 0.217 , 0.2075, 0.1924, 0.1827,\n",
       "            0.1805, 0.1749, 0.1638, 0.1561, 0.152 , 0.147 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.65, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05833333, 0.06666667, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.08333334, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.11666667, 0.125     ,\n",
       "            0.125     , 0.13333334, 0.14166667, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15      , 0.15      , 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.18333334, 0.19166666, 0.2       , 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.225     , 0.225     , 0.23333333, 0.24166666,\n",
       "            0.24166666, 0.24166666, 0.24166666, 0.24166666, 0.25833333,\n",
       "            0.26666668, 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.275     , 0.275     , 0.28333333, 0.3       , 0.3       ,\n",
       "            0.3       , 0.3       , 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.30833334, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.33333334, 0.33333334, 0.34166667, 0.34166667, 0.35      ,\n",
       "            0.35      , 0.35      , 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.38333333, 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.39166668, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.425     ,\n",
       "            0.425     , 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16923077, 0.1923077 , 0.2       ,\n",
       "            0.21538462, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.2769231 , 0.2846154 ,\n",
       "            0.2923077 , 0.3       , 0.32307693, 0.33076924, 0.34615386,\n",
       "            0.34615386, 0.34615386, 0.35384616, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.37692308, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.3923077 , 0.4       , 0.4076923 ,\n",
       "            0.42307693, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.44615385, 0.46153846, 0.46923077, 0.46923077,\n",
       "            0.46923077, 0.47692308, 0.50769234, 0.50769234, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.53846157, 0.54615384, 0.54615384,\n",
       "            0.5538462 , 0.56153846, 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.5923077 , 0.6       , 0.6076923 , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63846153, 0.64615387,\n",
       "            0.64615387, 0.65384614, 0.65384614, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 , 0.6923077 ,\n",
       "            0.7       , 0.7076923 , 0.7076923 , 0.72307694, 0.7307692 ,\n",
       "            0.73846155, 0.74615383, 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.76153845, 0.7692308 , 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8076923 , 0.8153846 , 0.8230769 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.83076924, 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.86923075, 0.8769231 , 0.88461536, 0.8923077 , 0.9       ,\n",
       "            0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 , 0.9230769 ,\n",
       "            0.9307692 , 0.93846154, 0.93846154, 0.93846154, 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.97  , 0.9546, 0.953 , 0.9478, 0.945 , 0.9434, 0.943 ,\n",
       "            0.9424, 0.9395, 0.939 , 0.9385, 0.9355, 0.9346, 0.933 , 0.931 ,\n",
       "            0.9287, 0.928 , 0.9277, 0.927 , 0.926 , 0.925 , 0.924 , 0.9233,\n",
       "            0.923 , 0.9214, 0.921 , 0.92  , 0.9185, 0.918 , 0.916 , 0.9155,\n",
       "            0.915 , 0.9146, 0.914 , 0.9136, 0.913 , 0.9116, 0.911 , 0.9106,\n",
       "            0.9097, 0.909 , 0.907 , 0.906 , 0.9053, 0.9043, 0.902 , 0.9014,\n",
       "            0.901 , 0.9   , 0.8994, 0.899 , 0.8984, 0.8975, 0.897 , 0.8965,\n",
       "            0.8936, 0.893 , 0.8926, 0.8916, 0.8906, 0.89  , 0.8896, 0.889 ,\n",
       "            0.888 , 0.887 , 0.886 , 0.8857, 0.8843, 0.883 , 0.8823, 0.881 ,\n",
       "            0.8804, 0.88  , 0.8794, 0.879 , 0.8784, 0.878 , 0.8774, 0.877 ,\n",
       "            0.876 , 0.8755, 0.875 , 0.874 , 0.8726, 0.872 , 0.8716, 0.87  ,\n",
       "            0.869 , 0.8667, 0.8657, 0.865 , 0.8647, 0.8643, 0.864 , 0.8633,\n",
       "            0.863 , 0.861 , 0.86  , 0.859 , 0.858 , 0.8545, 0.854 , 0.8525,\n",
       "            0.852 , 0.8516, 0.8506, 0.85  , 0.847 , 0.845 , 0.8423, 0.8413,\n",
       "            0.8403, 0.8394, 0.837 , 0.8364, 0.8335, 0.832 , 0.831 , 0.83  ,\n",
       "            0.829 , 0.8286, 0.8257, 0.824 , 0.8125, 0.8105, 0.8096, 0.808 ,\n",
       "            0.806 , 0.805 , 0.8022, 0.799 , 0.7954, 0.7944, 0.7935, 0.7925,\n",
       "            0.791 , 0.788 , 0.7866, 0.786 , 0.7837, 0.7783, 0.7773, 0.7764,\n",
       "            0.776 , 0.7695, 0.7686, 0.7646, 0.7617, 0.761 , 0.7554, 0.753 ,\n",
       "            0.7476, 0.7373, 0.723 , 0.701 , 0.6973, 0.692 , 0.6807, 0.6777,\n",
       "            0.6675, 0.6606, 0.644 , 0.6426, 0.636 , 0.6196, 0.6177, 0.6113,\n",
       "            0.6035, 0.598 , 0.5757, 0.575 , 0.5728, 0.5605, 0.5596, 0.5444,\n",
       "            0.5156, 0.499 , 0.4973, 0.496 , 0.4768, 0.4678, 0.4675, 0.4624,\n",
       "            0.448 , 0.4417, 0.4282, 0.4272, 0.4243, 0.4177, 0.4126, 0.3843,\n",
       "            0.3735, 0.372 , 0.3713, 0.3699, 0.3674, 0.359 , 0.3418, 0.3384,\n",
       "            0.3333, 0.3254, 0.272 , 0.2693, 0.2551, 0.2462, 0.2456, 0.239 ,\n",
       "            0.2216, 0.2167, 0.2085, 0.1917, 0.1829, 0.1824, 0.1747, 0.165 ,\n",
       "            0.1554, 0.1516, 0.1486], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.675, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.03333334, 0.03333334,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05      , 0.05      , 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.08333334, 0.08333334,\n",
       "            0.09166667, 0.1       , 0.10833333, 0.11666667, 0.11666667,\n",
       "            0.125     , 0.125     , 0.125     , 0.14166667, 0.14166667,\n",
       "            0.14166667, 0.15      , 0.15      , 0.15      , 0.15833333,\n",
       "            0.16666667, 0.16666667, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.18333334, 0.2       , 0.2       , 0.20833333, 0.20833333,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.21666667, 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.26666668, 0.275     , 0.275     , 0.275     ,\n",
       "            0.275     , 0.275     , 0.28333333, 0.3       , 0.3       ,\n",
       "            0.3       , 0.30833334, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.43333334, 0.45      ,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.68333334, 0.69166666, 0.7       , 0.7083333 , 0.71666664,\n",
       "            0.725     , 0.73333335, 0.7416667 , 0.75      , 0.7583333 ,\n",
       "            0.76666665, 0.775     , 0.78333336, 0.7916667 , 0.8       ,\n",
       "            0.80833334, 0.81666666, 0.825     , 0.8333333 , 0.84166664,\n",
       "            0.85      , 0.85833335, 0.8666667 , 0.875     , 0.8833333 ,\n",
       "            0.89166665, 0.9       , 0.90833336, 0.9166667 , 0.925     ,\n",
       "            0.93333334, 0.94166666, 0.95      , 0.9583333 , 0.96666664,\n",
       "            0.975     , 0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.12307692, 0.13076924,\n",
       "            0.13846155, 0.15384616, 0.16153847, 0.17692308, 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26923078, 0.2846154 ,\n",
       "            0.3       , 0.31538463, 0.33076924, 0.33846155, 0.34615386,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36153847, 0.36923078,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.37692308, 0.3923077 ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43846154, 0.43846154, 0.44615385, 0.46153846, 0.46923077,\n",
       "            0.46923077, 0.5       , 0.50769234, 0.50769234, 0.52307695,\n",
       "            0.5307692 , 0.53846157, 0.54615384, 0.54615384, 0.5538462 ,\n",
       "            0.5769231 , 0.5923077 , 0.6       , 0.6       , 0.6       ,\n",
       "            0.6076923 , 0.6076923 , 0.61538464, 0.6230769 , 0.63076925,\n",
       "            0.64615387, 0.64615387, 0.64615387, 0.6615385 , 0.66923076,\n",
       "            0.6769231 , 0.6846154 , 0.6846154 , 0.6846154 , 0.7       ,\n",
       "            0.7153846 , 0.7153846 , 0.7153846 , 0.7307692 , 0.73846155,\n",
       "            0.74615383, 0.75384617, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.7846154 , 0.7846154 , 0.7923077 , 0.7923077 , 0.8       ,\n",
       "            0.8153846 , 0.8230769 , 0.8230769 , 0.83076924, 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.85384613, 0.86153847,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.975 , 0.9614, 0.9595, 0.955 , 0.952 , 0.951 , 0.9507,\n",
       "            0.95  , 0.948 , 0.947 , 0.9463, 0.944 , 0.943 , 0.9414, 0.9395,\n",
       "            0.9375, 0.937 , 0.9365, 0.936 , 0.9355, 0.9346, 0.9336, 0.9326,\n",
       "            0.932 , 0.931 , 0.9307, 0.929 , 0.9277, 0.9272, 0.9263, 0.9253,\n",
       "            0.925 , 0.9243, 0.924 , 0.923 , 0.922 , 0.9214, 0.921 , 0.9204,\n",
       "            0.9194, 0.917 , 0.9165, 0.9155, 0.9146, 0.912 , 0.9116, 0.9106,\n",
       "            0.9097, 0.9087, 0.9077, 0.907 , 0.9067, 0.9043, 0.904 , 0.903 ,\n",
       "            0.902 , 0.9014, 0.9004, 0.9   , 0.8994, 0.8975, 0.897 , 0.8965,\n",
       "            0.8945, 0.894 , 0.893 , 0.892 , 0.8916, 0.8906, 0.89  , 0.889 ,\n",
       "            0.8887, 0.8877, 0.887 , 0.886 , 0.8857, 0.8843, 0.8833, 0.882 ,\n",
       "            0.881 , 0.8794, 0.8774, 0.877 , 0.8765, 0.8755, 0.8745, 0.874 ,\n",
       "            0.8735, 0.8706, 0.867 , 0.8667, 0.8647, 0.8643, 0.864 , 0.863 ,\n",
       "            0.86  , 0.858 , 0.855 , 0.8535, 0.852 , 0.851 , 0.849 , 0.8467,\n",
       "            0.8457, 0.8447, 0.8433, 0.843 , 0.8423, 0.839 , 0.8364, 0.8276,\n",
       "            0.8257, 0.8247, 0.8237, 0.82  , 0.8184, 0.8135, 0.8105, 0.8096,\n",
       "            0.8086, 0.807 , 0.8057, 0.804 , 0.8013, 0.7993, 0.7983, 0.792 ,\n",
       "            0.7915, 0.791 , 0.788 , 0.787 , 0.7812, 0.7803, 0.7793, 0.774 ,\n",
       "            0.773 , 0.7603, 0.7505, 0.742 , 0.7144, 0.71  , 0.7046, 0.6943,\n",
       "            0.694 , 0.68  , 0.673 , 0.6626, 0.6562, 0.6484, 0.644 , 0.6323,\n",
       "            0.624 , 0.6177, 0.611 , 0.593 , 0.592 , 0.588 , 0.576 , 0.573 ,\n",
       "            0.5576, 0.529 , 0.513 , 0.5103, 0.5093, 0.4897, 0.4841, 0.48  ,\n",
       "            0.4758, 0.46  , 0.455 , 0.4407, 0.4397, 0.4382, 0.4297, 0.4236,\n",
       "            0.395 , 0.3848, 0.383 , 0.3818, 0.3801, 0.3792, 0.3691, 0.3533,\n",
       "            0.3486, 0.3452, 0.3352, 0.281 , 0.279 , 0.265 , 0.2556, 0.2546,\n",
       "            0.2483, 0.2292, 0.2242, 0.2166, 0.1985, 0.1917, 0.1893, 0.1813,\n",
       "            0.1726, 0.1614, 0.1578, 0.156 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.69166666, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.03333334, 0.04166667,\n",
       "            0.05      , 0.05      , 0.05      , 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.06666667, 0.075     , 0.075     , 0.075     , 0.08333334,\n",
       "            0.09166667, 0.09166667, 0.1       , 0.10833333, 0.11666667,\n",
       "            0.11666667, 0.125     , 0.125     , 0.125     , 0.13333334,\n",
       "            0.14166667, 0.14166667, 0.14166667, 0.15      , 0.15833333,\n",
       "            0.15833333, 0.15833333, 0.15833333, 0.16666667, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.175     , 0.18333334, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.20833333, 0.20833333, 0.20833333,\n",
       "            0.21666667, 0.23333333, 0.24166666, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25      , 0.26666668, 0.275     , 0.275     ,\n",
       "            0.275     , 0.275     , 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.3       , 0.3       , 0.3       , 0.3       ,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.325     , 0.33333334, 0.34166667,\n",
       "            0.34166667, 0.35      , 0.35      , 0.35      , 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.36666667,\n",
       "            0.375     , 0.38333333, 0.38333333, 0.38333333, 0.39166668,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.40833333, 0.41666666,\n",
       "            0.41666666, 0.41666666, 0.425     , 0.425     , 0.45      ,\n",
       "            0.45      , 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.46666667, 0.475     , 0.48333332,\n",
       "            0.49166667, 0.5       , 0.5083333 , 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.55833334,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.6       , 0.60833335, 0.6166667 , 0.625     , 0.6333333 ,\n",
       "            0.64166665, 0.65      , 0.65833336, 0.6666667 , 0.675     ,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.12307692, 0.13076924, 0.13846155,\n",
       "            0.15384616, 0.16153847, 0.16153847, 0.17692308, 0.2       ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23076923, 0.23846154,\n",
       "            0.23846154, 0.24615385, 0.25384617, 0.26923078, 0.2846154 ,\n",
       "            0.2923077 , 0.30769232, 0.31538463, 0.33076924, 0.34615386,\n",
       "            0.34615386, 0.34615386, 0.36153847, 0.36923078, 0.36923078,\n",
       "            0.36923078, 0.37692308, 0.37692308, 0.37692308, 0.37692308,\n",
       "            0.3923077 , 0.4076923 , 0.41538462, 0.42307693, 0.42307693,\n",
       "            0.42307693, 0.43076923, 0.43846154, 0.43846154, 0.43846154,\n",
       "            0.44615385, 0.46153846, 0.46923077, 0.46923077, 0.4846154 ,\n",
       "            0.5       , 0.50769234, 0.52307695, 0.5307692 , 0.5307692 ,\n",
       "            0.53846157, 0.5538462 , 0.5692308 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.63076925, 0.64615387, 0.64615387, 0.64615387, 0.65384614,\n",
       "            0.6615385 , 0.66923076, 0.66923076, 0.6769231 , 0.6846154 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.7153846 , 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.76153845, 0.76153845, 0.7692308 ,\n",
       "            0.77692306, 0.77692306, 0.7846154 , 0.7923077 , 0.7923077 ,\n",
       "            0.8       , 0.8076923 , 0.8153846 , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.83076924, 0.84615386, 0.85384613, 0.85384613,\n",
       "            0.85384613, 0.86153847, 0.86923075, 0.8769231 , 0.88461536,\n",
       "            0.8923077 , 0.9       , 0.9076923 , 0.9076923 , 0.9153846 ,\n",
       "            0.9230769 , 0.9307692 , 0.9307692 , 0.93846154, 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.95384616, 0.96153843, 0.9692308 ,\n",
       "            0.97692305, 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.979 , 0.967 , 0.9653, 0.962 , 0.959 , 0.9575, 0.957 ,\n",
       "            0.9556, 0.954 , 0.9536, 0.951 , 0.9507, 0.9487, 0.9473, 0.9453,\n",
       "            0.945 , 0.9443, 0.944 , 0.9434, 0.943 , 0.942 , 0.9414, 0.941 ,\n",
       "            0.9404, 0.9395, 0.939 , 0.938 , 0.9365, 0.936 , 0.935 , 0.934 ,\n",
       "            0.9336, 0.933 , 0.9326, 0.932 , 0.9316, 0.9307, 0.93  , 0.9297,\n",
       "            0.9287, 0.9272, 0.9263, 0.926 , 0.9253, 0.9233, 0.9224, 0.922 ,\n",
       "            0.921 , 0.92  , 0.9185, 0.9175, 0.917 , 0.9165, 0.915 , 0.9146,\n",
       "            0.914 , 0.913 , 0.9126, 0.912 , 0.911 , 0.9106, 0.91  , 0.9097,\n",
       "            0.9087, 0.908 , 0.907 , 0.906 , 0.9053, 0.905 , 0.9043, 0.903 ,\n",
       "            0.9014, 0.901 , 0.9   , 0.899 , 0.8984, 0.897 , 0.8955, 0.894 ,\n",
       "            0.8936, 0.8926, 0.8916, 0.8896, 0.889 , 0.888 , 0.8877, 0.887 ,\n",
       "            0.8867, 0.8857, 0.8853, 0.883 , 0.8823, 0.8804, 0.88  , 0.8794,\n",
       "            0.878 , 0.876 , 0.875 , 0.8745, 0.8716, 0.8706, 0.87  , 0.8667,\n",
       "            0.866 , 0.8657, 0.8647, 0.864 , 0.8613, 0.861 , 0.8574, 0.857 ,\n",
       "            0.8564, 0.856 , 0.8555, 0.852 , 0.8486, 0.842 , 0.8413, 0.839 ,\n",
       "            0.837 , 0.8364, 0.831 , 0.828 , 0.826 , 0.8237, 0.822 , 0.8213,\n",
       "            0.821 , 0.8193, 0.8154, 0.8125, 0.812 , 0.8066, 0.8057, 0.8047,\n",
       "            0.804 , 0.8003, 0.7974, 0.7935, 0.792 , 0.791 , 0.7734, 0.7637,\n",
       "            0.7603, 0.727 , 0.7227, 0.7173, 0.7104, 0.706 , 0.693 , 0.6846,\n",
       "            0.68  , 0.669 , 0.668 , 0.6606, 0.645 , 0.6357, 0.63  , 0.623 ,\n",
       "            0.613 , 0.6074, 0.5996, 0.593 , 0.5845, 0.569 , 0.5415, 0.525 ,\n",
       "            0.5225, 0.5215, 0.5005, 0.4917, 0.4868, 0.4707, 0.4678, 0.4521,\n",
       "            0.452 , 0.451 , 0.4402, 0.4333, 0.404 , 0.3948, 0.3926, 0.3906,\n",
       "            0.39  , 0.3887, 0.3777, 0.3638, 0.3572, 0.3567, 0.343 , 0.289 ,\n",
       "            0.2864, 0.274 , 0.2644, 0.2625, 0.257 , 0.2351, 0.2301, 0.2235,\n",
       "            0.2039, 0.2002, 0.195 , 0.1869, 0.1797, 0.1661, 0.1632, 0.163 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7083333, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.025     , 0.03333334,\n",
       "            0.03333334, 0.03333334, 0.04166667, 0.05      , 0.05      ,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.06666667, 0.075     , 0.075     ,\n",
       "            0.075     , 0.08333334, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.11666667, 0.125     , 0.125     ,\n",
       "            0.125     , 0.125     , 0.13333334, 0.14166667, 0.14166667,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.16666667, 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.2       , 0.2       , 0.2       , 0.2       ,\n",
       "            0.20833333, 0.20833333, 0.20833333, 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.23333333, 0.24166666, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25      , 0.25833333, 0.26666668,\n",
       "            0.275     , 0.28333333, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.3       , 0.3       , 0.3       , 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.325     , 0.33333334, 0.34166667,\n",
       "            0.35      , 0.35      , 0.35      , 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.36666667, 0.36666667, 0.375     , 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.38333333, 0.39166668, 0.4       ,\n",
       "            0.4       , 0.4       , 0.4       , 0.4       , 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.44166666, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03846154, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.13076924, 0.13846155, 0.15384616,\n",
       "            0.16153847, 0.16153847, 0.1923077 , 0.2       , 0.20769231,\n",
       "            0.21538462, 0.22307692, 0.23076923, 0.23846154, 0.25384617,\n",
       "            0.26923078, 0.2846154 , 0.2923077 , 0.30769232, 0.31538463,\n",
       "            0.33076924, 0.34615386, 0.34615386, 0.34615386, 0.36153847,\n",
       "            0.36923078, 0.36923078, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.42307693, 0.43076923,\n",
       "            0.43076923, 0.43846154, 0.44615385, 0.46153846, 0.46923077,\n",
       "            0.4846154 , 0.5       , 0.5       , 0.5       , 0.5153846 ,\n",
       "            0.5307692 , 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5846154 ,\n",
       "            0.5923077 , 0.6       , 0.6       , 0.6076923 , 0.61538464,\n",
       "            0.61538464, 0.6230769 , 0.63076925, 0.63076925, 0.64615387,\n",
       "            0.65384614, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.74615383, 0.75384617,\n",
       "            0.76153845, 0.76153845, 0.7692308 , 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7846154 , 0.7923077 ,\n",
       "            0.8076923 , 0.8230769 , 0.83076924, 0.83076924, 0.83076924,\n",
       "            0.8384615 , 0.84615386, 0.85384613, 0.85384613, 0.85384613,\n",
       "            0.86153847, 0.86923075, 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 ,\n",
       "            0.93846154, 0.93846154, 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9824, 0.972 , 0.9707, 0.968 , 0.965 , 0.964 , 0.963 ,\n",
       "            0.9624, 0.9604, 0.96  , 0.958 , 0.957 , 0.9556, 0.9546, 0.9526,\n",
       "            0.9517, 0.951 , 0.9507, 0.95  , 0.949 , 0.9487, 0.948 , 0.9478,\n",
       "            0.9473, 0.9463, 0.9453, 0.9443, 0.9434, 0.942 , 0.9414, 0.941 ,\n",
       "            0.9404, 0.94  , 0.939 , 0.9385, 0.938 , 0.9375, 0.9365, 0.9355,\n",
       "            0.935 , 0.9346, 0.933 , 0.9316, 0.931 , 0.9307, 0.929 , 0.9277,\n",
       "            0.9272, 0.927 , 0.9263, 0.9253, 0.925 , 0.9243, 0.924 , 0.923 ,\n",
       "            0.9224, 0.921 , 0.92  , 0.9194, 0.9185, 0.918 , 0.9175, 0.917 ,\n",
       "            0.9165, 0.916 , 0.9146, 0.914 , 0.9136, 0.913 , 0.9126, 0.9116,\n",
       "            0.911 , 0.9106, 0.91  , 0.9097, 0.909 , 0.9087, 0.907 , 0.9062,\n",
       "            0.906 , 0.9053, 0.9043, 0.9033, 0.903 , 0.9004, 0.9   , 0.899 ,\n",
       "            0.8984, 0.8975, 0.8965, 0.8945, 0.893 , 0.891 , 0.8906, 0.887 ,\n",
       "            0.8867, 0.886 , 0.8853, 0.883 , 0.8823, 0.8813, 0.8794, 0.8784,\n",
       "            0.878 , 0.8774, 0.877 , 0.875 , 0.874 , 0.8726, 0.869 , 0.868 ,\n",
       "            0.8677, 0.8643, 0.861 , 0.858 , 0.856 , 0.8555, 0.853 , 0.8525,\n",
       "            0.8486, 0.8433, 0.842 , 0.8413, 0.8374, 0.835 , 0.834 , 0.8325,\n",
       "            0.829 , 0.8257, 0.8247, 0.82  , 0.8193, 0.8184, 0.8174, 0.8145,\n",
       "            0.8105, 0.8076, 0.807 , 0.786 , 0.7783, 0.7764, 0.7397, 0.736 ,\n",
       "            0.7305, 0.727 , 0.719 , 0.7056, 0.6987, 0.6973, 0.693 , 0.6826,\n",
       "            0.6733, 0.659 , 0.6484, 0.6436, 0.636 , 0.6343, 0.6245, 0.6123,\n",
       "            0.61  , 0.5977, 0.5815, 0.555 , 0.5396, 0.536 , 0.535 , 0.518 ,\n",
       "            0.5137, 0.505 , 0.5005, 0.4832, 0.4824, 0.467 , 0.4656, 0.464 ,\n",
       "            0.453 , 0.445 , 0.4153, 0.4067, 0.404 , 0.4026, 0.4016, 0.3997,\n",
       "            0.3884, 0.3765, 0.3704, 0.3684, 0.3535, 0.299 , 0.2966, 0.285 ,\n",
       "            0.2751, 0.2725, 0.2678, 0.2434, 0.2383, 0.2325, 0.2114, 0.2106,\n",
       "            0.2028, 0.1943, 0.1885, 0.1729, 0.1721, 0.1699], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7083333, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.025     , 0.025     , 0.03333334, 0.03333334,\n",
       "            0.04166667, 0.04166667, 0.05      , 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.06666667, 0.075     , 0.075     , 0.075     ,\n",
       "            0.08333334, 0.08333334, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.125     , 0.125     ,\n",
       "            0.125     , 0.125     , 0.125     , 0.13333334, 0.15      ,\n",
       "            0.15      , 0.15833333, 0.15833333, 0.15833333, 0.16666667,\n",
       "            0.16666667, 0.175     , 0.175     , 0.18333334, 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.2       , 0.2       , 0.2       ,\n",
       "            0.20833333, 0.21666667, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25      , 0.25833333,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.29166666, 0.29166666,\n",
       "            0.29166666, 0.3       , 0.3       , 0.3       , 0.3       ,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.325     ,\n",
       "            0.325     , 0.33333334, 0.34166667, 0.35      , 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.36666667,\n",
       "            0.36666667, 0.36666667, 0.375     , 0.375     , 0.38333333,\n",
       "            0.38333333, 0.38333333, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.4       , 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.525     , 0.53333336,\n",
       "            0.5416667 , 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.575     , 0.5833333 , 0.59166664, 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.8       , 0.80833334, 0.81666666,\n",
       "            0.825     , 0.8333333 , 0.84166664, 0.85      , 0.85833335,\n",
       "            0.8666667 , 0.875     , 0.8833333 , 0.89166665, 0.9       ,\n",
       "            0.90833336, 0.9166667 , 0.925     , 0.93333334, 0.94166666,\n",
       "            0.95      , 0.9583333 , 0.96666664, 0.975     , 0.98333335,\n",
       "            0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.04615385, 0.05384615,\n",
       "            0.06153846, 0.06923077, 0.07692308, 0.08461539, 0.09230769,\n",
       "            0.1       , 0.10769231, 0.11538462, 0.13846155, 0.14615385,\n",
       "            0.15384616, 0.16153847, 0.17692308, 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23846154, 0.25384617, 0.26923078,\n",
       "            0.2769231 , 0.2923077 , 0.3       , 0.30769232, 0.31538463,\n",
       "            0.33076924, 0.34615386, 0.34615386, 0.35384616, 0.36153847,\n",
       "            0.36153847, 0.36923078, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.4076923 , 0.41538462, 0.42307693, 0.42307693, 0.42307693,\n",
       "            0.43076923, 0.43076923, 0.43846154, 0.44615385, 0.45384616,\n",
       "            0.46923077, 0.4846154 , 0.4923077 , 0.5       , 0.50769234,\n",
       "            0.50769234, 0.5307692 , 0.53846157, 0.54615384, 0.5538462 ,\n",
       "            0.56153846, 0.5692308 , 0.5769231 , 0.5846154 , 0.5923077 ,\n",
       "            0.6       , 0.6       , 0.6076923 , 0.6230769 , 0.63076925,\n",
       "            0.64615387, 0.64615387, 0.65384614, 0.65384614, 0.6615385 ,\n",
       "            0.6769231 , 0.6769231 , 0.6846154 , 0.6923077 , 0.7       ,\n",
       "            0.7076923 , 0.7076923 , 0.7153846 , 0.7153846 , 0.72307694,\n",
       "            0.7307692 , 0.73846155, 0.74615383, 0.76153845, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.77692306, 0.7846154 , 0.7923077 , 0.8       , 0.8076923 ,\n",
       "            0.8230769 , 0.83076924, 0.83076924, 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.88461536, 0.88461536, 0.8923077 , 0.9       , 0.9076923 ,\n",
       "            0.9153846 , 0.9153846 , 0.9230769 , 0.9307692 , 0.93846154,\n",
       "            0.93846154, 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.9461538 , 0.95384616, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.986 , 0.9766, 0.975 , 0.9727, 0.9697, 0.969 , 0.9688,\n",
       "            0.9683, 0.968 , 0.966 , 0.9653, 0.964 , 0.963 , 0.9614, 0.9604,\n",
       "            0.959 , 0.958 , 0.9575, 0.957 , 0.9565, 0.956 , 0.955 , 0.9546,\n",
       "            0.953 , 0.952 , 0.951 , 0.9507, 0.949 , 0.9487, 0.948 , 0.9478,\n",
       "            0.9473, 0.947 , 0.9463, 0.946 , 0.9453, 0.945 , 0.9443, 0.9434,\n",
       "            0.943 , 0.9424, 0.942 , 0.9404, 0.9395, 0.939 , 0.9375, 0.936 ,\n",
       "            0.9355, 0.935 , 0.9346, 0.934 , 0.9336, 0.933 , 0.9326, 0.932 ,\n",
       "            0.9316, 0.931 , 0.929 , 0.9287, 0.928 , 0.9277, 0.9272, 0.927 ,\n",
       "            0.9263, 0.926 , 0.9253, 0.924 , 0.9233, 0.923 , 0.922 , 0.921 ,\n",
       "            0.9204, 0.9194, 0.919 , 0.918 , 0.917 , 0.9165, 0.916 , 0.9136,\n",
       "            0.9126, 0.9116, 0.9106, 0.91  , 0.909 , 0.9077, 0.9067, 0.9062,\n",
       "            0.905 , 0.9043, 0.9033, 0.9023, 0.902 , 0.9014, 0.8975, 0.897 ,\n",
       "            0.8965, 0.8955, 0.893 , 0.892 , 0.8916, 0.89  , 0.889 , 0.8887,\n",
       "            0.8877, 0.886 , 0.8857, 0.8833, 0.8804, 0.88  , 0.8794, 0.879 ,\n",
       "            0.876 , 0.8726, 0.872 , 0.8696, 0.868 , 0.8667, 0.866 , 0.86  ,\n",
       "            0.855 , 0.852 , 0.8506, 0.848 , 0.8477, 0.8457, 0.8447, 0.8423,\n",
       "            0.841 , 0.8384, 0.837 , 0.8354, 0.834 , 0.8335, 0.833 , 0.8325,\n",
       "            0.83  , 0.8296, 0.827 , 0.823 , 0.82  , 0.7983, 0.7954, 0.789 ,\n",
       "            0.752 , 0.748 , 0.743 , 0.7427, 0.7314, 0.7183, 0.716 , 0.7153,\n",
       "            0.709 , 0.695 , 0.6855, 0.6714, 0.66  , 0.656 , 0.6543, 0.6484,\n",
       "            0.64  , 0.626 , 0.6235, 0.6094, 0.5923, 0.5674, 0.551 , 0.5474,\n",
       "            0.5464, 0.534 , 0.5234, 0.5156, 0.5107, 0.4944, 0.493 , 0.48  ,\n",
       "            0.4763, 0.4744, 0.4626, 0.4536, 0.423 , 0.4155, 0.4124, 0.409 ,\n",
       "            0.407 , 0.3955, 0.386 , 0.3809, 0.3757, 0.36  , 0.3052, 0.302 ,\n",
       "            0.2927, 0.2827, 0.2788, 0.2751, 0.2477, 0.2424, 0.2379, 0.2179,\n",
       "            0.215 , 0.2065, 0.1982, 0.1941, 0.178 , 0.1758, 0.1733],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.725, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.04166667, 0.04166667, 0.05      ,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.075     ,\n",
       "            0.075     , 0.09166667, 0.09166667, 0.09166667, 0.10833333,\n",
       "            0.11666667, 0.125     , 0.125     , 0.125     , 0.125     ,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15      , 0.15833333,\n",
       "            0.15833333, 0.175     , 0.175     , 0.175     , 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.2       , 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.21666667, 0.23333333, 0.24166666,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.275     , 0.29166666, 0.29166666, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.3       , 0.3       , 0.30833334, 0.30833334,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.325     , 0.33333334,\n",
       "            0.34166667, 0.35      , 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.36666667, 0.36666667,\n",
       "            0.375     , 0.375     , 0.38333333, 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.41666666, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.43333334, 0.44166666, 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5       , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.525     , 0.53333336, 0.5416667 ,\n",
       "            0.55      , 0.55833334, 0.56666666, 0.575     , 0.575     ,\n",
       "            0.5833333 , 0.59166664, 0.6       , 0.60833335, 0.6166667 ,\n",
       "            0.625     , 0.6333333 , 0.64166665, 0.65      , 0.65833336,\n",
       "            0.6666667 , 0.675     , 0.68333334, 0.69166666, 0.7       ,\n",
       "            0.7083333 , 0.71666664, 0.725     , 0.73333335, 0.7416667 ,\n",
       "            0.75      , 0.7583333 , 0.76666665, 0.775     , 0.78333336,\n",
       "            0.7916667 , 0.8       , 0.80833334, 0.81666666, 0.825     ,\n",
       "            0.8333333 , 0.84166664, 0.85      , 0.85833335, 0.8666667 ,\n",
       "            0.875     , 0.8833333 , 0.89166665, 0.9       , 0.90833336,\n",
       "            0.9166667 , 0.925     , 0.93333334, 0.94166666, 0.95      ,\n",
       "            0.9583333 , 0.96666664, 0.975     , 0.98333335, 0.9916667 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03846154, 0.05384615, 0.06153846, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13076924, 0.14615385, 0.15384616, 0.16153847,\n",
       "            0.18461539, 0.20769231, 0.21538462, 0.22307692, 0.23076923,\n",
       "            0.24615385, 0.25384617, 0.26153848, 0.26923078, 0.2846154 ,\n",
       "            0.3       , 0.30769232, 0.31538463, 0.33846155, 0.35384616,\n",
       "            0.36153847, 0.36153847, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.3846154 , 0.3923077 , 0.4       ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.44615385, 0.44615385, 0.46153846, 0.4846154 , 0.5       ,\n",
       "            0.50769234, 0.50769234, 0.52307695, 0.5307692 , 0.54615384,\n",
       "            0.54615384, 0.5538462 , 0.5538462 , 0.56153846, 0.5692308 ,\n",
       "            0.5769231 , 0.5846154 , 0.5923077 , 0.6       , 0.6076923 ,\n",
       "            0.6076923 , 0.6230769 , 0.6230769 , 0.63076925, 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.6769231 , 0.6769231 ,\n",
       "            0.6846154 , 0.6923077 , 0.7       , 0.7076923 , 0.7153846 ,\n",
       "            0.7153846 , 0.72307694, 0.7307692 , 0.73846155, 0.74615383,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.77692306, 0.7846154 ,\n",
       "            0.7923077 , 0.8       , 0.8       , 0.8230769 , 0.83076924,\n",
       "            0.83076924, 0.8384615 , 0.8384615 , 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86923075, 0.8769231 ,\n",
       "            0.88461536, 0.8923077 , 0.9       , 0.9076923 , 0.9153846 ,\n",
       "            0.9153846 , 0.9230769 , 0.9307692 , 0.93846154, 0.9461538 ,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 ,\n",
       "            0.95384616, 0.96153843, 0.9692308 , 0.97692305, 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9883, 0.98  , 0.979 , 0.977 , 0.9746, 0.9736, 0.973 ,\n",
       "            0.9707, 0.97  , 0.9688, 0.9683, 0.967 , 0.9663, 0.9644, 0.964 ,\n",
       "            0.9634, 0.963 , 0.9624, 0.962 , 0.961 , 0.9604, 0.959 , 0.9585,\n",
       "            0.9575, 0.9565, 0.956 , 0.9556, 0.955 , 0.9546, 0.954 , 0.9536,\n",
       "            0.953 , 0.9526, 0.952 , 0.9507, 0.95  , 0.949 , 0.9478, 0.947 ,\n",
       "            0.9453, 0.944 , 0.9434, 0.943 , 0.9424, 0.942 , 0.9414, 0.941 ,\n",
       "            0.94  , 0.9395, 0.9375, 0.937 , 0.9365, 0.936 , 0.9355, 0.935 ,\n",
       "            0.9346, 0.934 , 0.9336, 0.9326, 0.932 , 0.931 , 0.9307, 0.93  ,\n",
       "            0.9297, 0.929 , 0.928 , 0.9277, 0.927 , 0.9263, 0.926 , 0.9253,\n",
       "            0.9233, 0.9224, 0.922 , 0.9214, 0.9204, 0.9185, 0.917 , 0.916 ,\n",
       "            0.9155, 0.915 , 0.9146, 0.913 , 0.912 , 0.9116, 0.9077, 0.9067,\n",
       "            0.906 , 0.9053, 0.904 , 0.9033, 0.903 , 0.9023, 0.9004, 0.9   ,\n",
       "            0.899 , 0.898 , 0.8975, 0.896 , 0.893 , 0.891 , 0.8906, 0.89  ,\n",
       "            0.889 , 0.887 , 0.8857, 0.883 , 0.8823, 0.8804, 0.88  , 0.879 ,\n",
       "            0.8706, 0.868 , 0.8677, 0.8657, 0.863 , 0.861 , 0.8604, 0.857 ,\n",
       "            0.8564, 0.856 , 0.8555, 0.851 , 0.8506, 0.848 , 0.847 , 0.846 ,\n",
       "            0.8457, 0.845 , 0.844 , 0.843 , 0.8413, 0.838 , 0.833 , 0.8105,\n",
       "            0.8013, 0.764 , 0.7603, 0.7573, 0.7554, 0.743 , 0.7354, 0.7314,\n",
       "            0.7305, 0.7207, 0.7065, 0.697 , 0.683 , 0.672 , 0.671 , 0.667 ,\n",
       "            0.6597, 0.654 , 0.64  , 0.634 , 0.6196, 0.602 , 0.5776, 0.56  ,\n",
       "            0.5566, 0.5557, 0.547 , 0.5317, 0.524 , 0.519 , 0.504 , 0.5005,\n",
       "            0.49  , 0.484 , 0.482 , 0.4692, 0.4592, 0.4277, 0.4211, 0.4187,\n",
       "            0.4175, 0.413 , 0.4111, 0.3992, 0.3918, 0.3877, 0.3796, 0.363 ,\n",
       "            0.3076, 0.304 , 0.2961, 0.286 , 0.2812, 0.2783, 0.2478, 0.2426,\n",
       "            0.2391, 0.2205, 0.2145, 0.2063, 0.1978, 0.1952, 0.1796, 0.1748,\n",
       "            0.1727], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.73333335, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.025     ,\n",
       "            0.025     , 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.075     , 0.075     , 0.09166667, 0.09166667, 0.09166667,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.14166667, 0.15      , 0.15      , 0.15833333,\n",
       "            0.16666667, 0.175     , 0.175     , 0.175     , 0.18333334,\n",
       "            0.18333334, 0.19166666, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.2       , 0.20833333, 0.21666667, 0.21666667, 0.21666667,\n",
       "            0.21666667, 0.225     , 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25      , 0.25      , 0.25833333, 0.26666668, 0.275     ,\n",
       "            0.28333333, 0.29166666, 0.29166666, 0.29166666, 0.3       ,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.325     , 0.33333334, 0.34166667, 0.35      ,\n",
       "            0.35833332, 0.35833332, 0.35833332, 0.35833332, 0.35833332,\n",
       "            0.36666667, 0.36666667, 0.36666667, 0.36666667, 0.375     ,\n",
       "            0.375     , 0.38333333, 0.39166668, 0.4       , 0.4       ,\n",
       "            0.4       , 0.4       , 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.41666666, 0.41666666,\n",
       "            0.41666666, 0.425     , 0.43333334, 0.44166666, 0.45      ,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.45833334, 0.46666667,\n",
       "            0.475     , 0.48333332, 0.49166667, 0.5083333 , 0.51666665,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.575     , 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.9       , 0.90833336, 0.9166667 ,\n",
       "            0.925     , 0.93333334, 0.94166666, 0.95      , 0.9583333 ,\n",
       "            0.96666664, 0.975     , 0.98333335, 0.9916667 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.03846154, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.13846155, 0.15384616, 0.15384616,\n",
       "            0.16153847, 0.1923077 , 0.20769231, 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23076923, 0.23076923, 0.24615385, 0.25384617,\n",
       "            0.26923078, 0.2846154 , 0.3       , 0.31538463, 0.32307693,\n",
       "            0.34615386, 0.35384616, 0.36153847, 0.36923078, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.41538462, 0.42307693, 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.43846154, 0.44615385, 0.46153846, 0.4923077 ,\n",
       "            0.50769234, 0.50769234, 0.52307695, 0.5307692 , 0.54615384,\n",
       "            0.54615384, 0.54615384, 0.5538462 , 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5923077 , 0.6       , 0.6076923 , 0.6076923 ,\n",
       "            0.61538464, 0.6230769 , 0.6230769 , 0.6230769 , 0.6230769 ,\n",
       "            0.63846153, 0.65384614, 0.6615385 , 0.6769231 , 0.6846154 ,\n",
       "            0.7       , 0.7       , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.74615383, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.7692308 , 0.7692308 ,\n",
       "            0.7692308 , 0.77692306, 0.7846154 , 0.7923077 , 0.8       ,\n",
       "            0.8076923 , 0.8153846 , 0.8230769 , 0.8384615 , 0.8384615 ,\n",
       "            0.84615386, 0.84615386, 0.85384613, 0.85384613, 0.86153847,\n",
       "            0.86923075, 0.8769231 , 0.8769231 , 0.88461536, 0.8923077 ,\n",
       "            0.9       , 0.9076923 , 0.9153846 , 0.9307692 , 0.93846154,\n",
       "            0.9461538 , 0.9461538 , 0.9461538 , 0.9461538 , 0.95384616,\n",
       "            0.96153843, 0.9692308 , 0.97692305, 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.99  , 0.9834, 0.9824, 0.981 , 0.9785, 0.978 , 0.9775,\n",
       "            0.977 , 0.975 , 0.9746, 0.9736, 0.973 , 0.9717, 0.9707, 0.969 ,\n",
       "            0.9688, 0.9683, 0.968 , 0.9673, 0.967 , 0.9663, 0.966 , 0.965 ,\n",
       "            0.9644, 0.964 , 0.9634, 0.963 , 0.9624, 0.962 , 0.961 , 0.9604,\n",
       "            0.96  , 0.9595, 0.959 , 0.9585, 0.958 , 0.957 , 0.9556, 0.9546,\n",
       "            0.9536, 0.952 , 0.9507, 0.9497, 0.949 , 0.9487, 0.948 , 0.9478,\n",
       "            0.9473, 0.947 , 0.946 , 0.945 , 0.9443, 0.944 , 0.9434, 0.943 ,\n",
       "            0.9424, 0.942 , 0.9414, 0.941 , 0.94  , 0.9395, 0.9385, 0.938 ,\n",
       "            0.9375, 0.936 , 0.9355, 0.935 , 0.9346, 0.934 , 0.9336, 0.933 ,\n",
       "            0.932 , 0.9316, 0.931 , 0.93  , 0.929 , 0.9272, 0.9253, 0.925 ,\n",
       "            0.924 , 0.923 , 0.922 , 0.921 , 0.9204, 0.9165, 0.9155, 0.9146,\n",
       "            0.9136, 0.913 , 0.912 , 0.9116, 0.91  , 0.9097, 0.909 , 0.908 ,\n",
       "            0.907 , 0.9053, 0.903 , 0.9014, 0.901 , 0.9004, 0.8994, 0.8984,\n",
       "            0.8975, 0.894 , 0.893 , 0.892 , 0.8906, 0.881 , 0.8804, 0.8794,\n",
       "            0.8784, 0.8765, 0.8745, 0.8735, 0.872 , 0.8696, 0.8677, 0.8657,\n",
       "            0.863 , 0.8604, 0.8594, 0.8584, 0.858 , 0.8574, 0.8525, 0.8516,\n",
       "            0.8457, 0.8257, 0.8223, 0.8135, 0.7764, 0.7725, 0.768 , 0.757 ,\n",
       "            0.756 , 0.7485, 0.743 , 0.733 , 0.719 , 0.709 , 0.6963, 0.6914,\n",
       "            0.683 , 0.68  , 0.673 , 0.6694, 0.6567, 0.646 , 0.6323, 0.6143,\n",
       "            0.591 , 0.573 , 0.5693, 0.569 , 0.564 , 0.544 , 0.5366, 0.5317,\n",
       "            0.5176, 0.512 , 0.505 , 0.4966, 0.4944, 0.4812, 0.4702, 0.438 ,\n",
       "            0.4324, 0.4304, 0.428 , 0.4233, 0.421 , 0.409 , 0.4036, 0.4001,\n",
       "            0.3896, 0.3723, 0.3164, 0.3127, 0.3062, 0.2957, 0.29  , 0.288 ,\n",
       "            0.2546, 0.2493, 0.247 , 0.2299, 0.2205, 0.2125, 0.2039, 0.2029,\n",
       "            0.1874, 0.1803, 0.1783], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.75, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.025     , 0.025     ,\n",
       "            0.03333334, 0.03333334, 0.03333334, 0.04166667, 0.04166667,\n",
       "            0.05      , 0.05833333, 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.06666667, 0.075     ,\n",
       "            0.075     , 0.09166667, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.125     , 0.13333334, 0.13333334,\n",
       "            0.13333334, 0.13333334, 0.14166667, 0.15      , 0.15      ,\n",
       "            0.16666667, 0.175     , 0.175     , 0.175     , 0.18333334,\n",
       "            0.19166666, 0.19166666, 0.19166666, 0.20833333, 0.21666667,\n",
       "            0.21666667, 0.21666667, 0.225     , 0.225     , 0.225     ,\n",
       "            0.23333333, 0.24166666, 0.25      , 0.25      , 0.25      ,\n",
       "            0.26666668, 0.275     , 0.28333333, 0.28333333, 0.29166666,\n",
       "            0.29166666, 0.29166666, 0.29166666, 0.3       , 0.3       ,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.30833334, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.325     , 0.34166667, 0.35      , 0.35833332, 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.36666667, 0.36666667,\n",
       "            0.36666667, 0.36666667, 0.36666667, 0.375     , 0.375     ,\n",
       "            0.38333333, 0.39166668, 0.4       , 0.4       , 0.4       ,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.425     ,\n",
       "            0.43333334, 0.45      , 0.45833334, 0.45833334, 0.45833334,\n",
       "            0.45833334, 0.46666667, 0.475     , 0.48333332, 0.49166667,\n",
       "            0.5       , 0.5083333 , 0.51666665, 0.51666665, 0.525     ,\n",
       "            0.53333336, 0.5416667 , 0.55      , 0.55833334, 0.56666666,\n",
       "            0.56666666, 0.575     , 0.5833333 , 0.59166664, 0.6       ,\n",
       "            0.60833335, 0.6166667 , 0.625     , 0.6333333 , 0.64166665,\n",
       "            0.65      , 0.65833336, 0.6666667 , 0.675     , 0.68333334,\n",
       "            0.69166666, 0.7       , 0.7083333 , 0.71666664, 0.725     ,\n",
       "            0.73333335, 0.7416667 , 0.75      , 0.7583333 , 0.76666665,\n",
       "            0.775     , 0.78333336, 0.7916667 , 0.8       , 0.80833334,\n",
       "            0.81666666, 0.825     , 0.8333333 , 0.84166664, 0.85      ,\n",
       "            0.85833335, 0.8666667 , 0.875     , 0.8833333 , 0.89166665,\n",
       "            0.9       , 0.90833336, 0.9166667 , 0.925     , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.04615385, 0.05384615, 0.06153846,\n",
       "            0.06923077, 0.07692308, 0.08461539, 0.09230769, 0.1       ,\n",
       "            0.10769231, 0.11538462, 0.13846155, 0.15384616, 0.16153847,\n",
       "            0.18461539, 0.2       , 0.20769231, 0.20769231, 0.21538462,\n",
       "            0.22307692, 0.23846154, 0.24615385, 0.25384617, 0.26153848,\n",
       "            0.2769231 , 0.30769232, 0.31538463, 0.32307693, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.37692308, 0.3846154 ,\n",
       "            0.4       , 0.4076923 , 0.42307693, 0.43076923, 0.43846154,\n",
       "            0.43846154, 0.43846154, 0.44615385, 0.46153846, 0.4923077 ,\n",
       "            0.50769234, 0.5307692 , 0.53846157, 0.54615384, 0.54615384,\n",
       "            0.5538462 , 0.5769231 , 0.5769231 , 0.5846154 , 0.6       ,\n",
       "            0.6       , 0.6076923 , 0.6076923 , 0.61538464, 0.6230769 ,\n",
       "            0.6230769 , 0.6230769 , 0.6230769 , 0.63846153, 0.64615387,\n",
       "            0.65384614, 0.6615385 , 0.6769231 , 0.6769231 , 0.6846154 ,\n",
       "            0.6923077 , 0.7       , 0.7076923 , 0.7153846 , 0.7153846 ,\n",
       "            0.72307694, 0.7307692 , 0.73846155, 0.75384617, 0.76153845,\n",
       "            0.7692308 , 0.7692308 , 0.7692308 , 0.7692308 , 0.77692306,\n",
       "            0.7846154 , 0.7923077 , 0.8       , 0.8076923 , 0.8153846 ,\n",
       "            0.8230769 , 0.83076924, 0.8384615 , 0.8384615 , 0.84615386,\n",
       "            0.84615386, 0.85384613, 0.85384613, 0.86153847, 0.86923075,\n",
       "            0.8769231 , 0.88461536, 0.8923077 , 0.9       , 0.9153846 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.9692308 , 0.97692305,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.992 , 0.9863, 0.9854, 0.984 , 0.982 , 0.9814, 0.981 ,\n",
       "            0.9805, 0.979 , 0.9785, 0.9775, 0.977 , 0.9756, 0.975 , 0.9736,\n",
       "            0.973 , 0.9727, 0.972 , 0.9717, 0.971 , 0.9707, 0.97  , 0.9697,\n",
       "            0.969 , 0.9688, 0.9683, 0.9673, 0.967 , 0.9663, 0.966 , 0.9653,\n",
       "            0.965 , 0.9644, 0.964 , 0.9634, 0.963 , 0.961 , 0.9604, 0.96  ,\n",
       "            0.9595, 0.958 , 0.957 , 0.9565, 0.956 , 0.9556, 0.955 , 0.9546,\n",
       "            0.954 , 0.9536, 0.953 , 0.9517, 0.951 , 0.9507, 0.95  , 0.9497,\n",
       "            0.9487, 0.948 , 0.9473, 0.946 , 0.9453, 0.945 , 0.944 , 0.9434,\n",
       "            0.943 , 0.9424, 0.942 , 0.9414, 0.941 , 0.9404, 0.94  , 0.939 ,\n",
       "            0.9385, 0.938 , 0.937 , 0.9365, 0.935 , 0.9336, 0.933 , 0.9326,\n",
       "            0.932 , 0.9316, 0.9307, 0.9297, 0.929 , 0.925 , 0.924 , 0.9233,\n",
       "            0.923 , 0.922 , 0.9204, 0.9194, 0.919 , 0.9175, 0.916 , 0.914 ,\n",
       "            0.911 , 0.9106, 0.91  , 0.9097, 0.909 , 0.9087, 0.9077, 0.907 ,\n",
       "            0.9053, 0.9033, 0.903 , 0.9014, 0.892 , 0.8906, 0.89  , 0.886 ,\n",
       "            0.8853, 0.885 , 0.883 , 0.879 , 0.8784, 0.878 , 0.8735, 0.872 ,\n",
       "            0.87  , 0.8696, 0.869 , 0.8643, 0.8633, 0.8574, 0.84  , 0.834 ,\n",
       "            0.825 , 0.788 , 0.7866, 0.785 , 0.7803, 0.777 , 0.7676, 0.764 ,\n",
       "            0.7554, 0.7446, 0.7324, 0.721 , 0.7104, 0.71  , 0.696 , 0.6934,\n",
       "            0.6855, 0.685 , 0.673 , 0.659 , 0.6455, 0.627 , 0.6045, 0.588 ,\n",
       "            0.583 , 0.5825, 0.5815, 0.557 , 0.55  , 0.5454, 0.532 , 0.525 ,\n",
       "            0.5205, 0.5103, 0.508 , 0.494 , 0.482 , 0.4497, 0.4446, 0.4436,\n",
       "            0.44  , 0.4346, 0.4321, 0.4202, 0.4165, 0.4143, 0.401 , 0.3828,\n",
       "            0.327 , 0.3235, 0.3179, 0.3071, 0.3005, 0.2993, 0.2634, 0.2578,\n",
       "            0.2563, 0.2411, 0.2285, 0.2207, 0.2125, 0.2119, 0.1973, 0.1873,\n",
       "            0.1858], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7583333, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00833333, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.01666667, 0.01666667, 0.01666667,\n",
       "            0.01666667, 0.01666667, 0.025     , 0.025     , 0.03333334,\n",
       "            0.04166667, 0.05      , 0.05833333, 0.05833333, 0.05833333,\n",
       "            0.05833333, 0.05833333, 0.05833333, 0.075     , 0.075     ,\n",
       "            0.09166667, 0.09166667, 0.09166667, 0.09166667, 0.1       ,\n",
       "            0.10833333, 0.11666667, 0.13333334, 0.13333334, 0.13333334,\n",
       "            0.15      , 0.15833333, 0.16666667, 0.175     , 0.175     ,\n",
       "            0.175     , 0.19166666, 0.19166666, 0.19166666, 0.19166666,\n",
       "            0.20833333, 0.20833333, 0.21666667, 0.21666667, 0.225     ,\n",
       "            0.225     , 0.23333333, 0.23333333, 0.24166666, 0.25      ,\n",
       "            0.25833333, 0.26666668, 0.26666668, 0.28333333, 0.28333333,\n",
       "            0.29166666, 0.29166666, 0.29166666, 0.29166666, 0.29166666,\n",
       "            0.3       , 0.30833334, 0.30833334, 0.30833334, 0.30833334,\n",
       "            0.30833334, 0.31666666, 0.31666666, 0.31666666, 0.31666666,\n",
       "            0.31666666, 0.31666666, 0.33333334, 0.35      , 0.35833332,\n",
       "            0.35833332, 0.35833332, 0.36666667, 0.36666667, 0.36666667,\n",
       "            0.36666667, 0.375     , 0.375     , 0.38333333, 0.38333333,\n",
       "            0.39166668, 0.4       , 0.4       , 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.40833333, 0.40833333, 0.40833333, 0.40833333,\n",
       "            0.40833333, 0.41666666, 0.41666666, 0.41666666, 0.41666666,\n",
       "            0.425     , 0.425     , 0.43333334, 0.45      , 0.45833334,\n",
       "            0.45833334, 0.45833334, 0.45833334, 0.46666667, 0.475     ,\n",
       "            0.48333332, 0.49166667, 0.5       , 0.5083333 , 0.5083333 ,\n",
       "            0.51666665, 0.525     , 0.53333336, 0.5416667 , 0.55      ,\n",
       "            0.55833334, 0.56666666, 0.56666666, 0.575     , 0.5833333 ,\n",
       "            0.59166664, 0.6       , 0.60833335, 0.6166667 , 0.625     ,\n",
       "            0.6333333 , 0.64166665, 0.65      , 0.65833336, 0.6666667 ,\n",
       "            0.675     , 0.68333334, 0.69166666, 0.7       , 0.7083333 ,\n",
       "            0.71666664, 0.725     , 0.73333335, 0.7416667 , 0.75      ,\n",
       "            0.7583333 , 0.76666665, 0.775     , 0.78333336, 0.7916667 ,\n",
       "            0.8       , 0.80833334, 0.81666666, 0.825     , 0.8333333 ,\n",
       "            0.84166664, 0.85      , 0.85833335, 0.8666667 , 0.875     ,\n",
       "            0.8833333 , 0.89166665, 0.90833336, 0.9166667 , 0.93333334,\n",
       "            0.94166666, 0.95      , 0.9583333 , 0.96666664, 0.975     ,\n",
       "            0.98333335, 0.9916667 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00769231, 0.01538462, 0.01538462, 0.01538462,\n",
       "            0.02307692, 0.03076923, 0.04615385, 0.05384615, 0.06923077,\n",
       "            0.07692308, 0.08461539, 0.09230769, 0.1       , 0.10769231,\n",
       "            0.11538462, 0.13846155, 0.15384616, 0.16923077, 0.1923077 ,\n",
       "            0.20769231, 0.21538462, 0.22307692, 0.23846154, 0.25384617,\n",
       "            0.2769231 , 0.3       , 0.30769232, 0.32307693, 0.34615386,\n",
       "            0.35384616, 0.36153847, 0.36923078, 0.37692308, 0.37692308,\n",
       "            0.37692308, 0.37692308, 0.37692308, 0.3923077 , 0.4       ,\n",
       "            0.41538462, 0.42307693, 0.43846154, 0.43846154, 0.45384616,\n",
       "            0.46923077, 0.50769234, 0.5153846 , 0.5307692 , 0.53846157,\n",
       "            0.53846157, 0.54615384, 0.54615384, 0.5692308 , 0.5769231 ,\n",
       "            0.5846154 , 0.5846154 , 0.6       , 0.6       , 0.6076923 ,\n",
       "            0.61538464, 0.61538464, 0.6230769 , 0.6230769 , 0.63846153,\n",
       "            0.64615387, 0.65384614, 0.6615385 , 0.66923076, 0.6769231 ,\n",
       "            0.6769231 , 0.6846154 , 0.6923077 , 0.7       , 0.7076923 ,\n",
       "            0.7153846 , 0.7153846 , 0.72307694, 0.7307692 , 0.73846155,\n",
       "            0.75384617, 0.76153845, 0.7692308 , 0.7692308 , 0.7692308 ,\n",
       "            0.77692306, 0.7846154 , 0.8       , 0.8153846 , 0.8230769 ,\n",
       "            0.83076924, 0.8384615 , 0.84615386, 0.84615386, 0.85384613,\n",
       "            0.85384613, 0.85384613, 0.86153847, 0.86153847, 0.8769231 ,\n",
       "            0.88461536, 0.9       , 0.9076923 , 0.9153846 , 0.9230769 ,\n",
       "            0.9307692 , 0.9307692 , 0.93846154, 0.9461538 , 0.95384616,\n",
       "            0.95384616, 0.96153843, 0.96153843, 0.96153843, 0.96153843,\n",
       "            0.9692308 , 0.97692305, 0.9846154 , 0.9846154 , 0.9846154 ,\n",
       "            0.9846154 , 0.9846154 , 0.9846154 , 0.9846154 , 0.99230766,\n",
       "            0.99230766, 0.99230766, 0.99230766, 0.99230766, 0.99230766,\n",
       "            0.99230766, 0.99230766, 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9937, 0.9883, 0.988 , 0.987 , 0.985 , 0.9844, 0.984 ,\n",
       "            0.9834, 0.982 , 0.981 , 0.9805, 0.9795, 0.979 , 0.9775, 0.977 ,\n",
       "            0.9766, 0.976 , 0.9756, 0.975 , 0.9746, 0.9736, 0.973 , 0.9727,\n",
       "            0.9717, 0.9707, 0.97  , 0.9697, 0.969 , 0.9688, 0.9683, 0.968 ,\n",
       "            0.9663, 0.966 , 0.9653, 0.965 , 0.9634, 0.963 , 0.9614, 0.961 ,\n",
       "            0.9604, 0.96  , 0.9595, 0.9575, 0.957 , 0.9565, 0.956 , 0.9556,\n",
       "            0.955 , 0.9546, 0.954 , 0.9536, 0.9526, 0.9517, 0.951 , 0.9507,\n",
       "            0.9497, 0.949 , 0.9487, 0.948 , 0.9478, 0.9473, 0.947 , 0.946 ,\n",
       "            0.945 , 0.9443, 0.9434, 0.9424, 0.942 , 0.941 , 0.9404, 0.94  ,\n",
       "            0.9395, 0.939 , 0.938 , 0.9375, 0.9365, 0.9326, 0.932 , 0.9316,\n",
       "            0.9307, 0.93  , 0.928 , 0.9277, 0.926 , 0.9243, 0.9224, 0.9194,\n",
       "            0.919 , 0.9185, 0.9175, 0.916 , 0.915 , 0.9136, 0.9126, 0.912 ,\n",
       "            0.911 , 0.903 , 0.901 , 0.9004, 0.896 , 0.8955, 0.8945, 0.893 ,\n",
       "            0.891 , 0.8896, 0.888 , 0.8877, 0.885 , 0.8843, 0.8833, 0.8813,\n",
       "            0.881 , 0.8804, 0.88  , 0.876 , 0.8735, 0.8687, 0.853 , 0.8447,\n",
       "            0.836 , 0.7993, 0.799 , 0.7964, 0.796 , 0.7915, 0.7793, 0.779 ,\n",
       "            0.7666, 0.756 , 0.7437, 0.7324, 0.728 , 0.722 , 0.7065, 0.7056,\n",
       "            0.6997, 0.697 , 0.688 , 0.67  , 0.6567, 0.638 , 0.6167, 0.6   ,\n",
       "            0.597 , 0.5947, 0.594 , 0.5684, 0.561 , 0.557 , 0.5444, 0.5356,\n",
       "            0.5347, 0.5215, 0.519 , 0.5044, 0.4917, 0.4587, 0.4548, 0.4546,\n",
       "            0.4495, 0.4434, 0.4407, 0.429 , 0.4275, 0.4263, 0.41  , 0.3909,\n",
       "            0.335 , 0.3315, 0.3274, 0.3164, 0.3086, 0.2695, 0.2637, 0.2505,\n",
       "            0.234 , 0.2264, 0.22  , 0.2175, 0.2053, 0.1923, 0.1912],\n",
       "           dtype=float16)}}],\n",
       "  [{'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.76865673, dtype=float32),\n",
       "    'tpr': array(0.7413793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.02238806,\n",
       "            0.02985075, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.07462686, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.08955224, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.10447761, 0.10447761, 0.1119403 , 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.1641791 , 0.18656716,\n",
       "            0.20149253, 0.20895523, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.25373134, 0.26865673, 0.2835821 , 0.29850745, 0.33582088,\n",
       "            0.36567163, 0.40298507, 0.41791046, 0.4552239 , 0.49253732,\n",
       "            0.52238804, 0.53731346, 0.5522388 , 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.619403  , 0.6492537 , 0.6641791 ,\n",
       "            0.6641791 , 0.67164177, 0.6865672 , 0.70149255, 0.7089552 ,\n",
       "            0.7238806 , 0.7238806 , 0.7238806 , 0.74626863, 0.76119405,\n",
       "            0.76865673, 0.7835821 , 0.7910448 , 0.79850745, 0.79850745,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.82835823, 0.8358209 ,\n",
       "            0.8358209 , 0.8507463 , 0.8507463 , 0.85820895, 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9328358 , 0.9328358 , 0.9402985 , 0.9402985 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.95522386, 0.95522386,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.97761196, 0.97761196, 0.98507464,\n",
       "            0.98507464, 0.9925373 , 0.9925373 , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.18965517, 0.19827586, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.22413793, 0.22413793, 0.22413793, 0.23275863, 0.25      ,\n",
       "            0.25862068, 0.27586207, 0.28448275, 0.29310346, 0.31034482,\n",
       "            0.31896552, 0.31896552, 0.3275862 , 0.3275862 , 0.3275862 ,\n",
       "            0.3448276 , 0.36206895, 0.37068966, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.39655173, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.46551725, 0.47413793, 0.51724136, 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.57758623, 0.5948276 , 0.6034483 ,\n",
       "            0.62068963, 0.62068963, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.6551724 , 0.6637931 , 0.6637931 , 0.67241377, 0.6896552 ,\n",
       "            0.6896552 , 0.7241379 , 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5854, 0.579 , 0.576 , 0.575 , 0.5728, 0.5723, 0.5693,\n",
       "            0.567 , 0.5664, 0.5654, 0.5645, 0.5625, 0.5586, 0.558 , 0.5576,\n",
       "            0.556 , 0.551 , 0.549 , 0.5464, 0.5454, 0.5425, 0.5415, 0.541 ,\n",
       "            0.54  , 0.5386, 0.538 , 0.537 , 0.5366, 0.536 , 0.5356, 0.535 ,\n",
       "            0.5347, 0.534 , 0.533 , 0.531 , 0.5303, 0.5283, 0.528 , 0.5273,\n",
       "            0.5264, 0.5254, 0.525 , 0.5244, 0.523 , 0.5225, 0.522 , 0.521 ,\n",
       "            0.5205, 0.52  , 0.5195, 0.519 , 0.5186, 0.518 , 0.5176, 0.517 ,\n",
       "            0.5166, 0.516 , 0.5156, 0.515 , 0.5146, 0.514 , 0.5137, 0.513 ,\n",
       "            0.5127, 0.512 , 0.5117, 0.511 , 0.5107, 0.5103, 0.51  , 0.5093,\n",
       "            0.509 , 0.5083, 0.508 , 0.507 , 0.5063, 0.506 , 0.5054, 0.504 ,\n",
       "            0.5034, 0.503 , 0.502 , 0.5015, 0.501 , 0.5005, 0.5   , 0.4998,\n",
       "            0.4995, 0.4993, 0.499 , 0.4985, 0.4983, 0.4978, 0.4968, 0.4963,\n",
       "            0.496 , 0.4956, 0.4954, 0.495 , 0.4949, 0.4946, 0.4944, 0.4941,\n",
       "            0.494 , 0.4934, 0.4932, 0.493 , 0.4927, 0.4924, 0.4922, 0.4917,\n",
       "            0.4907, 0.4905, 0.4895, 0.4893, 0.489 , 0.4888, 0.488 , 0.4875,\n",
       "            0.487 , 0.4868, 0.4854, 0.4849, 0.4844, 0.484 , 0.4836, 0.483 ,\n",
       "            0.4827, 0.482 , 0.4817, 0.4812, 0.4807, 0.4792, 0.4783, 0.4766,\n",
       "            0.4756], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.3880597, dtype=float32),\n",
       "    'tpr': array(0.2672414, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.05223881, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.10447761, 0.1119403 , 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.15671642, 0.1641791 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20895523, 0.21641791, 0.23880596, 0.26865673,\n",
       "            0.2835821 , 0.30597016, 0.31343284, 0.32089552, 0.35820895,\n",
       "            0.36567163, 0.3880597 , 0.3955224 , 0.3955224 , 0.41044775,\n",
       "            0.41791046, 0.43283582, 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.4552239 , 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 ,\n",
       "            0.6641791 , 0.6641791 , 0.6641791 , 0.67164177, 0.6865672 ,\n",
       "            0.69402987, 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.7238806 , 0.7238806 , 0.73134327, 0.73134327,\n",
       "            0.74626863, 0.74626863, 0.75373137, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.76865673, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7835821 , 0.7910448 , 0.7910448 , 0.7910448 , 0.7910448 ,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9029851 , 0.9029851 , 0.9104478 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9477612 , 0.95522386, 0.95522386,\n",
       "            0.95522386, 0.96268654, 0.96268654, 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.97761196, 0.97761196,\n",
       "            0.98507464, 0.98507464, 0.98507464, 0.98507464, 0.98507464,\n",
       "            0.98507464, 0.9925373 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0775862 ,\n",
       "            0.09482758, 0.09482758, 0.10344828, 0.10344828, 0.12068965,\n",
       "            0.12068965, 0.12068965, 0.12931034, 0.12931034, 0.12931034,\n",
       "            0.12931034, 0.13793103, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1724138 , 0.1724138 , 0.18103448, 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.20689656, 0.20689656, 0.20689656,\n",
       "            0.20689656, 0.20689656, 0.21551724, 0.21551724, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.22413793, 0.22413793, 0.22413793,\n",
       "            0.22413793, 0.22413793, 0.2413793 , 0.2413793 , 0.25      ,\n",
       "            0.25      , 0.2672414 , 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.30172414, 0.30172414, 0.31896552, 0.31896552, 0.3275862 ,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.35344827,\n",
       "            0.35344827, 0.35344827, 0.36206895, 0.36206895, 0.37068966,\n",
       "            0.37068966, 0.37068966, 0.37068966, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.38793105, 0.39655173, 0.39655173,\n",
       "            0.4051724 , 0.4224138 , 0.43965518, 0.43965518, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.5       , 0.5086207 , 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.6810345 , 0.6896552 , 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.73275864, 0.7413793 , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5522, 0.5503, 0.545 , 0.5425, 0.542 , 0.5415, 0.5376,\n",
       "            0.534 , 0.532 , 0.5317, 0.5303, 0.5293, 0.529 , 0.5283, 0.527 ,\n",
       "            0.5264, 0.526 , 0.525 , 0.5244, 0.524 , 0.5234, 0.523 , 0.521 ,\n",
       "            0.5205, 0.5176, 0.516 , 0.515 , 0.514 , 0.5137, 0.5127, 0.512 ,\n",
       "            0.5117, 0.511 , 0.5107, 0.5103, 0.51  , 0.509 , 0.5083, 0.508 ,\n",
       "            0.5073, 0.507 , 0.5063, 0.506 , 0.5054, 0.505 , 0.5044, 0.5034,\n",
       "            0.503 , 0.5024, 0.502 , 0.5005, 0.4998, 0.4993, 0.4988, 0.498 ,\n",
       "            0.4976, 0.497 , 0.4968, 0.4963, 0.4956, 0.4954, 0.4934, 0.4915,\n",
       "            0.4905, 0.4897, 0.4895, 0.4893, 0.489 , 0.4883, 0.488 , 0.4878,\n",
       "            0.4873, 0.487 , 0.4866, 0.4863, 0.486 , 0.4858, 0.4854, 0.485 ,\n",
       "            0.4846, 0.4844, 0.484 , 0.4836, 0.483 , 0.4827, 0.4824, 0.482 ,\n",
       "            0.4817, 0.4812, 0.481 , 0.4805, 0.4802, 0.48  , 0.4792, 0.479 ,\n",
       "            0.4788, 0.4785, 0.4783, 0.478 , 0.4778, 0.4775, 0.4773, 0.4768,\n",
       "            0.4763, 0.476 , 0.4758, 0.4756, 0.4753, 0.4736, 0.4734, 0.4731,\n",
       "            0.473 , 0.4724, 0.4722, 0.472 , 0.4717, 0.4714, 0.4712, 0.471 ,\n",
       "            0.4697, 0.4695, 0.4692, 0.469 , 0.4688, 0.4673, 0.4666, 0.4653,\n",
       "            0.4648, 0.4644, 0.464 , 0.4634, 0.463 , 0.4624, 0.4622, 0.4617,\n",
       "            0.4614, 0.461 , 0.46  , 0.4597, 0.4592, 0.4585, 0.458 , 0.4568,\n",
       "            0.456 , 0.4558, 0.4556, 0.455 , 0.4548, 0.454 , 0.4539, 0.4536,\n",
       "            0.4526, 0.4514, 0.4512, 0.4507, 0.4504, 0.45  , 0.4492, 0.4485,\n",
       "            0.4482, 0.4478, 0.4473, 0.4468, 0.443 , 0.4426, 0.4424, 0.4395,\n",
       "            0.431 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.14179105, dtype=float32),\n",
       "    'tpr': array(0.10344828, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.13432837, 0.14179105, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1641791 , 0.1716418 , 0.18656716, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.36567163, 0.37313432, 0.3880597 , 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6641791 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.6865672 , 0.6865672 ,\n",
       "            0.69402987, 0.69402987, 0.69402987, 0.69402987, 0.70149255,\n",
       "            0.70149255, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.7238806 , 0.7238806 , 0.7238806 , 0.73134327, 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.75373137, 0.75373137,\n",
       "            0.76119405, 0.76119405, 0.76865673, 0.7761194 , 0.7761194 ,\n",
       "            0.7835821 , 0.7835821 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.80597013, 0.8134328 , 0.8134328 , 0.82835823,\n",
       "            0.8432836 , 0.85820895, 0.86567163, 0.86567163, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8880597 , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.91791046,\n",
       "            0.91791046, 0.91791046, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.95522386, 0.95522386, 0.95522386, 0.96268654,\n",
       "            0.96268654, 0.96268654, 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.97761196, 0.97761196, 0.97761196, 0.98507464, 0.98507464,\n",
       "            0.9925373 , 0.9925373 , 0.9925373 , 0.9925373 , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.03448276, 0.04310345, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0862069 , 0.0862069 , 0.0862069 , 0.0862069 ,\n",
       "            0.0862069 , 0.10344828, 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12068965, 0.12068965, 0.12068965, 0.12068965,\n",
       "            0.12068965, 0.12068965, 0.12068965, 0.12068965, 0.12068965,\n",
       "            0.12068965, 0.12931034, 0.12931034, 0.12931034, 0.12931034,\n",
       "            0.12931034, 0.12931034, 0.12931034, 0.12931034, 0.12931034,\n",
       "            0.13793103, 0.13793103, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.15517241, 0.1637931 , 0.1637931 , 0.1637931 , 0.1724138 ,\n",
       "            0.1724138 , 0.18965517, 0.19827586, 0.19827586, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.23275863, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25      , 0.25862068, 0.27586207,\n",
       "            0.28448275, 0.28448275, 0.28448275, 0.28448275, 0.29310346,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.4051724 ,\n",
       "            0.41379312, 0.41379312, 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.43965518, 0.43965518, 0.43965518, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.51724136,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7155172 , 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.82758623, 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8534483 , 0.86206895, 0.86206895, 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5293, 0.523 , 0.521 , 0.52  , 0.519 , 0.5176, 0.5166,\n",
       "            0.516 , 0.5156, 0.515 , 0.5146, 0.514 , 0.5137, 0.512 , 0.5107,\n",
       "            0.5093, 0.509 , 0.5073, 0.506 , 0.504 , 0.5034, 0.503 , 0.5024,\n",
       "            0.5015, 0.501 , 0.5005, 0.4998, 0.4995, 0.4983, 0.4978, 0.4973,\n",
       "            0.4968, 0.4966, 0.4963, 0.496 , 0.495 , 0.4949, 0.4946, 0.4941,\n",
       "            0.494 , 0.4937, 0.493 , 0.4924, 0.4922, 0.492 , 0.4917, 0.4915,\n",
       "            0.491 , 0.4905, 0.4902, 0.49  , 0.4897, 0.4895, 0.4893, 0.4883,\n",
       "            0.4875, 0.4866, 0.4856, 0.4846, 0.4841, 0.484 , 0.4832, 0.4827,\n",
       "            0.4822, 0.482 , 0.481 , 0.4797, 0.4792, 0.4785, 0.4778, 0.4768,\n",
       "            0.4763, 0.476 , 0.4744, 0.4734, 0.4727, 0.4724, 0.4712, 0.471 ,\n",
       "            0.4695, 0.4692, 0.469 , 0.4685, 0.4683, 0.4675, 0.4666, 0.4658,\n",
       "            0.4648, 0.4626, 0.4622, 0.4614, 0.461 , 0.4604, 0.46  , 0.4595,\n",
       "            0.459 , 0.4585, 0.4583, 0.458 , 0.4573, 0.4568, 0.4563, 0.456 ,\n",
       "            0.4556, 0.455 , 0.4543, 0.4539, 0.4536, 0.4524, 0.4512, 0.4507,\n",
       "            0.4504, 0.4502, 0.4497, 0.4495, 0.4487, 0.4475, 0.4473, 0.447 ,\n",
       "            0.4468, 0.4465, 0.4463, 0.4458, 0.4453, 0.4448, 0.4446, 0.4438,\n",
       "            0.443 , 0.4421, 0.4417, 0.4414, 0.4412, 0.4402, 0.44  , 0.439 ,\n",
       "            0.4387, 0.4385, 0.438 , 0.4377, 0.4373, 0.4368, 0.4363, 0.436 ,\n",
       "            0.4358, 0.4355, 0.435 , 0.434 , 0.4336, 0.4329, 0.4321, 0.4302,\n",
       "            0.43  , 0.4297, 0.4294, 0.4292, 0.4287, 0.4285, 0.427 , 0.426 ,\n",
       "            0.4253, 0.424 , 0.4226, 0.4214, 0.4211, 0.421 , 0.4204, 0.42  ,\n",
       "            0.4197, 0.4194, 0.4192, 0.4187, 0.4185, 0.4177, 0.4172, 0.4165,\n",
       "            0.4163, 0.4158, 0.4148, 0.4146, 0.4143, 0.414 , 0.4138, 0.4128,\n",
       "            0.4116, 0.4106, 0.4102, 0.41  , 0.4084, 0.408 , 0.403 , 0.402 ,\n",
       "            0.401 , 0.4006, 0.4001, 0.3843], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.07462686, dtype=float32),\n",
       "    'tpr': array(0.00862069, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.1119403 ,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.13432837, 0.13432837,\n",
       "            0.14925373, 0.15671642, 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.33582088, 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.41044775, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.48507464, 0.48507464, 0.48507464, 0.48507464, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.619403  , 0.6268657 ,\n",
       "            0.6268657 , 0.6268657 , 0.63432837, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6791045 , 0.6865672 ,\n",
       "            0.6865672 , 0.6865672 , 0.6865672 , 0.69402987, 0.69402987,\n",
       "            0.69402987, 0.69402987, 0.69402987, 0.69402987, 0.69402987,\n",
       "            0.70149255, 0.7164179 , 0.7238806 , 0.7238806 , 0.7238806 ,\n",
       "            0.73134327, 0.73134327, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7761194 ,\n",
       "            0.7835821 , 0.7835821 , 0.7835821 , 0.7835821 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.82835823, 0.8358209 , 0.8358209 , 0.8358209 , 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.8731343 , 0.880597  , 0.8880597 , 0.8880597 ,\n",
       "            0.8955224 , 0.8955224 , 0.9029851 , 0.9104478 , 0.9104478 ,\n",
       "            0.9104478 , 0.9104478 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 0.9925373 , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.04310345, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.06896552, 0.06896552, 0.06896552, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.0862069 , 0.0862069 ,\n",
       "            0.0862069 , 0.10344828, 0.10344828, 0.10344828, 0.10344828,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.10344828, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.1724138 ,\n",
       "            0.18103448, 0.18103448, 0.18103448, 0.18965517, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.33620688,\n",
       "            0.3448276 , 0.3448276 , 0.35344827, 0.35344827, 0.36206895,\n",
       "            0.36206895, 0.37068966, 0.39655173, 0.4051724 , 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.43965518, 0.45689654,\n",
       "            0.46551725, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.54310346, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6465517 , 0.6637931 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.76724136,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.80172414, 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.86206895, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.88793105, 0.88793105,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5137, 0.511 , 0.5107, 0.51  , 0.5083, 0.507 , 0.5063,\n",
       "            0.5034, 0.503 , 0.501 , 0.4985, 0.4932, 0.4924, 0.4922, 0.4917,\n",
       "            0.4915, 0.491 , 0.4902, 0.4897, 0.4893, 0.4888, 0.4885, 0.4883,\n",
       "            0.488 , 0.4878, 0.4875, 0.487 , 0.4866, 0.486 , 0.4856, 0.4854,\n",
       "            0.485 , 0.4849, 0.484 , 0.4832, 0.4827, 0.4824, 0.4822, 0.4817,\n",
       "            0.4812, 0.4807, 0.4802, 0.4795, 0.4788, 0.4783, 0.4778, 0.4775,\n",
       "            0.4773, 0.477 , 0.4766, 0.4763, 0.476 , 0.4758, 0.474 , 0.4731,\n",
       "            0.473 , 0.4722, 0.471 , 0.4707, 0.4702, 0.47  , 0.4692, 0.4678,\n",
       "            0.4668, 0.4666, 0.466 , 0.4639, 0.4631, 0.4617, 0.46  , 0.4595,\n",
       "            0.4592, 0.458 , 0.4575, 0.4563, 0.4558, 0.4553, 0.4514, 0.4512,\n",
       "            0.4495, 0.4492, 0.4473, 0.447 , 0.4465, 0.446 , 0.4429, 0.4426,\n",
       "            0.4421, 0.4407, 0.4402, 0.44  , 0.4395, 0.4385, 0.4375, 0.437 ,\n",
       "            0.4365, 0.4363, 0.436 , 0.4355, 0.4353, 0.435 , 0.4343, 0.4336,\n",
       "            0.4329, 0.4321, 0.4314, 0.4297, 0.4294, 0.4287, 0.4285, 0.4282,\n",
       "            0.427 , 0.4263, 0.4255, 0.4253, 0.4246, 0.4243, 0.4229, 0.4224,\n",
       "            0.4194, 0.4175, 0.4172, 0.417 , 0.4163, 0.416 , 0.4155, 0.4153,\n",
       "            0.415 , 0.4143, 0.414 , 0.4136, 0.413 , 0.4124, 0.412 , 0.4114,\n",
       "            0.411 , 0.4106, 0.4104, 0.41  , 0.407 , 0.4067, 0.4065, 0.4058,\n",
       "            0.4055, 0.4043, 0.404 , 0.403 , 0.4026, 0.4023, 0.4019, 0.4014,\n",
       "            0.4011, 0.401 , 0.4006, 0.4   , 0.3992, 0.3987, 0.3984, 0.398 ,\n",
       "            0.3977, 0.3965, 0.396 , 0.3953, 0.3938, 0.3936, 0.3916, 0.3901,\n",
       "            0.3892, 0.388 , 0.3877, 0.3875, 0.3872, 0.3865, 0.3862, 0.386 ,\n",
       "            0.3855, 0.3853, 0.385 , 0.3848, 0.3835, 0.3833, 0.383 , 0.3823,\n",
       "            0.382 , 0.3816, 0.3804, 0.3801, 0.3792, 0.379 , 0.3782, 0.3777,\n",
       "            0.376 , 0.3745, 0.3743, 0.3716, 0.3699, 0.3677, 0.367 , 0.3652,\n",
       "            0.3635, 0.3625, 0.362 , 0.361 , 0.355 , 0.3396], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.02238806, dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.17910448,\n",
       "            0.18656716, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.30597016, 0.31343284,\n",
       "            0.31343284, 0.32089552, 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41791046, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.619403  , 0.6268657 ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.63432837, 0.63432837,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.67164177, 0.67164177,\n",
       "            0.67164177, 0.67164177, 0.6791045 , 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.70149255, 0.70149255, 0.70149255,\n",
       "            0.70149255, 0.70149255, 0.70149255, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.7238806 , 0.73880595, 0.73880595,\n",
       "            0.75373137, 0.75373137, 0.76119405, 0.76865673, 0.76865673,\n",
       "            0.7835821 , 0.7835821 , 0.7910448 , 0.79850745, 0.79850745,\n",
       "            0.80597013, 0.80597013, 0.8134328 , 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.85820895, 0.85820895,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.880597  , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.95522386, 0.95522386,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.98507464, 0.98507464, 0.9925373 ,\n",
       "            0.9925373 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06896552,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.13793103, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.23275863, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.37931034, 0.38793105, 0.38793105,\n",
       "            0.39655173, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43965518, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.5       , 0.5       , 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.6034483 , 0.6034483 , 0.61206895, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.6551724 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.7155172 , 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.8534483 , 0.8534483 , 0.87931037,\n",
       "            0.88793105, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.504 , 0.502 , 0.5015, 0.5   , 0.4993, 0.4973, 0.4966,\n",
       "            0.493 , 0.4912, 0.4897, 0.4895, 0.4844, 0.484 , 0.4836, 0.4834,\n",
       "            0.483 , 0.4822, 0.4805, 0.4802, 0.48  , 0.4792, 0.479 , 0.4788,\n",
       "            0.4785, 0.4783, 0.4778, 0.4773, 0.4766, 0.4763, 0.4756, 0.475 ,\n",
       "            0.4749, 0.4744, 0.4736, 0.4734, 0.4727, 0.4722, 0.4705, 0.4702,\n",
       "            0.4697, 0.4695, 0.4688, 0.4678, 0.4673, 0.4666, 0.4656, 0.465 ,\n",
       "            0.4646, 0.4644, 0.464 , 0.4631, 0.463 , 0.462 , 0.4617, 0.4612,\n",
       "            0.4604, 0.4575, 0.457 , 0.4563, 0.4543, 0.4531, 0.4514, 0.451 ,\n",
       "            0.4507, 0.4492, 0.445 , 0.4438, 0.4426, 0.442 , 0.4407, 0.4392,\n",
       "            0.4387, 0.4368, 0.4343, 0.434 , 0.4336, 0.4333, 0.433 , 0.43  ,\n",
       "            0.429 , 0.4253, 0.423 , 0.421 , 0.4204, 0.4182, 0.4177, 0.4167,\n",
       "            0.4163, 0.415 , 0.4146, 0.4138, 0.412 , 0.4116, 0.4114, 0.4104,\n",
       "            0.4102, 0.41  , 0.4087, 0.4084, 0.4077, 0.407 , 0.4067, 0.4058,\n",
       "            0.4045, 0.4043, 0.4001, 0.3997, 0.3994, 0.3975, 0.397 , 0.3955,\n",
       "            0.3953, 0.395 , 0.3948, 0.3936, 0.3933, 0.393 , 0.391 , 0.39  ,\n",
       "            0.3896, 0.3894, 0.388 , 0.3875, 0.387 , 0.3867, 0.3865, 0.3862,\n",
       "            0.3853, 0.3848, 0.3845, 0.384 , 0.3838, 0.383 , 0.382 , 0.3816,\n",
       "            0.3813, 0.381 , 0.3806, 0.3796, 0.3782, 0.3777, 0.3774, 0.3752,\n",
       "            0.3743, 0.374 , 0.3735, 0.3733, 0.373 , 0.3704, 0.3694, 0.3687,\n",
       "            0.3682, 0.3677, 0.367 , 0.3667, 0.3665, 0.3662, 0.3647, 0.364 ,\n",
       "            0.3633, 0.3623, 0.361 , 0.3608, 0.3606, 0.36  , 0.3594, 0.3591,\n",
       "            0.358 , 0.3572, 0.357 , 0.3564, 0.355 , 0.353 , 0.352 , 0.3516,\n",
       "            0.351 , 0.3503, 0.35  , 0.3496, 0.3494, 0.349 , 0.3484, 0.3481,\n",
       "            0.3477, 0.3474, 0.347 , 0.3455, 0.345 , 0.3445, 0.3435, 0.343 ,\n",
       "            0.342 , 0.3408, 0.3406, 0.3396, 0.3364, 0.3335, 0.3306, 0.3293,\n",
       "            0.3289, 0.3262, 0.3257, 0.3252, 0.325 , 0.3232, 0.3203, 0.312 ,\n",
       "            0.298 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.02238806, 0.03731343, 0.04477612,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.10447761, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2761194 ,\n",
       "            0.2835821 , 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.6268657 , 0.6268657 , 0.63432837,\n",
       "            0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 ,\n",
       "            0.6492537 , 0.6567164 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.67164177, 0.6791045 , 0.6791045 , 0.6791045 , 0.6865672 ,\n",
       "            0.6865672 , 0.6865672 , 0.6865672 , 0.70149255, 0.70149255,\n",
       "            0.70149255, 0.70149255, 0.70149255, 0.70149255, 0.70149255,\n",
       "            0.7089552 , 0.7089552 , 0.7238806 , 0.7238806 , 0.73134327,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76119405, 0.76119405, 0.76865673, 0.76865673, 0.7761194 ,\n",
       "            0.7761194 , 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8134328 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.880597  , 0.880597  , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9328358 , 0.9328358 , 0.9328358 ,\n",
       "            0.9328358 , 0.9402985 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.95522386, 0.96268654, 0.96268654, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.97761196, 0.98507464, 0.98507464, 0.98507464,\n",
       "            0.9925373 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.05172414, 0.06034483, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.18965517, 0.19827586, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.23275863, 0.25      , 0.25      , 0.25862068, 0.27586207,\n",
       "            0.28448275, 0.28448275, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.30172414, 0.30172414, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.36206895, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.4051724 ,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.45689654, 0.45689654,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.62068963, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7844828 , 0.80172414, 0.8103448 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4946, 0.4924, 0.4902, 0.4883, 0.4866, 0.4824, 0.4807,\n",
       "            0.4792, 0.4778, 0.4763, 0.4746, 0.4739, 0.473 , 0.4724, 0.4717,\n",
       "            0.4707, 0.4705, 0.4697, 0.4695, 0.4692, 0.469 , 0.4688, 0.4685,\n",
       "            0.4675, 0.4666, 0.466 , 0.4653, 0.465 , 0.4634, 0.4626, 0.462 ,\n",
       "            0.4617, 0.4614, 0.461 , 0.46  , 0.4595, 0.4587, 0.4585, 0.4583,\n",
       "            0.457 , 0.4568, 0.4553, 0.455 , 0.4543, 0.454 , 0.4539, 0.4531,\n",
       "            0.453 , 0.4524, 0.452 , 0.4517, 0.4504, 0.45  , 0.449 , 0.443 ,\n",
       "            0.4424, 0.442 , 0.4412, 0.4402, 0.4385, 0.436 , 0.4353, 0.4329,\n",
       "            0.4263, 0.424 , 0.423 , 0.4226, 0.4204, 0.42  , 0.4192, 0.4182,\n",
       "            0.4163, 0.416 , 0.415 , 0.413 , 0.4116, 0.4106, 0.4102, 0.4097,\n",
       "            0.4092, 0.406 , 0.3972, 0.397 , 0.3967, 0.3962, 0.3958, 0.394 ,\n",
       "            0.3926, 0.3923, 0.392 , 0.39  , 0.3884, 0.388 , 0.3875, 0.3872,\n",
       "            0.386 , 0.3857, 0.3818, 0.3809, 0.3806, 0.3801, 0.3794, 0.3787,\n",
       "            0.3777, 0.3772, 0.375 , 0.3728, 0.371 , 0.37  , 0.3699, 0.3696,\n",
       "            0.3691, 0.3684, 0.3674, 0.3645, 0.3643, 0.3635, 0.3616, 0.361 ,\n",
       "            0.3604, 0.36  , 0.3599, 0.3591, 0.3586, 0.3584, 0.358 , 0.3572,\n",
       "            0.357 , 0.356 , 0.3552, 0.355 , 0.3545, 0.3538, 0.352 , 0.3513,\n",
       "            0.351 , 0.3506, 0.3503, 0.3489, 0.3486, 0.348 , 0.3464, 0.3462,\n",
       "            0.346 , 0.3455, 0.3452, 0.345 , 0.3447, 0.3445, 0.3433, 0.3418,\n",
       "            0.341 , 0.3403, 0.34  , 0.3396, 0.3394, 0.3384, 0.3374, 0.3372,\n",
       "            0.3357, 0.3335, 0.3333, 0.333 , 0.3323, 0.3318, 0.3303, 0.3286,\n",
       "            0.328 , 0.3274, 0.3264, 0.3254, 0.324 , 0.322 , 0.3218, 0.3213,\n",
       "            0.321 , 0.3206, 0.3203, 0.3193, 0.3184, 0.318 , 0.3176, 0.317 ,\n",
       "            0.316 , 0.3154, 0.315 , 0.3147, 0.3135, 0.312 , 0.3115, 0.3105,\n",
       "            0.3098, 0.3096, 0.308 , 0.3074, 0.3071, 0.3062, 0.3052, 0.3042,\n",
       "            0.3032, 0.3022, 0.3005, 0.2993, 0.2952, 0.2922, 0.2898, 0.289 ,\n",
       "            0.2876, 0.2861, 0.2854, 0.28  , 0.2715, 0.2595], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.26119402, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.49253732,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 , 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.619403  , 0.6268657 , 0.6268657 , 0.6268657 , 0.6268657 ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.67164177, 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6865672 , 0.6865672 , 0.6865672 ,\n",
       "            0.6865672 , 0.6865672 , 0.70149255, 0.70149255, 0.70149255,\n",
       "            0.70149255, 0.70149255, 0.70149255, 0.70149255, 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.74626863, 0.75373137, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.76865673, 0.76865673, 0.7761194 , 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.86567163, 0.86567163,\n",
       "            0.8731343 , 0.8731343 , 0.8731343 , 0.8731343 , 0.880597  ,\n",
       "            0.880597  , 0.880597  , 0.880597  , 0.880597  , 0.8880597 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.9477612 , 0.95522386, 0.95522386, 0.96268654, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.97761196, 0.98507464,\n",
       "            0.98507464, 0.98507464, 0.9925373 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.04310345, 0.04310345, 0.05172414, 0.05172414,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.28448275, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.3448276 , 0.3448276 ,\n",
       "            0.35344827, 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.38793105, 0.39655173, 0.39655173, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.49137932, 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.51724136, 0.5344828 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.62931037, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.8103448 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8534483 , 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4854, 0.4832, 0.483 , 0.481 , 0.4802, 0.4792, 0.4768,\n",
       "            0.4722, 0.472 , 0.4683, 0.4666, 0.4663, 0.466 , 0.4656, 0.4646,\n",
       "            0.4644, 0.4636, 0.4631, 0.4624, 0.4622, 0.462 , 0.4604, 0.46  ,\n",
       "            0.4597, 0.4592, 0.4583, 0.458 , 0.4578, 0.4558, 0.4548, 0.4536,\n",
       "            0.4524, 0.4504, 0.4502, 0.4492, 0.4487, 0.4485, 0.4475, 0.4473,\n",
       "            0.447 , 0.4463, 0.446 , 0.4458, 0.4453, 0.4448, 0.4443, 0.4436,\n",
       "            0.443 , 0.442 , 0.441 , 0.4407, 0.4387, 0.4382, 0.437 , 0.4353,\n",
       "            0.4329, 0.4312, 0.4294, 0.4285, 0.4246, 0.4238, 0.421 , 0.4153,\n",
       "            0.4116, 0.4092, 0.4077, 0.4065, 0.402 , 0.3987, 0.3982, 0.3975,\n",
       "            0.396 , 0.3955, 0.3928, 0.3923, 0.3918, 0.3916, 0.3904, 0.3896,\n",
       "            0.3875, 0.386 , 0.3823, 0.3792, 0.3757, 0.3755, 0.3752, 0.3735,\n",
       "            0.3718, 0.3713, 0.3708, 0.3684, 0.3682, 0.367 , 0.3652, 0.364 ,\n",
       "            0.3618, 0.3606, 0.3604, 0.36  , 0.3577, 0.3555, 0.3547, 0.3545,\n",
       "            0.3535, 0.3523, 0.3499, 0.3486, 0.3467, 0.346 , 0.344 , 0.3433,\n",
       "            0.3423, 0.342 , 0.3418, 0.341 , 0.34  , 0.3398, 0.337 , 0.3367,\n",
       "            0.3364, 0.3357, 0.3345, 0.3342, 0.3333, 0.3325, 0.332 , 0.3306,\n",
       "            0.329 , 0.3286, 0.3274, 0.327 , 0.3267, 0.3264, 0.3257, 0.3252,\n",
       "            0.325 , 0.3245, 0.3215, 0.3213, 0.3208, 0.3206, 0.3203, 0.32  ,\n",
       "            0.3198, 0.319 , 0.3186, 0.3176, 0.317 , 0.3167, 0.3162, 0.3157,\n",
       "            0.3154, 0.315 , 0.3145, 0.3137, 0.3118, 0.311 , 0.31  , 0.3096,\n",
       "            0.3088, 0.3086, 0.308 , 0.3066, 0.3054, 0.3052, 0.304 , 0.3032,\n",
       "            0.301 , 0.2998, 0.2993, 0.2988, 0.298 , 0.2979, 0.2974, 0.2957,\n",
       "            0.2947, 0.2944, 0.294 , 0.2935, 0.292 , 0.2917, 0.2913, 0.2903,\n",
       "            0.2886, 0.2878, 0.2869, 0.2861, 0.2842, 0.2834, 0.282 , 0.281 ,\n",
       "            0.2795, 0.2783, 0.2776, 0.2756, 0.2751, 0.2742, 0.2712, 0.271 ,\n",
       "            0.2695, 0.2673, 0.267 , 0.2668, 0.2664, 0.2634, 0.2605, 0.2568,\n",
       "            0.2544, 0.252 , 0.251 , 0.2494, 0.2487, 0.243 , 0.2343, 0.2246],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.2761194 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.35074627, 0.35820895,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.6268657 , 0.6268657 ,\n",
       "            0.6268657 , 0.6268657 , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.67164177, 0.67164177,\n",
       "            0.67164177, 0.67164177, 0.67164177, 0.67164177, 0.6791045 ,\n",
       "            0.6791045 , 0.6865672 , 0.6865672 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.70149255, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7089552 , 0.7089552 , 0.7238806 , 0.73880595, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.75373137, 0.76119405, 0.76119405,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.80597013, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.82835823, 0.8358209 ,\n",
       "            0.8358209 , 0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.8507463 , 0.86567163, 0.86567163, 0.86567163, 0.86567163,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.880597  , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.97761196, 0.98507464,\n",
       "            0.98507464, 0.98507464, 0.9925373 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.04310345, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.13793103, 0.14655173, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18965517, 0.19827586,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.22413793,\n",
       "            0.23275863, 0.23275863, 0.2413793 , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.3448276 , 0.3448276 , 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.38793105, 0.39655173,\n",
       "            0.39655173, 0.39655173, 0.4051724 , 0.41379312, 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.47413793, 0.4827586 , 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5258621 , 0.5344828 , 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.6034483 , 0.61206895, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7155172 ,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.73275864, 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8103448 , 0.8189655 , 0.8362069 ,\n",
       "            0.8448276 , 0.86206895, 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4758, 0.474 , 0.4731, 0.472 , 0.4702, 0.467 , 0.4631,\n",
       "            0.4617, 0.4602, 0.4575, 0.4565, 0.4563, 0.4556, 0.455 , 0.4546,\n",
       "            0.4543, 0.454 , 0.4539, 0.4536, 0.4534, 0.4517, 0.4514, 0.4512,\n",
       "            0.4507, 0.45  , 0.4475, 0.4465, 0.4463, 0.4436, 0.442 , 0.4414,\n",
       "            0.4412, 0.4392, 0.439 , 0.4387, 0.438 , 0.4375, 0.4373, 0.4365,\n",
       "            0.4363, 0.4358, 0.4355, 0.4353, 0.435 , 0.4346, 0.4343, 0.434 ,\n",
       "            0.431 , 0.4304, 0.4285, 0.4282, 0.426 , 0.424 , 0.4229, 0.4219,\n",
       "            0.417 , 0.4158, 0.415 , 0.4128, 0.4094, 0.4084, 0.406 , 0.3918,\n",
       "            0.3916, 0.391 , 0.39  , 0.3845, 0.3813, 0.381 , 0.3794, 0.3762,\n",
       "            0.376 , 0.3752, 0.372 , 0.3699, 0.3694, 0.367 , 0.3655, 0.363 ,\n",
       "            0.3618, 0.3616, 0.3557, 0.3555, 0.3547, 0.3545, 0.3538, 0.3503,\n",
       "            0.348 , 0.3477, 0.3474, 0.347 , 0.3452, 0.3442, 0.3425, 0.3413,\n",
       "            0.3386, 0.337 , 0.3354, 0.3315, 0.3306, 0.3303, 0.3298, 0.3296,\n",
       "            0.3284, 0.3281, 0.3254, 0.325 , 0.3235, 0.3218, 0.3215, 0.3203,\n",
       "            0.3176, 0.317 , 0.3167, 0.3162, 0.3152, 0.3145, 0.314 , 0.3125,\n",
       "            0.3105, 0.31  , 0.3098, 0.3096, 0.3093, 0.3074, 0.3052, 0.305 ,\n",
       "            0.3037, 0.3032, 0.3018, 0.3013, 0.3005, 0.2993, 0.2988, 0.2986,\n",
       "            0.298 , 0.2976, 0.2974, 0.2966, 0.2964, 0.2957, 0.2952, 0.2944,\n",
       "            0.2932, 0.2925, 0.2922, 0.2905, 0.29  , 0.2886, 0.288 , 0.2874,\n",
       "            0.287 , 0.2869, 0.286 , 0.2854, 0.2852, 0.2834, 0.2817, 0.2815,\n",
       "            0.2808, 0.28  , 0.2793, 0.279 , 0.2778, 0.2751, 0.2737, 0.2708,\n",
       "            0.2703, 0.27  , 0.269 , 0.2688, 0.268 , 0.2668, 0.2666, 0.2651,\n",
       "            0.2646, 0.2644, 0.2642, 0.264 , 0.263 , 0.2612, 0.2607, 0.258 ,\n",
       "            0.2573, 0.255 , 0.2542, 0.2527, 0.2524, 0.2515, 0.2512, 0.251 ,\n",
       "            0.2502, 0.249 , 0.2489, 0.2466, 0.2426, 0.2415, 0.2397, 0.2382,\n",
       "            0.2374, 0.236 , 0.235 , 0.2347, 0.234 , 0.2338, 0.2311, 0.2266,\n",
       "            0.2242, 0.218 , 0.2166, 0.2162, 0.2156, 0.2095, 0.2009, 0.1934],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1716418 , 0.17910448, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.619403  , 0.619403  ,\n",
       "            0.619403  , 0.6268657 , 0.6268657 , 0.6268657 , 0.6268657 ,\n",
       "            0.63432837, 0.63432837, 0.63432837, 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6567164 , 0.6567164 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.67164177, 0.67164177, 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6791045 , 0.6791045 , 0.6791045 ,\n",
       "            0.6791045 , 0.69402987, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7089552 , 0.7089552 , 0.7164179 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76119405, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7835821 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.80597013, 0.80597013,\n",
       "            0.80597013, 0.8134328 , 0.82835823, 0.8358209 , 0.8358209 ,\n",
       "            0.8358209 , 0.8358209 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.8507463 , 0.8507463 , 0.8507463 , 0.8507463 , 0.8507463 ,\n",
       "            0.8507463 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.880597  , 0.880597  , 0.880597  ,\n",
       "            0.8880597 , 0.8880597 , 0.8955224 , 0.8955224 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.9104478 , 0.92537314, 0.92537314,\n",
       "            0.92537314, 0.92537314, 0.9328358 , 0.9328358 , 0.9402985 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.95522386, 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.9701493 , 0.97761196, 0.97761196,\n",
       "            0.97761196, 0.98507464, 0.98507464, 0.9925373 , 0.9925373 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.03448276, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12068965, 0.12931034, 0.12931034, 0.14655173, 0.15517241,\n",
       "            0.15517241, 0.1637931 , 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.21551724, 0.22413793, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.25      , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.35344827, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.41379312, 0.4224138 , 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.57758623, 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4663, 0.4646, 0.4634, 0.463 , 0.461 , 0.4602, 0.4573,\n",
       "            0.454 , 0.452 , 0.451 , 0.4487, 0.4485, 0.4473, 0.4465, 0.4463,\n",
       "            0.4458, 0.445 , 0.4448, 0.4446, 0.443 , 0.4426, 0.442 , 0.4417,\n",
       "            0.437 , 0.4368, 0.4353, 0.4326, 0.4321, 0.4307, 0.4304, 0.4287,\n",
       "            0.4285, 0.4282, 0.4277, 0.4275, 0.4272, 0.4268, 0.4265, 0.426 ,\n",
       "            0.4258, 0.4253, 0.4246, 0.4243, 0.4226, 0.4224, 0.4216, 0.42  ,\n",
       "            0.4192, 0.4165, 0.4155, 0.4148, 0.4136, 0.4114, 0.4087, 0.407 ,\n",
       "            0.4023, 0.4016, 0.3958, 0.3953, 0.3945, 0.392 , 0.391 , 0.3755,\n",
       "            0.3738, 0.371 , 0.369 , 0.3647, 0.364 , 0.3604, 0.358 , 0.357 ,\n",
       "            0.3564, 0.3552, 0.3523, 0.3472, 0.3447, 0.344 , 0.3423, 0.3406,\n",
       "            0.3367, 0.3357, 0.3345, 0.334 , 0.3306, 0.3296, 0.3289, 0.3284,\n",
       "            0.3281, 0.3276, 0.3271, 0.326 , 0.3252, 0.3245, 0.3228, 0.3206,\n",
       "            0.3193, 0.3162, 0.3137, 0.3127, 0.311 , 0.3083, 0.3074, 0.3066,\n",
       "            0.3064, 0.306 , 0.3042, 0.304 , 0.303 , 0.3018, 0.2996, 0.298 ,\n",
       "            0.2974, 0.2957, 0.2942, 0.294 , 0.2932, 0.2925, 0.291 , 0.2896,\n",
       "            0.289 , 0.2883, 0.2876, 0.2864, 0.2861, 0.2852, 0.2844, 0.2815,\n",
       "            0.28  , 0.2795, 0.2793, 0.278 , 0.2776, 0.2751, 0.2747, 0.2725,\n",
       "            0.2722, 0.2715, 0.2712, 0.271 , 0.2708, 0.2705, 0.2703, 0.2698,\n",
       "            0.2683, 0.2664, 0.2659, 0.2656, 0.2654, 0.2646, 0.2644, 0.2637,\n",
       "            0.2632, 0.261 , 0.2605, 0.2603, 0.2598, 0.2595, 0.2588, 0.2583,\n",
       "            0.2578, 0.2576, 0.2566, 0.2563, 0.2554, 0.2544, 0.2534, 0.2517,\n",
       "            0.251 , 0.2496, 0.2489, 0.2482, 0.2456, 0.2438, 0.2426, 0.2417,\n",
       "            0.2415, 0.241 , 0.2402, 0.2399, 0.2397, 0.2394, 0.2391, 0.2384,\n",
       "            0.2383, 0.2382, 0.2379, 0.237 , 0.2362, 0.2356, 0.2343, 0.2319,\n",
       "            0.2306, 0.2297, 0.2289, 0.2269, 0.226 , 0.2257, 0.2255, 0.2249,\n",
       "            0.2247, 0.2229, 0.2227, 0.2224, 0.2218, 0.2217, 0.2195, 0.2125,\n",
       "            0.2114, 0.2109, 0.2101, 0.208 , 0.2073, 0.206 , 0.2058, 0.2053,\n",
       "            0.2043, 0.2034, 0.2032, 0.1991, 0.1965, 0.1873, 0.1864, 0.1858,\n",
       "            0.1857, 0.1797, 0.1715, 0.1654], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.1119403 , 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.29104477, 0.29850745, 0.31343284, 0.32089552, 0.33582088,\n",
       "            0.3432836 , 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.6268657 , 0.6268657 ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6567164 , 0.6567164 , 0.6567164 ,\n",
       "            0.6567164 , 0.6641791 , 0.6641791 , 0.67164177, 0.67164177,\n",
       "            0.67164177, 0.67164177, 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.6865672 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7164179 , 0.7238806 , 0.7238806 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.74626863, 0.75373137, 0.75373137, 0.76865673, 0.7761194 ,\n",
       "            0.7761194 , 0.7761194 , 0.7835821 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.79850745, 0.79850745, 0.79850745,\n",
       "            0.80597013, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8358209 , 0.8358209 , 0.8358209 , 0.8358209 ,\n",
       "            0.8432836 , 0.8432836 , 0.8432836 , 0.8432836 , 0.8432836 ,\n",
       "            0.8507463 , 0.8507463 , 0.8507463 , 0.85820895, 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.8731343 , 0.8731343 , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.8955224 , 0.9029851 ,\n",
       "            0.9029851 , 0.9029851 , 0.9029851 , 0.91791046, 0.91791046,\n",
       "            0.92537314, 0.92537314, 0.92537314, 0.9328358 , 0.9328358 ,\n",
       "            0.9402985 , 0.9402985 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.96268654, 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.97761196, 0.97761196, 0.97761196, 0.98507464, 0.98507464,\n",
       "            0.9925373 , 0.9925373 , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.05172414, 0.06034483,\n",
       "            0.06896552, 0.0775862 , 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12068965, 0.12931034,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.15517241, 0.1637931 ,\n",
       "            0.1637931 , 0.1637931 , 0.1724138 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.23275863, 0.25      , 0.25862068,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.3448276 , 0.35344827, 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.55172414, 0.55172414, 0.55172414, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.69827586, 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.9913793 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.457 , 0.4553, 0.4539, 0.4521, 0.4502, 0.4473, 0.4453,\n",
       "            0.4438, 0.4404, 0.4402, 0.4385, 0.4382, 0.438 , 0.4375, 0.4365,\n",
       "            0.4363, 0.436 , 0.4353, 0.434 , 0.4336, 0.433 , 0.4329, 0.4304,\n",
       "            0.4297, 0.4275, 0.4268, 0.4238, 0.4233, 0.4216, 0.4202, 0.42  ,\n",
       "            0.4194, 0.4192, 0.4187, 0.4185, 0.4177, 0.4175, 0.4163, 0.416 ,\n",
       "            0.4158, 0.4155, 0.4148, 0.413 , 0.4104, 0.4102, 0.4094, 0.408 ,\n",
       "            0.4062, 0.405 , 0.4048, 0.4016, 0.3992, 0.3972, 0.394 , 0.3892,\n",
       "            0.388 , 0.381 , 0.3801, 0.38  , 0.376 , 0.36  , 0.3584, 0.355 ,\n",
       "            0.351 , 0.3489, 0.3467, 0.3418, 0.3416, 0.339 , 0.338 , 0.3372,\n",
       "            0.3328, 0.3286, 0.3257, 0.325 , 0.3228, 0.3218, 0.3184, 0.3179,\n",
       "            0.3154, 0.3147, 0.3127, 0.3125, 0.3103, 0.3098, 0.309 , 0.3086,\n",
       "            0.3076, 0.3074, 0.3062, 0.3057, 0.3047, 0.3037, 0.299 , 0.298 ,\n",
       "            0.2944, 0.2922, 0.2903, 0.2861, 0.286 , 0.2847, 0.284 , 0.2827,\n",
       "            0.2808, 0.2788, 0.2786, 0.278 , 0.2778, 0.2766, 0.2742, 0.2727,\n",
       "            0.2717, 0.2695, 0.269 , 0.267 , 0.2651, 0.265 , 0.264 , 0.2634,\n",
       "            0.2612, 0.26  , 0.2595, 0.2593, 0.2566, 0.2556, 0.255 , 0.2537,\n",
       "            0.2534, 0.251 , 0.2502, 0.2493, 0.2487, 0.2477, 0.2474, 0.2467,\n",
       "            0.2462, 0.2451, 0.2445, 0.2444, 0.2421, 0.2411, 0.2407, 0.2406,\n",
       "            0.2405, 0.2401, 0.2394, 0.2379, 0.2378, 0.2368, 0.2363, 0.236 ,\n",
       "            0.235 , 0.2346, 0.2344, 0.2339, 0.2328, 0.2322, 0.2318, 0.2303,\n",
       "            0.2286, 0.2283, 0.2278, 0.2274, 0.226 , 0.2255, 0.2234, 0.2229,\n",
       "            0.2218, 0.2191, 0.2186, 0.218 , 0.2177, 0.217 , 0.2168, 0.2167,\n",
       "            0.2162, 0.2161, 0.2147, 0.2139, 0.2135, 0.2128, 0.2125, 0.2119,\n",
       "            0.2114, 0.2109, 0.2094, 0.2073, 0.2051, 0.205 , 0.2035, 0.2013,\n",
       "            0.201 , 0.2001, 0.1989, 0.1984, 0.1982, 0.1976, 0.1967, 0.1962,\n",
       "            0.196 , 0.1942, 0.1941, 0.185 , 0.1846, 0.1844, 0.1841, 0.1838,\n",
       "            0.1826, 0.1805, 0.1799, 0.1797, 0.1785, 0.1781, 0.1758, 0.1757,\n",
       "            0.1737, 0.171 , 0.1598, 0.1597, 0.1592, 0.1583, 0.1531, 0.1453,\n",
       "            0.1403], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.3283582 , 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.619403  , 0.6268657 ,\n",
       "            0.6268657 , 0.6268657 , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.64179105, 0.64179105, 0.64179105, 0.6492537 , 0.6492537 ,\n",
       "            0.6567164 , 0.6567164 , 0.6567164 , 0.6641791 , 0.6641791 ,\n",
       "            0.67164177, 0.67164177, 0.67164177, 0.67164177, 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6865672 , 0.6865672 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73134327, 0.73134327, 0.73880595, 0.73880595,\n",
       "            0.74626863, 0.74626863, 0.75373137, 0.75373137, 0.75373137,\n",
       "            0.76119405, 0.76119405, 0.76865673, 0.7761194 , 0.7761194 ,\n",
       "            0.7835821 , 0.7835821 , 0.7910448 , 0.7910448 , 0.79850745,\n",
       "            0.79850745, 0.79850745, 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8432836 , 0.8507463 , 0.85820895, 0.85820895,\n",
       "            0.85820895, 0.86567163, 0.86567163, 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.880597  , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.8955224 , 0.8955224 , 0.9029851 , 0.9029851 ,\n",
       "            0.9104478 , 0.9104478 , 0.91791046, 0.92537314, 0.92537314,\n",
       "            0.92537314, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.95522386, 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.97761196, 0.97761196,\n",
       "            0.97761196, 0.97761196, 0.98507464, 0.9925373 , 0.9925373 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.04310345, 0.05172414, 0.06034483, 0.06896552,\n",
       "            0.0775862 , 0.0775862 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12068965, 0.12931034, 0.12931034,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1637931 , 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.25862068, 0.2672414 , 0.27586207, 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.3448276 , 0.3448276 , 0.35344827, 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.37931034, 0.37931034,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.43103448, 0.44827586, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5       , 0.51724136, 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.55172414, 0.55172414, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.57758623, 0.5948276 ,\n",
       "            0.5948276 , 0.6034483 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.7413793 , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4475 , 0.4463 , 0.4446 , 0.4443 , 0.4434 , 0.4402 ,\n",
       "            0.4373 , 0.4363 , 0.436  , 0.4326 , 0.4314 , 0.4304 , 0.4302 ,\n",
       "            0.43   , 0.4297 , 0.4292 , 0.4282 , 0.428  , 0.4277 , 0.4275 ,\n",
       "            0.4268 , 0.4253 , 0.425  , 0.424  , 0.4185 , 0.418  , 0.4175 ,\n",
       "            0.4165 , 0.4143 , 0.4126 , 0.411  , 0.4106 , 0.4104 , 0.4102 ,\n",
       "            0.41   , 0.4094 , 0.409  , 0.4087 , 0.408  , 0.407  , 0.4067 ,\n",
       "            0.4058 , 0.4053 , 0.405  , 0.4045 , 0.4038 , 0.4028 , 0.3994 ,\n",
       "            0.3987 , 0.3984 , 0.3975 , 0.3943 , 0.393  , 0.3892 , 0.3865 ,\n",
       "            0.385  , 0.3801 , 0.3757 , 0.3745 , 0.3667 , 0.3645 , 0.3625 ,\n",
       "            0.3608 , 0.36   , 0.344  , 0.343  , 0.3376 , 0.3328 , 0.332  ,\n",
       "            0.3296 , 0.325  , 0.3218 , 0.32   , 0.3198 , 0.318  , 0.3137 ,\n",
       "            0.3096 , 0.3066 , 0.3042 , 0.3022 , 0.302  , 0.3005 , 0.2998 ,\n",
       "            0.2974 , 0.2952 , 0.2942 , 0.2925 , 0.2917 , 0.2905 , 0.2903 ,\n",
       "            0.2898 , 0.289  , 0.288  , 0.2878 , 0.286  , 0.2847 , 0.2842 ,\n",
       "            0.284  , 0.2783 , 0.2773 , 0.2732 , 0.2712 , 0.2695 , 0.2664 ,\n",
       "            0.2659 , 0.2644 , 0.2632 , 0.2607 , 0.2605 , 0.2583 , 0.2563 ,\n",
       "            0.2554 , 0.2551 , 0.253  , 0.2522 , 0.2517 , 0.2489 , 0.2487 ,\n",
       "            0.247  , 0.2466 , 0.2451 , 0.2441 , 0.2429 , 0.2428 , 0.2422 ,\n",
       "            0.2399 , 0.2395 , 0.2382 , 0.2378 , 0.2368 , 0.236  , 0.2316 ,\n",
       "            0.2314 , 0.2303 , 0.2302 , 0.228  , 0.2272 , 0.2269 , 0.2268 ,\n",
       "            0.2261 , 0.2246 , 0.2239 , 0.2233 , 0.2225 , 0.2213 , 0.2208 ,\n",
       "            0.2198 , 0.2194 , 0.219  , 0.2172 , 0.2166 , 0.2162 , 0.2157 ,\n",
       "            0.2156 , 0.2152 , 0.2147 , 0.214  , 0.2137 , 0.213  , 0.212  ,\n",
       "            0.2109 , 0.2106 , 0.2104 , 0.2098 , 0.2094 , 0.2089 , 0.2076 ,\n",
       "            0.2058 , 0.205  , 0.2047 , 0.2042 , 0.2037 , 0.201  , 0.2    ,\n",
       "            0.1995 , 0.1989 , 0.1962 , 0.1958 , 0.1956 , 0.1954 , 0.1953 ,\n",
       "            0.1947 , 0.194  , 0.1925 , 0.1918 , 0.1913 , 0.19   , 0.189  ,\n",
       "            0.1882 , 0.1879 , 0.187  , 0.1869 , 0.1849 , 0.1826 , 0.1824 ,\n",
       "            0.1816 , 0.18   , 0.1797 , 0.178  , 0.1779 , 0.1765 , 0.1761 ,\n",
       "            0.1755 , 0.1735 , 0.1731 , 0.173  , 0.1729 , 0.1721 , 0.1709 ,\n",
       "            0.1696 , 0.1615 , 0.1608 , 0.1604 , 0.1603 , 0.1593 , 0.159  ,\n",
       "            0.1578 , 0.1561 , 0.1558 , 0.1545 , 0.1534 , 0.1511 , 0.151  ,\n",
       "            0.1508 , 0.1482 , 0.1361 , 0.1357 , 0.1355 , 0.134  , 0.1298 ,\n",
       "            0.12244, 0.1184 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.18656716, 0.19402985, 0.20895523,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.63432837, 0.64179105, 0.64179105, 0.64179105, 0.64179105,\n",
       "            0.64179105, 0.64179105, 0.6492537 , 0.6567164 , 0.6567164 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.6641791 , 0.67164177,\n",
       "            0.67164177, 0.67164177, 0.6791045 , 0.6791045 , 0.6791045 ,\n",
       "            0.6791045 , 0.6791045 , 0.6791045 , 0.6865672 , 0.6865672 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.73880595, 0.73880595,\n",
       "            0.73880595, 0.73880595, 0.74626863, 0.74626863, 0.74626863,\n",
       "            0.74626863, 0.74626863, 0.75373137, 0.76119405, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7835821 , 0.7835821 ,\n",
       "            0.7910448 , 0.7910448 , 0.7910448 , 0.7910448 , 0.79850745,\n",
       "            0.79850745, 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8507463 , 0.8507463 , 0.85820895, 0.85820895,\n",
       "            0.85820895, 0.86567163, 0.86567163, 0.8731343 , 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.8955224 , 0.8955224 , 0.9029851 , 0.9104478 , 0.9104478 ,\n",
       "            0.91791046, 0.91791046, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.95522386, 0.95522386, 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.97761196, 0.97761196,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 0.9925373 , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.04310345, 0.05172414, 0.06896552, 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.12931034, 0.12931034, 0.13793103, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.14655173, 0.15517241, 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.21551724,\n",
       "            0.22413793, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.25862068, 0.2672414 , 0.27586207, 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.35344827, 0.36206895, 0.36206895, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.55172414, 0.55172414, 0.55172414,\n",
       "            0.55172414, 0.55172414, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4382 , 0.4368 , 0.4353 , 0.4346 , 0.4343 , 0.43   ,\n",
       "            0.428  , 0.4275 , 0.427  , 0.4248 , 0.4229 , 0.4226 , 0.4224 ,\n",
       "            0.4219 , 0.4202 , 0.4194 , 0.4192 , 0.419  , 0.4177 , 0.4172 ,\n",
       "            0.4163 , 0.4153 , 0.4087 , 0.4062 , 0.4053 , 0.4023 , 0.402  ,\n",
       "            0.4014 , 0.401  , 0.4006 , 0.4004 , 0.3997 , 0.399  , 0.3977 ,\n",
       "            0.3965 , 0.3962 , 0.396  , 0.3955 , 0.3953 , 0.3948 , 0.3938 ,\n",
       "            0.3933 , 0.3926 , 0.3892 , 0.3887 , 0.3867 , 0.382  , 0.3813 ,\n",
       "            0.3809 , 0.3772 , 0.3745 , 0.3733 , 0.367  , 0.363  , 0.3613 ,\n",
       "            0.353  , 0.3499 , 0.3462 , 0.3442 , 0.329  , 0.3281 , 0.3215 ,\n",
       "            0.3179 , 0.3142 , 0.313  , 0.3096 , 0.3035 , 0.3027 , 0.2998 ,\n",
       "            0.2952 , 0.2917 , 0.2893 , 0.285  , 0.2842 , 0.2837 , 0.2832 ,\n",
       "            0.2805 , 0.2773 , 0.2766 , 0.2761 , 0.2751 , 0.2734 , 0.2703 ,\n",
       "            0.2698 , 0.2688 , 0.2678 , 0.266  , 0.2637 , 0.2588 , 0.2576 ,\n",
       "            0.2534 , 0.2524 , 0.2502 , 0.2477 , 0.2445 , 0.244  , 0.2429 ,\n",
       "            0.2397 , 0.2395 , 0.2374 , 0.2366 , 0.2358 , 0.2344 , 0.2335 ,\n",
       "            0.2332 , 0.2327 , 0.231  , 0.2303 , 0.2295 , 0.2277 , 0.226  ,\n",
       "            0.2257 , 0.2235 , 0.223  , 0.2229 , 0.2218 , 0.2217 , 0.2213 ,\n",
       "            0.2181 , 0.2179 , 0.2175 , 0.2167 , 0.2152 , 0.2118 , 0.2104 ,\n",
       "            0.2101 , 0.21   , 0.2094 , 0.209  , 0.2086 , 0.2073 , 0.2065 ,\n",
       "            0.2059 , 0.2054 , 0.2051 , 0.204  , 0.2037 , 0.2023 , 0.2018 ,\n",
       "            0.2009 , 0.1996 , 0.1995 , 0.1991 , 0.1989 , 0.1974 , 0.1964 ,\n",
       "            0.196  , 0.1958 , 0.1953 , 0.195  , 0.1948 , 0.1943 , 0.1942 ,\n",
       "            0.1941 , 0.1936 , 0.1925 , 0.1924 , 0.1915 , 0.1896 , 0.1891 ,\n",
       "            0.1887 , 0.1886 , 0.1877 , 0.1869 , 0.1857 , 0.1849 , 0.1846 ,\n",
       "            0.1843 , 0.1835 , 0.183  , 0.1823 , 0.1803 , 0.179  , 0.1785 ,\n",
       "            0.1775 , 0.177  , 0.1768 , 0.1764 , 0.1763 , 0.1747 , 0.1735 ,\n",
       "            0.173  , 0.1726 , 0.1715 , 0.1708 , 0.1704 , 0.1699 , 0.167  ,\n",
       "            0.1666 , 0.1661 , 0.1654 , 0.1648 , 0.163  , 0.1626 , 0.161  ,\n",
       "            0.1606 , 0.1582 , 0.1573 , 0.1572 , 0.1565 , 0.1556 , 0.1547 ,\n",
       "            0.1526 , 0.1525 , 0.1519 , 0.1514 , 0.151  , 0.1504 , 0.1477 ,\n",
       "            0.1412 , 0.1406 , 0.14   , 0.1387 , 0.1385 , 0.1377 , 0.1376 ,\n",
       "            0.1356 , 0.1342 , 0.1333 , 0.132  , 0.131  , 0.1298 , 0.1295 ,\n",
       "            0.1284 , 0.11597, 0.11554, 0.11475, 0.113  , 0.1099 , 0.1032 ,\n",
       "            0.1    ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.03731343,\n",
       "            0.05223881, 0.05970149, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.18656716,\n",
       "            0.19402985, 0.20895523, 0.21641791, 0.2238806 , 0.23134328,\n",
       "            0.23880596, 0.24626866, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29850745, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.619403  , 0.619403  ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.63432837, 0.63432837, 0.63432837, 0.64179105, 0.64179105,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6567164 , 0.6567164 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6791045 , 0.6791045 , 0.6791045 ,\n",
       "            0.6791045 , 0.6791045 , 0.6865672 , 0.69402987, 0.69402987,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 , 0.7238806 ,\n",
       "            0.73134327, 0.73134327, 0.73880595, 0.73880595, 0.73880595,\n",
       "            0.74626863, 0.74626863, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7835821 ,\n",
       "            0.7835821 , 0.7835821 , 0.7835821 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.79850745, 0.79850745, 0.80597013, 0.80597013,\n",
       "            0.80597013, 0.80597013, 0.80597013, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.82835823, 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.8507463 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.86567163, 0.86567163, 0.8731343 ,\n",
       "            0.8731343 , 0.8731343 , 0.880597  , 0.8880597 , 0.8880597 ,\n",
       "            0.8955224 , 0.8955224 , 0.9029851 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.91791046, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.92537314, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.95522386, 0.95522386, 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.97761196, 0.97761196, 0.98507464, 0.9925373 , 0.9925373 ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.04310345, 0.05172414, 0.06034483,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12931034, 0.12931034, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.14655173, 0.14655173, 0.14655173,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.18965517, 0.20689656, 0.21551724, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.3448276 , 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62068963, 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4282 , 0.427  , 0.4258 , 0.4246 , 0.4194 , 0.4185 ,\n",
       "            0.4163 , 0.4143 , 0.414  , 0.4138 , 0.4128 , 0.4111 , 0.4106 ,\n",
       "            0.4102 , 0.4087 , 0.4084 , 0.408  , 0.4075 , 0.4062 , 0.3994 ,\n",
       "            0.3962 , 0.3938 , 0.3936 , 0.3933 , 0.3928 , 0.3923 , 0.3918 ,\n",
       "            0.3916 , 0.3914 , 0.39   , 0.389  , 0.3887 , 0.3877 , 0.3875 ,\n",
       "            0.3865 , 0.3857 , 0.3845 , 0.384  , 0.3835 , 0.383  , 0.3828 ,\n",
       "            0.3823 , 0.38   , 0.3794 , 0.3792 , 0.375  , 0.372  , 0.3704 ,\n",
       "            0.367  , 0.3662 , 0.3633 , 0.363  , 0.3562 , 0.3508 , 0.3486 ,\n",
       "            0.3398 , 0.3381 , 0.3342 , 0.3315 , 0.3286 , 0.3152 , 0.3147 ,\n",
       "            0.3088 , 0.3044 , 0.3013 , 0.2969 , 0.2954 , 0.29   , 0.2893 ,\n",
       "            0.289  , 0.2815 , 0.2776 , 0.277  , 0.2751 , 0.2703 , 0.27   ,\n",
       "            0.2688 , 0.268  , 0.2646 , 0.2627 , 0.2612 , 0.2595 , 0.259  ,\n",
       "            0.2585 , 0.2556 , 0.255  , 0.2542 , 0.2532 , 0.2522 , 0.252  ,\n",
       "            0.2515 , 0.2487 , 0.2405 , 0.2386 , 0.2372 , 0.2351 , 0.2343 ,\n",
       "            0.2325 , 0.2289 , 0.2247 , 0.2242 , 0.2239 , 0.2211 , 0.2203 ,\n",
       "            0.2195 , 0.2189 , 0.2173 , 0.217  , 0.2158 , 0.215  , 0.2129 ,\n",
       "            0.2114 , 0.2076 , 0.2075 , 0.207  , 0.2069 , 0.206  , 0.2056 ,\n",
       "            0.2054 , 0.2032 , 0.2028 , 0.2026 , 0.2021 , 0.2018 , 0.1973 ,\n",
       "            0.1968 , 0.196  , 0.195  , 0.1943 , 0.1917 , 0.1903 , 0.1901 ,\n",
       "            0.19   , 0.1896 , 0.1885 , 0.1882 , 0.1879 , 0.1869 , 0.1859 ,\n",
       "            0.1858 , 0.1827 , 0.1823 , 0.1816 , 0.1812 , 0.1803 , 0.1799 ,\n",
       "            0.1791 , 0.1788 , 0.1775 , 0.1772 , 0.1768 , 0.1766 , 0.1758 ,\n",
       "            0.1754 , 0.1753 , 0.1749 , 0.1743 , 0.1731 , 0.1729 , 0.1704 ,\n",
       "            0.1703 , 0.1698 , 0.1692 , 0.1688 , 0.1685 , 0.1678 , 0.1677 ,\n",
       "            0.1669 , 0.1656 , 0.1646 , 0.1637 , 0.1631 , 0.1627 , 0.1619 ,\n",
       "            0.1611 , 0.1608 , 0.1606 , 0.16   , 0.1599 , 0.1592 , 0.1564 ,\n",
       "            0.156  , 0.1559 , 0.1555 , 0.1536 , 0.153  , 0.1528 , 0.151  ,\n",
       "            0.1506 , 0.1473 , 0.1465 , 0.1462 , 0.1453 , 0.1437 , 0.1431 ,\n",
       "            0.1411 , 0.1396 , 0.1393 , 0.139  , 0.1387 , 0.1373 , 0.1367 ,\n",
       "            0.1346 , 0.1345 , 0.1335 , 0.1328 , 0.1324 , 0.132  , 0.1315 ,\n",
       "            0.1282 , 0.124  , 0.1236 , 0.12213, 0.122  , 0.12   , 0.119  ,\n",
       "            0.1188 , 0.118  , 0.11554, 0.1152 , 0.1142 , 0.11316, 0.1118 ,\n",
       "            0.11145, 0.11084, 0.09894, 0.09875, 0.0972 , 0.0955 , 0.0933 ,\n",
       "            0.0874 , 0.08496], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.54477614, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.63432837, 0.63432837, 0.63432837, 0.63432837,\n",
       "            0.63432837, 0.64179105, 0.64179105, 0.6492537 , 0.6492537 ,\n",
       "            0.6492537 , 0.6567164 , 0.6567164 , 0.6567164 , 0.6567164 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.6641791 , 0.6791045 ,\n",
       "            0.6791045 , 0.6791045 , 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.69402987, 0.70149255, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.7238806 , 0.7238806 , 0.73134327,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.75373137, 0.76119405, 0.76865673, 0.76865673,\n",
       "            0.76865673, 0.7761194 , 0.7761194 , 0.7835821 , 0.7835821 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.79850745, 0.80597013,\n",
       "            0.80597013, 0.80597013, 0.80597013, 0.80597013, 0.80597013,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8432836 , 0.8432836 , 0.8432836 , 0.8507463 ,\n",
       "            0.8507463 , 0.8507463 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.86567163, 0.86567163, 0.86567163, 0.8731343 , 0.8731343 ,\n",
       "            0.880597  , 0.880597  , 0.8880597 , 0.8880597 , 0.8955224 ,\n",
       "            0.8955224 , 0.9029851 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.91791046, 0.92537314, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.95522386, 0.95522386, 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            0.9925373 , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.04310345, 0.04310345, 0.05172414,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.09482758, 0.09482758,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.12931034,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.14655173, 0.14655173,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.20689656, 0.21551724,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25      , 0.25862068, 0.2672414 , 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37068966, 0.37931034, 0.37931034,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.5       , 0.5       , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.5344828 , 0.5344828 ,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.62068963, 0.62068963, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.76724136, 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.9396552 , 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4167 , 0.4158 , 0.4146 , 0.4133 , 0.413  , 0.4094 ,\n",
       "            0.4077 , 0.4075 , 0.4065 , 0.4043 , 0.4036 , 0.4026 , 0.4011 ,\n",
       "            0.4004 , 0.4001 , 0.3994 , 0.399  , 0.3977 , 0.397  , 0.3958 ,\n",
       "            0.3955 , 0.3887 , 0.3855 , 0.3845 , 0.3828 , 0.3826 , 0.3818 ,\n",
       "            0.381  , 0.3809 , 0.38   , 0.379  , 0.377  , 0.3767 , 0.3765 ,\n",
       "            0.3762 , 0.376  , 0.3752 , 0.3735 , 0.3726 , 0.372  , 0.371  ,\n",
       "            0.3708 , 0.3704 , 0.3696 , 0.3684 , 0.3677 , 0.3616 , 0.3599 ,\n",
       "            0.3574 , 0.353  , 0.3518 , 0.3503 , 0.3499 , 0.3425 , 0.3367 ,\n",
       "            0.3345 , 0.3252 , 0.3235 , 0.3186 , 0.3157 , 0.3115 , 0.2996 ,\n",
       "            0.2993 , 0.2932 , 0.289  , 0.2847 , 0.28   , 0.2795 , 0.273  ,\n",
       "            0.2727 , 0.2627 , 0.2607 , 0.2585 , 0.258  , 0.253  , 0.2527 ,\n",
       "            0.2524 , 0.2512 , 0.251  , 0.2478 , 0.2462 , 0.2451 , 0.2428 ,\n",
       "            0.2422 , 0.241  , 0.2375 , 0.2367 , 0.2366 , 0.2362 , 0.2347 ,\n",
       "            0.2344 , 0.234  , 0.2332 , 0.2306 , 0.2216 , 0.2198 , 0.2194 ,\n",
       "            0.2177 , 0.2153 , 0.2147 , 0.2101 , 0.2058 , 0.205  , 0.2047 ,\n",
       "            0.2032 , 0.2028 , 0.2006 , 0.1993 , 0.1979 , 0.1976 , 0.1973 ,\n",
       "            0.1923 , 0.1918 , 0.1885 , 0.1884 , 0.188  , 0.1876 , 0.1874 ,\n",
       "            0.1871 , 0.1866 , 0.1855 , 0.185  , 0.1848 , 0.1843 , 0.1829 ,\n",
       "            0.1823 , 0.179  , 0.1771 , 0.1768 , 0.1761 , 0.1749 , 0.1743 ,\n",
       "            0.174  , 0.1724 , 0.1707 , 0.1705 , 0.1704 , 0.1703 , 0.17   ,\n",
       "            0.1677 , 0.1675 , 0.1664 , 0.1636 , 0.1633 , 0.1632 , 0.1626 ,\n",
       "            0.162  , 0.1617 , 0.1616 , 0.1604 , 0.1594 , 0.1592 , 0.159  ,\n",
       "            0.1582 , 0.1573 , 0.1564 , 0.1562 , 0.1558 , 0.1556 , 0.1548 ,\n",
       "            0.1547 , 0.1537 , 0.1519 , 0.1516 , 0.1512 , 0.1508 , 0.1505 ,\n",
       "            0.1498 , 0.1483 , 0.1473 , 0.146  , 0.1456 , 0.1453 , 0.1449 ,\n",
       "            0.1448 , 0.1445 , 0.1442 , 0.144  , 0.1438 , 0.1428 , 0.1412 ,\n",
       "            0.14   , 0.1382 , 0.1376 , 0.1365 , 0.1364 , 0.135  , 0.1343 ,\n",
       "            0.134  , 0.1337 , 0.132  , 0.1307 , 0.1284 , 0.128  , 0.1271 ,\n",
       "            0.1263 , 0.1254 , 0.1251 , 0.1225 , 0.1223 , 0.1219 , 0.1217 ,\n",
       "            0.12115, 0.1201 , 0.1197 , 0.1192 , 0.1174 , 0.1172 , 0.11597,\n",
       "            0.1158 , 0.1144 , 0.1134 , 0.11316, 0.1099 , 0.10724, 0.10706,\n",
       "            0.1058 , 0.10504, 0.1025 , 0.10144, 0.10126, 0.0981 , 0.0979 ,\n",
       "            0.0959 , 0.09436, 0.0937 , 0.0833 , 0.083  , 0.08124, 0.07935,\n",
       "            0.07806, 0.07275, 0.0709 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.25373134, 0.26119402, 0.26865673,\n",
       "            0.2761194 , 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.54477614, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 , 0.6119403 ,\n",
       "            0.6119403 , 0.619403  , 0.619403  , 0.63432837, 0.63432837,\n",
       "            0.63432837, 0.63432837, 0.64179105, 0.64179105, 0.64179105,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6791045 , 0.6865672 , 0.6865672 ,\n",
       "            0.6865672 , 0.69402987, 0.69402987, 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7089552 , 0.7164179 , 0.7238806 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.74626863, 0.74626863,\n",
       "            0.75373137, 0.75373137, 0.76119405, 0.76119405, 0.76865673,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7835821 , 0.7835821 ,\n",
       "            0.7835821 , 0.7910448 , 0.7910448 , 0.79850745, 0.79850745,\n",
       "            0.80597013, 0.80597013, 0.8134328 , 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.86567163, 0.86567163, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8880597 , 0.8880597 ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9029851 , 0.9104478 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.9328358 , 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.95522386, 0.95522386, 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.97761196, 0.97761196,\n",
       "            0.98507464, 0.9925373 , 0.9925373 , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.03448276, 0.04310345, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12068965,\n",
       "            0.12931034, 0.12931034, 0.13793103, 0.13793103, 0.14655173,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.1637931 , 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.23275863, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.38793105, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.45689654, 0.46551725, 0.47413793, 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.62068963, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.70689654, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8534483 , 0.8534483 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.4048 , 0.4038 , 0.4028 , 0.4014 , 0.4011 , 0.3992 ,\n",
       "            0.3967 , 0.3965 , 0.3948 , 0.3945 , 0.3943 , 0.3928 , 0.3918 ,\n",
       "            0.3916 , 0.391  , 0.3901 , 0.39   , 0.3892 , 0.3887 , 0.3884 ,\n",
       "            0.3867 , 0.3865 , 0.385  , 0.3823 , 0.378  , 0.3752 , 0.373  ,\n",
       "            0.3726 , 0.3723 , 0.3716 , 0.3706 , 0.3704 , 0.3662 , 0.366  ,\n",
       "            0.3652 , 0.365  , 0.3645 , 0.364  , 0.3635 , 0.362  , 0.3618 ,\n",
       "            0.361  , 0.3599 , 0.358  , 0.3577 , 0.3574 , 0.3572 , 0.349  ,\n",
       "            0.3481 , 0.3457 , 0.3408 , 0.3396 , 0.338  , 0.3357 , 0.3313 ,\n",
       "            0.3235 , 0.3208 , 0.3118 , 0.3115 , 0.3064 , 0.2998 , 0.2944 ,\n",
       "            0.2864 , 0.2854 , 0.281  , 0.276  , 0.2722 , 0.2664 , 0.2627 ,\n",
       "            0.2605 , 0.2603 , 0.26   , 0.2478 , 0.2456 , 0.2437 , 0.2401 ,\n",
       "            0.2399 , 0.2391 , 0.239  , 0.2384 , 0.2355 , 0.2327 , 0.2322 ,\n",
       "            0.2311 , 0.2281 , 0.2278 , 0.2247 , 0.2239 , 0.2235 , 0.2234 ,\n",
       "            0.223  , 0.2216 , 0.2212 , 0.2175 , 0.217  , 0.2148 , 0.2064 ,\n",
       "            0.2042 , 0.2034 , 0.202  , 0.2004 , 0.197  , 0.1956 , 0.1925 ,\n",
       "            0.19   , 0.1893 , 0.1873 , 0.1864 , 0.1859 , 0.1842 , 0.1812 ,\n",
       "            0.1798 , 0.1776 , 0.1754 , 0.1747 , 0.174  , 0.1733 , 0.172  ,\n",
       "            0.1718 , 0.1709 , 0.1705 , 0.1697 , 0.1682 , 0.1672 , 0.1653 ,\n",
       "            0.1641 , 0.1636 , 0.163  , 0.161  , 0.1589 , 0.1587 , 0.1584 ,\n",
       "            0.1572 , 0.1571 , 0.1558 , 0.1544 , 0.1539 , 0.1531 , 0.1521 ,\n",
       "            0.152  , 0.1504 , 0.1495 , 0.1493 , 0.1484 , 0.148  , 0.1477 ,\n",
       "            0.1464 , 0.1462 , 0.1454 , 0.1442 , 0.1437 , 0.1425 , 0.1414 ,\n",
       "            0.1412 , 0.141  , 0.1393 , 0.1387 , 0.1378 , 0.1377 , 0.137  ,\n",
       "            0.1366 , 0.1362 , 0.1361 , 0.1357 , 0.1342 , 0.1338 , 0.1322 ,\n",
       "            0.1311 , 0.1305 , 0.1301 , 0.1296 , 0.1295 , 0.129  , 0.1284 ,\n",
       "            0.1279 , 0.1274 , 0.1249 , 0.12335, 0.1225 , 0.12244, 0.12213,\n",
       "            0.12177, 0.1213 , 0.1197 , 0.1184 , 0.11816, 0.118  , 0.11676,\n",
       "            0.11536, 0.1118 , 0.11145, 0.1103 , 0.1097 , 0.1095 , 0.1086 ,\n",
       "            0.1074 , 0.1067 , 0.1058 , 0.1052 , 0.1045 , 0.1041 , 0.1036 ,\n",
       "            0.10266, 0.1023 , 0.1011 , 0.1005 , 0.09894, 0.09686, 0.09656,\n",
       "            0.0933 , 0.0932 , 0.09235, 0.0906 , 0.0871 , 0.0862 , 0.086  ,\n",
       "            0.08466, 0.08344, 0.083  , 0.0825 , 0.0804 , 0.07965, 0.07837,\n",
       "            0.06995, 0.0698 , 0.0677 , 0.06573, 0.06525, 0.06076, 0.05975],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.03731343,\n",
       "            0.04477612, 0.05970149, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.10447761, 0.1119403 , 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.1716418 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26865673, 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5597015 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.57462686, 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.58208954, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.64179105, 0.64179105, 0.64179105, 0.64179105,\n",
       "            0.64179105, 0.64179105, 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6641791 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.6865672 , 0.6865672 , 0.6865672 , 0.6865672 ,\n",
       "            0.69402987, 0.69402987, 0.70149255, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.74626863, 0.74626863, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76119405, 0.76865673, 0.76865673, 0.76865673,\n",
       "            0.7761194 , 0.7761194 , 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.7910448 , 0.7910448 , 0.79850745, 0.79850745, 0.79850745,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8134328 , 0.8134328 ,\n",
       "            0.8208955 , 0.8358209 , 0.8432836 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.86567163, 0.86567163, 0.86567163, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8880597 , 0.8880597 ,\n",
       "            0.8955224 , 0.8955224 , 0.9029851 , 0.9104478 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.92537314, 0.92537314, 0.9328358 ,\n",
       "            0.9328358 , 0.9402985 , 0.9402985 , 0.9477612 , 0.9477612 ,\n",
       "            0.95522386, 0.95522386, 0.95522386, 0.95522386, 0.96268654,\n",
       "            0.96268654, 0.9701493 , 0.9701493 , 0.9701493 , 0.97761196,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00862069, 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.04310345, 0.06034483, 0.06896552,\n",
       "            0.06896552, 0.0775862 , 0.0862069 , 0.09482758, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.12931034, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.14655173, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.19827586, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.2413793 , 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43103448, 0.44827586, 0.45689654, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.49137932, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.6034483 , 0.6034483 , 0.61206895, 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.62068963, 0.62931037, 0.63793105, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.82758623, 0.82758623, 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3933 , 0.3928 , 0.392  , 0.39   , 0.389  , 0.3867 ,\n",
       "            0.3845 , 0.3843 , 0.3833 , 0.3826 , 0.381  , 0.3801 , 0.38   ,\n",
       "            0.3792 , 0.379  , 0.3784 , 0.3767 , 0.3762 , 0.3752 , 0.375  ,\n",
       "            0.37   , 0.368  , 0.3652 , 0.3628 , 0.3625 , 0.362  , 0.361  ,\n",
       "            0.3606 , 0.3604 , 0.3596 , 0.3562 , 0.3552 , 0.3547 , 0.354  ,\n",
       "            0.3528 , 0.3523 , 0.352  , 0.3516 , 0.3513 , 0.35   , 0.3481 ,\n",
       "            0.348  , 0.3477 , 0.3467 , 0.346  , 0.3455 , 0.3398 , 0.3372 ,\n",
       "            0.3357 , 0.331  , 0.3303 , 0.3281 , 0.323  , 0.322  , 0.3132 ,\n",
       "            0.3103 , 0.303  , 0.3013 , 0.2974 , 0.2874 , 0.281  , 0.2769 ,\n",
       "            0.2751 , 0.2722 , 0.2664 , 0.2637 , 0.2568 , 0.252  , 0.2515 ,\n",
       "            0.2502 , 0.2394 , 0.2368 , 0.2316 , 0.2314 , 0.2302 , 0.2301 ,\n",
       "            0.2297 , 0.2251 , 0.2247 , 0.2235 , 0.2216 , 0.2185 , 0.2175 ,\n",
       "            0.2167 , 0.2158 , 0.2152 , 0.2145 , 0.2129 , 0.2114 , 0.2095 ,\n",
       "            0.2053 , 0.2021 , 0.1979 , 0.1958 , 0.1934 , 0.191  , 0.1893 ,\n",
       "            0.1876 , 0.1848 , 0.1826 , 0.1816 , 0.181  , 0.1796 , 0.1776 ,\n",
       "            0.1755 , 0.1743 , 0.173  , 0.1704 , 0.1678 , 0.1666 , 0.1665 ,\n",
       "            0.1649 , 0.1646 , 0.1636 , 0.1624 , 0.1611 , 0.1599 , 0.1586 ,\n",
       "            0.1581 , 0.1566 , 0.1564 , 0.156  , 0.1552 , 0.1531 , 0.1511 ,\n",
       "            0.1509 , 0.1497 , 0.1495 , 0.1493 , 0.1486 , 0.1469 , 0.1467 ,\n",
       "            0.144  , 0.1437 , 0.1431 , 0.142  , 0.1417 , 0.1409 , 0.1405 ,\n",
       "            0.1404 , 0.1396 , 0.139  , 0.1389 , 0.1387 , 0.1377 , 0.1371 ,\n",
       "            0.135  , 0.134  , 0.1323 , 0.1312 , 0.131  , 0.1305 , 0.1293 ,\n",
       "            0.1289 , 0.1288 , 0.1271 , 0.1266 , 0.1262 , 0.1257 , 0.1254 ,\n",
       "            0.1252 , 0.12445, 0.1242 , 0.12366, 0.1232 , 0.12286, 0.12177,\n",
       "            0.1213 , 0.12024, 0.1194 , 0.1193 , 0.1188 , 0.1184 , 0.1174 ,\n",
       "            0.1172 , 0.1166 , 0.115  , 0.1144 , 0.1142 , 0.113  , 0.1128 ,\n",
       "            0.1118 , 0.11127, 0.1105 , 0.1084 , 0.1067 , 0.1063 , 0.1052 ,\n",
       "            0.1023 , 0.10126, 0.1011 , 0.0995 , 0.0991 , 0.09894, 0.09875,\n",
       "            0.0986 , 0.09753, 0.0959 , 0.09534, 0.09515, 0.0939 , 0.0937 ,\n",
       "            0.0935 , 0.0925 , 0.09155, 0.0899 , 0.0869 , 0.0868 , 0.0854 ,\n",
       "            0.0851 , 0.0845 , 0.0831 , 0.082  , 0.0788 , 0.07825, 0.0774 ,\n",
       "            0.0771 , 0.07684, 0.075  , 0.0749 , 0.0742 , 0.07135, 0.0712 ,\n",
       "            0.0694 , 0.06244, 0.06232, 0.0601 , 0.05814, 0.058  , 0.054  ,\n",
       "            0.0535 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.5298507 , 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6044776 , 0.6044776 , 0.6119403 , 0.619403  , 0.619403  ,\n",
       "            0.619403  , 0.619403  , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.63432837, 0.63432837, 0.64179105,\n",
       "            0.64179105, 0.64179105, 0.64179105, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.6641791 , 0.6641791 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6791045 , 0.6865672 ,\n",
       "            0.6865672 , 0.69402987, 0.69402987, 0.69402987, 0.69402987,\n",
       "            0.70149255, 0.70149255, 0.70149255, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.73880595,\n",
       "            0.74626863, 0.74626863, 0.74626863, 0.75373137, 0.75373137,\n",
       "            0.75373137, 0.76119405, 0.76119405, 0.76119405, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7835821 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.79850745, 0.79850745, 0.79850745,\n",
       "            0.79850745, 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8507463 , 0.8507463 , 0.8507463 , 0.85820895, 0.85820895,\n",
       "            0.86567163, 0.86567163, 0.8731343 , 0.8731343 , 0.8880597 ,\n",
       "            0.8880597 , 0.8880597 , 0.8955224 , 0.8955224 , 0.8955224 ,\n",
       "            0.9029851 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9328358 , 0.9402985 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.95522386, 0.95522386, 0.95522386, 0.95522386,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.02586207, 0.02586207, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1637931 , 0.1637931 , 0.1724138 , 0.1724138 ,\n",
       "            0.18103448, 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.23275863,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.45689654, 0.46551725, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.5086207 ,\n",
       "            0.5086207 , 0.51724136, 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.54310346, 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.63793105, 0.6465517 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.6896552 , 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.70689654, 0.7155172 , 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3828 , 0.3823 , 0.3816 , 0.3792 , 0.379  , 0.3782 ,\n",
       "            0.3772 , 0.377  , 0.3748 , 0.3743 , 0.373  , 0.3728 , 0.3708 ,\n",
       "            0.3706 , 0.37   , 0.3699 , 0.3694 , 0.369  , 0.3677 , 0.3667 ,\n",
       "            0.3657 , 0.36   , 0.3591 , 0.3557 , 0.3545 , 0.3528 , 0.3523 ,\n",
       "            0.3513 , 0.3508 , 0.3499 , 0.3489 , 0.3474 , 0.3472 , 0.347  ,\n",
       "            0.3467 , 0.3462 , 0.3447 , 0.344  , 0.3438 , 0.343  , 0.3423 ,\n",
       "            0.3413 , 0.3408 , 0.3406 , 0.3398 , 0.3389 , 0.337  , 0.3345 ,\n",
       "            0.334  , 0.3293 , 0.3289 , 0.3252 , 0.3245 , 0.3218 , 0.318  ,\n",
       "            0.3137 , 0.3074 , 0.304  , 0.3008 , 0.2964 , 0.2961 , 0.2803 ,\n",
       "            0.2732 , 0.2727 , 0.2717 , 0.271  , 0.2646 , 0.2634 , 0.2542 ,\n",
       "            0.2534 , 0.2522 , 0.2515 , 0.244  , 0.2401 , 0.237  , 0.2339 ,\n",
       "            0.2322 , 0.2319 , 0.229  , 0.2225 , 0.2222 , 0.2208 , 0.2195 ,\n",
       "            0.2194 , 0.219  , 0.2179 , 0.2177 , 0.2168 , 0.2163 , 0.2152 ,\n",
       "            0.2147 , 0.2137 , 0.2134 , 0.2124 , 0.206  , 0.201  , 0.199  ,\n",
       "            0.197  , 0.1965 , 0.194  , 0.1936 , 0.1882 , 0.1859 , 0.1835 ,\n",
       "            0.1827 , 0.1824 , 0.182  , 0.1794 , 0.1768 , 0.1754 , 0.172  ,\n",
       "            0.1697 , 0.1692 , 0.1677 , 0.1675 , 0.1652 , 0.1638 , 0.1624 ,\n",
       "            0.1608 , 0.1587 , 0.1584 , 0.1573 , 0.1567 , 0.1547 , 0.1544 ,\n",
       "            0.1537 , 0.1525 , 0.152  , 0.1515 , 0.1512 , 0.1504 , 0.1498 ,\n",
       "            0.1469 , 0.1465 , 0.1456 , 0.1438 , 0.143  , 0.1427 , 0.1422 ,\n",
       "            0.1417 , 0.1412 , 0.1395 , 0.1387 , 0.1385 , 0.1382 , 0.138  ,\n",
       "            0.1376 , 0.1368 , 0.1365 , 0.1364 , 0.1359 , 0.134  , 0.1335 ,\n",
       "            0.1334 , 0.1328 , 0.1305 , 0.1294 , 0.1288 , 0.1287 , 0.128  ,\n",
       "            0.1277 , 0.127  , 0.1265 , 0.1262 , 0.1251 , 0.1249 , 0.124  ,\n",
       "            0.1239 , 0.1232 , 0.1226 , 0.1225 , 0.1216 , 0.12146, 0.12115,\n",
       "            0.1207 , 0.1195 , 0.119  , 0.1186 , 0.11816, 0.118  , 0.11676,\n",
       "            0.11597, 0.115  , 0.11475, 0.1134 , 0.11316, 0.113  , 0.1128 ,\n",
       "            0.112  , 0.11145, 0.11127, 0.10913, 0.10876, 0.1065 , 0.1034 ,\n",
       "            0.103  , 0.1025 , 0.10034, 0.0998 , 0.09845, 0.0981 , 0.0974 ,\n",
       "            0.0967 , 0.0964 , 0.096  , 0.0942 , 0.0939 , 0.0933 , 0.0927 ,\n",
       "            0.0922 , 0.0914 , 0.09125, 0.0899 , 0.0882 , 0.0848 , 0.08417,\n",
       "            0.08405, 0.0806 , 0.0798 , 0.0775 , 0.0763 , 0.0761 , 0.07544,\n",
       "            0.0752 , 0.0742 , 0.07367, 0.07227, 0.0695 , 0.06903, 0.0672 ,\n",
       "            0.0613 , 0.05878, 0.05707, 0.05634, 0.0533 , 0.0532 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.06716418, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.2238806 , 0.23880596, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2835821 , 0.29104477, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.5298507 , 0.5298507 , 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.58208954, 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.6119403 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.619403  , 0.619403  , 0.619403  , 0.6268657 ,\n",
       "            0.6268657 , 0.63432837, 0.63432837, 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.6641791 , 0.6641791 , 0.6641791 , 0.6641791 , 0.67164177,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.69402987,\n",
       "            0.70149255, 0.70149255, 0.70149255, 0.70149255, 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.73880595, 0.73880595, 0.74626863, 0.75373137, 0.75373137,\n",
       "            0.75373137, 0.75373137, 0.76119405, 0.76119405, 0.76119405,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.79850745, 0.79850745, 0.79850745,\n",
       "            0.79850745, 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8358209 , 0.8432836 , 0.8432836 ,\n",
       "            0.8507463 , 0.8507463 , 0.85820895, 0.85820895, 0.85820895,\n",
       "            0.8731343 , 0.880597  , 0.880597  , 0.8880597 , 0.8880597 ,\n",
       "            0.8880597 , 0.8955224 , 0.8955224 , 0.8955224 , 0.9029851 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9402985 , 0.9402985 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.95522386, 0.95522386, 0.95522386,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.97761196, 0.97761196, 0.98507464, 0.9925373 , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00862069, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.03448276, 0.03448276, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06896552, 0.0775862 , 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.19827586,\n",
       "            0.20689656, 0.20689656, 0.20689656, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31896552, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.37931034, 0.38793105,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.43965518, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5       , 0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5344828 , 0.54310346, 0.54310346,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 , 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.6034483 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.62068963, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.70689654, 0.70689654, 0.7155172 , 0.7241379 , 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3745 , 0.374  , 0.3735 , 0.3718 , 0.3699 , 0.3696 ,\n",
       "            0.3674 , 0.3667 , 0.365  , 0.3645 , 0.3643 , 0.3633 , 0.3623 ,\n",
       "            0.3616 , 0.3613 , 0.361  , 0.3608 , 0.3599 , 0.3591 , 0.3584 ,\n",
       "            0.3582 , 0.3552 , 0.353  , 0.3499 , 0.348  , 0.344  , 0.343  ,\n",
       "            0.3425 , 0.341  , 0.3406 , 0.34   , 0.3398 , 0.3396 , 0.3394 ,\n",
       "            0.3389 , 0.3386 , 0.3381 , 0.337  , 0.3364 , 0.336  , 0.3347 ,\n",
       "            0.3315 , 0.3281 , 0.327  , 0.3242 , 0.3235 , 0.3232 , 0.321  ,\n",
       "            0.3186 , 0.3127 , 0.3083 , 0.305  , 0.3042 , 0.301  , 0.298  ,\n",
       "            0.282  , 0.278  , 0.2776 , 0.2754 , 0.2742 , 0.273  , 0.2683 ,\n",
       "            0.263  , 0.2607 , 0.2598 , 0.2595 , 0.2493 , 0.2477 , 0.246  ,\n",
       "            0.2451 , 0.2426 , 0.2417 , 0.237  , 0.2319 , 0.2314 , 0.2306 ,\n",
       "            0.2278 , 0.2272 , 0.2266 , 0.2261 , 0.2252 , 0.2249 , 0.2242 ,\n",
       "            0.2238 , 0.2233 , 0.222  , 0.2217 , 0.2119 , 0.21   , 0.2081 ,\n",
       "            0.208  , 0.2076 , 0.2042 , 0.2023 , 0.202  , 0.1964 , 0.1952 ,\n",
       "            0.1941 , 0.1924 , 0.1912 , 0.1882 , 0.1866 , 0.1853 , 0.1831 ,\n",
       "            0.1819 , 0.1771 , 0.177  , 0.1766 , 0.1743 , 0.173  , 0.1727 ,\n",
       "            0.1721 , 0.1672 , 0.167  , 0.1665 , 0.1664 , 0.1653 , 0.1648 ,\n",
       "            0.1646 , 0.1643 , 0.1641 , 0.1626 , 0.1589 , 0.1588 , 0.1575 ,\n",
       "            0.1567 , 0.1562 , 0.156  , 0.154  , 0.1538 , 0.1527 , 0.1511 ,\n",
       "            0.1498 , 0.1489 , 0.1487 , 0.1481 , 0.1477 , 0.1475 , 0.1461 ,\n",
       "            0.146  , 0.1455 , 0.1451 , 0.1447 , 0.1445 , 0.1423 , 0.1421 ,\n",
       "            0.139  , 0.1389 , 0.1381 , 0.1372 , 0.1364 , 0.1361 , 0.1359 ,\n",
       "            0.1357 , 0.1355 , 0.1349 , 0.1334 , 0.1329 , 0.1324 , 0.132  ,\n",
       "            0.1318 , 0.1313 , 0.1312 , 0.131  , 0.1304 , 0.13   , 0.1288 ,\n",
       "            0.1283 , 0.127  , 0.1268 , 0.1262 , 0.1256 , 0.1243 , 0.1241 ,\n",
       "            0.1232 , 0.1229 , 0.1225 , 0.1219 , 0.121  , 0.12085, 0.1207 ,\n",
       "            0.1188 , 0.1172 , 0.11597, 0.112  , 0.1099 , 0.1097 , 0.1093 ,\n",
       "            0.1076 , 0.10706, 0.1058 , 0.1054 , 0.1052 , 0.1043 , 0.1034 ,\n",
       "            0.1032 , 0.1021 , 0.1019 , 0.10156, 0.1009 , 0.0998 , 0.0993 ,\n",
       "            0.0974 , 0.0942 , 0.0933 , 0.0922 , 0.09204, 0.0898 , 0.0871 ,\n",
       "            0.0866 , 0.08527, 0.0848 , 0.08386, 0.0836 , 0.0831 , 0.0824 ,\n",
       "            0.0805 , 0.0778 , 0.07684, 0.07477, 0.06964, 0.0695 , 0.06683,\n",
       "            0.0651 , 0.06396, 0.0613 , 0.0611 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.10447761, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14925373, 0.15671642,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 ,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.54477614, 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.6119403 , 0.619403  , 0.619403  , 0.619403  ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.6268657 , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6567164 , 0.6641791 , 0.6641791 , 0.67164177, 0.67164177,\n",
       "            0.6791045 , 0.6791045 , 0.6865672 , 0.70149255, 0.70149255,\n",
       "            0.70149255, 0.70149255, 0.7089552 , 0.7089552 , 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7164179 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76119405, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7761194 , 0.7761194 , 0.7835821 , 0.7910448 , 0.7910448 ,\n",
       "            0.79850745, 0.79850745, 0.79850745, 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8134328 , 0.8208955 , 0.82835823, 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.85820895, 0.85820895, 0.86567163, 0.880597  , 0.8880597 ,\n",
       "            0.8880597 , 0.8880597 , 0.8955224 , 0.8955224 , 0.8955224 ,\n",
       "            0.9029851 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9402985 , 0.9402985 , 0.9402985 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.9477612 , 0.95522386,\n",
       "            0.95522386, 0.95522386, 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.97761196, 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.00862069, 0.01724138, 0.01724138, 0.01724138, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.05172414, 0.06034483, 0.06896552,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.11206897, 0.12931034, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.19827586,\n",
       "            0.19827586, 0.19827586, 0.19827586, 0.20689656, 0.20689656,\n",
       "            0.21551724, 0.21551724, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.28448275, 0.30172414, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.3448276 , 0.35344827,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.5086207 , 0.5086207 , 0.51724136, 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.62931037, 0.63793105, 0.6465517 , 0.6465517 ,\n",
       "            0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.67241377, 0.6810345 , 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7155172 , 0.7155172 , 0.7241379 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3672 , 0.3667 , 0.3662 , 0.3657 , 0.3633 , 0.3613 ,\n",
       "            0.3594 , 0.359  , 0.3582 , 0.3577 , 0.3567 , 0.3564 , 0.3557 ,\n",
       "            0.3555 , 0.3545 , 0.3542 , 0.353  , 0.3525 , 0.3523 , 0.3518 ,\n",
       "            0.3516 , 0.3499 , 0.3484 , 0.3474 , 0.3418 , 0.3413 , 0.3403 ,\n",
       "            0.3396 , 0.3386 , 0.3381 , 0.338  , 0.3372 , 0.337  , 0.3364 ,\n",
       "            0.3362 , 0.336  , 0.3357 , 0.3354 , 0.3345 , 0.3342 , 0.334  ,\n",
       "            0.3335 , 0.3328 , 0.3315 , 0.3298 , 0.3286 , 0.328  , 0.327  ,\n",
       "            0.3247 , 0.3235 , 0.3228 , 0.3137 , 0.3132 , 0.3123 , 0.3115 ,\n",
       "            0.3113 , 0.308  , 0.3027 , 0.2893 , 0.287  , 0.2852 , 0.2847 ,\n",
       "            0.2822 , 0.278  , 0.277  , 0.2764 , 0.2742 , 0.2722 , 0.268  ,\n",
       "            0.263  , 0.2612 , 0.259  , 0.2583 , 0.2556 , 0.2534 , 0.25   ,\n",
       "            0.2483 , 0.2438 , 0.2428 , 0.2421 , 0.2394 , 0.2388 , 0.237  ,\n",
       "            0.2367 , 0.2356 , 0.2338 , 0.2328 , 0.2314 , 0.2311 , 0.2286 ,\n",
       "            0.2274 , 0.2251 , 0.2233 , 0.2211 , 0.2195 , 0.2181 , 0.2163 ,\n",
       "            0.215  , 0.2113 , 0.2096 , 0.2073 , 0.2004 , 0.199  , 0.1984 ,\n",
       "            0.1959 , 0.1925 , 0.191  , 0.1909 , 0.1873 , 0.186  , 0.1848 ,\n",
       "            0.1836 , 0.1823 , 0.1821 , 0.182  , 0.181  , 0.1803 , 0.1794 ,\n",
       "            0.1775 , 0.1749 , 0.1737 , 0.1735 , 0.173  , 0.1727 , 0.172  ,\n",
       "            0.1714 , 0.1677 , 0.1671 , 0.1665 , 0.1648 , 0.1625 , 0.1624 ,\n",
       "            0.1609 , 0.1606 , 0.1594 , 0.1589 , 0.158  , 0.157  , 0.1567 ,\n",
       "            0.1562 , 0.1558 , 0.1542 , 0.1536 , 0.1521 , 0.1508 , 0.1503 ,\n",
       "            0.1494 , 0.1492 , 0.149  , 0.1489 , 0.1478 , 0.1477 , 0.1472 ,\n",
       "            0.1469 , 0.1462 , 0.1449 , 0.1448 , 0.1431 , 0.142  , 0.1418 ,\n",
       "            0.1415 , 0.1414 , 0.1409 , 0.1405 , 0.1404 , 0.1396 , 0.1376 ,\n",
       "            0.1372 , 0.1353 , 0.135  , 0.1349 , 0.1348 , 0.1342 , 0.134  ,\n",
       "            0.1338 , 0.1332 , 0.1324 , 0.1321 , 0.1302 , 0.1301 , 0.1273 ,\n",
       "            0.12274, 0.1222 , 0.12085, 0.12054, 0.1193 , 0.1184 , 0.11694,\n",
       "            0.1158 , 0.11536, 0.11456, 0.1144 , 0.1138 , 0.1134 , 0.1128 ,\n",
       "            0.112  , 0.1103 , 0.1099 , 0.1086 , 0.1054 , 0.10486, 0.1045 ,\n",
       "            0.10175, 0.10144, 0.10034, 0.0972 , 0.096  , 0.0957 , 0.09485,\n",
       "            0.094  , 0.0939 , 0.0935 , 0.09283, 0.0903 , 0.0877 , 0.0859 ,\n",
       "            0.08374, 0.07947, 0.07935, 0.0763 , 0.07465, 0.0729 , 0.07104,\n",
       "            0.07056], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.01492537, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.06716418, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.31343284, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47014925, 0.47014925,\n",
       "            0.47761193, 0.47761193, 0.48507464, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.53731346, 0.53731346, 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5597015 , 0.5597015 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.619403  , 0.619403  , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.63432837, 0.63432837, 0.64179105, 0.6492537 , 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.6641791 , 0.6641791 , 0.67164177,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.69402987,\n",
       "            0.69402987, 0.69402987, 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7164179 , 0.7164179 , 0.7238806 , 0.7238806 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7761194 ,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8134328 ,\n",
       "            0.8208955 , 0.8208955 , 0.82835823, 0.82835823, 0.8358209 ,\n",
       "            0.8358209 , 0.8432836 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.85820895, 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8880597 , 0.8955224 , 0.8955224 ,\n",
       "            0.8955224 , 0.9029851 , 0.9029851 , 0.9029851 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9402985 , 0.9477612 , 0.9477612 , 0.9477612 , 0.9477612 ,\n",
       "            0.95522386, 0.95522386, 0.96268654, 0.96268654, 0.9701493 ,\n",
       "            0.9701493 , 0.9701493 , 0.97761196, 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00862069,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.03448276, 0.04310345, 0.04310345, 0.05172414, 0.05172414,\n",
       "            0.05172414, 0.06034483, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.0775862 , 0.0862069 , 0.09482758, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.14655173, 0.15517241,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.28448275,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.4827586 , 0.4827586 , 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5603448 , 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.7586207 , 0.76724136, 0.76724136,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9310345 , 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.     , 0.362  , 0.3613 , 0.361  , 0.3591 , 0.3586 , 0.3574 ,\n",
       "            0.3545 , 0.3538 , 0.3535 , 0.3528 , 0.3516 , 0.3513 , 0.3494 ,\n",
       "            0.3489 , 0.3484 , 0.348  , 0.3472 , 0.3464 , 0.3455 , 0.3447 ,\n",
       "            0.3433 , 0.343  , 0.3428 , 0.3416 , 0.341  , 0.3408 , 0.3403 ,\n",
       "            0.3398 , 0.3396 , 0.339  , 0.3389 , 0.3386 , 0.3381 , 0.338  ,\n",
       "            0.3376 , 0.3374 , 0.3357 , 0.3354 , 0.335  , 0.3347 , 0.3335 ,\n",
       "            0.3328 , 0.3325 , 0.3315 , 0.3313 , 0.3298 , 0.3296 , 0.3286 ,\n",
       "            0.3271 , 0.326  , 0.3257 , 0.3245 , 0.322  , 0.3188 , 0.3179 ,\n",
       "            0.3154 , 0.3118 , 0.3079 , 0.3066 , 0.3047 , 0.3003 , 0.297  ,\n",
       "            0.2947 , 0.2942 , 0.2932 , 0.2908 , 0.2898 , 0.2852 , 0.2847 ,\n",
       "            0.2834 , 0.282  , 0.2817 , 0.2788 , 0.2769 , 0.2766 , 0.2764 ,\n",
       "            0.269  , 0.2673 , 0.2664 , 0.2637 , 0.2607 , 0.2605 , 0.2595 ,\n",
       "            0.2588 , 0.2576 , 0.2524 , 0.2493 , 0.249  , 0.2474 , 0.2467 ,\n",
       "            0.246  , 0.2428 , 0.2418 , 0.2391 , 0.2384 , 0.2374 , 0.2352 ,\n",
       "            0.233  , 0.2328 , 0.2313 , 0.2311 , 0.2246 , 0.2227 , 0.219  ,\n",
       "            0.2186 , 0.2162 , 0.2145 , 0.2124 , 0.2095 , 0.2079 , 0.2075 ,\n",
       "            0.2063 , 0.206  , 0.2056 , 0.2047 , 0.2045 , 0.2028 , 0.2024 ,\n",
       "            0.2013 , 0.2002 , 0.1971 , 0.1965 , 0.1964 , 0.1958 , 0.1952 ,\n",
       "            0.1913 , 0.1892 , 0.1891 , 0.1887 , 0.1874 , 0.1869 , 0.1858 ,\n",
       "            0.1833 , 0.1805 , 0.1803 , 0.1796 , 0.179  , 0.1788 , 0.1776 ,\n",
       "            0.1775 , 0.1754 , 0.1753 , 0.1752 , 0.1747 , 0.1744 , 0.1733 ,\n",
       "            0.1718 , 0.1704 , 0.1697 , 0.169  , 0.1687 , 0.1686 , 0.1681 ,\n",
       "            0.1677 , 0.1661 , 0.166  , 0.1659 , 0.1649 , 0.164  , 0.1638 ,\n",
       "            0.1631 , 0.163  , 0.1619 , 0.1606 , 0.1593 , 0.159  , 0.1588 ,\n",
       "            0.158  , 0.1572 , 0.1561 , 0.156  , 0.1543 , 0.1536 , 0.1533 ,\n",
       "            0.1528 , 0.1526 , 0.1525 , 0.1509 , 0.1508 , 0.1504 , 0.1498 ,\n",
       "            0.1495 , 0.1488 , 0.1464 , 0.1459 , 0.1443 , 0.1406 , 0.1393 ,\n",
       "            0.1392 , 0.1389 , 0.1378 , 0.1368 , 0.1353 , 0.134  , 0.1333 ,\n",
       "            0.1332 , 0.1327 , 0.1326 , 0.1324 , 0.1316 , 0.131  , 0.1302 ,\n",
       "            0.13   , 0.1289 , 0.1282 , 0.1268 , 0.1266 , 0.12366, 0.12317,\n",
       "            0.1226 , 0.118  , 0.1172 , 0.11475, 0.11395, 0.1118 , 0.11066,\n",
       "            0.1105 , 0.1103 , 0.1067 , 0.1043 , 0.10126, 0.09894, 0.096  ,\n",
       "            0.0959 , 0.0925 , 0.0909 , 0.0883 , 0.0874 , 0.0865 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.00746269, 0.01492537, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.15671642, 0.1716418 , 0.17910448, 0.18656716, 0.19402985,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.2238806 , 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.25373134, 0.26865673, 0.2761194 ,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.41791046, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5       , 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.51492536, 0.51492536,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.52238804, 0.52238804, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.53731346, 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.5671642 , 0.5671642 , 0.57462686, 0.57462686,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.58208954, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6044776 , 0.6044776 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.64179105, 0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 ,\n",
       "            0.6567164 , 0.6567164 , 0.6567164 , 0.6641791 , 0.6865672 ,\n",
       "            0.6865672 , 0.6865672 , 0.70149255, 0.70149255, 0.70149255,\n",
       "            0.70149255, 0.7089552 , 0.7089552 , 0.7164179 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73134327, 0.73134327, 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.74626863, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.76865673, 0.7761194 , 0.7761194 ,\n",
       "            0.7835821 , 0.7835821 , 0.7835821 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.8955224 , 0.9029851 ,\n",
       "            0.9029851 , 0.9029851 , 0.9029851 , 0.9104478 , 0.9104478 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9402985 , 0.9477612 , 0.9477612 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.95522386, 0.96268654, 0.96268654,\n",
       "            0.96268654, 0.96268654, 0.9701493 , 0.9701493 , 0.9701493 ,\n",
       "            0.97761196, 0.97761196, 0.98507464, 0.9925373 , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.00862069, 0.00862069, 0.00862069,\n",
       "            0.00862069, 0.00862069, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.01724138, 0.01724138, 0.01724138,\n",
       "            0.01724138, 0.01724138, 0.02586207, 0.02586207, 0.02586207,\n",
       "            0.02586207, 0.02586207, 0.03448276, 0.04310345, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.04310345, 0.05172414, 0.05172414,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.0862069 , 0.10344828, 0.10344828, 0.10344828,\n",
       "            0.11206897, 0.12068965, 0.12931034, 0.13793103, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25      , 0.25      , 0.25862068, 0.2672414 , 0.2672414 ,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31034482, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.35344827, 0.36206895, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5       , 0.5086207 ,\n",
       "            0.5086207 , 0.51724136, 0.51724136, 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5258621 , 0.5344828 , 0.54310346, 0.55172414,\n",
       "            0.55172414, 0.5689655 , 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.63793105, 0.63793105, 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7758621 , 0.7758621 , 0.7844828 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.8189655 , 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.     , 0.3608 , 0.3594 , 0.359  , 0.3586 , 0.3584 , 0.3582 ,\n",
       "            0.3577 , 0.354  , 0.3538 , 0.353  , 0.3525 , 0.3513 , 0.351  ,\n",
       "            0.3503 , 0.348  , 0.3477 , 0.3474 , 0.3472 , 0.347  , 0.3467 ,\n",
       "            0.3462 , 0.346  , 0.3457 , 0.3455 , 0.3452 , 0.3447 , 0.3445 ,\n",
       "            0.3442 , 0.344  , 0.3438 , 0.3435 , 0.3433 , 0.343  , 0.3425 ,\n",
       "            0.341  , 0.3398 , 0.3394 , 0.3389 , 0.3386 , 0.3381 , 0.338  ,\n",
       "            0.3372 , 0.3367 , 0.3364 , 0.3357 , 0.3352 , 0.3335 , 0.3328 ,\n",
       "            0.3308 , 0.3289 , 0.3284 , 0.3281 , 0.3276 , 0.3257 , 0.3252 ,\n",
       "            0.3237 , 0.321  , 0.3196 , 0.3193 , 0.3167 , 0.3142 , 0.314  ,\n",
       "            0.3125 , 0.3098 , 0.3096 , 0.3088 , 0.3086 , 0.306  , 0.3037 ,\n",
       "            0.303  , 0.3022 , 0.3005 , 0.2988 , 0.2979 , 0.2961 , 0.2954 ,\n",
       "            0.295  , 0.288  , 0.2876 , 0.2864 , 0.2834 , 0.2825 , 0.2808 ,\n",
       "            0.277  , 0.2766 , 0.275  , 0.2747 , 0.2737 , 0.2715 , 0.2683 ,\n",
       "            0.2659 , 0.265  , 0.2646 , 0.2642 , 0.2637 , 0.2617 , 0.2605 ,\n",
       "            0.256  , 0.255  , 0.2537 , 0.2517 , 0.249  , 0.2485 , 0.2482 ,\n",
       "            0.2451 , 0.2434 , 0.2399 , 0.2384 , 0.2374 , 0.2347 , 0.2318 ,\n",
       "            0.2316 , 0.2313 , 0.231  , 0.2294 , 0.2266 , 0.2257 , 0.2252 ,\n",
       "            0.2247 , 0.2246 , 0.2208 , 0.2195 , 0.2184 , 0.2161 , 0.213  ,\n",
       "            0.2124 , 0.209  , 0.2075 , 0.2073 , 0.2051 , 0.2034 , 0.2023 ,\n",
       "            0.2017 , 0.2009 , 0.1998 , 0.1973 , 0.1971 , 0.1967 , 0.1965 ,\n",
       "            0.1959 , 0.1956 , 0.1954 , 0.1953 , 0.1935 , 0.1924 , 0.1906 ,\n",
       "            0.1897 , 0.1896 , 0.189  , 0.1884 , 0.1882 , 0.1876 , 0.1866 ,\n",
       "            0.186  , 0.1853 , 0.185  , 0.1848 , 0.1842 , 0.1838 , 0.1829 ,\n",
       "            0.1816 , 0.1812 , 0.1808 , 0.1804 , 0.1803 , 0.1796 , 0.179  ,\n",
       "            0.1781 , 0.177  , 0.1768 , 0.1763 , 0.1757 , 0.1752 , 0.1749 ,\n",
       "            0.1747 , 0.1744 , 0.1741 , 0.1733 , 0.1726 , 0.1711 , 0.1707 ,\n",
       "            0.1697 , 0.1678 , 0.1669 , 0.1653 , 0.1646 , 0.162  , 0.1614 ,\n",
       "            0.1611 , 0.1605 , 0.1598 , 0.1592 , 0.1575 , 0.1548 , 0.1545 ,\n",
       "            0.1544 , 0.1543 , 0.1539 , 0.1532 , 0.153  , 0.1527 , 0.151  ,\n",
       "            0.1501 , 0.1495 , 0.1494 , 0.1488 , 0.1473 , 0.1462 , 0.1459 ,\n",
       "            0.145  , 0.1399 , 0.1377 , 0.1366 , 0.1365 , 0.136  , 0.1339 ,\n",
       "            0.1326 , 0.1321 , 0.1313 , 0.131  , 0.128  , 0.127  , 0.12494,\n",
       "            0.1201 , 0.1178 , 0.11676, 0.1166 , 0.113  , 0.11145, 0.1084 ,\n",
       "            0.1076 , 0.1069 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02985075, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.07462686, 0.08955224, 0.08955224, 0.09701493,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.18656716, 0.20149253,\n",
       "            0.20895523, 0.2238806 , 0.23134328, 0.23880596, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4552239 , 0.46268657, 0.47014925, 0.47014925,\n",
       "            0.47014925, 0.47014925, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 ,\n",
       "            0.5522388 , 0.5522388 , 0.5522388 , 0.5522388 , 0.5597015 ,\n",
       "            0.5597015 , 0.5671642 , 0.5671642 , 0.5671642 , 0.5671642 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.58208954, 0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.5970149 , 0.5970149 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6492537 , 0.6492537 , 0.6492537 , 0.6567164 ,\n",
       "            0.6567164 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.70149255, 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7164179 , 0.7238806 , 0.7238806 ,\n",
       "            0.7238806 , 0.73134327, 0.73134327, 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.76865673,\n",
       "            0.7761194 , 0.7761194 , 0.7761194 , 0.7761194 , 0.7910448 ,\n",
       "            0.79850745, 0.79850745, 0.80597013, 0.8134328 , 0.8134328 ,\n",
       "            0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.880597  , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9328358 , 0.9328358 , 0.9328358 , 0.9402985 , 0.9402985 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.96268654, 0.96268654,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.02586207,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "            0.03448276, 0.03448276, 0.03448276, 0.04310345, 0.04310345,\n",
       "            0.04310345, 0.04310345, 0.04310345, 0.04310345, 0.05172414,\n",
       "            0.06034483, 0.06034483, 0.06034483, 0.06896552, 0.06896552,\n",
       "            0.06896552, 0.06896552, 0.0775862 , 0.0775862 , 0.0775862 ,\n",
       "            0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 , 0.0775862 ,\n",
       "            0.0775862 , 0.0862069 , 0.0862069 , 0.09482758, 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.10344828, 0.11206897, 0.11206897,\n",
       "            0.12068965, 0.12068965, 0.12068965, 0.12068965, 0.12068965,\n",
       "            0.12068965, 0.12068965, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.14655173, 0.14655173, 0.14655173, 0.14655173,\n",
       "            0.14655173, 0.14655173, 0.15517241, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.19827586,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.2413793 , 0.25      , 0.25862068,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.31896552, 0.31896552, 0.31896552, 0.31896552,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.39655173, 0.39655173,\n",
       "            0.4051724 , 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.54310346, 0.54310346, 0.54310346,\n",
       "            0.54310346, 0.55172414, 0.5603448 , 0.5689655 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.5948276 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.61206895, 0.61206895,\n",
       "            0.62068963, 0.62068963, 0.63793105, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6551724 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.73275864, 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.82758623, 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.3735, 0.3655, 0.3652, 0.3623, 0.3616, 0.3591, 0.3582,\n",
       "            0.3564, 0.3562, 0.356 , 0.3557, 0.3552, 0.3545, 0.3542, 0.353 ,\n",
       "            0.3528, 0.352 , 0.3506, 0.3503, 0.35  , 0.3499, 0.3496, 0.3494,\n",
       "            0.3489, 0.3484, 0.348 , 0.3477, 0.3474, 0.347 , 0.346 , 0.3457,\n",
       "            0.3455, 0.345 , 0.3447, 0.3445, 0.344 , 0.3433, 0.342 , 0.341 ,\n",
       "            0.3406, 0.3403, 0.3396, 0.3394, 0.3389, 0.338 , 0.3376, 0.337 ,\n",
       "            0.3367, 0.3364, 0.3362, 0.3354, 0.333 , 0.3325, 0.3315, 0.3306,\n",
       "            0.3303, 0.33  , 0.329 , 0.328 , 0.3264, 0.3254, 0.325 , 0.3232,\n",
       "            0.3203, 0.3193, 0.318 , 0.3176, 0.3171, 0.3152, 0.3137, 0.3135,\n",
       "            0.3123, 0.3118, 0.3074, 0.3064, 0.306 , 0.304 , 0.2998, 0.2961,\n",
       "            0.2957, 0.2952, 0.294 , 0.2935, 0.292 , 0.2917, 0.2903, 0.2898,\n",
       "            0.2842, 0.2837, 0.282 , 0.2795, 0.2788, 0.2764, 0.2751, 0.2722,\n",
       "            0.2693, 0.2686, 0.2664, 0.2651, 0.265 , 0.2632, 0.263 , 0.2617,\n",
       "            0.2605, 0.2559, 0.2534, 0.2494, 0.248 , 0.2466, 0.2407, 0.2378,\n",
       "            0.237 , 0.2356, 0.2343, 0.234 , 0.2303, 0.2286, 0.2283, 0.2261,\n",
       "            0.226 , 0.2249, 0.2247, 0.2203, 0.2197, 0.219 , 0.218 , 0.2168,\n",
       "            0.2161, 0.2157, 0.215 , 0.2133, 0.213 , 0.212 , 0.2118, 0.211 ,\n",
       "            0.2109, 0.2108, 0.2106, 0.2086, 0.2084, 0.2081, 0.2079, 0.2076,\n",
       "            0.2059, 0.2056, 0.2054, 0.2031, 0.2024, 0.2021, 0.202 , 0.2009,\n",
       "            0.2007, 0.2006, 0.2004, 0.1996, 0.1995, 0.1985, 0.1971, 0.1968,\n",
       "            0.1967, 0.1956, 0.1954, 0.1947, 0.1943, 0.1942, 0.1903, 0.1896,\n",
       "            0.1886, 0.1848, 0.1844, 0.1842, 0.1838, 0.1835, 0.183 , 0.1829,\n",
       "            0.1821, 0.1807, 0.1797, 0.1779, 0.1775, 0.1772, 0.1763, 0.1753,\n",
       "            0.1743, 0.173 , 0.1726, 0.1709, 0.1707, 0.1705, 0.1696, 0.1686,\n",
       "            0.1676, 0.1674, 0.1671, 0.1622, 0.1598, 0.1592, 0.1575, 0.1564,\n",
       "            0.1547, 0.1542, 0.1533, 0.152 , 0.1515, 0.1473, 0.1458, 0.1447,\n",
       "            0.1384, 0.1383, 0.1359, 0.134 , 0.1327, 0.1313, 0.1285, 0.127 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.1119403 , 0.11940298,\n",
       "            0.12686567, 0.14179105, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.17910448, 0.19402985, 0.20149253, 0.20895523, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29850745, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.37313432, 0.37313432, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.41044775,\n",
       "            0.41044775, 0.41791046, 0.41791046, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5597015 , 0.5671642 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 , 0.5895522 ,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6044776 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6492537 , 0.6492537 ,\n",
       "            0.6492537 , 0.6641791 , 0.67164177, 0.6791045 , 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.7238806 , 0.73134327, 0.73134327,\n",
       "            0.73134327, 0.73134327, 0.73880595, 0.74626863, 0.74626863,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7761194 , 0.7835821 , 0.7835821 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.80597013, 0.8134328 ,\n",
       "            0.8134328 , 0.8134328 , 0.8208955 , 0.8208955 , 0.8208955 ,\n",
       "            0.8208955 , 0.8208955 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.86567163, 0.86567163, 0.8731343 , 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9328358 , 0.9328358 , 0.9328358 ,\n",
       "            0.9402985 , 0.9402985 , 0.9477612 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.95522386, 0.95522386, 0.96268654,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.9701493 , 0.9701493 ,\n",
       "            0.9701493 , 0.97761196, 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.13793103, 0.13793103, 0.14655173,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 ,\n",
       "            0.1724138 , 0.1724138 , 0.1724138 , 0.1724138 , 0.18103448,\n",
       "            0.18103448, 0.18103448, 0.18103448, 0.18103448, 0.18103448,\n",
       "            0.18965517, 0.18965517, 0.18965517, 0.18965517, 0.18965517,\n",
       "            0.18965517, 0.18965517, 0.18965517, 0.20689656, 0.20689656,\n",
       "            0.20689656, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.2672414 , 0.2672414 , 0.2672414 , 0.27586207, 0.27586207,\n",
       "            0.28448275, 0.28448275, 0.29310346, 0.30172414, 0.30172414,\n",
       "            0.30172414, 0.31034482, 0.31034482, 0.31896552, 0.31896552,\n",
       "            0.31896552, 0.3275862 , 0.3275862 , 0.3275862 , 0.3275862 ,\n",
       "            0.33620688, 0.35344827, 0.36206895, 0.36206895, 0.37068966,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.37931034, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.44827586, 0.44827586,\n",
       "            0.46551725, 0.46551725, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5258621 , 0.5258621 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.54310346, 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5603448 , 0.5689655 , 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.6034483 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 , 0.67241377,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7155172 , 0.73275864, 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.80172414, 0.80172414, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4011, 0.3997, 0.3982, 0.3928, 0.3906, 0.3904, 0.39  ,\n",
       "            0.389 , 0.3838, 0.3833, 0.3823, 0.3818, 0.3804, 0.373 , 0.3718,\n",
       "            0.3716, 0.3706, 0.3699, 0.3694, 0.3684, 0.3665, 0.3643, 0.3633,\n",
       "            0.3623, 0.3618, 0.3613, 0.361 , 0.3608, 0.3606, 0.3604, 0.36  ,\n",
       "            0.3599, 0.3596, 0.3594, 0.3591, 0.3582, 0.358 , 0.3577, 0.3574,\n",
       "            0.357 , 0.3564, 0.3562, 0.356 , 0.3557, 0.3547, 0.354 , 0.3538,\n",
       "            0.3528, 0.3525, 0.3523, 0.351 , 0.3503, 0.35  , 0.3494, 0.3489,\n",
       "            0.3486, 0.3472, 0.346 , 0.3457, 0.3455, 0.3452, 0.345 , 0.3447,\n",
       "            0.344 , 0.3435, 0.343 , 0.3428, 0.3408, 0.3398, 0.3389, 0.3386,\n",
       "            0.3384, 0.338 , 0.3364, 0.336 , 0.3357, 0.3354, 0.335 , 0.3323,\n",
       "            0.3308, 0.33  , 0.3293, 0.3289, 0.3267, 0.326 , 0.3242, 0.3228,\n",
       "            0.3223, 0.3208, 0.3198, 0.3193, 0.3164, 0.3157, 0.315 , 0.3147,\n",
       "            0.3127, 0.3103, 0.3088, 0.3086, 0.3066, 0.3062, 0.3052, 0.301 ,\n",
       "            0.2954, 0.2908, 0.288 , 0.2874, 0.2852, 0.2827, 0.28  , 0.276 ,\n",
       "            0.275 , 0.2725, 0.2676, 0.2673, 0.2642, 0.264 , 0.2637, 0.2632,\n",
       "            0.2605, 0.259 , 0.2573, 0.2566, 0.2563, 0.2556, 0.2524, 0.252 ,\n",
       "            0.2512, 0.2498, 0.2474, 0.2471, 0.246 , 0.2458, 0.2449, 0.244 ,\n",
       "            0.2437, 0.2428, 0.2426, 0.2422, 0.2405, 0.2397, 0.2384, 0.2383,\n",
       "            0.2378, 0.2375, 0.2366, 0.2363, 0.236 , 0.2351, 0.2347, 0.2343,\n",
       "            0.2338, 0.233 , 0.2328, 0.2327, 0.2323, 0.2318, 0.2316, 0.2297,\n",
       "            0.2295, 0.2294, 0.2285, 0.2283, 0.2278, 0.2277, 0.2266, 0.2252,\n",
       "            0.2249, 0.2247, 0.2238, 0.223 , 0.2222, 0.2205, 0.2194, 0.2186,\n",
       "            0.2184, 0.218 , 0.2173, 0.2167, 0.2161, 0.2148, 0.2144, 0.2119,\n",
       "            0.2115, 0.2113, 0.2109, 0.2108, 0.2103, 0.2101, 0.2081, 0.2076,\n",
       "            0.2063, 0.2056, 0.2051, 0.205 , 0.2047, 0.2045, 0.2031, 0.2015,\n",
       "            0.1993, 0.1976, 0.1964, 0.1946, 0.1943, 0.1935, 0.1924, 0.1882,\n",
       "            0.1873, 0.1865, 0.1852, 0.185 , 0.1846, 0.1799, 0.1792, 0.1736,\n",
       "            0.1726, 0.1694, 0.1682, 0.167 , 0.1665, 0.1664, 0.163 , 0.1594],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.01492537,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.02985075, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.1119403 , 0.12686567, 0.13432837,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.1641791 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23134328, 0.23880596, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.29850745, 0.30597016, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.5298507 ,\n",
       "            0.53731346, 0.53731346, 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5895522 , 0.5970149 , 0.5970149 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.619403  ,\n",
       "            0.6268657 , 0.6268657 , 0.6268657 , 0.63432837, 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.6865672 , 0.69402987, 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7238806 , 0.73134327, 0.73134327,\n",
       "            0.73880595, 0.73880595, 0.74626863, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7761194 , 0.7835821 , 0.7835821 , 0.7910448 ,\n",
       "            0.7910448 , 0.7910448 , 0.7910448 , 0.7910448 , 0.79850745,\n",
       "            0.79850745, 0.79850745, 0.79850745, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.82835823, 0.8432836 , 0.8432836 , 0.8432836 ,\n",
       "            0.8432836 , 0.8507463 , 0.8507463 , 0.8507463 , 0.86567163,\n",
       "            0.8731343 , 0.8731343 , 0.880597  , 0.8880597 , 0.9104478 ,\n",
       "            0.91791046, 0.91791046, 0.92537314, 0.92537314, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.95522386, 0.96268654, 0.96268654,\n",
       "            0.96268654, 0.96268654, 0.96268654, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.98507464, 0.9925373 , 0.9925373 ,\n",
       "            0.9925373 , 0.9925373 , 1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.27586207, 0.28448275,\n",
       "            0.29310346, 0.29310346, 0.30172414, 0.31034482, 0.31034482,\n",
       "            0.31896552, 0.31896552, 0.31896552, 0.3275862 , 0.33620688,\n",
       "            0.33620688, 0.33620688, 0.33620688, 0.3448276 , 0.3448276 ,\n",
       "            0.3448276 , 0.35344827, 0.35344827, 0.35344827, 0.35344827,\n",
       "            0.35344827, 0.35344827, 0.35344827, 0.35344827, 0.36206895,\n",
       "            0.36206895, 0.36206895, 0.36206895, 0.36206895, 0.36206895,\n",
       "            0.36206895, 0.36206895, 0.37068966, 0.37068966, 0.37931034,\n",
       "            0.37931034, 0.37931034, 0.37931034, 0.37931034, 0.37931034,\n",
       "            0.38793105, 0.38793105, 0.38793105, 0.38793105, 0.39655173,\n",
       "            0.39655173, 0.39655173, 0.4051724 , 0.4051724 , 0.4051724 ,\n",
       "            0.4051724 , 0.41379312, 0.41379312, 0.41379312, 0.41379312,\n",
       "            0.41379312, 0.41379312, 0.41379312, 0.41379312, 0.4224138 ,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43103448, 0.43103448,\n",
       "            0.43103448, 0.43103448, 0.43103448, 0.43965518, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.46551725, 0.46551725, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.49137932, 0.49137932, 0.49137932, 0.5       , 0.5086207 ,\n",
       "            0.5086207 , 0.5258621 , 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.55172414, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 , 0.5948276 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.6034483 , 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.62931037, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6551724 , 0.6637931 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8189655 , 0.82758623, 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8362069 , 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.4548, 0.449 , 0.4453, 0.445 , 0.4438, 0.441 , 0.4387,\n",
       "            0.4373, 0.437 , 0.4316, 0.4307, 0.4272, 0.4246, 0.4207, 0.4202,\n",
       "            0.419 , 0.4165, 0.4133, 0.413 , 0.4097, 0.4094, 0.4087, 0.4048,\n",
       "            0.4038, 0.4026, 0.3982, 0.3977, 0.3953, 0.393 , 0.3926, 0.39  ,\n",
       "            0.3896, 0.3894, 0.3887, 0.3865, 0.3848, 0.384 , 0.381 , 0.3782,\n",
       "            0.3777, 0.3767, 0.3765, 0.3762, 0.376 , 0.3752, 0.3748, 0.3745,\n",
       "            0.3738, 0.3733, 0.373 , 0.3728, 0.3726, 0.3723, 0.372 , 0.3716,\n",
       "            0.371 , 0.3706, 0.3704, 0.37  , 0.3699, 0.3691, 0.3684, 0.3674,\n",
       "            0.367 , 0.3667, 0.3652, 0.3647, 0.3638, 0.3635, 0.3633, 0.363 ,\n",
       "            0.3625, 0.3618, 0.3616, 0.3608, 0.3606, 0.3599, 0.359 , 0.3584,\n",
       "            0.3552, 0.355 , 0.3542, 0.3538, 0.3533, 0.3518, 0.3516, 0.3513,\n",
       "            0.3496, 0.3486, 0.348 , 0.3474, 0.344 , 0.3425, 0.3423, 0.3418,\n",
       "            0.3413, 0.341 , 0.3386, 0.338 , 0.3372, 0.336 , 0.3352, 0.3345,\n",
       "            0.3308, 0.3276, 0.3247, 0.324 , 0.3232, 0.321 , 0.32  , 0.3196,\n",
       "            0.3193, 0.3176, 0.315 , 0.3142, 0.313 , 0.3123, 0.3118, 0.3103,\n",
       "            0.3074, 0.3064, 0.3062, 0.305 , 0.3015, 0.2998, 0.2993, 0.2974,\n",
       "            0.2969, 0.2964, 0.2957, 0.2932, 0.2917, 0.2903, 0.29  , 0.289 ,\n",
       "            0.2886, 0.2883, 0.2874, 0.287 , 0.2864, 0.2861, 0.2847, 0.2842,\n",
       "            0.284 , 0.2837, 0.2832, 0.283 , 0.282 , 0.2788, 0.2783, 0.278 ,\n",
       "            0.2776, 0.2769, 0.2766, 0.2764, 0.276 , 0.2756, 0.2751, 0.275 ,\n",
       "            0.2742, 0.2737, 0.2734, 0.2727, 0.271 , 0.2708, 0.2695, 0.2693,\n",
       "            0.2688, 0.2686, 0.2664, 0.2654, 0.265 , 0.2644, 0.2642, 0.263 ,\n",
       "            0.2625, 0.2622, 0.2615, 0.2607, 0.2605, 0.2595, 0.2588, 0.2585,\n",
       "            0.2583, 0.2554, 0.255 , 0.2546, 0.2544, 0.2534, 0.2532, 0.2522,\n",
       "            0.2502, 0.2498, 0.2471, 0.2458, 0.2456, 0.2452, 0.2448, 0.243 ,\n",
       "            0.2428, 0.2413, 0.2382, 0.2352, 0.2339, 0.2332, 0.2327, 0.2297,\n",
       "            0.2289, 0.2283, 0.2235, 0.2198, 0.2189, 0.2184, 0.2163, 0.2158,\n",
       "            0.2147, 0.213 , 0.209 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.03448276, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02985075, 0.02985075, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08955224, 0.09701493,\n",
       "            0.1119403 , 0.12686567, 0.13432837, 0.14179105, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.2761194 , 0.2835821 , 0.30597016, 0.31343284,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.41044775, 0.41791046, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.47014925,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.52238804, 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.5671642 , 0.57462686, 0.58208954, 0.58208954,\n",
       "            0.5895522 , 0.5895522 , 0.5970149 , 0.6119403 , 0.6119403 ,\n",
       "            0.619403  , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.69402987, 0.70149255, 0.7089552 , 0.7089552 ,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.76865673, 0.7835821 , 0.7835821 , 0.7910448 , 0.7910448 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.80597013, 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9029851 , 0.9104478 ,\n",
       "            0.9104478 , 0.91791046, 0.91791046, 0.91791046, 0.92537314,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.9477612 ,\n",
       "            0.9477612 , 0.9477612 , 0.9477612 , 0.9477612 , 0.95522386,\n",
       "            0.9701493 , 0.9701493 , 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 0.9925373 , 0.9925373 , 0.9925373 , 0.9925373 ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.39655173, 0.39655173, 0.39655173, 0.4051724 , 0.41379312,\n",
       "            0.41379312, 0.41379312, 0.41379312, 0.41379312, 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.43103448, 0.43103448, 0.43103448,\n",
       "            0.43965518, 0.43965518, 0.43965518, 0.43965518, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.43965518, 0.44827586, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.44827586, 0.44827586,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.44827586, 0.45689654,\n",
       "            0.45689654, 0.45689654, 0.45689654, 0.45689654, 0.45689654,\n",
       "            0.46551725, 0.46551725, 0.46551725, 0.46551725, 0.46551725,\n",
       "            0.46551725, 0.46551725, 0.46551725, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5       , 0.5086207 , 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5258621 , 0.5258621 , 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.5689655 , 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.57758623, 0.5862069 , 0.5948276 , 0.5948276 , 0.6034483 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62068963, 0.62068963, 0.62931037, 0.62931037, 0.62931037,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6551724 ,\n",
       "            0.6551724 , 0.67241377, 0.67241377, 0.67241377, 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.70689654, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7155172 , 0.7155172 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.82758623, 0.82758623, 0.8362069 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9741379 , 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.524 , 0.5117, 0.51  , 0.5054, 0.4973, 0.4963, 0.496 ,\n",
       "            0.4958, 0.4912, 0.491 , 0.484 , 0.4797, 0.4766, 0.4758, 0.474 ,\n",
       "            0.4731, 0.4727, 0.4612, 0.46  , 0.4592, 0.4573, 0.457 , 0.454 ,\n",
       "            0.4539, 0.4514, 0.4512, 0.4487, 0.4475, 0.4473, 0.4468, 0.446 ,\n",
       "            0.4438, 0.4436, 0.4385, 0.4326, 0.4304, 0.4297, 0.4287, 0.427 ,\n",
       "            0.426 , 0.4233, 0.419 , 0.4163, 0.4146, 0.41  , 0.4075, 0.4055,\n",
       "            0.4028, 0.4023, 0.402 , 0.4001, 0.3975, 0.3967, 0.395 , 0.3943,\n",
       "            0.3926, 0.3914, 0.3904, 0.388 , 0.387 , 0.3862, 0.3853, 0.385 ,\n",
       "            0.3848, 0.383 , 0.3823, 0.382 , 0.381 , 0.3806, 0.38  , 0.3796,\n",
       "            0.3784, 0.378 , 0.3774, 0.3772, 0.3767, 0.3757, 0.3755, 0.3743,\n",
       "            0.3738, 0.3718, 0.3716, 0.3684, 0.3674, 0.3672, 0.367 , 0.3667,\n",
       "            0.365 , 0.3638, 0.3635, 0.3633, 0.361 , 0.3599, 0.3591, 0.359 ,\n",
       "            0.3584, 0.3582, 0.3574, 0.3552, 0.3535, 0.3528, 0.351 , 0.35  ,\n",
       "            0.3489, 0.3486, 0.3484, 0.348 , 0.3477, 0.3464, 0.3442, 0.343 ,\n",
       "            0.3425, 0.3413, 0.3408, 0.3403, 0.339 , 0.3389, 0.3386, 0.3381,\n",
       "            0.3376, 0.337 , 0.3364, 0.3352, 0.3347, 0.3345, 0.3342, 0.3335,\n",
       "            0.3325, 0.3318, 0.33  , 0.3298, 0.3296, 0.3293, 0.329 , 0.3289,\n",
       "            0.3286, 0.3271, 0.327 , 0.3267, 0.3264, 0.3254, 0.3245, 0.324 ,\n",
       "            0.3232, 0.323 , 0.3228, 0.3215, 0.3203, 0.32  , 0.3198, 0.3196,\n",
       "            0.3193, 0.3186, 0.3184, 0.3179, 0.3174, 0.3171, 0.317 , 0.3157,\n",
       "            0.3152, 0.3147, 0.3145, 0.3142, 0.314 , 0.3132, 0.313 , 0.3125,\n",
       "            0.3115, 0.3113, 0.3108, 0.31  , 0.3096, 0.3093, 0.309 , 0.3086,\n",
       "            0.3083, 0.3079, 0.307 , 0.3064, 0.3062, 0.3047, 0.3042, 0.3035,\n",
       "            0.3032, 0.3025, 0.3022, 0.302 , 0.3018, 0.3003, 0.3   , 0.2986,\n",
       "            0.2976, 0.293 , 0.2922, 0.2917, 0.2915, 0.2908, 0.2883, 0.2874,\n",
       "            0.2861, 0.286 , 0.2832, 0.2822, 0.2817, 0.2795, 0.2793, 0.279 ,\n",
       "            0.2717, 0.2698, 0.269 , 0.2666], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.31896552, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05970149,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.08208955, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.13432837, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.18656716, 0.20149253,\n",
       "            0.21641791, 0.2238806 , 0.2238806 , 0.24626866, 0.24626866,\n",
       "            0.25373134, 0.26865673, 0.29104477, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.37313432, 0.37313432, 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.47761193, 0.47761193, 0.48507464, 0.49253732, 0.5074627 ,\n",
       "            0.51492536, 0.51492536, 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.54477614, 0.54477614,\n",
       "            0.5597015 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5970149 , 0.5970149 , 0.6044776 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6641791 , 0.6641791 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.69402987, 0.7089552 ,\n",
       "            0.7238806 , 0.73134327, 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.8208955 , 0.8208955 , 0.82835823, 0.82835823,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.8507463 ,\n",
       "            0.8507463 , 0.85820895, 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.8731343 , 0.880597  , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9029851 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25      , 0.2672414 ,\n",
       "            0.27586207, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.44827586, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.45689654, 0.45689654, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.47413793, 0.47413793, 0.47413793, 0.47413793, 0.47413793,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5       , 0.5086207 , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.54310346, 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5603448 , 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.5689655 , 0.5689655 , 0.57758623, 0.5948276 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6465517 , 0.6551724 ,\n",
       "            0.6551724 , 0.6551724 , 0.6551724 , 0.6637931 , 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.6896552 , 0.69827586, 0.69827586,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7758621 ,\n",
       "            0.7758621 , 0.79310346, 0.79310346, 0.79310346, 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.86206895, 0.86206895, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.5996, 0.592 , 0.584 , 0.5776, 0.5723, 0.57  , 0.568 ,\n",
       "            0.5674, 0.565 , 0.563 , 0.56  , 0.558 , 0.5527, 0.5444, 0.544 ,\n",
       "            0.533 , 0.532 , 0.529 , 0.5273, 0.5264, 0.52  , 0.519 , 0.518 ,\n",
       "            0.515 , 0.5137, 0.512 , 0.511 , 0.51  , 0.5093, 0.508 , 0.5073,\n",
       "            0.505 , 0.504 , 0.502 , 0.5   , 0.4998, 0.4976, 0.4941, 0.492 ,\n",
       "            0.4895, 0.4858, 0.4722, 0.4653, 0.462 , 0.46  , 0.4563, 0.4539,\n",
       "            0.4492, 0.4456, 0.443 , 0.441 , 0.439 , 0.4373, 0.4333, 0.4329,\n",
       "            0.4326, 0.424 , 0.422 , 0.4219, 0.4202, 0.4187, 0.4185, 0.4177,\n",
       "            0.4143, 0.413 , 0.4124, 0.4104, 0.4087, 0.4082, 0.4062, 0.404 ,\n",
       "            0.4036, 0.4033, 0.403 , 0.402 , 0.4014, 0.4011, 0.4001, 0.4   ,\n",
       "            0.3992, 0.399 , 0.3975, 0.3965, 0.396 , 0.3958, 0.3955, 0.3953,\n",
       "            0.395 , 0.3943, 0.394 , 0.3936, 0.3926, 0.3923, 0.392 , 0.391 ,\n",
       "            0.3909, 0.3906, 0.3901, 0.3892, 0.3887, 0.3884, 0.3872, 0.387 ,\n",
       "            0.3867, 0.3865, 0.386 , 0.3853, 0.385 , 0.3848, 0.3845, 0.3843,\n",
       "            0.3838, 0.3835, 0.3833, 0.3823, 0.382 , 0.3816, 0.381 , 0.3804,\n",
       "            0.3796, 0.3792, 0.379 , 0.3787, 0.3784, 0.3782, 0.378 , 0.3777,\n",
       "            0.3762, 0.376 , 0.3757, 0.3755, 0.3752, 0.375 , 0.374 , 0.3733,\n",
       "            0.373 , 0.372 , 0.3718, 0.371 , 0.3704, 0.37  , 0.3699, 0.3694,\n",
       "            0.369 , 0.3684, 0.3682, 0.3677, 0.3674, 0.3662, 0.366 , 0.3657,\n",
       "            0.3655, 0.3652, 0.3645, 0.3635, 0.3633, 0.3628, 0.3625, 0.361 ,\n",
       "            0.3608, 0.36  , 0.359 , 0.3584, 0.3577, 0.3564, 0.3557, 0.3547,\n",
       "            0.354 , 0.3538, 0.3535, 0.3528, 0.3523, 0.3518, 0.3508, 0.3503,\n",
       "            0.3496, 0.3472, 0.3447, 0.343 , 0.342 , 0.341 , 0.3398, 0.3374,\n",
       "            0.336 , 0.3352, 0.3335, 0.3298, 0.3264, 0.3235, 0.3186, 0.311 ,\n",
       "            0.31  , 0.3088, 0.3083, 0.3022, 0.2751], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0., dtype=float32),\n",
       "    'tpr': array(0.43965518, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02985075, 0.02985075, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.1716418 , 0.18656716, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.2835821 , 0.2835821 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.30597016, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.35074627, 0.36567163,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3880597 , 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.49253732, 0.5       , 0.5074627 , 0.5298507 ,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.6492537 , 0.6567164 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.70149255, 0.70149255, 0.7089552 , 0.7164179 , 0.7164179 ,\n",
       "            0.7164179 , 0.7164179 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.2413793 , 0.25862068, 0.27586207,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.39655173, 0.4051724 ,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.49137932, 0.49137932, 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.5086207 , 0.5086207 , 0.5086207 , 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.5344828 , 0.5344828 , 0.54310346,\n",
       "            0.54310346, 0.5603448 , 0.57758623, 0.57758623, 0.5948276 ,\n",
       "            0.6034483 , 0.62068963, 0.62931037, 0.6465517 , 0.6637931 ,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.6896552 , 0.70689654, 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.75      , 0.7586207 ,\n",
       "            0.7586207 , 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.79310346, 0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8362069 , 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.94827586, 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.672 , 0.669 , 0.6685, 0.659 , 0.651 , 0.649 , 0.6445,\n",
       "            0.6406, 0.638 , 0.637 , 0.629 , 0.62  , 0.6104, 0.6064, 0.606 ,\n",
       "            0.6045, 0.604 , 0.598 , 0.596 , 0.594 , 0.5903, 0.586 , 0.585 ,\n",
       "            0.583 , 0.582 , 0.581 , 0.5757, 0.572 , 0.57  , 0.5693, 0.568 ,\n",
       "            0.5664, 0.5645, 0.5615, 0.56  , 0.559 , 0.554 , 0.5522, 0.5503,\n",
       "            0.546 , 0.5312, 0.529 , 0.523 , 0.521 , 0.52  , 0.5156, 0.5137,\n",
       "            0.491 , 0.49  , 0.4832, 0.4795, 0.4792, 0.479 , 0.4785, 0.473 ,\n",
       "            0.4714, 0.4707, 0.4644, 0.462 , 0.4617, 0.461 , 0.4607, 0.46  ,\n",
       "            0.4597, 0.4595, 0.4585, 0.458 , 0.4575, 0.4568, 0.4565, 0.456 ,\n",
       "            0.4558, 0.4556, 0.4553, 0.455 , 0.4548, 0.4546, 0.4543, 0.454 ,\n",
       "            0.4539, 0.4536, 0.4534, 0.4526, 0.4524, 0.4521, 0.452 , 0.451 ,\n",
       "            0.45  , 0.449 , 0.4465, 0.4456, 0.4448, 0.444 , 0.443 , 0.4426,\n",
       "            0.4421, 0.4412, 0.4397, 0.4387, 0.4373, 0.437 , 0.4365, 0.4363,\n",
       "            0.436 , 0.4358, 0.4348, 0.4343, 0.4338, 0.4326, 0.4321, 0.4294,\n",
       "            0.4292, 0.429 , 0.4287, 0.428 , 0.4255, 0.425 , 0.424 , 0.4238,\n",
       "            0.4226, 0.4219, 0.4204, 0.4202, 0.4194, 0.4185, 0.4182, 0.418 ,\n",
       "            0.4165, 0.4155, 0.4148, 0.4143, 0.414 , 0.4138, 0.413 , 0.4124,\n",
       "            0.4104, 0.4102, 0.4077, 0.4072, 0.407 , 0.4067, 0.4058, 0.4053,\n",
       "            0.4048, 0.4038, 0.4036, 0.402 , 0.4001, 0.3984, 0.3972, 0.397 ,\n",
       "            0.393 , 0.3909, 0.3896, 0.3853, 0.3826, 0.3823, 0.382 , 0.3816,\n",
       "            0.3796, 0.3772, 0.3767, 0.3726, 0.371 , 0.3708, 0.3704, 0.3684,\n",
       "            0.3667, 0.3662, 0.3604, 0.3582, 0.3562, 0.3552, 0.3547, 0.35  ,\n",
       "            0.348 , 0.337 , 0.3337, 0.3313, 0.3308, 0.3237, 0.3235, 0.315 ,\n",
       "            0.3093, 0.3062, 0.3037, 0.3035, 0.2993, 0.2703], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.29850745, dtype=float32),\n",
       "    'tpr': array(0.7758621, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.01492537, 0.02238806, 0.02985075, 0.02985075,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.06716418, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.15671642,\n",
       "            0.15671642, 0.1716418 , 0.17910448, 0.17910448, 0.17910448,\n",
       "            0.19402985, 0.21641791, 0.2238806 , 0.23880596, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.26865673, 0.26865673, 0.2835821 ,\n",
       "            0.2835821 , 0.29104477, 0.29850745, 0.30597016, 0.31343284,\n",
       "            0.31343284, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3955224 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.54477614, 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.57462686, 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.619403  , 0.6268657 , 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.25      , 0.25862068,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.4224138 , 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.49137932, 0.49137932, 0.5086207 ,\n",
       "            0.51724136, 0.51724136, 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.6034483 , 0.61206895, 0.62068963,\n",
       "            0.62931037, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.7413793 , 0.7586207 , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.7758621 , 0.7758621 ,\n",
       "            0.7844828 , 0.79310346, 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.80172414, 0.80172414, 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 ,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7373, 0.7334, 0.732 , 0.731 , 0.7217, 0.7163, 0.704 ,\n",
       "            0.7007, 0.7   , 0.6973, 0.6943, 0.685 , 0.675 , 0.674 , 0.672 ,\n",
       "            0.6675, 0.6616, 0.6606, 0.66  , 0.6597, 0.6567, 0.648 , 0.6475,\n",
       "            0.6455, 0.6436, 0.642 , 0.634 , 0.6333, 0.6304, 0.627 , 0.625 ,\n",
       "            0.6245, 0.6206, 0.616 , 0.615 , 0.61  , 0.605 , 0.6045, 0.6   ,\n",
       "            0.5996, 0.5977, 0.596 , 0.588 , 0.578 , 0.5776, 0.572 , 0.5674,\n",
       "            0.565 , 0.5605, 0.5547, 0.543 , 0.542 , 0.539 , 0.536 , 0.5337,\n",
       "            0.5327, 0.5317, 0.5312, 0.531 , 0.5303, 0.53  , 0.5293, 0.5273,\n",
       "            0.527 , 0.5264, 0.5254, 0.525 , 0.5244, 0.5234, 0.5225, 0.522 ,\n",
       "            0.5215, 0.521 , 0.5205, 0.52  , 0.5195, 0.519 , 0.5186, 0.518 ,\n",
       "            0.5166, 0.5156, 0.5146, 0.514 , 0.5137, 0.513 , 0.5127, 0.512 ,\n",
       "            0.5107, 0.5103, 0.51  , 0.5063, 0.506 , 0.505 , 0.5044, 0.504 ,\n",
       "            0.502 , 0.5005, 0.4998, 0.4993, 0.4983, 0.4976, 0.4973, 0.4966,\n",
       "            0.4949, 0.494 , 0.4932, 0.4927, 0.4922, 0.4917, 0.4915, 0.4905,\n",
       "            0.49  , 0.4895, 0.489 , 0.4878, 0.486 , 0.485 , 0.4846, 0.482 ,\n",
       "            0.4814, 0.4812, 0.4805, 0.4778, 0.4768, 0.476 , 0.4746, 0.474 ,\n",
       "            0.4736, 0.4734, 0.4712, 0.4695, 0.469 , 0.4675, 0.4636, 0.4614,\n",
       "            0.4612, 0.459 , 0.4587, 0.4585, 0.4583, 0.458 , 0.4558, 0.4556,\n",
       "            0.4553, 0.4536, 0.4526, 0.4521, 0.4478, 0.4473, 0.4468, 0.4463,\n",
       "            0.445 , 0.4412, 0.4402, 0.4387, 0.4358, 0.4333, 0.4326, 0.4324,\n",
       "            0.431 , 0.429 , 0.4272, 0.4255, 0.425 , 0.4238, 0.4229, 0.4194,\n",
       "            0.4192, 0.419 , 0.4172, 0.417 , 0.4136, 0.4094, 0.4016, 0.4   ,\n",
       "            0.3958, 0.3896, 0.388 , 0.3872, 0.387 , 0.3853, 0.3848, 0.3816,\n",
       "            0.3757, 0.374 , 0.3735, 0.373 , 0.371 , 0.3696, 0.3655, 0.3638,\n",
       "            0.3591, 0.3584, 0.3567, 0.352 , 0.3506, 0.3367, 0.332 , 0.3315,\n",
       "            0.3298, 0.324 , 0.3208, 0.3115, 0.3079, 0.3044, 0.299 , 0.2983,\n",
       "            0.2969, 0.2659], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.46268657, dtype=float32),\n",
       "    'tpr': array(0.94827586, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.01492537, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.05223881, 0.05970149, 0.05970149, 0.05970149,\n",
       "            0.07462686, 0.08208955, 0.08955224, 0.10447761, 0.1119403 ,\n",
       "            0.1119403 , 0.11940298, 0.12686567, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14179105, 0.14179105,\n",
       "            0.14925373, 0.15671642, 0.1641791 , 0.1716418 , 0.18656716,\n",
       "            0.20149253, 0.20149253, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.2238806 , 0.23880596, 0.24626866, 0.25373134, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.3283582 , 0.33582088, 0.33582088, 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.38059703, 0.3955224 ,\n",
       "            0.40298507, 0.41791046, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1637931 ,\n",
       "            0.1724138 , 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37931034, 0.38793105,\n",
       "            0.39655173, 0.4051724 , 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.43965518, 0.43965518, 0.44827586, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5086207 , 0.5086207 , 0.5086207 , 0.51724136, 0.51724136,\n",
       "            0.5258621 , 0.5344828 , 0.54310346, 0.55172414, 0.5689655 ,\n",
       "            0.5689655 , 0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.61206895, 0.62068963, 0.63793105,\n",
       "            0.63793105, 0.6465517 , 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.67241377, 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.7586207 , 0.76724136, 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8534483 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.7915, 0.791 , 0.782 , 0.7783, 0.778 , 0.7705, 0.7573,\n",
       "            0.749 , 0.7476, 0.747 , 0.7407, 0.7324, 0.732 , 0.727 , 0.722 ,\n",
       "            0.7197, 0.7188, 0.7183, 0.7173, 0.7046, 0.703 , 0.7017, 0.694 ,\n",
       "            0.6934, 0.693 , 0.688 , 0.686 , 0.6855, 0.684 , 0.6797, 0.674 ,\n",
       "            0.672 , 0.6714, 0.665 , 0.6587, 0.658 , 0.6543, 0.6484, 0.647 ,\n",
       "            0.6455, 0.6436, 0.641 , 0.6396, 0.6333, 0.6294, 0.6274, 0.624 ,\n",
       "            0.62  , 0.616 , 0.6147, 0.612 , 0.608 , 0.6074, 0.607 , 0.605 ,\n",
       "            0.6016, 0.601 , 0.6   , 0.599 , 0.5986, 0.5977, 0.596 , 0.5957,\n",
       "            0.595 , 0.594 , 0.592 , 0.588 , 0.587 , 0.5864, 0.5854, 0.585 ,\n",
       "            0.5845, 0.5835, 0.583 , 0.582 , 0.5815, 0.581 , 0.58  , 0.5786,\n",
       "            0.5776, 0.5767, 0.5757, 0.575 , 0.5747, 0.574 , 0.573 , 0.5728,\n",
       "            0.571 , 0.5684, 0.567 , 0.5664, 0.566 , 0.565 , 0.5645, 0.564 ,\n",
       "            0.5625, 0.562 , 0.561 , 0.56  , 0.5596, 0.5576, 0.556 , 0.555 ,\n",
       "            0.5537, 0.553 , 0.5522, 0.552 , 0.5493, 0.5474, 0.5464, 0.5454,\n",
       "            0.545 , 0.5435, 0.543 , 0.5425, 0.542 , 0.5415, 0.541 , 0.538 ,\n",
       "            0.5376, 0.5366, 0.536 , 0.533 , 0.5327, 0.5312, 0.531 , 0.5273,\n",
       "            0.526 , 0.5244, 0.522 , 0.52  , 0.519 , 0.5186, 0.518 , 0.5156,\n",
       "            0.5137, 0.5073, 0.5034, 0.503 , 0.5015, 0.4998, 0.498 , 0.4978,\n",
       "            0.497 , 0.4968, 0.4958, 0.4956, 0.4915, 0.4905, 0.4895, 0.4836,\n",
       "            0.4834, 0.482 , 0.479 , 0.4785, 0.4768, 0.4746, 0.471 , 0.4697,\n",
       "            0.469 , 0.4688, 0.4631, 0.4612, 0.4502, 0.4495, 0.446 , 0.4456,\n",
       "            0.442 , 0.4397, 0.439 , 0.4373, 0.4368, 0.4363, 0.4346, 0.4314,\n",
       "            0.4307, 0.4304, 0.4292, 0.4275, 0.424 , 0.4182, 0.4116, 0.4065,\n",
       "            0.4014, 0.3967, 0.3938, 0.3928, 0.3923, 0.3916, 0.3906, 0.3857,\n",
       "            0.3804, 0.379 , 0.3772, 0.3765, 0.375 , 0.373 , 0.3704, 0.369 ,\n",
       "            0.3628, 0.3606, 0.359 , 0.3557, 0.3516, 0.3367, 0.3328, 0.3308,\n",
       "            0.3286, 0.3242, 0.3188, 0.309 , 0.3066, 0.303 , 0.2954, 0.2947,\n",
       "            0.2944, 0.2622], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5298507, dtype=float32),\n",
       "    'tpr': array(0.9913793, dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.06716418, 0.06716418,\n",
       "            0.07462686, 0.08208955, 0.08208955, 0.08955224, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.14179105,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.15671642, 0.15671642,\n",
       "            0.1716418 , 0.17910448, 0.17910448, 0.18656716, 0.18656716,\n",
       "            0.18656716, 0.19402985, 0.19402985, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.2835821 , 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.3283582 , 0.33582088, 0.33582088,\n",
       "            0.3432836 , 0.35820895, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3955224 , 0.41044775, 0.42537314, 0.42537314,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4477612 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.47014925, 0.47761193, 0.47761193,\n",
       "            0.48507464, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.03448276, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.38793105,\n",
       "            0.39655173, 0.39655173, 0.4051724 , 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.4827586 , 0.4827586 , 0.5       , 0.5       , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.55172414, 0.5603448 , 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.6034483 , 0.6034483 , 0.61206895,\n",
       "            0.61206895, 0.61206895, 0.61206895, 0.62068963, 0.63793105,\n",
       "            0.6465517 , 0.6465517 , 0.6465517 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.7413793 , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.7758621 , 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8189655 , 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.88793105, 0.88793105, 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.835 , 0.832 , 0.821 , 0.816 , 0.8125, 0.7993, 0.7886,\n",
       "            0.787 , 0.785 , 0.7783, 0.777 , 0.7715, 0.771 , 0.7705, 0.7646,\n",
       "            0.762 , 0.7617, 0.756 , 0.75  , 0.739 , 0.7383, 0.735 , 0.733 ,\n",
       "            0.7314, 0.7295, 0.7256, 0.7246, 0.7197, 0.7134, 0.7104, 0.709 ,\n",
       "            0.7075, 0.703 , 0.6987, 0.695 , 0.6943, 0.6914, 0.6865, 0.6846,\n",
       "            0.681 , 0.6807, 0.68  , 0.6763, 0.6753, 0.673 , 0.6704, 0.67  ,\n",
       "            0.6694, 0.6685, 0.6655, 0.665 , 0.6587, 0.6562, 0.656 , 0.6543,\n",
       "            0.654 , 0.6514, 0.6504, 0.6484, 0.648 , 0.6475, 0.647 , 0.6465,\n",
       "            0.6406, 0.6396, 0.639 , 0.6387, 0.6377, 0.636 , 0.6357, 0.6343,\n",
       "            0.632 , 0.6313, 0.631 , 0.6304, 0.63  , 0.629 , 0.628 , 0.6274,\n",
       "            0.627 , 0.6265, 0.625 , 0.6245, 0.623 , 0.6226, 0.622 , 0.621 ,\n",
       "            0.6196, 0.617 , 0.6167, 0.616 , 0.615 , 0.614 , 0.6123, 0.6113,\n",
       "            0.611 , 0.61  , 0.6094, 0.6084, 0.6074, 0.607 , 0.605 , 0.6045,\n",
       "            0.603 , 0.6025, 0.6006, 0.5996, 0.5977, 0.5957, 0.594 , 0.5938,\n",
       "            0.5933, 0.5923, 0.592 , 0.5913, 0.5884, 0.588 , 0.587 , 0.586 ,\n",
       "            0.5854, 0.5825, 0.5767, 0.575 , 0.5747, 0.5728, 0.571 , 0.57  ,\n",
       "            0.5684, 0.5674, 0.5654, 0.56  , 0.559 , 0.556 , 0.5557, 0.552 ,\n",
       "            0.547 , 0.546 , 0.544 , 0.5435, 0.542 , 0.5386, 0.538 , 0.535 ,\n",
       "            0.5337, 0.532 , 0.5303, 0.53  , 0.529 , 0.523 , 0.52  , 0.516 ,\n",
       "            0.515 , 0.508 , 0.502 , 0.4995, 0.4966, 0.4946, 0.494 , 0.489 ,\n",
       "            0.4856, 0.4822, 0.478 , 0.4646, 0.4636, 0.4583, 0.4578, 0.4539,\n",
       "            0.451 , 0.45  , 0.4485, 0.4478, 0.4475, 0.4456, 0.4426, 0.442 ,\n",
       "            0.4414, 0.4404, 0.4368, 0.4338, 0.4265, 0.4204, 0.413 , 0.4072,\n",
       "            0.4028, 0.3994, 0.3987, 0.3982, 0.3962, 0.3958, 0.3901, 0.3848,\n",
       "            0.3823, 0.3809, 0.3806, 0.3796, 0.3784, 0.3765, 0.3745, 0.3733,\n",
       "            0.366 , 0.3625, 0.3606, 0.359 , 0.3525, 0.3367, 0.3333, 0.3298,\n",
       "            0.3276, 0.3242, 0.317 , 0.3066, 0.305 , 0.3013, 0.2925, 0.292 ,\n",
       "            0.2905, 0.2585], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.58208954, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.06716418, 0.06716418,\n",
       "            0.06716418, 0.07462686, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.14179105, 0.14179105,\n",
       "            0.14179105, 0.14925373, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1641791 , 0.1641791 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.17910448, 0.18656716, 0.18656716, 0.18656716, 0.19402985,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23134328, 0.23134328, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2761194 ,\n",
       "            0.2835821 , 0.2835821 , 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.3283582 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.3955224 , 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.43283582, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.46268657,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31896552,\n",
       "            0.3275862 , 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.36206895, 0.37068966, 0.37931034, 0.38793105, 0.41379312,\n",
       "            0.4224138 , 0.43103448, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.46551725, 0.47413793, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.5344828 , 0.5344828 , 0.55172414,\n",
       "            0.5603448 , 0.5603448 , 0.5603448 , 0.5689655 , 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7758621 , 0.7844828 , 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8189655 , 0.82758623, 0.8362069 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9310345 ,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.94827586, 0.94827586,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.9741379 , 0.9741379 , 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.873 , 0.869 , 0.86  , 0.8564, 0.8506, 0.838 , 0.8257,\n",
       "            0.8247, 0.821 , 0.819 , 0.8174, 0.8145, 0.8125, 0.8086, 0.807 ,\n",
       "            0.8037, 0.8022, 0.794 , 0.792 , 0.776 , 0.7754, 0.775 , 0.774 ,\n",
       "            0.772 , 0.769 , 0.7686, 0.7656, 0.758 , 0.7544, 0.753 , 0.7495,\n",
       "            0.7476, 0.747 , 0.743 , 0.741 , 0.737 , 0.732 , 0.731 , 0.73  ,\n",
       "            0.7295, 0.729 , 0.7266, 0.719 , 0.7163, 0.716 , 0.7144, 0.714 ,\n",
       "            0.713 , 0.7114, 0.7095, 0.708 , 0.706 , 0.7056, 0.705 , 0.7046,\n",
       "            0.7036, 0.702 , 0.7017, 0.698 , 0.695 , 0.6943, 0.694 , 0.6934,\n",
       "            0.6924, 0.692 , 0.6914, 0.6895, 0.689 , 0.6875, 0.6846, 0.681 ,\n",
       "            0.6807, 0.68  , 0.6797, 0.6787, 0.678 , 0.6777, 0.676 , 0.6753,\n",
       "            0.675 , 0.6733, 0.673 , 0.6724, 0.6714, 0.6704, 0.6694, 0.669 ,\n",
       "            0.6685, 0.667 , 0.6655, 0.665 , 0.6646, 0.6626, 0.662 , 0.66  ,\n",
       "            0.659 , 0.658 , 0.657 , 0.656 , 0.6553, 0.655 , 0.6543, 0.654 ,\n",
       "            0.6514, 0.65  , 0.6494, 0.649 , 0.6455, 0.642 , 0.6416, 0.6406,\n",
       "            0.6367, 0.636 , 0.6353, 0.6343, 0.634 , 0.6333, 0.633 , 0.6323,\n",
       "            0.63  , 0.622 , 0.621 , 0.6206, 0.6196, 0.618 , 0.61  , 0.606 ,\n",
       "            0.6045, 0.603 , 0.602 , 0.6006, 0.5957, 0.5938, 0.593 , 0.5923,\n",
       "            0.59  , 0.588 , 0.5874, 0.5864, 0.5815, 0.5806, 0.579 , 0.578 ,\n",
       "            0.572 , 0.571 , 0.57  , 0.569 , 0.565 , 0.5645, 0.5576, 0.5405,\n",
       "            0.538 , 0.536 , 0.5303, 0.5264, 0.522 , 0.5166, 0.513 , 0.512 ,\n",
       "            0.5107, 0.505 , 0.5034, 0.495 , 0.4805, 0.4783, 0.472 , 0.471 ,\n",
       "            0.4668, 0.4636, 0.4622, 0.461 , 0.4604, 0.4595, 0.4585, 0.4558,\n",
       "            0.4536, 0.4534, 0.4475, 0.445 , 0.4355, 0.4314, 0.4202, 0.4133,\n",
       "            0.4106, 0.4072, 0.406 , 0.4043, 0.4019, 0.4014, 0.395 , 0.39  ,\n",
       "            0.3862, 0.3855, 0.3843, 0.3833, 0.3828, 0.3806, 0.3804, 0.3792,\n",
       "            0.3704, 0.3652, 0.3635, 0.3538, 0.3374, 0.3352, 0.3293, 0.3271,\n",
       "            0.3252, 0.3157, 0.3047, 0.3044, 0.3005, 0.291 , 0.2888, 0.2869,\n",
       "            0.2556], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.5895522, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.02985075, 0.03731343, 0.03731343,\n",
       "            0.03731343, 0.04477612, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.06716418, 0.06716418, 0.06716418, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.08208955, 0.08955224, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.11940298, 0.11940298, 0.12686567,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1641791 , 0.1716418 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.19402985, 0.19402985, 0.19402985, 0.19402985,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23134328, 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.32089552, 0.32089552, 0.32089552,\n",
       "            0.3283582 , 0.33582088, 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.38059703, 0.3955224 ,\n",
       "            0.3955224 , 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.46268657, 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.47761193, 0.48507464, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.21551724, 0.22413793,\n",
       "            0.23275863, 0.2413793 , 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.28448275, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31034482, 0.31896552, 0.31896552, 0.31896552, 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.38793105, 0.4051724 ,\n",
       "            0.41379312, 0.41379312, 0.4224138 , 0.4224138 , 0.43103448,\n",
       "            0.44827586, 0.44827586, 0.44827586, 0.46551725, 0.47413793,\n",
       "            0.4827586 , 0.49137932, 0.5       , 0.5086207 , 0.5086207 ,\n",
       "            0.51724136, 0.5258621 , 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.54310346, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.63793105, 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.73275864, 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 ,\n",
       "            0.76724136, 0.7758621 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.8189655 , 0.8362069 , 0.8448276 , 0.8534483 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.92241377, 0.9310345 , 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9   , 0.895 , 0.887 , 0.883 , 0.878 , 0.8765, 0.866 ,\n",
       "            0.854 , 0.8535, 0.8516, 0.8506, 0.8486, 0.8438, 0.843 , 0.8413,\n",
       "            0.8354, 0.833 , 0.8267, 0.821 , 0.8096, 0.8066, 0.806 , 0.8047,\n",
       "            0.8027, 0.8022, 0.799 , 0.7974, 0.795 , 0.7905, 0.786 , 0.785 ,\n",
       "            0.784 , 0.7827, 0.781 , 0.7793, 0.7734, 0.773 , 0.7725, 0.772 ,\n",
       "            0.7617, 0.7607, 0.7603, 0.7583, 0.7554, 0.755 , 0.753 , 0.7515,\n",
       "            0.751 , 0.75  , 0.7495, 0.749 , 0.747 , 0.746 , 0.7456, 0.745 ,\n",
       "            0.744 , 0.7427, 0.7407, 0.738 , 0.7363, 0.735 , 0.734 , 0.733 ,\n",
       "            0.7324, 0.732 , 0.7314, 0.7295, 0.729 , 0.7285, 0.727 , 0.7266,\n",
       "            0.726 , 0.724 , 0.721 , 0.72  , 0.719 , 0.7183, 0.7173, 0.717 ,\n",
       "            0.7163, 0.716 , 0.7153, 0.714 , 0.7134, 0.712 , 0.711 , 0.7104,\n",
       "            0.709 , 0.707 , 0.7065, 0.705 , 0.704 , 0.7026, 0.702 , 0.7017,\n",
       "            0.701 , 0.6987, 0.698 , 0.697 , 0.696 , 0.6953, 0.695 , 0.693 ,\n",
       "            0.6914, 0.691 , 0.6904, 0.6895, 0.6885, 0.6865, 0.6846, 0.6836,\n",
       "            0.68  , 0.679 , 0.6777, 0.6724, 0.672 , 0.6714, 0.671 , 0.6704,\n",
       "            0.67  , 0.6694, 0.6685, 0.6626, 0.662 , 0.6597, 0.658 , 0.6562,\n",
       "            0.656 , 0.655 , 0.6533, 0.6445, 0.636 , 0.635 , 0.6333, 0.6323,\n",
       "            0.628 , 0.627 , 0.6265, 0.622 , 0.6177, 0.6167, 0.615 , 0.6147,\n",
       "            0.6104, 0.61  , 0.609 , 0.604 , 0.602 , 0.601 , 0.6006, 0.5967,\n",
       "            0.596 , 0.594 , 0.5933, 0.59  , 0.5596, 0.559 , 0.557 , 0.5547,\n",
       "            0.5503, 0.5396, 0.5337, 0.5303, 0.5293, 0.529 , 0.5234, 0.52  ,\n",
       "            0.5107, 0.4934, 0.491 , 0.4841, 0.483 , 0.4783, 0.4756, 0.473 ,\n",
       "            0.471 , 0.4705, 0.4702, 0.4688, 0.4663, 0.4639, 0.4634, 0.4573,\n",
       "            0.4558, 0.4434, 0.4424, 0.4263, 0.4187, 0.4177, 0.416 , 0.412 ,\n",
       "            0.4104, 0.4075, 0.406 , 0.3994, 0.395 , 0.3901, 0.3894, 0.3875,\n",
       "            0.3872, 0.3865, 0.3862, 0.3857, 0.3845, 0.3752, 0.369 , 0.3684,\n",
       "            0.3665, 0.3555, 0.3386, 0.3374, 0.329 , 0.3271, 0.3267, 0.315 ,\n",
       "            0.3047, 0.3035, 0.3005, 0.2903, 0.2864, 0.284 , 0.254 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6044776, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.08955224, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.11940298, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.15671642, 0.1641791 , 0.1641791 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.21641791, 0.2238806 ,\n",
       "            0.23880596, 0.23880596, 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3283582 , 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47761193, 0.47761193,\n",
       "            0.47761193, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.23275863, 0.25      , 0.25862068, 0.2672414 ,\n",
       "            0.27586207, 0.27586207, 0.28448275, 0.29310346, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.3448276 ,\n",
       "            0.35344827, 0.36206895, 0.37068966, 0.37068966, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.43103448, 0.43965518,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.49137932, 0.5       , 0.5086207 , 0.5086207 ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.54310346, 0.54310346, 0.55172414, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5948276 , 0.6034483 , 0.61206895, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6810345 , 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.7241379 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.7586207 ,\n",
       "            0.7586207 , 0.7586207 , 0.7586207 , 0.7586207 , 0.76724136,\n",
       "            0.7844828 , 0.79310346, 0.80172414, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.8448276 , 0.8534483 , 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.923 , 0.917 , 0.911 , 0.906 , 0.902 , 0.899 , 0.8916,\n",
       "            0.8813, 0.879 , 0.8784, 0.8735, 0.8716, 0.8706, 0.868 , 0.8643,\n",
       "            0.8613, 0.861 , 0.857 , 0.847 , 0.8403, 0.836 , 0.8354, 0.835 ,\n",
       "            0.834 , 0.8335, 0.832 , 0.8296, 0.829 , 0.827 , 0.8267, 0.8228,\n",
       "            0.821 , 0.8174, 0.817 , 0.816 , 0.8135, 0.8105, 0.8096, 0.801 ,\n",
       "            0.8003, 0.799 , 0.7983, 0.796 , 0.794 , 0.793 , 0.792 , 0.791 ,\n",
       "            0.7896, 0.789 , 0.788 , 0.7876, 0.7866, 0.785 , 0.7847, 0.7837,\n",
       "            0.78  , 0.7783, 0.777 , 0.7764, 0.775 , 0.7744, 0.774 , 0.7734,\n",
       "            0.773 , 0.772 , 0.771 , 0.7705, 0.77  , 0.769 , 0.768 , 0.765 ,\n",
       "            0.762 , 0.7617, 0.7603, 0.7593, 0.759 , 0.7573, 0.757 , 0.7563,\n",
       "            0.756 , 0.7544, 0.754 , 0.7534, 0.752 , 0.7515, 0.75  , 0.7485,\n",
       "            0.7466, 0.744 , 0.742 , 0.741 , 0.7407, 0.738 , 0.736 , 0.735 ,\n",
       "            0.7344, 0.7334, 0.733 , 0.73  , 0.7295, 0.7285, 0.728 , 0.7275,\n",
       "            0.722 , 0.721 , 0.7188, 0.718 , 0.715 , 0.7124, 0.712 , 0.7114,\n",
       "            0.711 , 0.7095, 0.708 , 0.707 , 0.706 , 0.699 , 0.6973, 0.696 ,\n",
       "            0.6953, 0.693 , 0.6904, 0.69  , 0.6836, 0.6772, 0.6743, 0.6733,\n",
       "            0.672 , 0.6685, 0.6636, 0.6626, 0.6616, 0.6597, 0.6567, 0.6543,\n",
       "            0.6523, 0.649 , 0.648 , 0.646 , 0.642 , 0.6396, 0.638 , 0.636 ,\n",
       "            0.6357, 0.635 , 0.63  , 0.628 , 0.6255, 0.619 , 0.586 , 0.584 ,\n",
       "            0.5796, 0.579 , 0.5786, 0.559 , 0.5537, 0.5503, 0.5493, 0.5474,\n",
       "            0.546 , 0.5386, 0.529 , 0.5103, 0.5063, 0.4988, 0.4973, 0.4927,\n",
       "            0.4897, 0.4873, 0.486 , 0.4841, 0.484 , 0.4836, 0.4834, 0.481 ,\n",
       "            0.4775, 0.4768, 0.4695, 0.4688, 0.4553, 0.4543, 0.4355, 0.4272,\n",
       "            0.4268, 0.421 , 0.4187, 0.4158, 0.4136, 0.4067, 0.4023, 0.3972,\n",
       "            0.3962, 0.3948, 0.3943, 0.394 , 0.3926, 0.391 , 0.382 , 0.3765,\n",
       "            0.374 , 0.3718, 0.3596, 0.3425, 0.342 , 0.3318, 0.3308, 0.3298,\n",
       "            0.317 , 0.3074, 0.305 , 0.303 , 0.2922, 0.287 , 0.2844, 0.2546],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.64179105, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.01492537, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.14179105, 0.14179105, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.1641791 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20149253, 0.20149253,\n",
       "            0.20149253, 0.20895523, 0.20895523, 0.20895523, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.23880596, 0.23880596,\n",
       "            0.24626866, 0.26865673, 0.2761194 , 0.2835821 , 0.2835821 ,\n",
       "            0.2835821 , 0.2835821 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.29850745, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.31343284, 0.32089552,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.3955224 , 0.3955224 ,\n",
       "            0.3955224 , 0.3955224 , 0.40298507, 0.41044775, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5074627 , 0.51492536, 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.09482758, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.22413793, 0.23275863, 0.2413793 ,\n",
       "            0.2413793 , 0.25      , 0.25862068, 0.2672414 , 0.27586207,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.3275862 , 0.33620688,\n",
       "            0.3448276 , 0.35344827, 0.35344827, 0.35344827, 0.35344827,\n",
       "            0.36206895, 0.37931034, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.4051724 , 0.4224138 , 0.43103448, 0.43965518, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.49137932, 0.49137932,\n",
       "            0.5       , 0.5       , 0.5086207 , 0.5086207 , 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.5603448 , 0.5603448 ,\n",
       "            0.5689655 , 0.57758623, 0.5862069 , 0.5948276 , 0.5948276 ,\n",
       "            0.6034483 , 0.61206895, 0.62068963, 0.62931037, 0.63793105,\n",
       "            0.6551724 , 0.6637931 , 0.6637931 , 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.67241377, 0.6896552 , 0.69827586,\n",
       "            0.70689654, 0.70689654, 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.7241379 , 0.7241379 , 0.7241379 , 0.73275864, 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7758621 , 0.79310346,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.9396552 , 0.9396552 , 0.94827586,\n",
       "            0.94827586, 0.94827586, 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9404, 0.9346, 0.9297, 0.9243, 0.922 , 0.918 , 0.912 ,\n",
       "            0.906 , 0.9014, 0.9004, 0.895 , 0.8945, 0.8896, 0.888 , 0.8843,\n",
       "            0.8833, 0.8823, 0.8696, 0.8687, 0.8667, 0.8647, 0.861 , 0.8604,\n",
       "            0.86  , 0.8584, 0.856 , 0.8535, 0.853 , 0.852 , 0.8516, 0.851 ,\n",
       "            0.84  , 0.837 , 0.835 , 0.8345, 0.833 , 0.832 , 0.831 , 0.8296,\n",
       "            0.828 , 0.8267, 0.8257, 0.825 , 0.8247, 0.8237, 0.823 , 0.817 ,\n",
       "            0.8164, 0.816 , 0.8154, 0.8145, 0.813 , 0.8125, 0.811 , 0.8105,\n",
       "            0.81  , 0.8086, 0.8076, 0.807 , 0.806 , 0.805 , 0.804 , 0.8013,\n",
       "            0.8   , 0.7993, 0.799 , 0.7974, 0.797 , 0.7964, 0.795 , 0.7925,\n",
       "            0.792 , 0.7915, 0.79  , 0.7896, 0.7886, 0.788 , 0.7876, 0.787 ,\n",
       "            0.7837, 0.782 , 0.7817, 0.78  , 0.7783, 0.7773, 0.7764, 0.776 ,\n",
       "            0.7744, 0.773 , 0.7725, 0.7705, 0.7695, 0.769 , 0.768 , 0.7646,\n",
       "            0.764 , 0.7637, 0.7627, 0.762 , 0.7607, 0.76  , 0.7583, 0.7563,\n",
       "            0.755 , 0.753 , 0.7515, 0.7495, 0.749 , 0.7485, 0.747 , 0.746 ,\n",
       "            0.743 , 0.742 , 0.7393, 0.737 , 0.7334, 0.733 , 0.7314, 0.731 ,\n",
       "            0.7295, 0.724 , 0.722 , 0.7188, 0.7183, 0.717 , 0.709 , 0.7085,\n",
       "            0.706 , 0.698 , 0.6953, 0.6943, 0.692 , 0.691 , 0.686 , 0.6816,\n",
       "            0.68  , 0.6797, 0.679 , 0.6772, 0.677 , 0.6753, 0.6733, 0.672 ,\n",
       "            0.6685, 0.667 , 0.6665, 0.6606, 0.6597, 0.657 , 0.656 , 0.643 ,\n",
       "            0.612 , 0.6113, 0.6064, 0.5986, 0.598 , 0.578 , 0.5723, 0.571 ,\n",
       "            0.568 , 0.567 , 0.5635, 0.556 , 0.5454, 0.526 , 0.521 , 0.512 ,\n",
       "            0.5103, 0.506 , 0.503 , 0.5005, 0.4983, 0.497 , 0.4963, 0.496 ,\n",
       "            0.4958, 0.4937, 0.4902, 0.489 , 0.4807, 0.466 , 0.464 , 0.4438,\n",
       "            0.4353, 0.435 , 0.4287, 0.4263, 0.423 , 0.4202, 0.4128, 0.4084,\n",
       "            0.403 , 0.4016, 0.4011, 0.4004, 0.3997, 0.399 , 0.3977, 0.3965,\n",
       "            0.3875, 0.3816, 0.3782, 0.3757, 0.3625, 0.3447, 0.3445, 0.333 ,\n",
       "            0.3328, 0.331 , 0.3174, 0.308 , 0.305 , 0.3035, 0.2922, 0.2861,\n",
       "            0.2832, 0.2534], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.6865672, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.03731343, 0.04477612, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.06716418, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08208955, 0.08955224, 0.08955224, 0.09701493, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.11940298, 0.11940298, 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.14925373, 0.1641791 ,\n",
       "            0.1641791 , 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.20149253, 0.20895523,\n",
       "            0.20895523, 0.21641791, 0.2238806 , 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26119402, 0.26865673, 0.2761194 , 0.2835821 ,\n",
       "            0.2835821 , 0.2835821 , 0.2835821 , 0.29104477, 0.29850745,\n",
       "            0.29850745, 0.29850745, 0.29850745, 0.29850745, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.3432836 , 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.3955224 , 0.3955224 ,\n",
       "            0.40298507, 0.41044775, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.46268657, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.09482758, 0.10344828, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.13793103, 0.14655173, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.2413793 , 0.25      , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.30172414,\n",
       "            0.31034482, 0.31896552, 0.3275862 , 0.33620688, 0.33620688,\n",
       "            0.33620688, 0.3448276 , 0.3448276 , 0.35344827, 0.35344827,\n",
       "            0.37068966, 0.38793105, 0.39655173, 0.39655173, 0.4051724 ,\n",
       "            0.41379312, 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.46551725, 0.47413793, 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.51724136, 0.51724136, 0.5258621 ,\n",
       "            0.5344828 , 0.54310346, 0.55172414, 0.55172414, 0.5603448 ,\n",
       "            0.5603448 , 0.5689655 , 0.57758623, 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.6034483 , 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.67241377, 0.67241377,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.70689654, 0.7155172 , 0.7241379 ,\n",
       "            0.7241379 , 0.7241379 , 0.73275864, 0.7413793 , 0.7413793 ,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.7758621 , 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.80172414, 0.8103448 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.952 , 0.947 , 0.943 , 0.937 , 0.9355, 0.931 , 0.927 ,\n",
       "            0.9233, 0.918 , 0.9155, 0.9126, 0.9116, 0.91  , 0.906 , 0.9053,\n",
       "            0.902 , 0.901 , 0.8994, 0.8936, 0.89  , 0.8867, 0.8857, 0.8843,\n",
       "            0.882 , 0.8813, 0.8804, 0.88  , 0.8794, 0.879 , 0.878 , 0.8745,\n",
       "            0.874 , 0.8726, 0.8696, 0.864 , 0.862 , 0.8613, 0.86  , 0.859 ,\n",
       "            0.8584, 0.857 , 0.8564, 0.855 , 0.8545, 0.853 , 0.852 , 0.8516,\n",
       "            0.851 , 0.85  , 0.847 , 0.844 , 0.841 , 0.8403, 0.84  , 0.8394,\n",
       "            0.8384, 0.838 , 0.8374, 0.837 , 0.836 , 0.8354, 0.8335, 0.833 ,\n",
       "            0.832 , 0.8306, 0.83  , 0.829 , 0.8286, 0.828 , 0.827 , 0.8267,\n",
       "            0.8257, 0.825 , 0.8237, 0.8228, 0.8203, 0.82  , 0.818 , 0.817 ,\n",
       "            0.8164, 0.815 , 0.8145, 0.814 , 0.811 , 0.8105, 0.81  , 0.8096,\n",
       "            0.8047, 0.804 , 0.803 , 0.8013, 0.8003, 0.7993, 0.7983, 0.798 ,\n",
       "            0.797 , 0.7964, 0.7954, 0.793 , 0.7925, 0.792 , 0.7915, 0.7905,\n",
       "            0.79  , 0.7886, 0.7876, 0.7837, 0.783 , 0.7827, 0.7817, 0.78  ,\n",
       "            0.779 , 0.7783, 0.778 , 0.777 , 0.7754, 0.7734, 0.7715, 0.77  ,\n",
       "            0.766 , 0.7656, 0.765 , 0.762 , 0.7603, 0.7593, 0.7554, 0.753 ,\n",
       "            0.751 , 0.748 , 0.7476, 0.7456, 0.7417, 0.7373, 0.737 , 0.736 ,\n",
       "            0.7334, 0.7275, 0.724 , 0.722 , 0.7197, 0.716 , 0.7075, 0.707 ,\n",
       "            0.7056, 0.7046, 0.7036, 0.703 , 0.702 , 0.701 , 0.7   , 0.699 ,\n",
       "            0.6953, 0.693 , 0.681 , 0.6807, 0.6772, 0.6636, 0.6343, 0.633 ,\n",
       "            0.629 , 0.6157, 0.614 , 0.5938, 0.5884, 0.588 , 0.5845, 0.583 ,\n",
       "            0.578 , 0.571 , 0.56  , 0.5386, 0.533 , 0.5234, 0.5215, 0.517 ,\n",
       "            0.514 , 0.5117, 0.509 , 0.5083, 0.5073, 0.5063, 0.505 , 0.5   ,\n",
       "            0.499 , 0.491 , 0.49  , 0.4753, 0.472 , 0.4502, 0.4424, 0.4421,\n",
       "            0.441 , 0.4348, 0.4321, 0.429 , 0.425 , 0.4177, 0.413 , 0.4075,\n",
       "            0.4067, 0.4058, 0.4053, 0.4038, 0.4026, 0.4014, 0.4006, 0.3918,\n",
       "            0.386 , 0.381 , 0.3787, 0.3643, 0.3467, 0.346 , 0.3345, 0.3333,\n",
       "            0.3313, 0.317 , 0.3083, 0.304 , 0.3035, 0.2917, 0.2842, 0.2808,\n",
       "            0.2517], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7164179, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.03731343,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.11940298, 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1641791 , 0.1716418 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.18656716, 0.19402985, 0.20149253,\n",
       "            0.20895523, 0.20895523, 0.21641791, 0.2238806 , 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.25373134, 0.26865673, 0.2761194 ,\n",
       "            0.2761194 , 0.2835821 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.29850745, 0.29850745, 0.29850745, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.32089552, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.3955224 , 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.42537314, 0.42537314,\n",
       "            0.43283582, 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.51492536, 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6567164 , 0.6641791 , 0.67164177, 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18103448, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.29310346,\n",
       "            0.30172414, 0.31034482, 0.31896552, 0.3275862 , 0.3275862 ,\n",
       "            0.3275862 , 0.3275862 , 0.33620688, 0.3448276 , 0.35344827,\n",
       "            0.37068966, 0.37068966, 0.37931034, 0.37931034, 0.39655173,\n",
       "            0.4051724 , 0.41379312, 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.45689654, 0.47413793, 0.47413793,\n",
       "            0.4827586 , 0.4827586 , 0.49137932, 0.5086207 , 0.5258621 ,\n",
       "            0.5344828 , 0.5344828 , 0.54310346, 0.55172414, 0.55172414,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.5689655 , 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62068963,\n",
       "            0.63793105, 0.63793105, 0.6465517 , 0.6551724 , 0.6637931 ,\n",
       "            0.67241377, 0.67241377, 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.70689654, 0.70689654, 0.7155172 , 0.7241379 , 0.7241379 ,\n",
       "            0.73275864, 0.7413793 , 0.7413793 , 0.7413793 , 0.7413793 ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.8103448 , 0.82758623,\n",
       "            0.82758623, 0.8448276 , 0.8534483 , 0.86206895, 0.86206895,\n",
       "            0.86206895, 0.87068963, 0.87068963, 0.87068963, 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.9396552 , 0.9396552 ,\n",
       "            0.94827586, 0.94827586, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9624, 0.9575, 0.954 , 0.9487, 0.9473, 0.9434, 0.94  ,\n",
       "            0.938 , 0.932 , 0.9297, 0.929 , 0.928 , 0.9263, 0.924 , 0.9214,\n",
       "            0.9194, 0.9175, 0.915 , 0.9146, 0.9116, 0.906 , 0.904 , 0.903 ,\n",
       "            0.902 , 0.9014, 0.9004, 0.8994, 0.8984, 0.8975, 0.897 , 0.8945,\n",
       "            0.8916, 0.89  , 0.887 , 0.8867, 0.886 , 0.8853, 0.885 , 0.883 ,\n",
       "            0.8804, 0.8794, 0.879 , 0.8784, 0.8774, 0.877 , 0.876 , 0.8755,\n",
       "            0.875 , 0.8745, 0.869 , 0.8657, 0.865 , 0.8643, 0.8633, 0.863 ,\n",
       "            0.8623, 0.862 , 0.8613, 0.8604, 0.859 , 0.8584, 0.858 , 0.857 ,\n",
       "            0.8564, 0.855 , 0.8545, 0.854 , 0.8535, 0.8525, 0.852 , 0.8516,\n",
       "            0.85  , 0.8486, 0.848 , 0.8477, 0.8467, 0.846 , 0.845 , 0.8433,\n",
       "            0.843 , 0.8423, 0.841 , 0.8403, 0.84  , 0.8394, 0.839 , 0.837 ,\n",
       "            0.8364, 0.8354, 0.83  , 0.8286, 0.828 , 0.826 , 0.8247, 0.823 ,\n",
       "            0.8223, 0.822 , 0.821 , 0.82  , 0.8193, 0.8184, 0.818 , 0.8174,\n",
       "            0.8164, 0.816 , 0.8154, 0.815 , 0.8105, 0.8096, 0.8086, 0.808 ,\n",
       "            0.806 , 0.805 , 0.804 , 0.8037, 0.8022, 0.799 , 0.7983, 0.797 ,\n",
       "            0.794 , 0.791 , 0.7905, 0.79  , 0.787 , 0.7866, 0.7803, 0.7783,\n",
       "            0.7773, 0.775 , 0.7734, 0.7686, 0.765 , 0.7646, 0.7637, 0.7603,\n",
       "            0.756 , 0.7534, 0.748 , 0.74  , 0.734 , 0.7314, 0.73  , 0.7295,\n",
       "            0.7285, 0.7275, 0.7246, 0.724 , 0.7236, 0.7217, 0.719 , 0.706 ,\n",
       "            0.7056, 0.702 , 0.697 , 0.684 , 0.658 , 0.655 , 0.6523, 0.6343,\n",
       "            0.6313, 0.611 , 0.6064, 0.6055, 0.604 , 0.6   , 0.5947, 0.5874,\n",
       "            0.576 , 0.5537, 0.5474, 0.536 , 0.5347, 0.5303, 0.5273, 0.525 ,\n",
       "            0.5215, 0.521 , 0.5195, 0.5186, 0.5127, 0.5117, 0.5034, 0.5015,\n",
       "            0.488 , 0.4827, 0.4592, 0.4531, 0.4514, 0.4495, 0.4436, 0.441 ,\n",
       "            0.4375, 0.4324, 0.425 , 0.4207, 0.415 , 0.4148, 0.4146, 0.4119,\n",
       "            0.4111, 0.409 , 0.4077, 0.4075, 0.399 , 0.3936, 0.387 , 0.3845,\n",
       "            0.3691, 0.352 , 0.35  , 0.3389, 0.3367, 0.3347, 0.3198, 0.3115,\n",
       "            0.3066, 0.3064, 0.2944, 0.286 , 0.2822, 0.2534], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7164179, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02985075, 0.03731343, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.08208955, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.1119403 , 0.11940298, 0.11940298, 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.1716418 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.20149253, 0.20895523,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.25373134, 0.26865673,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29850745, 0.29850745, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.32089552, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.35074627, 0.35074627, 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.42537314, 0.42537314, 0.42537314, 0.4402985 , 0.4477612 ,\n",
       "            0.4552239 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.1724138 , 0.18103448,\n",
       "            0.18103448, 0.18965517, 0.18965517, 0.19827586, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.23275863, 0.2413793 , 0.25      ,\n",
       "            0.25862068, 0.2672414 , 0.27586207, 0.28448275, 0.31034482,\n",
       "            0.31034482, 0.31034482, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.36206895, 0.36206895, 0.37068966, 0.37931034,\n",
       "            0.38793105, 0.39655173, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.47413793, 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5086207 , 0.5086207 , 0.51724136, 0.5258621 , 0.5344828 ,\n",
       "            0.55172414, 0.5603448 , 0.5689655 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.61206895, 0.62068963, 0.63793105, 0.63793105,\n",
       "            0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.6896552 , 0.69827586, 0.69827586, 0.70689654, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.7413793 , 0.7413793 , 0.7413793 , 0.75      , 0.75      ,\n",
       "            0.7758621 , 0.7758621 , 0.79310346, 0.80172414, 0.80172414,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.8362069 , 0.8534483 ,\n",
       "            0.86206895, 0.86206895, 0.86206895, 0.86206895, 0.87068963,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9310345 , 0.9310345 ,\n",
       "            0.9396552 , 0.9396552 , 0.94827586, 0.94827586, 0.95689654,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9707, 0.966 , 0.9634, 0.9585, 0.9575, 0.953 , 0.9507,\n",
       "            0.945 , 0.942 , 0.9414, 0.9395, 0.9355, 0.935 , 0.9336, 0.932 ,\n",
       "            0.9316, 0.931 , 0.93  , 0.9277, 0.926 , 0.9224, 0.9214, 0.9204,\n",
       "            0.9194, 0.9185, 0.917 , 0.916 , 0.914 , 0.913 , 0.9126, 0.912 ,\n",
       "            0.9087, 0.907 , 0.9062, 0.905 , 0.9043, 0.903 , 0.9023, 0.9014,\n",
       "            0.901 , 0.8994, 0.8984, 0.897 , 0.8955, 0.895 , 0.8926, 0.888 ,\n",
       "            0.887 , 0.886 , 0.8857, 0.8853, 0.885 , 0.8833, 0.883 , 0.8823,\n",
       "            0.882 , 0.8813, 0.88  , 0.8794, 0.879 , 0.8784, 0.878 , 0.8765,\n",
       "            0.876 , 0.8745, 0.874 , 0.8726, 0.8716, 0.8706, 0.869 , 0.8687,\n",
       "            0.867 , 0.8667, 0.866 , 0.8643, 0.864 , 0.8633, 0.8623, 0.862 ,\n",
       "            0.861 , 0.86  , 0.8584, 0.8574, 0.8545, 0.854 , 0.853 , 0.8506,\n",
       "            0.848 , 0.847 , 0.8467, 0.8457, 0.845 , 0.843 , 0.8423, 0.8413,\n",
       "            0.841 , 0.8403, 0.8384, 0.838 , 0.8364, 0.8335, 0.833 , 0.832 ,\n",
       "            0.83  , 0.8296, 0.8286, 0.828 , 0.825 , 0.8247, 0.824 , 0.8228,\n",
       "            0.8213, 0.8174, 0.816 , 0.8154, 0.814 , 0.8086, 0.805 , 0.803 ,\n",
       "            0.8022, 0.7935, 0.7925, 0.7915, 0.791 , 0.7886, 0.787 , 0.7847,\n",
       "            0.7837, 0.777 , 0.7744, 0.764 , 0.7627, 0.7617, 0.7603, 0.7554,\n",
       "            0.7534, 0.7515, 0.751 , 0.7495, 0.747 , 0.746 , 0.7456, 0.7324,\n",
       "            0.7305, 0.723 , 0.715 , 0.705 , 0.684 , 0.678 , 0.6772, 0.653 ,\n",
       "            0.6475, 0.6284, 0.627 , 0.625 , 0.6235, 0.6167, 0.61  , 0.604 ,\n",
       "            0.592 , 0.5703, 0.562 , 0.5503, 0.549 , 0.544 , 0.5405, 0.538 ,\n",
       "            0.5347, 0.534 , 0.5337, 0.532 , 0.5312, 0.527 , 0.5254, 0.5156,\n",
       "            0.513 , 0.4985, 0.4944, 0.4692, 0.4617, 0.4602, 0.4587, 0.4524,\n",
       "            0.4497, 0.446 , 0.4407, 0.4326, 0.428 , 0.422 , 0.4216, 0.4214,\n",
       "            0.4192, 0.4177, 0.416 , 0.4148, 0.4143, 0.405 , 0.3994, 0.3923,\n",
       "            0.39  , 0.3735, 0.3555, 0.3538, 0.3418, 0.3396, 0.3376, 0.322 ,\n",
       "            0.3135, 0.3083, 0.3079, 0.296 , 0.2869, 0.2837, 0.2534],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.73134327, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.00746269, 0.01492537, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.04477612, 0.05223881, 0.05223881, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.06716418, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.08208955,\n",
       "            0.08955224, 0.09701493, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.10447761, 0.11940298, 0.11940298, 0.11940298, 0.12686567,\n",
       "            0.12686567, 0.12686567, 0.13432837, 0.14179105, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.15671642, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.1716418 , 0.17910448, 0.17910448, 0.19402985,\n",
       "            0.20149253, 0.21641791, 0.21641791, 0.21641791, 0.21641791,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.24626866, 0.26119402, 0.26865673, 0.26865673,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.32089552, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.3880597 , 0.3880597 , 0.3955224 ,\n",
       "            0.3955224 , 0.40298507, 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.42537314, 0.42537314, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5074627 , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.73880595, 0.74626863, 0.75373137,\n",
       "            0.76119405, 0.76865673, 0.7761194 , 0.7835821 , 0.7910448 ,\n",
       "            0.79850745, 0.80597013, 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.06896552, 0.0775862 ,\n",
       "            0.0862069 , 0.09482758, 0.10344828, 0.11206897, 0.12068965,\n",
       "            0.12931034, 0.13793103, 0.14655173, 0.15517241, 0.1724138 ,\n",
       "            0.1724138 , 0.18965517, 0.18965517, 0.18965517, 0.19827586,\n",
       "            0.20689656, 0.21551724, 0.22413793, 0.23275863, 0.25      ,\n",
       "            0.2672414 , 0.27586207, 0.28448275, 0.29310346, 0.29310346,\n",
       "            0.29310346, 0.29310346, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.3448276 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.4051724 , 0.4051724 ,\n",
       "            0.4224138 , 0.4224138 , 0.43103448, 0.43103448, 0.43965518,\n",
       "            0.44827586, 0.44827586, 0.46551725, 0.4827586 , 0.5       ,\n",
       "            0.5086207 , 0.51724136, 0.5258621 , 0.5258621 , 0.5344828 ,\n",
       "            0.5344828 , 0.54310346, 0.5603448 , 0.5689655 , 0.5862069 ,\n",
       "            0.5948276 , 0.6034483 , 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6637931 , 0.6637931 ,\n",
       "            0.6637931 , 0.6637931 , 0.67241377, 0.6810345 , 0.6896552 ,\n",
       "            0.69827586, 0.69827586, 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.7413793 , 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.80172414, 0.8103448 , 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.86206895, 0.86206895, 0.87931037,\n",
       "            0.87931037, 0.87931037, 0.88793105, 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 , 0.92241377,\n",
       "            0.9310345 , 0.9310345 , 0.9396552 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9741379 , 0.9741379 ,\n",
       "            0.9741379 , 0.9741379 , 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.977 , 0.973 , 0.9707, 0.9663, 0.966 , 0.9614, 0.961 ,\n",
       "            0.96  , 0.955 , 0.9526, 0.9517, 0.951 , 0.95  , 0.9487, 0.9463,\n",
       "            0.946 , 0.9453, 0.944 , 0.9424, 0.9414, 0.9385, 0.938 , 0.937 ,\n",
       "            0.9365, 0.933 , 0.9326, 0.9297, 0.929 , 0.9277, 0.9263, 0.9253,\n",
       "            0.925 , 0.9243, 0.923 , 0.9224, 0.921 , 0.9204, 0.92  , 0.9194,\n",
       "            0.918 , 0.917 , 0.916 , 0.9155, 0.9146, 0.913 , 0.9097, 0.9077,\n",
       "            0.907 , 0.9067, 0.906 , 0.9053, 0.9043, 0.9033, 0.903 , 0.9023,\n",
       "            0.9014, 0.9004, 0.8994, 0.8984, 0.898 , 0.8975, 0.8965, 0.8945,\n",
       "            0.894 , 0.893 , 0.8926, 0.892 , 0.891 , 0.89  , 0.8896, 0.889 ,\n",
       "            0.888 , 0.8877, 0.887 , 0.8857, 0.8853, 0.8843, 0.883 , 0.882 ,\n",
       "            0.8813, 0.8765, 0.876 , 0.8755, 0.875 , 0.874 , 0.8726, 0.8696,\n",
       "            0.8687, 0.868 , 0.867 , 0.8657, 0.8647, 0.8643, 0.864 , 0.8623,\n",
       "            0.86  , 0.857 , 0.856 , 0.8555, 0.854 , 0.8535, 0.8525, 0.852 ,\n",
       "            0.848 , 0.8467, 0.846 , 0.8438, 0.8423, 0.8384, 0.838 , 0.8354,\n",
       "            0.8276, 0.827 , 0.82  , 0.818 , 0.816 , 0.812 , 0.811 , 0.8105,\n",
       "            0.81  , 0.803 , 0.799 , 0.7896, 0.788 , 0.787 , 0.7866, 0.784 ,\n",
       "            0.7773, 0.7754, 0.775 , 0.7725, 0.772 , 0.7715, 0.7686, 0.7656,\n",
       "            0.757 , 0.755 , 0.7437, 0.734 , 0.725 , 0.709 , 0.701 , 0.7007,\n",
       "            0.6714, 0.6655, 0.6475, 0.6465, 0.6455, 0.6416, 0.635 , 0.6274,\n",
       "            0.6216, 0.609 , 0.5864, 0.5776, 0.565 , 0.5635, 0.5586, 0.555 ,\n",
       "            0.553 , 0.55  , 0.5493, 0.548 , 0.547 , 0.5464, 0.5415, 0.5396,\n",
       "            0.53  , 0.5264, 0.513 , 0.5073, 0.4802, 0.4749, 0.4714, 0.4692,\n",
       "            0.4631, 0.4602, 0.4563, 0.45  , 0.4421, 0.4373, 0.4329, 0.431 ,\n",
       "            0.428 , 0.4268, 0.4243, 0.423 , 0.4229, 0.4143, 0.41  , 0.4004,\n",
       "            0.3977, 0.3806, 0.363 , 0.3604, 0.3489, 0.3452, 0.3433, 0.3271,\n",
       "            0.3193, 0.3137, 0.3127, 0.3008, 0.2913, 0.288 , 0.2576],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.73134327, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.03731343,\n",
       "            0.04477612, 0.04477612, 0.04477612, 0.05223881, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.08208955, 0.08208955,\n",
       "            0.09701493, 0.09701493, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.12686567, 0.13432837, 0.13432837, 0.14179105, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.15671642, 0.15671642, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1641791 , 0.1641791 , 0.1716418 ,\n",
       "            0.1716418 , 0.17910448, 0.17910448, 0.18656716, 0.20149253,\n",
       "            0.20149253, 0.20895523, 0.21641791, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.2238806 , 0.23134328, 0.23880596, 0.23880596,\n",
       "            0.24626866, 0.24626866, 0.24626866, 0.24626866, 0.24626866,\n",
       "            0.25373134, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.3283582 , 0.33582088,\n",
       "            0.33582088, 0.33582088, 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.35820895, 0.35820895, 0.36567163, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3880597 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.10344828, 0.12068965, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.1637931 , 0.18103448, 0.18103448,\n",
       "            0.18965517, 0.19827586, 0.20689656, 0.21551724, 0.22413793,\n",
       "            0.2413793 , 0.25862068, 0.2672414 , 0.27586207, 0.28448275,\n",
       "            0.28448275, 0.29310346, 0.30172414, 0.30172414, 0.31034482,\n",
       "            0.31034482, 0.3275862 , 0.33620688, 0.33620688, 0.35344827,\n",
       "            0.37068966, 0.37931034, 0.38793105, 0.38793105, 0.4051724 ,\n",
       "            0.4051724 , 0.4224138 , 0.43103448, 0.43965518, 0.44827586,\n",
       "            0.44827586, 0.45689654, 0.46551725, 0.47413793, 0.4827586 ,\n",
       "            0.49137932, 0.5       , 0.5086207 , 0.5258621 , 0.5258621 ,\n",
       "            0.5344828 , 0.55172414, 0.55172414, 0.5689655 , 0.57758623,\n",
       "            0.5948276 , 0.6034483 , 0.61206895, 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.63793105, 0.6551724 , 0.6551724 , 0.6551724 ,\n",
       "            0.6637931 , 0.6637931 , 0.6637931 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.7413793 , 0.75      ,\n",
       "            0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
       "            0.7586207 , 0.76724136, 0.7758621 , 0.7844828 , 0.7844828 ,\n",
       "            0.7844828 , 0.79310346, 0.8103448 , 0.82758623, 0.8362069 ,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.86206895, 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.9051724 , 0.9137931 , 0.92241377, 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9741379 , 0.9741379 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.982 , 0.9785, 0.977 , 0.9727, 0.9688, 0.9683, 0.9673,\n",
       "            0.9634, 0.962 , 0.9604, 0.96  , 0.9595, 0.9575, 0.956 , 0.9546,\n",
       "            0.954 , 0.952 , 0.9517, 0.951 , 0.95  , 0.948 , 0.9453, 0.9443,\n",
       "            0.942 , 0.941 , 0.94  , 0.9395, 0.939 , 0.938 , 0.9375, 0.937 ,\n",
       "            0.9365, 0.936 , 0.935 , 0.934 , 0.9336, 0.9326, 0.9316, 0.931 ,\n",
       "            0.928 , 0.9263, 0.9243, 0.924 , 0.923 , 0.9224, 0.922 , 0.921 ,\n",
       "            0.9204, 0.9194, 0.919 , 0.9185, 0.9175, 0.916 , 0.9155, 0.9146,\n",
       "            0.914 , 0.9136, 0.912 , 0.9106, 0.91  , 0.9097, 0.908 , 0.9077,\n",
       "            0.907 , 0.9062, 0.9053, 0.905 , 0.9043, 0.904 , 0.9033, 0.903 ,\n",
       "            0.9023, 0.9014, 0.9004, 0.898 , 0.8965, 0.8955, 0.895 , 0.894 ,\n",
       "            0.8916, 0.89  , 0.889 , 0.888 , 0.8877, 0.887 , 0.8867, 0.886 ,\n",
       "            0.8857, 0.8853, 0.885 , 0.8843, 0.8833, 0.8823, 0.882 , 0.8804,\n",
       "            0.878 , 0.877 , 0.876 , 0.8755, 0.8745, 0.8735, 0.8726, 0.869 ,\n",
       "            0.8687, 0.868 , 0.8667, 0.8643, 0.861 , 0.8604, 0.86  , 0.8594,\n",
       "            0.859 , 0.8584, 0.8496, 0.8486, 0.848 , 0.8433, 0.841 , 0.839 ,\n",
       "            0.8354, 0.8345, 0.832 , 0.8306, 0.827 , 0.8267, 0.822 , 0.814 ,\n",
       "            0.813 , 0.811 , 0.8096, 0.808 , 0.7993, 0.799 , 0.7983, 0.795 ,\n",
       "            0.7935, 0.792 , 0.789 , 0.785 , 0.78  , 0.778 , 0.763 , 0.751 ,\n",
       "            0.7446, 0.7324, 0.7246, 0.722 , 0.6895, 0.6816, 0.667 , 0.665 ,\n",
       "            0.663 , 0.658 , 0.651 , 0.6426, 0.6377, 0.6245, 0.602 , 0.593 ,\n",
       "            0.5786, 0.577 , 0.5723, 0.568 , 0.567 , 0.5625, 0.562 , 0.56  ,\n",
       "            0.5596, 0.559 , 0.5547, 0.5522, 0.5425, 0.5376, 0.5244, 0.5186,\n",
       "            0.489 , 0.4841, 0.4802, 0.4778, 0.4714, 0.4683, 0.464 , 0.457 ,\n",
       "            0.449 , 0.4443, 0.4404, 0.4402, 0.4375, 0.434 , 0.433 , 0.4302,\n",
       "            0.429 , 0.4207, 0.4165, 0.4055, 0.4028, 0.3845, 0.367 , 0.3635,\n",
       "            0.352 , 0.3474, 0.3457, 0.3289, 0.3213, 0.3157, 0.3137, 0.3022,\n",
       "            0.2915, 0.2888, 0.2576], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.73134327, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05223881, 0.05970149, 0.05970149, 0.06716418,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.09701493, 0.09701493, 0.09701493,\n",
       "            0.10447761, 0.10447761, 0.10447761, 0.11940298, 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.12686567, 0.13432837, 0.13432837,\n",
       "            0.13432837, 0.14179105, 0.14925373, 0.14925373, 0.14925373,\n",
       "            0.15671642, 0.15671642, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.17910448, 0.18656716,\n",
       "            0.18656716, 0.20149253, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.23134328, 0.23880596,\n",
       "            0.23880596, 0.24626866, 0.24626866, 0.24626866, 0.25373134,\n",
       "            0.2761194 , 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.3283582 , 0.3283582 , 0.3432836 , 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35820895, 0.35820895, 0.35820895,\n",
       "            0.36567163, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3880597 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.42537314,\n",
       "            0.43283582, 0.43283582, 0.4402985 , 0.4402985 , 0.4477612 ,\n",
       "            0.4477612 , 0.4552239 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06034483, 0.06896552, 0.0775862 , 0.0862069 ,\n",
       "            0.09482758, 0.11206897, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.1637931 , 0.1637931 , 0.1724138 , 0.18103448, 0.18965517,\n",
       "            0.19827586, 0.20689656, 0.21551724, 0.22413793, 0.23275863,\n",
       "            0.25      , 0.25862068, 0.25862068, 0.2672414 , 0.28448275,\n",
       "            0.28448275, 0.30172414, 0.31034482, 0.3275862 , 0.3275862 ,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.37931034, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.4224138 , 0.43965518, 0.44827586, 0.44827586, 0.45689654,\n",
       "            0.47413793, 0.47413793, 0.4827586 , 0.4827586 , 0.49137932,\n",
       "            0.5       , 0.5086207 , 0.5086207 , 0.5344828 , 0.54310346,\n",
       "            0.55172414, 0.5603448 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.62068963, 0.62068963, 0.62931037, 0.62931037,\n",
       "            0.63793105, 0.6465517 , 0.6551724 , 0.6551724 , 0.6551724 ,\n",
       "            0.67241377, 0.6810345 , 0.6810345 , 0.6810345 , 0.6810345 ,\n",
       "            0.6896552 , 0.6896552 , 0.73275864, 0.75      , 0.75      ,\n",
       "            0.75      , 0.75      , 0.7586207 , 0.76724136, 0.7758621 ,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.8189655 , 0.82758623, 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.95689654, 0.95689654, 0.9655172 , 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.9741379 , 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9863, 0.983 , 0.982 , 0.978 , 0.9756, 0.974 , 0.9736,\n",
       "            0.9707, 0.9697, 0.969 , 0.9673, 0.967 , 0.9644, 0.963 , 0.962 ,\n",
       "            0.9614, 0.961 , 0.9604, 0.9595, 0.9565, 0.9556, 0.954 , 0.953 ,\n",
       "            0.952 , 0.9517, 0.951 , 0.9507, 0.9497, 0.949 , 0.9487, 0.9478,\n",
       "            0.9473, 0.9463, 0.9453, 0.945 , 0.9443, 0.9434, 0.9414, 0.9385,\n",
       "            0.938 , 0.9375, 0.9365, 0.936 , 0.9355, 0.935 , 0.934 , 0.9336,\n",
       "            0.933 , 0.932 , 0.9316, 0.9307, 0.93  , 0.929 , 0.9287, 0.928 ,\n",
       "            0.9272, 0.9263, 0.9253, 0.9243, 0.9233, 0.923 , 0.922 , 0.9214,\n",
       "            0.921 , 0.9204, 0.9194, 0.9185, 0.918 , 0.9175, 0.917 , 0.9165,\n",
       "            0.915 , 0.9126, 0.912 , 0.9116, 0.91  , 0.908 , 0.906 , 0.9053,\n",
       "            0.905 , 0.9043, 0.904 , 0.903 , 0.902 , 0.9014, 0.8994, 0.8984,\n",
       "            0.896 , 0.895 , 0.894 , 0.893 , 0.8916, 0.891 , 0.89  , 0.8877,\n",
       "            0.887 , 0.8853, 0.885 , 0.884 , 0.8833, 0.8823, 0.8794, 0.879 ,\n",
       "            0.878 , 0.877 , 0.8765, 0.869 , 0.8677, 0.8667, 0.864 , 0.8613,\n",
       "            0.859 , 0.857 , 0.8555, 0.8545, 0.851 , 0.8496, 0.8486, 0.8423,\n",
       "            0.842 , 0.8354, 0.833 , 0.832 , 0.8276, 0.8203, 0.82  , 0.8193,\n",
       "            0.8164, 0.8125, 0.8105, 0.8086, 0.8037, 0.8013, 0.799 , 0.782 ,\n",
       "            0.767 , 0.7637, 0.7544, 0.746 , 0.743 , 0.707 , 0.6973, 0.6855,\n",
       "            0.6836, 0.6797, 0.6753, 0.667 , 0.6577, 0.6533, 0.64  , 0.6167,\n",
       "            0.607 , 0.592 , 0.5903, 0.585 , 0.581 , 0.5806, 0.5757, 0.5747,\n",
       "            0.5728, 0.5723, 0.572 , 0.5713, 0.5674, 0.565 , 0.555 , 0.549 ,\n",
       "            0.5356, 0.5293, 0.4978, 0.493 , 0.4888, 0.4858, 0.4795, 0.4763,\n",
       "            0.472 , 0.4639, 0.4558, 0.451 , 0.4475, 0.4473, 0.4438, 0.4397,\n",
       "            0.4392, 0.4358, 0.435 , 0.4343, 0.4265, 0.4224, 0.4104, 0.4075,\n",
       "            0.388 , 0.3704, 0.3665, 0.355 , 0.3494, 0.3477, 0.33  , 0.3228,\n",
       "            0.317 , 0.3145, 0.303 , 0.2913, 0.2883, 0.257 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.74626863, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.00746269, 0.01492537, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.06716418, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.08955224, 0.09701493, 0.09701493, 0.10447761,\n",
       "            0.10447761, 0.10447761, 0.11940298, 0.11940298, 0.11940298,\n",
       "            0.12686567, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.15671642, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.1716418 , 0.17910448,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20149253, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.21641791, 0.21641791, 0.2238806 ,\n",
       "            0.23134328, 0.23880596, 0.23880596, 0.24626866, 0.24626866,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.2761194 , 0.2761194 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.32089552, 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35074627, 0.35074627,\n",
       "            0.35820895, 0.35820895, 0.35820895, 0.36567163, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.64179105, 0.6492537 , 0.6567164 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.04310345,\n",
       "            0.05172414, 0.06896552, 0.0775862 , 0.0862069 , 0.09482758,\n",
       "            0.10344828, 0.12068965, 0.12931034, 0.12931034, 0.13793103,\n",
       "            0.14655173, 0.15517241, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18103448, 0.18965517, 0.19827586, 0.20689656, 0.21551724,\n",
       "            0.22413793, 0.2413793 , 0.25862068, 0.2672414 , 0.2672414 ,\n",
       "            0.28448275, 0.28448275, 0.31034482, 0.31896552, 0.3275862 ,\n",
       "            0.33620688, 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37068966, 0.38793105, 0.38793105, 0.41379312, 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.44827586, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.4827586 , 0.49137932, 0.5       ,\n",
       "            0.5       , 0.5086207 , 0.5344828 , 0.54310346, 0.5603448 ,\n",
       "            0.57758623, 0.57758623, 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6551724 , 0.6637931 , 0.67241377, 0.6810345 , 0.6810345 ,\n",
       "            0.6810345 , 0.6896552 , 0.69827586, 0.70689654, 0.7155172 ,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.82758623, 0.82758623,\n",
       "            0.8448276 , 0.86206895, 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.8965517 ,\n",
       "            0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.94827586, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9893, 0.987 , 0.986 , 0.9824, 0.981 , 0.979 , 0.977 ,\n",
       "            0.9766, 0.9756, 0.9746, 0.973 , 0.9727, 0.972 , 0.971 , 0.9707,\n",
       "            0.97  , 0.9697, 0.969 , 0.9683, 0.968 , 0.9663, 0.9644, 0.964 ,\n",
       "            0.963 , 0.9624, 0.962 , 0.961 , 0.96  , 0.959 , 0.9585, 0.958 ,\n",
       "            0.957 , 0.9565, 0.956 , 0.9556, 0.9526, 0.952 , 0.95  , 0.9497,\n",
       "            0.949 , 0.9487, 0.948 , 0.9478, 0.947 , 0.9463, 0.946 , 0.9453,\n",
       "            0.945 , 0.9443, 0.943 , 0.9424, 0.942 , 0.9414, 0.94  , 0.9395,\n",
       "            0.939 , 0.9385, 0.9365, 0.9355, 0.935 , 0.9346, 0.9336, 0.933 ,\n",
       "            0.932 , 0.9316, 0.9307, 0.93  , 0.9287, 0.9277, 0.927 , 0.9263,\n",
       "            0.925 , 0.9233, 0.923 , 0.921 , 0.9204, 0.92  , 0.9194, 0.919 ,\n",
       "            0.9185, 0.9175, 0.917 , 0.9165, 0.916 , 0.915 , 0.9136, 0.912 ,\n",
       "            0.911 , 0.91  , 0.909 , 0.9087, 0.908 , 0.907 , 0.9062, 0.9043,\n",
       "            0.9014, 0.901 , 0.898 , 0.897 , 0.8965, 0.8945, 0.8936, 0.8916,\n",
       "            0.8906, 0.887 , 0.8853, 0.8843, 0.883 , 0.88  , 0.8774, 0.8765,\n",
       "            0.875 , 0.8735, 0.868 , 0.8677, 0.8613, 0.8564, 0.856 , 0.8535,\n",
       "            0.8525, 0.8467, 0.8403, 0.839 , 0.8364, 0.831 , 0.8286, 0.827 ,\n",
       "            0.822 , 0.819 , 0.8003, 0.7827, 0.782 , 0.776 , 0.768 , 0.763 ,\n",
       "            0.725 , 0.7124, 0.705 , 0.7026, 0.6963, 0.692 , 0.683 , 0.6724,\n",
       "            0.6694, 0.656 , 0.6323, 0.622 , 0.606 , 0.604 , 0.599 , 0.594 ,\n",
       "            0.5884, 0.588 , 0.585 , 0.581 , 0.5786, 0.568 , 0.5605, 0.546 ,\n",
       "            0.541 , 0.5073, 0.5015, 0.4976, 0.495 , 0.4883, 0.4849, 0.4805,\n",
       "            0.4717, 0.4636, 0.4578, 0.4548, 0.4539, 0.4504, 0.4463, 0.4456,\n",
       "            0.4421, 0.4414, 0.4407, 0.4324, 0.428 , 0.4153, 0.4124, 0.3918,\n",
       "            0.3735, 0.3694, 0.3574, 0.3516, 0.3499, 0.3315, 0.3237, 0.3179,\n",
       "            0.3152, 0.3035, 0.2915, 0.2886, 0.2563], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.76119405, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.03731343, 0.04477612, 0.05223881,\n",
       "            0.05970149, 0.05970149, 0.06716418, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.09701493, 0.09701493, 0.10447761, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.12686567, 0.12686567,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.15671642, 0.15671642, 0.15671642, 0.1641791 ,\n",
       "            0.1716418 , 0.1716418 , 0.18656716, 0.18656716, 0.20149253,\n",
       "            0.20149253, 0.20149253, 0.20895523, 0.21641791, 0.21641791,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.2238806 , 0.23880596,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.24626866, 0.25373134,\n",
       "            0.26119402, 0.26865673, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29850745, 0.30597016, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.32089552, 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35074627, 0.35074627,\n",
       "            0.35074627, 0.35820895, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.3955224 , 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.41044775, 0.41791046, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4402985 , 0.4402985 ,\n",
       "            0.4477612 , 0.4477612 , 0.4552239 , 0.46268657, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5074627 , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.0775862 , 0.0862069 ,\n",
       "            0.10344828, 0.11206897, 0.12931034, 0.13793103, 0.14655173,\n",
       "            0.1637931 , 0.1724138 , 0.18103448, 0.18965517, 0.20689656,\n",
       "            0.21551724, 0.2413793 , 0.2413793 , 0.2672414 , 0.27586207,\n",
       "            0.27586207, 0.30172414, 0.30172414, 0.30172414, 0.31034482,\n",
       "            0.3275862 , 0.33620688, 0.3448276 , 0.35344827, 0.36206895,\n",
       "            0.37068966, 0.37931034, 0.4051724 , 0.41379312, 0.4224138 ,\n",
       "            0.43965518, 0.43965518, 0.44827586, 0.46551725, 0.47413793,\n",
       "            0.47413793, 0.4827586 , 0.49137932, 0.5       , 0.51724136,\n",
       "            0.5344828 , 0.54310346, 0.5603448 , 0.5689655 , 0.5689655 ,\n",
       "            0.5689655 , 0.5862069 , 0.5948276 , 0.6034483 , 0.61206895,\n",
       "            0.62068963, 0.62931037, 0.62931037, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.67241377, 0.6896552 , 0.6896552 ,\n",
       "            0.69827586, 0.70689654, 0.7155172 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.73275864, 0.73275864,\n",
       "            0.7413793 , 0.75      , 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.7844828 , 0.7844828 , 0.79310346, 0.80172414, 0.8103448 ,\n",
       "            0.8103448 , 0.8189655 , 0.82758623, 0.82758623, 0.82758623,\n",
       "            0.8362069 , 0.8448276 , 0.8534483 , 0.86206895, 0.87068963,\n",
       "            0.87931037, 0.87931037, 0.88793105, 0.88793105, 0.8965517 ,\n",
       "            0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.92241377, 0.9310345 , 0.9396552 ,\n",
       "            0.94827586, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 , 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.992 , 0.9897, 0.989 , 0.9863, 0.986 , 0.9854, 0.9834,\n",
       "            0.983 , 0.9814, 0.981 , 0.9785, 0.978 , 0.977 , 0.9766, 0.976 ,\n",
       "            0.974 , 0.9736, 0.972 , 0.971 , 0.97  , 0.9697, 0.969 , 0.9683,\n",
       "            0.9673, 0.967 , 0.966 , 0.9653, 0.965 , 0.9644, 0.964 , 0.9634,\n",
       "            0.9614, 0.9604, 0.9595, 0.959 , 0.9585, 0.9575, 0.957 , 0.9565,\n",
       "            0.956 , 0.9556, 0.9546, 0.9536, 0.953 , 0.9526, 0.952 , 0.951 ,\n",
       "            0.95  , 0.9497, 0.949 , 0.9478, 0.9473, 0.9463, 0.946 , 0.9453,\n",
       "            0.945 , 0.944 , 0.943 , 0.9424, 0.942 , 0.94  , 0.9395, 0.939 ,\n",
       "            0.9375, 0.937 , 0.9365, 0.9355, 0.934 , 0.9336, 0.933 , 0.9326,\n",
       "            0.932 , 0.9316, 0.931 , 0.9307, 0.93  , 0.9297, 0.9287, 0.928 ,\n",
       "            0.9272, 0.927 , 0.9263, 0.9253, 0.9243, 0.9233, 0.923 , 0.922 ,\n",
       "            0.921 , 0.9204, 0.9194, 0.9185, 0.916 , 0.9155, 0.914 , 0.912 ,\n",
       "            0.9097, 0.9087, 0.906 , 0.905 , 0.9043, 0.9033, 0.901 , 0.9   ,\n",
       "            0.8994, 0.8965, 0.8945, 0.894 , 0.892 , 0.89  , 0.886 , 0.8843,\n",
       "            0.884 , 0.8784, 0.8755, 0.8745, 0.873 , 0.872 , 0.8706, 0.8696,\n",
       "            0.864 , 0.8594, 0.8574, 0.857 , 0.8555, 0.848 , 0.8457, 0.844 ,\n",
       "            0.841 , 0.8384, 0.818 , 0.8003, 0.7974, 0.7964, 0.789 , 0.783 ,\n",
       "            0.743 , 0.728 , 0.7246, 0.7217, 0.7134, 0.709 , 0.6997, 0.6875,\n",
       "            0.6855, 0.6714, 0.649 , 0.638 , 0.6206, 0.6187, 0.6143, 0.609 ,\n",
       "            0.6084, 0.603 , 0.602 , 0.5996, 0.599 , 0.5986, 0.596 , 0.5938,\n",
       "            0.582 , 0.5737, 0.558 , 0.554 , 0.5186, 0.5117, 0.508 , 0.506 ,\n",
       "            0.4988, 0.4954, 0.4905, 0.4814, 0.4731, 0.4666, 0.4636, 0.4624,\n",
       "            0.459 , 0.4548, 0.4539, 0.4504, 0.4497, 0.449 , 0.4404, 0.4355,\n",
       "            0.4226, 0.4192, 0.3982, 0.3792, 0.3745, 0.3623, 0.3562, 0.3545,\n",
       "            0.3352, 0.3271, 0.3213, 0.3186, 0.3064, 0.2942, 0.292 , 0.258 ],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7835821, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.00746269, 0.01492537,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.03731343, 0.04477612, 0.04477612,\n",
       "            0.05223881, 0.05970149, 0.05970149, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.08955224,\n",
       "            0.09701493, 0.09701493, 0.10447761, 0.10447761, 0.1119403 ,\n",
       "            0.11940298, 0.11940298, 0.11940298, 0.12686567, 0.13432837,\n",
       "            0.13432837, 0.13432837, 0.14179105, 0.14925373, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.15671642, 0.15671642, 0.15671642,\n",
       "            0.1641791 , 0.1716418 , 0.17910448, 0.18656716, 0.18656716,\n",
       "            0.19402985, 0.20149253, 0.20149253, 0.20149253, 0.21641791,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.2238806 , 0.23880596,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.26865673, 0.2761194 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.31343284, 0.32089552,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35074627, 0.35074627, 0.35820895, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6567164 , 0.6641791 , 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.03448276,\n",
       "            0.04310345, 0.05172414, 0.06034483, 0.0775862 , 0.09482758,\n",
       "            0.10344828, 0.10344828, 0.11206897, 0.12931034, 0.13793103,\n",
       "            0.15517241, 0.1637931 , 0.18103448, 0.18965517, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.22413793, 0.2413793 , 0.25862068,\n",
       "            0.27586207, 0.27586207, 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.31896552, 0.33620688, 0.3448276 , 0.35344827, 0.37068966,\n",
       "            0.37931034, 0.38793105, 0.39655173, 0.41379312, 0.43103448,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.45689654,\n",
       "            0.46551725, 0.4827586 , 0.4827586 , 0.4827586 , 0.5       ,\n",
       "            0.5258621 , 0.54310346, 0.54310346, 0.5603448 , 0.5689655 ,\n",
       "            0.5689655 , 0.57758623, 0.57758623, 0.57758623, 0.5862069 ,\n",
       "            0.5948276 , 0.5948276 , 0.6034483 , 0.62068963, 0.62931037,\n",
       "            0.63793105, 0.6551724 , 0.6637931 , 0.6810345 , 0.6810345 ,\n",
       "            0.69827586, 0.70689654, 0.7241379 , 0.7241379 , 0.73275864,\n",
       "            0.73275864, 0.73275864, 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.7844828 , 0.7844828 ,\n",
       "            0.79310346, 0.8103448 , 0.8103448 , 0.8189655 , 0.8189655 ,\n",
       "            0.82758623, 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8534483 , 0.86206895, 0.87068963, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9137931 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.92241377, 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.994 , 0.992 , 0.9917, 0.9893, 0.989 , 0.9883, 0.9873,\n",
       "            0.9863, 0.9854, 0.985 , 0.9834, 0.983 , 0.9824, 0.982 , 0.9814,\n",
       "            0.981 , 0.9785, 0.9775, 0.977 , 0.9766, 0.976 , 0.9756, 0.975 ,\n",
       "            0.9746, 0.974 , 0.9736, 0.9727, 0.972 , 0.9717, 0.97  , 0.9697,\n",
       "            0.9688, 0.9673, 0.967 , 0.9663, 0.966 , 0.9653, 0.965 , 0.9644,\n",
       "            0.964 , 0.9634, 0.963 , 0.962 , 0.9614, 0.961 , 0.9604, 0.96  ,\n",
       "            0.9595, 0.959 , 0.9585, 0.9575, 0.957 , 0.9565, 0.956 , 0.9556,\n",
       "            0.9546, 0.954 , 0.9536, 0.953 , 0.9526, 0.952 , 0.9517, 0.951 ,\n",
       "            0.949 , 0.9487, 0.9478, 0.9463, 0.9453, 0.9443, 0.944 , 0.9434,\n",
       "            0.943 , 0.9424, 0.942 , 0.9414, 0.941 , 0.94  , 0.9395, 0.9385,\n",
       "            0.938 , 0.937 , 0.9365, 0.936 , 0.9346, 0.9336, 0.9326, 0.931 ,\n",
       "            0.93  , 0.9287, 0.928 , 0.9277, 0.9272, 0.925 , 0.9224, 0.9214,\n",
       "            0.9194, 0.918 , 0.917 , 0.916 , 0.914 , 0.913 , 0.9106, 0.9087,\n",
       "            0.9067, 0.905 , 0.9014, 0.8984, 0.898 , 0.8936, 0.891 , 0.89  ,\n",
       "            0.8896, 0.888 , 0.886 , 0.8833, 0.8794, 0.8755, 0.8735, 0.8726,\n",
       "            0.8716, 0.8643, 0.861 , 0.8604, 0.8574, 0.855 , 0.8545, 0.834 ,\n",
       "            0.818 , 0.815 , 0.814 , 0.807 , 0.8013, 0.7607, 0.745 , 0.742 ,\n",
       "            0.739 , 0.7295, 0.7256, 0.7163, 0.705 , 0.702 , 0.6875, 0.664 ,\n",
       "            0.6533, 0.6353, 0.6333, 0.6294, 0.6245, 0.623 , 0.618 , 0.615 ,\n",
       "            0.614 , 0.6133, 0.6104, 0.6074, 0.5967, 0.587 , 0.574 , 0.5664,\n",
       "            0.5293, 0.5264, 0.5195, 0.516 , 0.5093, 0.506 , 0.501 , 0.491 ,\n",
       "            0.4827, 0.4766, 0.4756, 0.4753, 0.4685, 0.4634, 0.4626, 0.4585,\n",
       "            0.4583, 0.4568, 0.4504, 0.4475, 0.431 , 0.4275, 0.405 , 0.3872,\n",
       "            0.3813, 0.3699, 0.3618, 0.36  , 0.3403, 0.3333, 0.3271, 0.323 ,\n",
       "            0.3118, 0.298 , 0.2954, 0.2622], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.7910448, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.        , 0.00746269,\n",
       "            0.01492537, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02985075, 0.03731343, 0.04477612,\n",
       "            0.05970149, 0.05970149, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.08208955, 0.09701493,\n",
       "            0.09701493, 0.10447761, 0.10447761, 0.11940298, 0.11940298,\n",
       "            0.11940298, 0.12686567, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.15671642, 0.1641791 , 0.1716418 , 0.17910448, 0.18656716,\n",
       "            0.18656716, 0.19402985, 0.20149253, 0.20149253, 0.20149253,\n",
       "            0.20149253, 0.21641791, 0.21641791, 0.21641791, 0.2238806 ,\n",
       "            0.2238806 , 0.2238806 , 0.23880596, 0.23880596, 0.24626866,\n",
       "            0.24626866, 0.25373134, 0.26119402, 0.26865673, 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.30597016, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.31343284, 0.32089552, 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.35820895,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3955224 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.41791046, 0.42537314, 0.43283582, 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.47014925, 0.47761193, 0.48507464, 0.49253732, 0.5       ,\n",
       "            0.5074627 , 0.5074627 , 0.51492536, 0.52238804, 0.5298507 ,\n",
       "            0.53731346, 0.54477614, 0.5522388 , 0.5597015 , 0.5671642 ,\n",
       "            0.57462686, 0.58208954, 0.5895522 , 0.5970149 , 0.6044776 ,\n",
       "            0.6119403 , 0.619403  , 0.6268657 , 0.63432837, 0.64179105,\n",
       "            0.6492537 , 0.6567164 , 0.6641791 , 0.67164177, 0.6791045 ,\n",
       "            0.6865672 , 0.69402987, 0.70149255, 0.7089552 , 0.7164179 ,\n",
       "            0.7238806 , 0.73134327, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.03448276, 0.05172414,\n",
       "            0.06034483, 0.0775862 , 0.0862069 , 0.10344828, 0.10344828,\n",
       "            0.12068965, 0.13793103, 0.14655173, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.20689656, 0.22413793, 0.22413793, 0.25      ,\n",
       "            0.2672414 , 0.27586207, 0.30172414, 0.31034482, 0.31896552,\n",
       "            0.3275862 , 0.3448276 , 0.35344827, 0.36206895, 0.37068966,\n",
       "            0.37931034, 0.39655173, 0.41379312, 0.4224138 , 0.43103448,\n",
       "            0.43965518, 0.44827586, 0.45689654, 0.46551725, 0.46551725,\n",
       "            0.49137932, 0.5       , 0.51724136, 0.5344828 , 0.54310346,\n",
       "            0.5603448 , 0.5689655 , 0.5689655 , 0.57758623, 0.57758623,\n",
       "            0.5862069 , 0.5862069 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.61206895, 0.62931037, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6810345 , 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.73275864, 0.73275864,\n",
       "            0.73275864, 0.7413793 , 0.75      , 0.7586207 , 0.76724136,\n",
       "            0.7758621 , 0.7844828 , 0.79310346, 0.8103448 , 0.8103448 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.82758623, 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.8534483 , 0.87068963,\n",
       "            0.87931037, 0.88793105, 0.8965517 , 0.8965517 , 0.9051724 ,\n",
       "            0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 , 0.92241377,\n",
       "            0.92241377, 0.9310345 , 0.9396552 , 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9655172 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9956, 0.9937, 0.9917, 0.991 , 0.99  , 0.9893, 0.989 ,\n",
       "            0.9883, 0.9873, 0.9863, 0.986 , 0.9854, 0.985 , 0.983 , 0.9824,\n",
       "            0.9814, 0.981 , 0.9805, 0.98  , 0.9795, 0.979 , 0.978 , 0.977 ,\n",
       "            0.9756, 0.975 , 0.9746, 0.974 , 0.9736, 0.973 , 0.9727, 0.972 ,\n",
       "            0.9717, 0.971 , 0.97  , 0.9697, 0.969 , 0.9688, 0.9683, 0.9673,\n",
       "            0.967 , 0.9663, 0.966 , 0.9653, 0.965 , 0.9644, 0.964 , 0.963 ,\n",
       "            0.9624, 0.962 , 0.9614, 0.961 , 0.9604, 0.96  , 0.9595, 0.9585,\n",
       "            0.958 , 0.957 , 0.956 , 0.9556, 0.9546, 0.954 , 0.9536, 0.953 ,\n",
       "            0.9526, 0.952 , 0.9517, 0.951 , 0.9507, 0.95  , 0.9497, 0.948 ,\n",
       "            0.9478, 0.9473, 0.9463, 0.9453, 0.945 , 0.944 , 0.9434, 0.9424,\n",
       "            0.941 , 0.9395, 0.9385, 0.9365, 0.936 , 0.9336, 0.9326, 0.9297,\n",
       "            0.929 , 0.9277, 0.927 , 0.9263, 0.9253, 0.9233, 0.922 , 0.9214,\n",
       "            0.92  , 0.9175, 0.9146, 0.9116, 0.911 , 0.907 , 0.906 , 0.9043,\n",
       "            0.9023, 0.901 , 0.896 , 0.894 , 0.8906, 0.888 , 0.887 , 0.879 ,\n",
       "            0.8755, 0.875 , 0.873 , 0.8706, 0.869 , 0.8496, 0.834 , 0.832 ,\n",
       "            0.8296, 0.8247, 0.8184, 0.778 , 0.761 , 0.7603, 0.756 , 0.746 ,\n",
       "            0.7417, 0.733 , 0.7217, 0.7183, 0.704 , 0.6797, 0.6694, 0.6504,\n",
       "            0.6484, 0.644 , 0.64  , 0.6377, 0.6343, 0.634 , 0.6313, 0.6284,\n",
       "            0.628 , 0.6274, 0.6245, 0.6216, 0.612 , 0.6   , 0.5894, 0.579 ,\n",
       "            0.54  , 0.5312, 0.5264, 0.5205, 0.5166, 0.5117, 0.5005, 0.4927,\n",
       "            0.4873, 0.4866, 0.4783, 0.473 , 0.4712, 0.4678, 0.4668, 0.465 ,\n",
       "            0.4604, 0.4583, 0.4392, 0.4358, 0.412 , 0.395 , 0.388 , 0.377 ,\n",
       "            0.3672, 0.3657, 0.3452, 0.3389, 0.3325, 0.3274, 0.3167, 0.3015,\n",
       "            0.2986, 0.266 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.79850745, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.        , 0.00746269, 0.00746269,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.03731343, 0.04477612, 0.05970149,\n",
       "            0.05970149, 0.07462686, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.09701493, 0.10447761, 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.13432837, 0.13432837, 0.13432837, 0.14925373,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.15671642, 0.1641791 ,\n",
       "            0.17910448, 0.18656716, 0.19402985, 0.20149253, 0.20149253,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.2238806 , 0.2238806 ,\n",
       "            0.23880596, 0.23880596, 0.23880596, 0.25373134, 0.25373134,\n",
       "            0.26119402, 0.2761194 , 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.30597016,\n",
       "            0.30597016, 0.30597016, 0.30597016, 0.31343284, 0.31343284,\n",
       "            0.32089552, 0.3283582 , 0.33582088, 0.3432836 , 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.35820895, 0.36567163, 0.36567163,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5074627 ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.57462686,\n",
       "            0.58208954, 0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 ,\n",
       "            0.619403  , 0.6268657 , 0.63432837, 0.64179105, 0.6492537 ,\n",
       "            0.6567164 , 0.6641791 , 0.67164177, 0.6791045 , 0.6865672 ,\n",
       "            0.69402987, 0.70149255, 0.7089552 , 0.7164179 , 0.7238806 ,\n",
       "            0.73134327, 0.73880595, 0.74626863, 0.75373137, 0.76119405,\n",
       "            0.76865673, 0.7761194 , 0.7835821 , 0.7910448 , 0.79850745,\n",
       "            0.80597013, 0.8134328 , 0.8208955 , 0.82835823, 0.8358209 ,\n",
       "            0.8432836 , 0.8507463 , 0.85820895, 0.86567163, 0.8731343 ,\n",
       "            0.880597  , 0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 ,\n",
       "            0.91791046, 0.92537314, 0.9328358 , 0.9402985 , 0.9477612 ,\n",
       "            0.95522386, 0.96268654, 0.9701493 , 0.97761196, 0.98507464,\n",
       "            0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.05172414, 0.06034483,\n",
       "            0.0775862 , 0.09482758, 0.10344828, 0.10344828, 0.11206897,\n",
       "            0.12068965, 0.12931034, 0.15517241, 0.1637931 , 0.1724138 ,\n",
       "            0.18965517, 0.21551724, 0.21551724, 0.23275863, 0.25862068,\n",
       "            0.29310346, 0.30172414, 0.31034482, 0.3275862 , 0.3448276 ,\n",
       "            0.35344827, 0.37068966, 0.41379312, 0.4224138 , 0.4224138 ,\n",
       "            0.43103448, 0.43965518, 0.44827586, 0.45689654, 0.46551725,\n",
       "            0.47413793, 0.4827586 , 0.5258621 , 0.5603448 , 0.5689655 ,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.5862069 , 0.6034483 ,\n",
       "            0.62068963, 0.63793105, 0.63793105, 0.6465517 , 0.6551724 ,\n",
       "            0.6637931 , 0.67241377, 0.6896552 , 0.70689654, 0.7155172 ,\n",
       "            0.7241379 , 0.73275864, 0.73275864, 0.73275864, 0.7413793 ,\n",
       "            0.75      , 0.7586207 , 0.76724136, 0.76724136, 0.76724136,\n",
       "            0.7844828 , 0.80172414, 0.8103448 , 0.8103448 , 0.8189655 ,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.86206895, 0.87931037,\n",
       "            0.88793105, 0.8965517 , 0.8965517 , 0.9051724 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.9137931 , 0.92241377, 0.92241377,\n",
       "            0.9310345 , 0.9396552 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9966, 0.995 , 0.993 , 0.9927, 0.9917, 0.991 , 0.9907,\n",
       "            0.99  , 0.9897, 0.9893, 0.989 , 0.9883, 0.988 , 0.9863, 0.986 ,\n",
       "            0.9854, 0.985 , 0.9844, 0.984 , 0.983 , 0.9824, 0.9814, 0.98  ,\n",
       "            0.9795, 0.979 , 0.9785, 0.9775, 0.977 , 0.9766, 0.976 , 0.975 ,\n",
       "            0.9746, 0.974 , 0.9736, 0.973 , 0.9727, 0.972 , 0.971 , 0.9707,\n",
       "            0.9697, 0.9688, 0.9683, 0.968 , 0.9663, 0.9653, 0.9644, 0.9634,\n",
       "            0.963 , 0.9624, 0.962 , 0.9614, 0.961 , 0.9604, 0.96  , 0.9595,\n",
       "            0.959 , 0.9585, 0.958 , 0.957 , 0.9565, 0.956 , 0.9556, 0.954 ,\n",
       "            0.9536, 0.953 , 0.9526, 0.952 , 0.9517, 0.95  , 0.9497, 0.9487,\n",
       "            0.948 , 0.9463, 0.944 , 0.943 , 0.94  , 0.9385, 0.9375, 0.937 ,\n",
       "            0.9365, 0.936 , 0.9346, 0.9336, 0.9326, 0.9316, 0.929 , 0.927 ,\n",
       "            0.9233, 0.923 , 0.9194, 0.919 , 0.9185, 0.9175, 0.9155, 0.914 ,\n",
       "            0.907 , 0.9043, 0.902 , 0.901 , 0.9004, 0.8926, 0.8887, 0.888 ,\n",
       "            0.8853, 0.883 , 0.8643, 0.8496, 0.849 , 0.8438, 0.842 , 0.835 ,\n",
       "            0.795 , 0.778 , 0.777 , 0.7725, 0.7627, 0.759 , 0.7495, 0.7373,\n",
       "            0.7344, 0.72  , 0.6953, 0.6855, 0.6655, 0.663 , 0.6597, 0.6553,\n",
       "            0.6523, 0.65  , 0.6494, 0.647 , 0.6436, 0.6426, 0.642 , 0.639 ,\n",
       "            0.636 , 0.6265, 0.614 , 0.604 , 0.5923, 0.5527, 0.5513, 0.5425,\n",
       "            0.537 , 0.5317, 0.528 , 0.5225, 0.5107, 0.503 , 0.4988, 0.4985,\n",
       "            0.4968, 0.4878, 0.4822, 0.4797, 0.4766, 0.4753, 0.4731, 0.47  ,\n",
       "            0.4685, 0.4473, 0.4438, 0.419 , 0.402 , 0.3943, 0.3833, 0.3723,\n",
       "            0.3708, 0.3496, 0.344 , 0.3374, 0.3313, 0.321 , 0.3047, 0.3018,\n",
       "            0.269 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8208955, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.        , 0.00746269, 0.00746269, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.03731343, 0.05223881, 0.05970149, 0.05970149, 0.07462686,\n",
       "            0.07462686, 0.07462686, 0.08955224, 0.09701493, 0.10447761,\n",
       "            0.1119403 , 0.11940298, 0.11940298, 0.13432837, 0.13432837,\n",
       "            0.13432837, 0.14925373, 0.14925373, 0.14925373, 0.15671642,\n",
       "            0.1641791 , 0.1641791 , 0.17910448, 0.18656716, 0.20149253,\n",
       "            0.20895523, 0.21641791, 0.21641791, 0.21641791, 0.2238806 ,\n",
       "            0.23880596, 0.23880596, 0.24626866, 0.25373134, 0.26119402,\n",
       "            0.2761194 , 0.2835821 , 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.30597016, 0.30597016,\n",
       "            0.31343284, 0.31343284, 0.31343284, 0.32089552, 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.8507463 ,\n",
       "            0.85820895, 0.86567163, 0.8731343 , 0.880597  , 0.8880597 ,\n",
       "            0.8955224 , 0.9029851 , 0.9104478 , 0.91791046, 0.92537314,\n",
       "            0.9328358 , 0.9402985 , 0.9477612 , 0.95522386, 0.96268654,\n",
       "            0.9701493 , 0.97761196, 0.98507464, 0.9925373 , 1.        ],\n",
       "           dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.06034483,\n",
       "            0.0775862 , 0.09482758, 0.10344828, 0.11206897, 0.12931034,\n",
       "            0.15517241, 0.1637931 , 0.1724138 , 0.18103448, 0.20689656,\n",
       "            0.21551724, 0.22413793, 0.25862068, 0.27586207, 0.30172414,\n",
       "            0.31034482, 0.33620688, 0.36206895, 0.36206895, 0.38793105,\n",
       "            0.4224138 , 0.43103448, 0.43965518, 0.43965518, 0.44827586,\n",
       "            0.45689654, 0.47413793, 0.49137932, 0.5086207 , 0.5258621 ,\n",
       "            0.55172414, 0.5689655 , 0.57758623, 0.5862069 , 0.5862069 ,\n",
       "            0.5948276 , 0.61206895, 0.62931037, 0.63793105, 0.6465517 ,\n",
       "            0.6465517 , 0.6810345 , 0.69827586, 0.69827586, 0.70689654,\n",
       "            0.7155172 , 0.7241379 , 0.73275864, 0.75      , 0.7586207 ,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.7758621 , 0.79310346,\n",
       "            0.79310346, 0.8103448 , 0.8189655 , 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.86206895, 0.87068963, 0.87931037, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.9655172 , 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ],\n",
       "           dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9976, 0.9966, 0.996 , 0.9946, 0.9937, 0.993 , 0.9927,\n",
       "            0.992 , 0.9917, 0.9907, 0.99  , 0.9897, 0.9893, 0.989 , 0.9883,\n",
       "            0.988 , 0.9873, 0.987 , 0.9863, 0.9854, 0.984 , 0.9834, 0.983 ,\n",
       "            0.9824, 0.982 , 0.9814, 0.9805, 0.98  , 0.9795, 0.979 , 0.9785,\n",
       "            0.978 , 0.9775, 0.977 , 0.9766, 0.976 , 0.9756, 0.9746, 0.974 ,\n",
       "            0.972 , 0.9717, 0.971 , 0.97  , 0.9697, 0.9688, 0.9683, 0.968 ,\n",
       "            0.9673, 0.967 , 0.9663, 0.966 , 0.9653, 0.9644, 0.964 , 0.9634,\n",
       "            0.9624, 0.9614, 0.961 , 0.9604, 0.96  , 0.9595, 0.9585, 0.958 ,\n",
       "            0.9575, 0.957 , 0.955 , 0.9526, 0.952 , 0.9497, 0.9478, 0.947 ,\n",
       "            0.9463, 0.946 , 0.945 , 0.9443, 0.943 , 0.9424, 0.94  , 0.938 ,\n",
       "            0.9336, 0.931 , 0.9307, 0.929 , 0.9277, 0.9263, 0.919 , 0.9175,\n",
       "            0.915 , 0.914 , 0.9126, 0.905 , 0.9014, 0.899 , 0.8955, 0.878 ,\n",
       "            0.8647, 0.858 , 0.857 , 0.851 , 0.811 , 0.795 , 0.792 , 0.7896,\n",
       "            0.7793, 0.7754, 0.7656, 0.7534, 0.7505, 0.7363, 0.7114, 0.702 ,\n",
       "            0.6816, 0.6787, 0.6753, 0.6714, 0.6675, 0.6655, 0.665 , 0.663 ,\n",
       "            0.659 , 0.6577, 0.657 , 0.655 , 0.652 , 0.642 , 0.628 , 0.619 ,\n",
       "            0.607 , 0.567 , 0.564 , 0.5557, 0.5493, 0.544 , 0.54  , 0.5347,\n",
       "            0.522 , 0.514 , 0.511 , 0.5107, 0.508 , 0.4988, 0.4927, 0.4895,\n",
       "            0.4868, 0.485 , 0.483 , 0.481 , 0.4797, 0.4568, 0.4531, 0.4272,\n",
       "            0.4106, 0.402 , 0.3914, 0.3792, 0.3777, 0.3555, 0.3503, 0.3438,\n",
       "            0.3367, 0.327 , 0.3093, 0.3066, 0.274 ], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8432836, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.02238806, 0.02985075, 0.04477612,\n",
       "            0.05970149, 0.05970149, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.09701493, 0.1119403 , 0.11940298,\n",
       "            0.11940298, 0.11940298, 0.13432837, 0.13432837, 0.14179105,\n",
       "            0.14925373, 0.14925373, 0.14925373, 0.1641791 , 0.1641791 ,\n",
       "            0.17910448, 0.18656716, 0.20149253, 0.20895523, 0.21641791,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.23880596, 0.23880596,\n",
       "            0.24626866, 0.25373134, 0.2761194 , 0.2835821 , 0.29104477,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29104477, 0.29850745,\n",
       "            0.30597016, 0.30597016, 0.31343284, 0.31343284, 0.31343284,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.3432836 , 0.35074627,\n",
       "            0.35820895, 0.36567163, 0.36567163, 0.36567163, 0.37313432,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.3880597 ,\n",
       "            0.3955224 , 0.40298507, 0.40298507, 0.40298507, 0.40298507,\n",
       "            0.41044775, 0.41791046, 0.42537314, 0.43283582, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.05172414, 0.06034483,\n",
       "            0.06896552, 0.09482758, 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.14655173, 0.1724138 , 0.18103448, 0.19827586, 0.20689656,\n",
       "            0.23275863, 0.25      , 0.29310346, 0.30172414, 0.31034482,\n",
       "            0.3275862 , 0.35344827, 0.36206895, 0.39655173, 0.41379312,\n",
       "            0.43103448, 0.43965518, 0.43965518, 0.44827586, 0.45689654,\n",
       "            0.46551725, 0.49137932, 0.5086207 , 0.5344828 , 0.55172414,\n",
       "            0.57758623, 0.5862069 , 0.5862069 , 0.6034483 , 0.6034483 ,\n",
       "            0.62931037, 0.63793105, 0.63793105, 0.6465517 , 0.6637931 ,\n",
       "            0.6896552 , 0.69827586, 0.70689654, 0.7155172 , 0.7155172 ,\n",
       "            0.7241379 , 0.75      , 0.7586207 , 0.76724136, 0.76724136,\n",
       "            0.76724136, 0.7758621 , 0.7844828 , 0.79310346, 0.80172414,\n",
       "            0.8189655 , 0.82758623, 0.82758623, 0.8362069 , 0.8448276 ,\n",
       "            0.8448276 , 0.8448276 , 0.8534483 , 0.87931037, 0.87931037,\n",
       "            0.88793105, 0.9051724 , 0.9051724 , 0.9137931 , 0.9137931 ,\n",
       "            0.9137931 , 0.92241377, 0.9310345 , 0.94827586, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9655172 , 0.9741379 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.998 , 0.997 , 0.996 , 0.9956, 0.995 , 0.9946, 0.994 ,\n",
       "            0.9937, 0.993 , 0.9927, 0.992 , 0.9917, 0.991 , 0.9907, 0.99  ,\n",
       "            0.9897, 0.9893, 0.989 , 0.988 , 0.9873, 0.987 , 0.9863, 0.986 ,\n",
       "            0.9854, 0.985 , 0.9844, 0.984 , 0.9834, 0.983 , 0.9824, 0.982 ,\n",
       "            0.9814, 0.981 , 0.9805, 0.98  , 0.979 , 0.9785, 0.977 , 0.9766,\n",
       "            0.976 , 0.9756, 0.975 , 0.974 , 0.9736, 0.973 , 0.9727, 0.972 ,\n",
       "            0.9717, 0.971 , 0.9707, 0.97  , 0.9697, 0.969 , 0.9683, 0.968 ,\n",
       "            0.9673, 0.967 , 0.9663, 0.9653, 0.965 , 0.964 , 0.9634, 0.962 ,\n",
       "            0.9595, 0.957 , 0.9556, 0.954 , 0.9536, 0.953 , 0.9526, 0.952 ,\n",
       "            0.951 , 0.9507, 0.948 , 0.947 , 0.9424, 0.941 , 0.9404, 0.9395,\n",
       "            0.9375, 0.936 , 0.929 , 0.9277, 0.927 , 0.9253, 0.925 , 0.923 ,\n",
       "            0.916 , 0.913 , 0.9126, 0.912 , 0.9106, 0.9067, 0.89  , 0.879 ,\n",
       "            0.878 , 0.8726, 0.8706, 0.865 , 0.826 , 0.8105, 0.807 , 0.8057,\n",
       "            0.795 , 0.7915, 0.7817, 0.77  , 0.766 , 0.752 , 0.7275, 0.7183,\n",
       "            0.6973, 0.695 , 0.6914, 0.688 , 0.6836, 0.6816, 0.681 , 0.675 ,\n",
       "            0.6733, 0.673 , 0.6704, 0.6675, 0.6587, 0.6436, 0.637 , 0.6216,\n",
       "            0.5845, 0.578 , 0.57  , 0.5625, 0.5576, 0.5537, 0.5483, 0.5347,\n",
       "            0.5273, 0.527 , 0.5215, 0.512 , 0.506 , 0.501 , 0.4993, 0.4968,\n",
       "            0.4954, 0.495 , 0.4944, 0.469 , 0.465 , 0.438 , 0.423 , 0.4128,\n",
       "            0.4028, 0.3887, 0.3875, 0.3647, 0.3606, 0.3538, 0.3455, 0.3367,\n",
       "            0.3174, 0.3145, 0.2827], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.880597, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.        , 0.00746269, 0.00746269, 0.02238806, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.03731343, 0.05223881, 0.05970149,\n",
       "            0.07462686, 0.07462686, 0.07462686, 0.07462686, 0.08955224,\n",
       "            0.09701493, 0.11940298, 0.11940298, 0.11940298, 0.13432837,\n",
       "            0.13432837, 0.14925373, 0.14925373, 0.14925373, 0.1641791 ,\n",
       "            0.17910448, 0.17910448, 0.18656716, 0.20149253, 0.21641791,\n",
       "            0.21641791, 0.21641791, 0.2238806 , 0.23880596, 0.24626866,\n",
       "            0.25373134, 0.26865673, 0.2835821 , 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.30597016, 0.31343284,\n",
       "            0.31343284, 0.3283582 , 0.3283582 , 0.3283582 , 0.33582088,\n",
       "            0.3432836 , 0.3432836 , 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.37313432, 0.37313432,\n",
       "            0.38059703, 0.38059703, 0.38059703, 0.3880597 , 0.3955224 ,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.42537314, 0.43283582, 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 , 0.46268657,\n",
       "            0.46268657, 0.47014925, 0.47761193, 0.48507464, 0.49253732,\n",
       "            0.5       , 0.5       , 0.5074627 , 0.51492536, 0.52238804,\n",
       "            0.5298507 , 0.53731346, 0.54477614, 0.5522388 , 0.5597015 ,\n",
       "            0.5671642 , 0.57462686, 0.58208954, 0.5895522 , 0.5970149 ,\n",
       "            0.6044776 , 0.6119403 , 0.619403  , 0.6268657 , 0.63432837,\n",
       "            0.64179105, 0.6492537 , 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.79850745, 0.80597013, 0.8134328 , 0.8208955 ,\n",
       "            0.82835823, 0.8358209 , 0.8432836 , 0.8507463 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.01724138, 0.02586207, 0.05172414,\n",
       "            0.06896552, 0.0775862 , 0.11206897, 0.12068965, 0.12931034,\n",
       "            0.1724138 , 0.18103448, 0.19827586, 0.22413793, 0.25      ,\n",
       "            0.27586207, 0.29310346, 0.30172414, 0.31896552, 0.3448276 ,\n",
       "            0.35344827, 0.4051724 , 0.41379312, 0.43965518, 0.43965518,\n",
       "            0.44827586, 0.46551725, 0.4827586 , 0.49137932, 0.5258621 ,\n",
       "            0.55172414, 0.5603448 , 0.5862069 , 0.5862069 , 0.6034483 ,\n",
       "            0.61206895, 0.62068963, 0.63793105, 0.6465517 , 0.6637931 ,\n",
       "            0.6810345 , 0.6810345 , 0.70689654, 0.7155172 , 0.73275864,\n",
       "            0.76724136, 0.76724136, 0.76724136, 0.7758621 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8189655 , 0.82758623,\n",
       "            0.82758623, 0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.8534483 , 0.86206895, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.88793105, 0.9051724 , 0.9137931 , 0.9137931 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.9655172 ,\n",
       "            0.9741379 , 0.98275864, 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9985, 0.998 , 0.9976, 0.997 , 0.9966, 0.996 , 0.9956,\n",
       "            0.995 , 0.9946, 0.994 , 0.9937, 0.993 , 0.9927, 0.992 , 0.9917,\n",
       "            0.991 , 0.9907, 0.99  , 0.9897, 0.9893, 0.989 , 0.9883, 0.988 ,\n",
       "            0.9873, 0.987 , 0.9863, 0.986 , 0.9854, 0.985 , 0.9844, 0.984 ,\n",
       "            0.9834, 0.983 , 0.9814, 0.981 , 0.9805, 0.98  , 0.979 , 0.9785,\n",
       "            0.978 , 0.9775, 0.977 , 0.976 , 0.9756, 0.975 , 0.974 , 0.9736,\n",
       "            0.973 , 0.9727, 0.972 , 0.971 , 0.9707, 0.97  , 0.9697, 0.9688,\n",
       "            0.9683, 0.9663, 0.9644, 0.9634, 0.962 , 0.9614, 0.961 , 0.9604,\n",
       "            0.96  , 0.9595, 0.959 , 0.958 , 0.9565, 0.9556, 0.9507, 0.95  ,\n",
       "            0.9497, 0.9487, 0.9473, 0.946 , 0.939 , 0.9385, 0.936 , 0.9355,\n",
       "            0.9346, 0.933 , 0.927 , 0.9243, 0.924 , 0.923 , 0.9224, 0.9175,\n",
       "            0.902 , 0.8926, 0.8906, 0.8867, 0.8813, 0.8794, 0.841 , 0.8267,\n",
       "            0.8223, 0.82  , 0.8105, 0.8066, 0.7964, 0.783 , 0.781 , 0.7666,\n",
       "            0.743 , 0.7344, 0.7124, 0.7095, 0.7065, 0.7026, 0.698 , 0.697 ,\n",
       "            0.6963, 0.695 , 0.69  , 0.688 , 0.687 , 0.6855, 0.6826, 0.673 ,\n",
       "            0.657 , 0.65  , 0.636 , 0.5947, 0.591 , 0.581 , 0.5747, 0.5693,\n",
       "            0.565 , 0.559 , 0.5454, 0.538 , 0.5376, 0.5366, 0.5312, 0.5215,\n",
       "            0.515 , 0.5103, 0.5083, 0.5063, 0.5044, 0.504 , 0.5034, 0.4768,\n",
       "            0.473 , 0.445 , 0.4294, 0.419 , 0.4084, 0.394 , 0.3926, 0.369 ,\n",
       "            0.3647, 0.3577, 0.349 , 0.3398, 0.3203, 0.3176, 0.2847],\n",
       "           dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.880597, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "            0.00746269, 0.02238806, 0.02238806, 0.02238806, 0.02985075,\n",
       "            0.05223881, 0.05970149, 0.07462686, 0.07462686, 0.07462686,\n",
       "            0.08208955, 0.1119403 , 0.11940298, 0.11940298, 0.13432837,\n",
       "            0.13432837, 0.14925373, 0.14925373, 0.1641791 , 0.1641791 ,\n",
       "            0.17910448, 0.18656716, 0.20149253, 0.20149253, 0.21641791,\n",
       "            0.21641791, 0.2238806 , 0.23134328, 0.23880596, 0.24626866,\n",
       "            0.26865673, 0.2835821 , 0.29104477, 0.29104477, 0.29104477,\n",
       "            0.29104477, 0.29850745, 0.30597016, 0.31343284, 0.3283582 ,\n",
       "            0.3283582 , 0.3283582 , 0.33582088, 0.33582088, 0.3432836 ,\n",
       "            0.35074627, 0.35820895, 0.36567163, 0.36567163, 0.36567163,\n",
       "            0.37313432, 0.37313432, 0.38059703, 0.38059703, 0.38059703,\n",
       "            0.3880597 , 0.3955224 , 0.3955224 , 0.40298507, 0.40298507,\n",
       "            0.40298507, 0.41044775, 0.41791046, 0.42537314, 0.43283582,\n",
       "            0.4402985 , 0.4402985 , 0.4402985 , 0.4477612 , 0.4552239 ,\n",
       "            0.46268657, 0.46268657, 0.47014925, 0.47761193, 0.48507464,\n",
       "            0.49253732, 0.5       , 0.5       , 0.5074627 , 0.51492536,\n",
       "            0.52238804, 0.5298507 , 0.53731346, 0.54477614, 0.5522388 ,\n",
       "            0.5597015 , 0.5671642 , 0.57462686, 0.58208954, 0.5895522 ,\n",
       "            0.5970149 , 0.6044776 , 0.6119403 , 0.619403  , 0.6268657 ,\n",
       "            0.63432837, 0.64179105, 0.6567164 , 0.6641791 , 0.67164177,\n",
       "            0.6791045 , 0.6865672 , 0.69402987, 0.70149255, 0.7089552 ,\n",
       "            0.7164179 , 0.7238806 , 0.73134327, 0.73880595, 0.74626863,\n",
       "            0.75373137, 0.76119405, 0.76865673, 0.7761194 , 0.7835821 ,\n",
       "            0.7910448 , 0.80597013, 0.8134328 , 0.8208955 , 0.82835823,\n",
       "            0.8358209 , 0.8432836 , 0.8507463 , 0.85820895, 0.86567163,\n",
       "            0.8731343 , 0.880597  , 0.8880597 , 0.8955224 , 0.9029851 ,\n",
       "            0.9104478 , 0.91791046, 0.92537314, 0.9328358 , 0.9402985 ,\n",
       "            0.9477612 , 0.95522386, 0.96268654, 0.9701493 , 0.97761196,\n",
       "            0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.02586207, 0.03448276, 0.06896552,\n",
       "            0.0775862 , 0.12068965, 0.12931034, 0.15517241, 0.18103448,\n",
       "            0.20689656, 0.2413793 , 0.27586207, 0.29310346, 0.30172414,\n",
       "            0.3448276 , 0.3448276 , 0.4051724 , 0.41379312, 0.43103448,\n",
       "            0.44827586, 0.46551725, 0.4827586 , 0.5086207 , 0.5258621 ,\n",
       "            0.5603448 , 0.5689655 , 0.5862069 , 0.5948276 , 0.6034483 ,\n",
       "            0.62068963, 0.62931037, 0.63793105, 0.6465517 , 0.67241377,\n",
       "            0.67241377, 0.6896552 , 0.69827586, 0.70689654, 0.7241379 ,\n",
       "            0.75      , 0.76724136, 0.7758621 , 0.79310346, 0.79310346,\n",
       "            0.80172414, 0.8103448 , 0.8103448 , 0.8189655 , 0.8362069 ,\n",
       "            0.8448276 , 0.8448276 , 0.8448276 , 0.8534483 , 0.86206895,\n",
       "            0.87068963, 0.87931037, 0.88793105, 0.8965517 , 0.9051724 ,\n",
       "            0.9137931 , 0.9137931 , 0.92241377, 0.9396552 , 0.94827586,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.9655172 , 0.98275864, 0.98275864, 0.98275864,\n",
       "            0.98275864, 0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.999 , 0.9985, 0.998 , 0.9976, 0.997 , 0.9966, 0.996 ,\n",
       "            0.9956, 0.995 , 0.9946, 0.994 , 0.9937, 0.993 , 0.9927, 0.992 ,\n",
       "            0.9917, 0.991 , 0.9907, 0.99  , 0.9897, 0.9893, 0.989 , 0.9883,\n",
       "            0.988 , 0.9873, 0.987 , 0.9863, 0.9854, 0.985 , 0.9844, 0.984 ,\n",
       "            0.9834, 0.983 , 0.9824, 0.982 , 0.9814, 0.981 , 0.9805, 0.98  ,\n",
       "            0.9795, 0.979 , 0.978 , 0.9775, 0.9766, 0.976 , 0.9756, 0.975 ,\n",
       "            0.9746, 0.974 , 0.972 , 0.9707, 0.9697, 0.9683, 0.968 , 0.9673,\n",
       "            0.967 , 0.966 , 0.9653, 0.965 , 0.9634, 0.963 , 0.9585, 0.958 ,\n",
       "            0.9575, 0.9565, 0.9556, 0.9536, 0.9478, 0.9473, 0.9453, 0.9443,\n",
       "            0.942 , 0.9365, 0.9346, 0.9336, 0.9326, 0.932 , 0.927 , 0.9126,\n",
       "            0.9053, 0.9023, 0.8994, 0.892 , 0.8916, 0.854 , 0.842 , 0.8374,\n",
       "            0.8325, 0.8247, 0.8213, 0.81  , 0.796 , 0.795 , 0.781 , 0.7583,\n",
       "            0.7495, 0.7266, 0.7236, 0.7217, 0.7163, 0.712 , 0.7104, 0.7085,\n",
       "            0.7046, 0.7017, 0.7007, 0.7   , 0.6973, 0.686 , 0.6704, 0.6626,\n",
       "            0.6494, 0.6064, 0.6035, 0.593 , 0.5874, 0.5806, 0.576 , 0.5703,\n",
       "            0.5557, 0.5483, 0.547 , 0.5415, 0.5317, 0.5244, 0.5195, 0.518 ,\n",
       "            0.515 , 0.5137, 0.513 , 0.512 , 0.4854, 0.4812, 0.4524, 0.4365,\n",
       "            0.4255, 0.4148, 0.4   , 0.3984, 0.374 , 0.3699, 0.3628, 0.3535,\n",
       "            0.3445, 0.3242, 0.3218, 0.2883], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.880597, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00746269, 0.02238806,\n",
       "            0.02238806, 0.02238806, 0.05223881, 0.05970149, 0.07462686,\n",
       "            0.07462686, 0.08208955, 0.1119403 , 0.11940298, 0.11940298,\n",
       "            0.13432837, 0.14925373, 0.14925373, 0.1641791 , 0.17910448,\n",
       "            0.18656716, 0.20149253, 0.20149253, 0.21641791, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.24626866, 0.25373134, 0.2761194 ,\n",
       "            0.29104477, 0.29104477, 0.29104477, 0.29850745, 0.29850745,\n",
       "            0.30597016, 0.31343284, 0.31343284, 0.3283582 , 0.3283582 ,\n",
       "            0.33582088, 0.3432836 , 0.3432836 , 0.35074627, 0.35820895,\n",
       "            0.36567163, 0.36567163, 0.37313432, 0.37313432, 0.38059703,\n",
       "            0.38059703, 0.38059703, 0.3880597 , 0.3955224 , 0.3955224 ,\n",
       "            0.3955224 , 0.3955224 , 0.40298507, 0.40298507, 0.41044775,\n",
       "            0.41791046, 0.43283582, 0.4402985 , 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.4552239 , 0.46268657, 0.47014925,\n",
       "            0.47761193, 0.48507464, 0.49253732, 0.5       , 0.5       ,\n",
       "            0.5074627 , 0.51492536, 0.52238804, 0.5298507 , 0.53731346,\n",
       "            0.54477614, 0.5522388 , 0.5597015 , 0.5671642 , 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.64179105, 0.6492537 , 0.6567164 ,\n",
       "            0.6641791 , 0.67164177, 0.6791045 , 0.6865672 , 0.69402987,\n",
       "            0.70149255, 0.7089552 , 0.7164179 , 0.7238806 , 0.73134327,\n",
       "            0.73880595, 0.74626863, 0.75373137, 0.76119405, 0.76865673,\n",
       "            0.7761194 , 0.7835821 , 0.7910448 , 0.79850745, 0.80597013,\n",
       "            0.8134328 , 0.8208955 , 0.82835823, 0.8358209 , 0.8432836 ,\n",
       "            0.8507463 , 0.85820895, 0.86567163, 0.8731343 , 0.880597  ,\n",
       "            0.8880597 , 0.8955224 , 0.9029851 , 0.9104478 , 0.91791046,\n",
       "            0.92537314, 0.9328358 , 0.9402985 , 0.9477612 , 0.95522386,\n",
       "            0.96268654, 0.9701493 , 0.97761196, 0.98507464, 0.9925373 ,\n",
       "            1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.01724138, 0.04310345, 0.06896552, 0.11206897,\n",
       "            0.12931034, 0.1637931 , 0.19827586, 0.23275863, 0.2672414 ,\n",
       "            0.28448275, 0.3448276 , 0.35344827, 0.39655173, 0.4224138 ,\n",
       "            0.43103448, 0.46551725, 0.4827586 , 0.5       , 0.5344828 ,\n",
       "            0.5689655 , 0.5689655 , 0.5862069 , 0.5948276 , 0.62068963,\n",
       "            0.62068963, 0.62931037, 0.6551724 , 0.67241377, 0.67241377,\n",
       "            0.6810345 , 0.69827586, 0.7241379 , 0.7413793 , 0.7586207 ,\n",
       "            0.76724136, 0.7844828 , 0.79310346, 0.79310346, 0.80172414,\n",
       "            0.8103448 , 0.82758623, 0.8362069 , 0.8448276 , 0.8448276 ,\n",
       "            0.8448276 , 0.86206895, 0.87068963, 0.87931037, 0.88793105,\n",
       "            0.8965517 , 0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 ,\n",
       "            0.92241377, 0.9310345 , 0.94827586, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.98275864, 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 0.9913793 , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.999 , 0.9985, 0.998 , 0.9976, 0.997 , 0.9966, 0.996 ,\n",
       "            0.9956, 0.995 , 0.9946, 0.994 , 0.9937, 0.993 , 0.9927, 0.992 ,\n",
       "            0.9917, 0.991 , 0.9907, 0.99  , 0.9897, 0.9893, 0.989 , 0.9883,\n",
       "            0.988 , 0.9873, 0.987 , 0.9863, 0.986 , 0.9854, 0.985 , 0.9844,\n",
       "            0.984 , 0.9834, 0.983 , 0.9824, 0.982 , 0.9814, 0.981 , 0.9805,\n",
       "            0.98  , 0.9785, 0.978 , 0.977 , 0.9756, 0.975 , 0.9736, 0.973 ,\n",
       "            0.972 , 0.9717, 0.9707, 0.97  , 0.9697, 0.969 , 0.9683, 0.9653,\n",
       "            0.965 , 0.9644, 0.964 , 0.9624, 0.961 , 0.955 , 0.953 , 0.9526,\n",
       "            0.95  , 0.9487, 0.9453, 0.9434, 0.9424, 0.9414, 0.936 , 0.9224,\n",
       "            0.917 , 0.9136, 0.9116, 0.9043, 0.9014, 0.8677, 0.856 , 0.8516,\n",
       "            0.8447, 0.839 , 0.8354, 0.8237, 0.8086, 0.7954, 0.7725, 0.764 ,\n",
       "            0.74  , 0.7373, 0.737 , 0.7305, 0.7256, 0.724 , 0.7236, 0.7217,\n",
       "            0.7188, 0.7153, 0.7144, 0.714 , 0.7114, 0.6997, 0.6836, 0.675 ,\n",
       "            0.6626, 0.617 , 0.6157, 0.603 , 0.5986, 0.591 , 0.5864, 0.5806,\n",
       "            0.5654, 0.5586, 0.558 , 0.556 , 0.5503, 0.54  , 0.5327, 0.527 ,\n",
       "            0.526 , 0.523 , 0.522 , 0.5215, 0.52  , 0.492 , 0.488 , 0.458 ,\n",
       "            0.442 , 0.4302, 0.419 , 0.4033, 0.4019, 0.3765, 0.3723, 0.365 ,\n",
       "            0.3552, 0.3462, 0.3252, 0.3223, 0.2886], dtype=float16)}},\n",
       "   {'model': LitClassifier(\n",
       "      (model): SimpleClassifier(\n",
       "        (layer_stack): Sequential(\n",
       "          (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "    ),\n",
       "    'fpr': array(0.8880597, dtype=float32),\n",
       "    'tpr': array(1., dtype=float32),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.00746269, 0.02238806,\n",
       "            0.02238806, 0.02985075, 0.05970149, 0.07462686, 0.07462686,\n",
       "            0.09701493, 0.11940298, 0.12686567, 0.13432837, 0.14925373,\n",
       "            0.15671642, 0.17910448, 0.17910448, 0.20149253, 0.21641791,\n",
       "            0.2238806 , 0.23134328, 0.23880596, 0.26119402, 0.2835821 ,\n",
       "            0.29104477, 0.29104477, 0.29850745, 0.29850745, 0.31343284,\n",
       "            0.31343284, 0.3283582 , 0.3283582 , 0.33582088, 0.3432836 ,\n",
       "            0.3432836 , 0.35074627, 0.35074627, 0.35820895, 0.36567163,\n",
       "            0.36567163, 0.37313432, 0.37313432, 0.38059703, 0.38059703,\n",
       "            0.38059703, 0.3880597 , 0.3955224 , 0.3955224 , 0.40298507,\n",
       "            0.40298507, 0.40298507, 0.40298507, 0.41044775, 0.41791046,\n",
       "            0.42537314, 0.43283582, 0.4402985 , 0.4402985 , 0.4402985 ,\n",
       "            0.4402985 , 0.4477612 , 0.46268657, 0.47014925, 0.47761193,\n",
       "            0.48507464, 0.49253732, 0.5       , 0.5       , 0.5074627 ,\n",
       "            0.51492536, 0.52238804, 0.5298507 , 0.53731346, 0.54477614,\n",
       "            0.5522388 , 0.5597015 , 0.5671642 , 0.57462686, 0.58208954,\n",
       "            0.5895522 , 0.5970149 , 0.6044776 , 0.6119403 , 0.619403  ,\n",
       "            0.6268657 , 0.63432837, 0.6492537 , 0.6567164 , 0.6641791 ,\n",
       "            0.67164177, 0.6791045 , 0.6865672 , 0.69402987, 0.70149255,\n",
       "            0.7089552 , 0.7164179 , 0.7238806 , 0.73134327, 0.73880595,\n",
       "            0.74626863, 0.75373137, 0.76119405, 0.76865673, 0.7761194 ,\n",
       "            0.7835821 , 0.7910448 , 0.79850745, 0.80597013, 0.8134328 ,\n",
       "            0.8208955 , 0.82835823, 0.8358209 , 0.8432836 , 0.85820895,\n",
       "            0.86567163, 0.8731343 , 0.880597  , 0.8880597 , 0.8955224 ,\n",
       "            0.9029851 , 0.9104478 , 0.91791046, 0.92537314, 0.9328358 ,\n",
       "            0.9402985 , 0.9477612 , 0.95522386, 0.96268654, 0.9701493 ,\n",
       "            0.97761196, 0.98507464, 0.9925373 , 1.        ], dtype=float32),\n",
       "     'tpr': array([0.        , 0.00862069, 0.03448276, 0.06896552, 0.12068965,\n",
       "            0.14655173, 0.18965517, 0.2413793 , 0.2672414 , 0.30172414,\n",
       "            0.3448276 , 0.39655173, 0.4224138 , 0.43103448, 0.47413793,\n",
       "            0.4827586 , 0.51724136, 0.5689655 , 0.57758623, 0.5948276 ,\n",
       "            0.62068963, 0.62068963, 0.6465517 , 0.67241377, 0.6810345 ,\n",
       "            0.6810345 , 0.69827586, 0.7413793 , 0.7586207 , 0.7844828 ,\n",
       "            0.79310346, 0.79310346, 0.80172414, 0.8103448 , 0.82758623,\n",
       "            0.8362069 , 0.8362069 , 0.8448276 , 0.8448276 , 0.8448276 ,\n",
       "            0.86206895, 0.87068963, 0.87931037, 0.88793105, 0.8965517 ,\n",
       "            0.9051724 , 0.9051724 , 0.9051724 , 0.9137931 , 0.9310345 ,\n",
       "            0.9396552 , 0.94827586, 0.95689654, 0.95689654, 0.95689654,\n",
       "            0.95689654, 0.95689654, 0.95689654, 0.9655172 , 0.9741379 ,\n",
       "            0.98275864, 0.98275864, 0.98275864, 0.9913793 , 0.9913793 ,\n",
       "            0.9913793 , 0.9913793 , 0.9913793 , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "            1.        , 1.        , 1.        , 1.        ], dtype=float32),\n",
       "     'thresholds': array([1.    , 0.9995, 0.999 , 0.9985, 0.998 , 0.9976, 0.997 , 0.9966,\n",
       "            0.996 , 0.9956, 0.995 , 0.9946, 0.994 , 0.9937, 0.993 , 0.9927,\n",
       "            0.992 , 0.9917, 0.991 , 0.99  , 0.9897, 0.9893, 0.989 , 0.9883,\n",
       "            0.988 , 0.9873, 0.987 , 0.9863, 0.986 , 0.985 , 0.9844, 0.984 ,\n",
       "            0.9834, 0.983 , 0.982 , 0.9814, 0.981 , 0.9805, 0.979 , 0.9785,\n",
       "            0.9775, 0.9766, 0.976 , 0.9756, 0.9746, 0.974 , 0.9736, 0.973 ,\n",
       "            0.9727, 0.9697, 0.969 , 0.9688, 0.9683, 0.9673, 0.966 , 0.9614,\n",
       "            0.9604, 0.959 , 0.958 , 0.956 , 0.955 , 0.952 , 0.9497, 0.948 ,\n",
       "            0.9434, 0.931 , 0.925 , 0.9224, 0.9194, 0.913 , 0.911 , 0.879 ,\n",
       "            0.8667, 0.8623, 0.8574, 0.851 , 0.847 , 0.8364, 0.8228, 0.822 ,\n",
       "            0.8086, 0.7847, 0.7773, 0.7534, 0.751 , 0.75  , 0.7446, 0.7397,\n",
       "            0.739 , 0.738 , 0.7314, 0.7285, 0.7275, 0.7266, 0.7236, 0.7144,\n",
       "            0.6973, 0.6914, 0.675 , 0.634 , 0.6274, 0.616 , 0.61  , 0.603 ,\n",
       "            0.5986, 0.5923, 0.5757, 0.5737, 0.572 , 0.569 , 0.5625, 0.5522,\n",
       "            0.545 , 0.537 , 0.5366, 0.535 , 0.5327, 0.5293, 0.503 , 0.4988,\n",
       "            0.4675, 0.4543, 0.44  , 0.4302, 0.4119, 0.4104, 0.3843, 0.3818,\n",
       "            0.3745, 0.3628, 0.355 , 0.3318, 0.3289, 0.2966], dtype=float16)}}]],\n",
       " 'roc_results': {'fpr': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.00333333,\n",
       "         0.00333333, 0.00666667, 0.00666667, 0.01      , 0.01      ,\n",
       "         0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,\n",
       "         0.01333333, 0.01666667, 0.02      , 0.02666667, 0.04      ,\n",
       "         0.04666667, 0.05333333, 0.06333333, 0.06666667, 0.07      ,\n",
       "         0.07333333, 0.08666667, 0.09666666, 0.10333333, 0.10333333,\n",
       "         0.10333333, 0.11      , 0.12333333, 0.13333334, 0.13333334,\n",
       "         0.15      , 0.16666667, 0.18666667, 0.19      , 0.19666667,\n",
       "         0.21      , 0.22666667, 0.24      , 0.25666666, 0.26666668,\n",
       "         0.28333333, 0.29333332, 0.30666667, 0.32      , 0.34      ,\n",
       "         0.35      , 0.36      , 0.36666667, 0.37      , 0.38333333,\n",
       "         0.40333334, 0.41333333, 0.41666666, 0.42333335, 0.43333334,\n",
       "         0.44333333, 0.44666666, 0.45666668, 0.46      , 0.46333334,\n",
       "         0.47      , 0.48      , 0.48666668, 0.49      , 0.49      ,\n",
       "         0.49666667, 0.50333333, 0.52      , 0.52666664, 0.53      ,\n",
       "         0.53333336, 0.54      , 0.54333335, 0.55      , 0.55333334,\n",
       "         0.56333333, 0.56333333, 0.57      , 0.5833333 , 0.5933333 ,\n",
       "         0.5966667 , 0.5966667 , 0.61      , 0.61333334, 0.62      ,\n",
       "         0.62666667, 0.6333333 , 0.6333333 , 0.6333333 , 0.63666666,\n",
       "         0.64      , 0.64      , 0.6433333 , 0.65      , 0.6533333 ,\n",
       "         0.6533333 , 0.6566667 , 0.66      , 0.66333336, 0.6666667 ,\n",
       "         0.67333335, 0.6766667 , 0.6766667 , 0.68      , 0.6933333 ,\n",
       "         0.69666666, 0.7       , 0.7033333 , 0.70666665, 0.71      ,\n",
       "         0.7133333 , 0.7133333 , 0.7133333 , 0.72      , 0.72333336,\n",
       "         0.7266667 , 0.7266667 , 0.73      , 0.73      , 0.74      ,\n",
       "         0.74      , 0.74333334, 0.74333334, 0.75      , 0.75333333,\n",
       "         0.75666666, 0.76      , 0.76666665, 0.77      , 0.77      ,\n",
       "         0.77      , 0.7733333 , 0.77666664, 0.78      , 0.78333336,\n",
       "         0.78333336, 0.79      , 0.79333335, 0.7966667 , 0.8       ,\n",
       "         0.81      , 0.82      , 0.82      , 0.82      , 0.82      ,\n",
       "         0.82      , 0.82      , 0.8233333 , 0.82666665, 0.82666665,\n",
       "         0.82666665, 0.83      , 0.83      , 0.83      , 0.8333333 ,\n",
       "         0.83666664, 0.83666664, 0.84      , 0.84      , 0.8433333 ,\n",
       "         0.8433333 , 0.8433333 , 0.8466667 , 0.85      , 0.85      ,\n",
       "         0.85      , 0.85333335, 0.85333335, 0.86      , 0.86333334,\n",
       "         0.86333334, 0.87      , 0.87666667, 0.88      , 0.8833333 ,\n",
       "         0.89      , 0.89      , 0.89      , 0.8933333 , 0.8933333 ,\n",
       "         0.8933333 , 0.8933333 , 0.89666665, 0.89666665, 0.89666665,\n",
       "         0.9       , 0.9033333 , 0.9066667 , 0.9066667 , 0.9066667 ,\n",
       "         0.9066667 , 0.91      , 0.91333336, 0.91333336, 0.9166667 ,\n",
       "         0.9166667 , 0.9166667 , 0.92      , 0.92333335, 0.9266667 ,\n",
       "         0.93      , 0.93333334, 0.93666667, 0.9433333 , 0.94666666,\n",
       "         0.95      , 0.9533333 , 0.9533333 , 0.9533333 , 0.95666665,\n",
       "         0.96      , 0.96      , 0.96      , 0.9633333 , 0.9633333 ,\n",
       "         0.9633333 , 0.96666664, 0.96666664, 0.97      , 0.97333336,\n",
       "         0.97333336, 0.98      , 0.98      , 0.98333335, 0.9866667 ,\n",
       "         0.9866667 , 0.9866667 , 0.9866667 , 0.99      , 0.99333334,\n",
       "         0.99333334, 0.99333334, 0.99333334, 0.99333334, 0.99666667,\n",
       "         0.99666667, 0.99666667, 1.        , 1.        , 1.        ],\n",
       "        dtype=float32),\n",
       "  'tpr': array([0.        , 0.00333333, 0.00666667, 0.01      , 0.02      ,\n",
       "         0.03      , 0.05333333, 0.07333333, 0.07666667, 0.08      ,\n",
       "         0.1       , 0.11333334, 0.12666667, 0.13      , 0.14      ,\n",
       "         0.15      , 0.16      , 0.16666667, 0.17333333, 0.18666667,\n",
       "         0.19      , 0.19333333, 0.20333333, 0.21333334, 0.23333333,\n",
       "         0.23333333, 0.23666666, 0.24666667, 0.25333333, 0.26333332,\n",
       "         0.27333334, 0.28333333, 0.28666666, 0.29333332, 0.3       ,\n",
       "         0.30333334, 0.31333333, 0.31666666, 0.32      , 0.33      ,\n",
       "         0.33333334, 0.34666666, 0.34666666, 0.35333332, 0.36666667,\n",
       "         0.37      , 0.38      , 0.39      , 0.39      , 0.4       ,\n",
       "         0.40666667, 0.41666666, 0.42666668, 0.43333334, 0.43666667,\n",
       "         0.43666667, 0.44333333, 0.45      , 0.45      , 0.46      ,\n",
       "         0.47666666, 0.47666666, 0.48333332, 0.48333332, 0.48666668,\n",
       "         0.48666668, 0.49333334, 0.50666666, 0.51666665, 0.53      ,\n",
       "         0.54333335, 0.55      , 0.55      , 0.5566667 , 0.56666666,\n",
       "         0.56666666, 0.56666666, 0.5733333 , 0.57666665, 0.58666664,\n",
       "         0.5966667 , 0.5966667 , 0.5966667 , 0.60333335, 0.61      ,\n",
       "         0.61333334, 0.62      , 0.62      , 0.62333333, 0.62333333,\n",
       "         0.63      , 0.63      , 0.63666666, 0.63666666, 0.6433333 ,\n",
       "         0.65      , 0.6533333 , 0.6566667 , 0.66      , 0.66333336,\n",
       "         0.6666667 , 0.67333335, 0.6766667 , 0.68      , 0.68666667,\n",
       "         0.68666667, 0.68666667, 0.69      , 0.69666666, 0.69666666,\n",
       "         0.69666666, 0.7       , 0.7       , 0.7       , 0.7033333 ,\n",
       "         0.71      , 0.71666664, 0.71666664, 0.71666664, 0.71666664,\n",
       "         0.72      , 0.72      , 0.73      , 0.73333335, 0.73333335,\n",
       "         0.73333335, 0.73333335, 0.73333335, 0.73333335, 0.7366667 ,\n",
       "         0.74333334, 0.74666667, 0.75      , 0.75      , 0.75      ,\n",
       "         0.75      , 0.75333333, 0.75666666, 0.76      , 0.76      ,\n",
       "         0.7633333 , 0.77      , 0.7733333 , 0.77666664, 0.77666664,\n",
       "         0.78      , 0.78333336, 0.78333336, 0.78333336, 0.7866667 ,\n",
       "         0.79      , 0.79333335, 0.79333335, 0.79333335, 0.79333335,\n",
       "         0.7966667 , 0.7966667 , 0.7966667 , 0.7966667 , 0.7966667 ,\n",
       "         0.7966667 , 0.7966667 , 0.8       , 0.80333334, 0.8066667 ,\n",
       "         0.81      , 0.81333333, 0.81666666, 0.81666666, 0.8233333 ,\n",
       "         0.82666665, 0.83      , 0.8333333 , 0.83666664, 0.83666664,\n",
       "         0.83666664, 0.84      , 0.84      , 0.8433333 , 0.8433333 ,\n",
       "         0.8466667 , 0.85      , 0.85      , 0.85      , 0.85333335,\n",
       "         0.8566667 , 0.86      , 0.86333334, 0.8666667 , 0.8666667 ,\n",
       "         0.87      , 0.87666667, 0.87666667, 0.87666667, 0.87666667,\n",
       "         0.87666667, 0.88      , 0.8833333 , 0.8833333 , 0.88666666,\n",
       "         0.89      , 0.8933333 , 0.8933333 , 0.89666665, 0.9       ,\n",
       "         0.9       , 0.9       , 0.9       , 0.9033333 , 0.9066667 ,\n",
       "         0.91      , 0.91      , 0.91      , 0.91333336, 0.91333336,\n",
       "         0.9166667 , 0.92      , 0.92      , 0.92      , 0.92      ,\n",
       "         0.92      , 0.92      , 0.92      , 0.92      , 0.92333335,\n",
       "         0.92333335, 0.9266667 , 0.93      , 0.93333334, 0.93333334,\n",
       "         0.93666667, 0.94      , 0.9433333 , 0.94666666, 0.95      ,\n",
       "         0.9533333 , 0.9533333 , 0.95666665, 0.95666665, 0.95666665,\n",
       "         0.96      , 0.96      , 0.9633333 , 0.9633333 , 0.9633333 ,\n",
       "         0.96666664, 0.97      , 0.97333336, 0.97333336, 0.97333336,\n",
       "         0.9766667 , 0.98      , 0.98333335, 0.9866667 , 0.9866667 ,\n",
       "         0.99      , 0.99333334, 0.99333334, 0.99666667, 1.        ],\n",
       "        dtype=float32),\n",
       "  'thresholds': array([1.    , 0.5356, 0.535 , 0.5347, 0.534 , 0.5337, 0.533 , 0.5327,\n",
       "         0.532 , 0.5317, 0.5312, 0.531 , 0.5303, 0.53  , 0.5293, 0.529 ,\n",
       "         0.5283, 0.528 , 0.5273, 0.527 , 0.5264, 0.5254, 0.525 , 0.5244,\n",
       "         0.524 , 0.5234, 0.523 , 0.5225, 0.522 , 0.5215, 0.521 , 0.5205,\n",
       "         0.52  , 0.5195, 0.519 , 0.5186, 0.518 , 0.5176, 0.517 , 0.516 ,\n",
       "         0.5156, 0.515 , 0.5146, 0.5137, 0.513 , 0.5127, 0.512 , 0.5117,\n",
       "         0.511 , 0.5107, 0.5103, 0.51  , 0.5093, 0.509 , 0.5083, 0.508 ,\n",
       "         0.5073, 0.507 , 0.5063, 0.506 , 0.5054, 0.505 , 0.5044, 0.504 ,\n",
       "         0.5034, 0.503 , 0.5024, 0.502 , 0.5015, 0.501 , 0.5005, 0.5   ,\n",
       "         0.4998, 0.4995, 0.4993, 0.499 , 0.4988, 0.4985, 0.4983, 0.498 ,\n",
       "         0.4978, 0.4976, 0.4973, 0.497 , 0.4968, 0.4966, 0.4963, 0.4958,\n",
       "         0.4956, 0.4954, 0.495 , 0.4949, 0.4946, 0.4944, 0.4941, 0.4937,\n",
       "         0.4934, 0.4932, 0.493 , 0.4927, 0.4924, 0.4922, 0.492 , 0.4917,\n",
       "         0.4912, 0.491 , 0.4907, 0.4902, 0.49  , 0.4897, 0.4895, 0.489 ,\n",
       "         0.4885, 0.4883, 0.4868, 0.4863, 0.486 , 0.4856, 0.485 , 0.4849,\n",
       "         0.4844, 0.4841, 0.484 , 0.483 , 0.4827, 0.4822, 0.482 , 0.4812,\n",
       "         0.481 , 0.4807, 0.4805, 0.4802, 0.48  , 0.4797, 0.4795, 0.4792,\n",
       "         0.479 , 0.4788, 0.4783, 0.4778, 0.477 , 0.4768, 0.4766, 0.476 ,\n",
       "         0.4749, 0.4744, 0.474 , 0.4739, 0.4736, 0.4727, 0.4724, 0.472 ,\n",
       "         0.471 , 0.4707, 0.4697, 0.469 , 0.4688, 0.4685, 0.4683, 0.4678,\n",
       "         0.4675, 0.4673, 0.467 , 0.4668, 0.4663, 0.466 , 0.4653, 0.464 ,\n",
       "         0.4639, 0.4634, 0.4631, 0.463 , 0.4626, 0.4624, 0.462 , 0.4617,\n",
       "         0.4614, 0.4612, 0.4602, 0.46  , 0.4597, 0.4595, 0.4592, 0.4587,\n",
       "         0.4583, 0.458 , 0.4575, 0.457 , 0.4568, 0.4563, 0.4558, 0.4553,\n",
       "         0.455 , 0.4548, 0.454 , 0.4521, 0.452 , 0.4512, 0.4504, 0.4502,\n",
       "         0.4495, 0.4482, 0.4475, 0.4473, 0.4463, 0.4453, 0.4448, 0.4436,\n",
       "         0.4426, 0.4424, 0.4412, 0.441 , 0.4407, 0.4402, 0.44  , 0.438 ,\n",
       "         0.4373, 0.4355, 0.435 , 0.4348, 0.4346, 0.434 , 0.4324, 0.432 ,\n",
       "         0.431 , 0.43  , 0.4297, 0.4294, 0.429 , 0.4282, 0.4277, 0.4275,\n",
       "         0.4268, 0.426 , 0.4253, 0.425 , 0.424 , 0.4236, 0.4229, 0.4214,\n",
       "         0.4211, 0.421 , 0.4194, 0.418 , 0.4177, 0.4172, 0.4167, 0.415 ,\n",
       "         0.4138, 0.4136, 0.4128, 0.4106, 0.4094, 0.4082, 0.4053, 0.405 ,\n",
       "         0.4043, 0.3977, 0.3958, 0.381 ], dtype=float16),\n",
       "  'name': 'Original NN data1',\n",
       "  'auc': array(0.6139444, dtype=float32),\n",
       "  'model': LitClassifier(\n",
       "    (model): SimpleClassifier(\n",
       "      (layer_stack): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): BCEWithLogitsLoss()\n",
       "    (train_accuracy): BinaryAccuracy()\n",
       "    (test_accuracy): BinaryAccuracy()\n",
       "    (test_auc): BinaryAUROC()\n",
       "  )},\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x768ad2f304a0>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Save the data\n",
    "save_to_pickle(list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader, filename='pickle/NN_data2_undersampling.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd7c930",
   "metadata": {},
   "source": [
    "# Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b5b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Load the data\n",
    "list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader = load_from_pickle(filename='pickle/NN_data2_undersampling.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d9c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275941a6",
   "metadata": {},
   "source": [
    "### Ensemble prediction using voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586c430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a single ensemble from 165 models across all folds.\n",
      "Extracting full dataset...\n",
      "Getting predictions from all models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Loop through all the FPR values to generate the ensemble ROC curve ---\n",
    "\n",
    "\n",
    "\n",
    "results_tuple = predict_ensemble_and_evaluate(list_folds_best_models=list_folds_best_models,\n",
    "    test_loader=test_loader)\n",
    "\n",
    "ensemble_results_soft = results_tuple['soft_voting']\n",
    "ensemble_results_hard = results_tuple['hard_voting']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae1a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Plotting all ROC curves for comparison ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "results_lists.append(ensemble_results_soft)\n",
    "results_lists.append(ensemble_results_hard)\n",
    "\n",
    "\n",
    "# --- Plot the final comparison ---\n",
    "print(\"\\n--- Plotting all ROC curves for comparison ---\")\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\", \"Ensemble_voting_soft\", \"Ensemble_voting_hard\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54a198",
   "metadata": {},
   "source": [
    "## Check performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ba0e7",
   "metadata": {},
   "source": [
    "## Check performance on test1 and test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f504bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_performance_tester(classifier_list, test_loader):\n",
    "\n",
    "    list_weighted_clfs = []  # Reset the list for final testing\n",
    "    for i, model_info in enumerate(classifier_list):\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "\n",
    "        model = model_info[\"model\"]\n",
    "        raw_threshold = model_info[\"threshold\"]\n",
    "\n",
    "\n",
    "        # CORRECTED: Use isinstance() to check if model is a string\n",
    "        if isinstance(model, str):\n",
    "            print(f\"Skipping model {i+1} as it is a string placeholder: '{model}'\")\n",
    "            continue\n",
    "\n",
    "        # Check if the stored threshold is a NumPy number or a PyTorch Tensor\n",
    "        if isinstance(raw_threshold, (np.number, torch.Tensor)):\n",
    "            # If it is, we can safely call .item() to extract the Python float\n",
    "            threshold = raw_threshold.item()\n",
    "        else:\n",
    "            # Otherwise, it's already a float or something that can be cast to one\n",
    "            threshold = float(raw_threshold)\n",
    "        model.current_test_threshold = threshold  # Set the threshold for this model\n",
    "\n",
    "        # This code will now only run if 'model' is a PyTorch Lightning module\n",
    "        # and not a string.\n",
    "        print(f\"--- Testing model {i+1} ---\")\n",
    "\n",
    "        trainer.test(model, dataloaders=test_loader, ckpt_path=None)\n",
    "        \n",
    "        results_classifier = model.last_test_results.copy()\n",
    "        current_model = {\n",
    "            \"model\": model,\n",
    "            \"fpr\": results_classifier[\"fpr\"],\n",
    "            \"tpr\": results_classifier[\"tpr\"],\n",
    "            \"threshold\": results_classifier[\"threshold\"],\n",
    "            \"full_roc\": results_classifier[\"full_roc\"]\n",
    "        }\n",
    "        list_weighted_clfs.append(current_model)\n",
    "\n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not list_weighted_clfs or list_weighted_clfs[0]['fpr'] > 0.0:\n",
    "        list_weighted_clfs.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if list_weighted_clfs[-1]['fpr'] < 1.0 or list_weighted_clfs[-1]['tpr'] < 1.0:\n",
    "        list_weighted_clfs.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return list_weighted_clfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLlabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
