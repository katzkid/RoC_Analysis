{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b31b88",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc819711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d840881",
   "metadata": {},
   "source": [
    "## Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c24af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for displaying ROC curves of multiple classifiers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_connected_points(results_list, results_original_roc, name=\"All Classifiers\"):\n",
    "    \"\"\"\n",
    "    Creates a plot showing the performance of all classifiers as points,\n",
    "    and connects them with a line, sorted by FPR.\n",
    "\n",
    "    Args:\n",
    "        results_list: A list of dictionaries, where each dict contains 'fpr', 'tpr'.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    # Convert results to a pandas DataFrame for easy sorting\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Sort the models by their False Positive Rate to create a left-to-right line\n",
    "    df_sorted = df.sort_values(by=['fpr','tpr']).reset_index(drop=True)\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot all the individual model points as a scatter plot\n",
    "    # This helps see the actual performance of each model\n",
    "    plt.scatter(df_sorted['fpr'], df_sorted['tpr'], c='black', marker='o', \n",
    "                alpha=0.6, s=100, zorder=3) # zorder=3 puts dots on top\n",
    "\n",
    "    # Plot the line connecting the points\n",
    "    plt.plot(df_sorted['fpr'], df_sorted['tpr'], color='red', lw=1.5,\n",
    "             alpha=0.8, label=f'{name} (AUC = {auc(df_sorted[\"fpr\"], df_sorted[\"tpr\"]):.2f})')\n",
    "    \n",
    "    #plot the original ROC curve\n",
    "    plt.plot(results_original_roc[\"fpr\"], results_original_roc[\"tpr\"], color='blue', \n",
    "             label=f'{results_original_roc[\"name\"]} (AUC = {results_original_roc[\"auc\"]:.2f})')\n",
    "\n",
    "    # Plot the \"no-skill\" line for reference\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Performance Path of All Trained Classifiers')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9508c52",
   "metadata": {},
   "source": [
    "## Best ROC envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "535c203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def get_best_roc_envelope(results_list, results_original_roc=None):\n",
    "    \"\"\"\n",
    "    Constructs the upper envelope of multiple ROC curves to find the best\n",
    "    possible operating points from a collection of classifiers.\n",
    "\n",
    "    This function is guaranteed to produce a list of points that starts at\n",
    "    (FPR=0, TPR=0) and ends at (FPR=1, TPR=1), making it suitable for direct\n",
    "    plotting and AUC calculation.\n",
    "\n",
    "    Args:\n",
    "        results_list (list): A list of dictionaries. Each dictionary must\n",
    "                             contain a 'model' name and the full ROC results\n",
    "                             under the 'full_roc' key.\n",
    "        results_original_roc (dict, optional): A dictionary containing the\n",
    "                                               ROC results of a baseline model,\n",
    "                                               which will also be included in\n",
    "                                               the comparison. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of dictionaries representing the optimal ROC\n",
    "              envelope. Each dictionary includes 'model', 'fpr', 'tpr',\n",
    "              and 'threshold'.\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "\n",
    "    # Step 1: Gather all ROC points from all provided models\n",
    "    all_results = results_list[:]\n",
    "    if results_original_roc:\n",
    "        all_results.append({\n",
    "            'model': 'original_baseline',\n",
    "            'full_roc': results_original_roc\n",
    "        })\n",
    "\n",
    "    for result in all_results:\n",
    "        model_name = result.get('model', 'Unknown Model')\n",
    "        roc = result.get('full_roc')\n",
    "        if not roc: continue\n",
    "\n",
    "        fprs = roc.get('fpr', [])\n",
    "        tprs = roc.get('tpr', [])\n",
    "        thresholds = roc.get('thresholds', [])\n",
    "\n",
    "        for i in range(len(fprs)):\n",
    "            threshold = thresholds[i] if i < len(thresholds) else thresholds[-1]\n",
    "            all_points.append({\n",
    "                'model': model_name, 'fpr': fprs[i],\n",
    "                'tpr': tprs[i], 'threshold': threshold\n",
    "            })\n",
    "\n",
    "    # Handle case with no data by returning a default diagonal line\n",
    "    if not all_points:\n",
    "        return [\n",
    "            {'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf},\n",
    "            {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}\n",
    "        ]\n",
    "\n",
    "    # Step 2: Sort all points by FPR (asc), then by TPR (desc)\n",
    "    all_points.sort(key=lambda p: (p['fpr'], -p['tpr']))\n",
    "\n",
    "    # Step 3: Build the core ROC envelope\n",
    "    best_roc_envelope = []\n",
    "    max_tpr_so_far = -1.0\n",
    "    for point in all_points:\n",
    "        # Add a point only if it has a strictly higher TPR\n",
    "        if point['tpr'] > max_tpr_so_far:\n",
    "            # To prevent adding multiple points at the same FPR, check if the last point\n",
    "            # has the same FPR and replace it if so (since this one has a higher TPR)\n",
    "            if best_roc_envelope and best_roc_envelope[-1]['fpr'] == point['fpr']:\n",
    "                best_roc_envelope[-1] = point\n",
    "            else:\n",
    "                best_roc_envelope.append(point)\n",
    "            max_tpr_so_far = point['tpr']\n",
    "    \n",
    "    # Step 4: Manually add extremities if they are missing\n",
    "    \n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not best_roc_envelope or best_roc_envelope[0]['fpr'] > 0.0:\n",
    "        best_roc_envelope.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if best_roc_envelope[-1]['fpr'] < 1.0 or best_roc_envelope[-1]['tpr'] < 1.0:\n",
    "        best_roc_envelope.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return best_roc_envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b781e9",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8c3deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_data(dataset):\n",
    "    if dataset == \"data1\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [0, 2], [2, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "    elif dataset == \"data2\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [1, 2], [1, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    elif dataset == \"pneumoniaMNIST\":\n",
    "        import medmnist\n",
    "        print(medmnist.__version__)\n",
    "        # read in the PneumoniaMNIST dataset\n",
    "        from medmnist import PneumoniaMNIST\n",
    "        train_data = PneumoniaMNIST(split='train', download=True, size=224)\n",
    "        test_data = PneumoniaMNIST(split='test', download=True, size=224)\n",
    "        val_data = PneumoniaMNIST(split='val', download=True, size=224)\n",
    "        # print the dataset info\n",
    "        print(f\"Number of training samples: {len(train_data)}\")\n",
    "        print(f\"Number of test samples: {len(test_data)}\")\n",
    "        print(f\"Number of validation samples: {len(val_data)}\")\n",
    "\n",
    "    elif dataset == \"breast_cancer\":\n",
    "        from ucimlrepo import fetch_ucirepo\n",
    "        from sklearn.compose import ColumnTransformer\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        # Fetch and print columns for the dataset your code is using\n",
    "\n",
    "        # 1. Fetch data for Breast Cancer (ID 15)\n",
    "        bc = fetch_ucirepo(id=14)\n",
    "        X_df, y_df = bc.data.features, bc.data.targets\n",
    "\n",
    "        # 2. Replace '?' with a standard missing value format\n",
    "        X_df = X_df.replace('?', np.nan)\n",
    "\n",
    "        # 3. Encode the target variable\n",
    "        y = LabelEncoder().fit_transform(y_df.to_numpy().ravel())\n",
    "\n",
    "        # 4. Define column lists using the correct names for this dataset\n",
    "        #categorical_features = ['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'breast', 'breast-quad', 'irradiat']\n",
    "        categorical_features = ['menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'breast', 'breast-quad', 'irradiat']\n",
    "        numeric_features = ['deg-malig']\n",
    "\n",
    "        # 5. Create preprocessing pipelines\n",
    "        numeric_pipeline = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        categorical_pipeline = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        # 6. Build the master preprocessor\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_pipeline, numeric_features),\n",
    "                ('cat', categorical_pipeline, categorical_features)\n",
    "            ])\n",
    "\n",
    "        # 7. Apply the transformations\n",
    "        X_sparse = preprocessor.fit_transform(X_df)\n",
    "\n",
    "        X = X_sparse.toarray()\n",
    "\n",
    "        # --- CRITICAL DEBUGGING STEP ---\n",
    "        print(f\"Shape of X after preprocessing: {X.shape}\")\n",
    "        # This MUST print a shape like (286, 46). If it prints (286, 0), the preprocessor failed.\n",
    "        # -----------------------------\n",
    "\n",
    "        # 8. Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, train_size=0.7, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "        y_train = y_train.reshape(-1, 1) if len(y_train.shape) == 1 else y_train\n",
    "        y_test = y_test.reshape(-1, 1) if len(y_test.shape) == 1 else y_test\n",
    "\n",
    "\n",
    "        # 9. Concatenate the data\n",
    "        train_data = np.concatenate((X_train, y_train), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test), axis=1)\n",
    "        val_data = test_data  # For simplicity, using test data as validation data\n",
    "\n",
    "        print(f\"Shape of training data: {train_data.shape}\")\n",
    "        print(f\"Shape of test data: {test_data.shape}\")\n",
    "\n",
    "        print(\"\\nData successfully processed and concatenated.\")\n",
    "        print(f\"Shape of final training data: {train_data.shape}\")\n",
    "\n",
    "\n",
    "    return train_data, test_data, val_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bfe355",
   "metadata": {},
   "source": [
    "## Calculate Statistics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af73be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_fpr_tpr(clf_model, X_test, y_test, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculates the False Positive Rate (FPR) and True Positive Rate (TPR) at a given threshold.\n",
    "\n",
    "    Args:\n",
    "        X_test: The test features.\n",
    "        y_test: The true test labels (0 or 1).\n",
    "        threshold: The probability threshold.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the FPR and TPR. Returns None if there's an error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y_prob = clf_model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  #Avoid division by zero\n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0 #Avoid division by zero\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        misclassification_rate = 1 - accuracy\n",
    "\n",
    "        return {\"fpr\": fpr, \"tpr\": tpr, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy, \"misclassification_rate\": misclassification_rate}\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error calculating FPR and TPR: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be8897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 4\n",
    "K_FOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59034e",
   "metadata": {},
   "source": [
    "## Data1: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a060ccc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after preprocessing: (286, 33)\n",
      "Training data shape: (200, 33), (200,)\n",
      "Test data shape: (86, 33), (86,)\n",
      "Shape of training data: (200, 34)\n",
      "Shape of test data: (86, 34)\n",
      "\n",
      "Data successfully processed and concatenated.\n",
      "Shape of final training data: (200, 34)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "train_data, test_data, val_data = generate_data(\"breast_cancer\")  # Change to \"data1\", \"data2\", \"pneumoniaMNIST\" or \"ionosphere\" as needed\n",
    "\n",
    "\n",
    "train_data_tensor = data.TensorDataset(torch.tensor(train_data[:, :-1], dtype=torch.float32),\n",
    "                                        torch.tensor(train_data[:, -1], dtype=torch.float32))\n",
    "train_loader = data.DataLoader(train_data_tensor, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) #over-write later for k-fold cross-validation\n",
    "test_data_tensor = data.TensorDataset(torch.tensor(test_data[:, :-1], dtype=torch.float32),\n",
    "                                       torch.tensor(test_data[:, -1], dtype=torch.float32))\n",
    "test_loader = data.DataLoader(test_data_tensor, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# initialize fold\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a602762",
   "metadata": {},
   "source": [
    "### Regular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cb33b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# Logistic Regression\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]\n",
    "clf = LogisticRegression(fit_intercept=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#calculate ROC results\n",
    "fpr_roc, tpr_roc, threshold_roc = roc_curve(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "results_original_roc = {\"fpr\": fpr_roc, \"tpr\": tpr_roc, \"thresholds\": threshold_roc, \"name\": \"Logistic Regression\", \"auc\": auc(fpr_roc, tpr_roc), \"model\": clf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6615c53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x725f066427b0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(fpr_roc, tpr_roc, label='Logistic Regression (AUC = {:.2f})'.format(auc(fpr_roc, tpr_roc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6b01cb",
   "metadata": {},
   "source": [
    "## Weighted ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d23d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 1/4 ---\n",
      "--- Starting Fold 2/4 ---\n",
      "--- Starting Fold 3/4 ---\n",
      "--- Starting Fold 4/4 ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#store the weighted classifiers of all the folds\n",
    "list_folds_weighted_clfs = []  # List to store classifiers from all folds\n",
    "#store the best classfiers of all the folds \n",
    "list_folds_best_models = []  # List to store best models from all folds\n",
    "# Weight the X_train and y_train for cost-sensitive learning\n",
    "minority_class_weight = np.arange(0.001, 0.999, 0.01)\n",
    "majority_class_weight = 1.0 - minority_class_weight\n",
    "list_weighted_clfs = []\n",
    "\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data[:, :-1], train_data[:, -1])):\n",
    "    list_weighted_clfs = [] # List to store the models trained at each stage\n",
    "    best_clfs = [] # List to store the best models from each stage\n",
    "    \n",
    "\n",
    "    print(f\"--- Starting Fold {fold + 1}/{K_FOLDS} ---\")\n",
    "    X_train_fold = train_data[train_ids][:, :-1]\n",
    "    y_train_fold = train_data[train_ids][:, -1]\n",
    "    X_test_fold = train_data[val_ids][:, :-1]\n",
    "    y_test_fold = train_data[val_ids][:, -1]\n",
    "    for w in minority_class_weight:\n",
    "        class_weights = {0: 1 - w, 1: w}\n",
    "\n",
    "        clf_weighted = LogisticRegression(fit_intercept=True, class_weight=class_weights)\n",
    "        clf_weighted.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        res = get_fpr_tpr(clf_weighted, X_test_fold, y_test_fold, threshold=0.5)\n",
    "\n",
    "        array_of_all_fprs, array_of_all_tprs, threshold_vals = roc_curve(y_test_fold, clf_weighted.predict_proba(X_test_fold)[:, 1])\n",
    "\n",
    "        current_result = {\n",
    "            \"model\": clf_weighted,\n",
    "            \"fpr\": res[\"fpr\"],\n",
    "            \"tpr\": res[\"tpr\"],\n",
    "            \"threshold\": 0.5,\n",
    "            \"full_roc\": {\"fpr\": array_of_all_fprs, \"tpr\": array_of_all_tprs, \"thresholds\": threshold_vals},\n",
    "        }\n",
    "        list_weighted_clfs.append(current_result)\n",
    "    best_clfs = get_best_roc_envelope(list_weighted_clfs, results_original_roc)\n",
    "    list_folds_weighted_clfs.append(list_weighted_clfs)\n",
    "    list_folds_best_models.append(best_clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5f6037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to pickle/Logistic_BreastCancer_weighted.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_models': [[{'model': LogisticRegression(class_weight={0: np.float64(0.08900000000000019),\n",
       "                                     1: np.float64(0.9109999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.38461538461538464),\n",
       "    'threshold': np.float64(0.9006839547483418)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.08900000000000019),\n",
       "                                     1: np.float64(0.9109999999999998)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.46153846153846156),\n",
       "    'threshold': np.float64(0.8923526717007904)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.05405405405405406),\n",
       "    'tpr': np.float64(0.7692307692307693),\n",
       "    'threshold': np.float64(0.0005097332311330169)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.10810810810810811),\n",
       "    'tpr': np.float64(0.8461538461538461),\n",
       "    'threshold': np.float64(0.0004994173480528745)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.989), 1: np.float64(0.011)}),\n",
       "    'fpr': np.float64(0.21621621621621623),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': np.float64(0.0052941044996306155)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3690000000000001),\n",
       "                                     1: np.float64(0.6309999999999999)}),\n",
       "    'fpr': np.float64(0.7567567567567568),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': np.float64(0.23311931199929498)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': np.float64(0.00044166704879418573)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.03333333333333333),\n",
       "    'tpr': np.float64(0.19230769230769232),\n",
       "    'threshold': np.float64(0.6863271338898213)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.05),\n",
       "    'tpr': np.float64(0.23076923076923078),\n",
       "    'threshold': np.float64(0.6563366086730571)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.08333333333333333),\n",
       "    'tpr': np.float64(0.2692307692307692),\n",
       "    'threshold': np.float64(0.5699074833016486)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.979),\n",
       "                                     1: np.float64(0.020999999999999998)}),\n",
       "    'fpr': np.float64(0.09375),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': np.float64(0.014042376532422667)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.11666666666666667),\n",
       "    'tpr': np.float64(0.34615384615384615),\n",
       "    'threshold': np.float64(0.536286881448389)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.15),\n",
       "    'tpr': np.float64(0.38461538461538464),\n",
       "    'threshold': np.float64(0.4771835098758897)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.15625),\n",
       "    'tpr': np.float64(0.3888888888888889),\n",
       "    'threshold': np.float64(0.00041346057139625024)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.21666666666666667),\n",
       "    'tpr': np.float64(0.4230769230769231),\n",
       "    'threshold': np.float64(0.3846742894389957)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.23333333333333334),\n",
       "    'tpr': np.float64(0.46153846153846156),\n",
       "    'threshold': np.float64(0.37444519163528606)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': np.float64(0.35595507671897847)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.34375),\n",
       "    'tpr': np.float64(0.5555555555555556),\n",
       "    'threshold': np.float64(0.00040363983724583854)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.375),\n",
       "    'tpr': np.float64(0.6111111111111112),\n",
       "    'threshold': np.float64(0.00040328281519206704)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.4),\n",
       "    'tpr': np.float64(0.6538461538461539),\n",
       "    'threshold': np.float64(0.24946802438159524)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.43333333333333335),\n",
       "    'tpr': np.float64(0.6923076923076923),\n",
       "    'threshold': np.float64(0.23780847289078658)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.029000000000000137),\n",
       "                                     1: np.float64(0.9709999999999999)}),\n",
       "    'fpr': np.float64(0.4375),\n",
       "    'tpr': np.float64(0.7222222222222222),\n",
       "    'threshold': np.float64(0.8928943252898521)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.48333333333333334),\n",
       "    'tpr': np.float64(0.7307692307692307),\n",
       "    'threshold': np.float64(0.2239808744600477)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.929), 1: np.float64(0.071)}),\n",
       "    'fpr': np.float64(0.53125),\n",
       "    'tpr': np.float64(0.7777777777777778),\n",
       "    'threshold': np.float64(0.01811097336854023)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.5333333333333333),\n",
       "    'tpr': np.float64(0.8076923076923077),\n",
       "    'threshold': np.float64(0.1972600004889744)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.55),\n",
       "    'tpr': np.float64(0.8461538461538461),\n",
       "    'threshold': np.float64(0.18399211007791166)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.7),\n",
       "    'tpr': np.float64(0.8846153846153846),\n",
       "    'threshold': np.float64(0.140271110570612)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.7166666666666667),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': np.float64(0.13151769546321562)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.029000000000000137),\n",
       "                                     1: np.float64(0.9709999999999999)}),\n",
       "    'fpr': np.float64(0.75),\n",
       "    'tpr': np.float64(0.9444444444444444),\n",
       "    'threshold': np.float64(0.8183831439936529)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.7666666666666667),\n",
       "    'tpr': np.float64(0.9615384615384616),\n",
       "    'threshold': np.float64(0.09721290089750874)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.8333333333333334),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': np.float64(0.08989054699992374)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': np.float64(0.00045898147202544956)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.08333333333333333),\n",
       "    'tpr': np.float64(0.2692307692307692),\n",
       "    'threshold': np.float64(0.5699074833016486)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.08823529411764706),\n",
       "    'tpr': np.float64(0.4375),\n",
       "    'threshold': np.float64(0.0004445826760383338)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.20588235294117646),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': np.float64(0.0004392747229092236)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.2647058823529412),\n",
       "    'tpr': np.float64(0.5625),\n",
       "    'threshold': np.float64(0.00043608944135230346)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.979),\n",
       "                                     1: np.float64(0.020999999999999998)}),\n",
       "    'fpr': np.float64(0.29411764705882354),\n",
       "    'tpr': np.float64(0.625),\n",
       "    'threshold': np.float64(0.012497742095610553)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.969),\n",
       "                                     1: np.float64(0.030999999999999996)}),\n",
       "    'fpr': np.float64(0.3235294117647059),\n",
       "    'tpr': np.float64(0.6875),\n",
       "    'threshold': np.float64(0.019650802182225667)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.43333333333333335),\n",
       "    'tpr': np.float64(0.6923076923076923),\n",
       "    'threshold': np.float64(0.23780847289078658)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.48333333333333334),\n",
       "    'tpr': np.float64(0.7307692307692307),\n",
       "    'threshold': np.float64(0.2239808744600477)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4990000000000001),\n",
       "                                     1: np.float64(0.5009999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': np.float64(0.2664128191683055)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.5333333333333333),\n",
       "    'tpr': np.float64(0.8076923076923077),\n",
       "    'threshold': np.float64(0.1972600004889744)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.55),\n",
       "    'tpr': np.float64(0.8461538461538461),\n",
       "    'threshold': np.float64(0.18399211007791166)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.7),\n",
       "    'tpr': np.float64(0.8846153846153846),\n",
       "    'threshold': np.float64(0.140271110570612)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.7166666666666667),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': np.float64(0.13151769546321562)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.7666666666666667),\n",
       "    'tpr': np.float64(0.9615384615384616),\n",
       "    'threshold': np.float64(0.09721290089750874)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.06900000000000017),\n",
       "                                     1: np.float64(0.9309999999999998)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': np.float64(0.5658498985994914)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LogisticRegression(class_weight={0: np.float64(0.909),\n",
       "                                     1: np.float64(0.09099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': np.float64(0.13822133979863946)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.959),\n",
       "                                     1: np.float64(0.040999999999999995)}),\n",
       "    'fpr': np.float64(0.02631578947368421),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': np.float64(0.04820540154359493)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.03333333333333333),\n",
       "    'tpr': np.float64(0.19230769230769232),\n",
       "    'threshold': np.float64(0.6863271338898213)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.05),\n",
       "    'tpr': np.float64(0.23076923076923078),\n",
       "    'threshold': np.float64(0.6563366086730571)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7290000000000001),\n",
       "                                     1: np.float64(0.27099999999999996)}),\n",
       "    'fpr': np.float64(0.05263157894736842),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': np.float64(0.2994368164417947)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.07900000000000018),\n",
       "                                     1: np.float64(0.9209999999999998)}),\n",
       "    'fpr': np.float64(0.07894736842105263),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': np.float64(0.888533942215706)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.029000000000000137),\n",
       "                                     1: np.float64(0.9709999999999999)}),\n",
       "    'fpr': np.float64(0.18421052631578946),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': np.float64(0.9415284603261269)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': np.float64(0.00047029026498053334)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.929), 1: np.float64(0.071)}),\n",
       "    'fpr': np.float64(0.2894736842105263),\n",
       "    'tpr': np.float64(0.6666666666666666),\n",
       "    'threshold': np.float64(0.026009993026656148)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.43333333333333335),\n",
       "    'tpr': np.float64(0.6923076923076923),\n",
       "    'threshold': np.float64(0.23780847289078658)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.989), 1: np.float64(0.011)}),\n",
       "    'fpr': np.float64(0.4473684210526316),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': np.float64(0.004494876752710188)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.5333333333333333),\n",
       "    'tpr': np.float64(0.8076923076923077),\n",
       "    'threshold': np.float64(0.1972600004889744)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.55),\n",
       "    'tpr': np.float64(0.8461538461538461),\n",
       "    'threshold': np.float64(0.18399211007791166)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.7),\n",
       "    'tpr': np.float64(0.8846153846153846),\n",
       "    'threshold': np.float64(0.140271110570612)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.659),\n",
       "                                     1: np.float64(0.34099999999999997)}),\n",
       "    'fpr': np.float64(0.7105263157894737),\n",
       "    'tpr': np.float64(0.9166666666666666),\n",
       "    'threshold': np.float64(0.04787301300021645)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.7166666666666667),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': np.float64(0.13151769546321562)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.20900000000000007),\n",
       "                                     1: np.float64(0.7909999999999999)}),\n",
       "    'fpr': np.float64(0.7631578947368421),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': np.float64(0.23376045960024916)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}]],\n",
       " 'weighted_clfs': [[{'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.18918919, 0.24324324, 0.24324324, 0.94594595, 0.94594595,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.38461538,\n",
       "            0.38461538, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.00053503, 0.00052589, 0.00052483, 0.00052195,\n",
       "            0.00051998, 0.00050973, 0.0004997 , 0.00049942, 0.00049917,\n",
       "            0.00049833, 0.00049597, 0.00049512, 0.00047009, 0.00046888,\n",
       "            0.00046715])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.989), 1: np.float64(0.011)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.13513514, 0.13513514, 0.18918919,\n",
       "            0.21621622, 0.21621622, 0.94594595, 0.94594595, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.38461538,\n",
       "            0.38461538, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.00808354, 0.00761813, 0.00743614, 0.00716109,\n",
       "            0.00708332, 0.00626978, 0.0056389 , 0.00563516, 0.00561291,\n",
       "            0.00549814, 0.0052941 , 0.00362416, 0.00355024, 0.00352896])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.979),\n",
       "                                     1: np.float64(0.020999999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.13513514, 0.13513514, 0.18918919,\n",
       "            0.24324324, 0.24324324, 0.94594595, 0.94594595, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.38461538,\n",
       "            0.38461538, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.01936525, 0.01810374, 0.01743536, 0.01618447,\n",
       "            0.01609324, 0.01310013, 0.01167409, 0.01130123, 0.0112263 ,\n",
       "            0.01014982, 0.01014173, 0.00592871, 0.0057148 , 0.00565788])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.969),\n",
       "                                     1: np.float64(0.030999999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.13513514, 0.13513514, 0.18918919,\n",
       "            0.24324324, 0.24324324, 0.94594595, 0.94594595, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.03281747, 0.03075362, 0.02942546, 0.02878581,\n",
       "            0.02647677, 0.02019643, 0.01821533, 0.01710504, 0.01698851,\n",
       "            0.01506501, 0.01482344, 0.00787541, 0.00750598, 0.00742486])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.959),\n",
       "                                     1: np.float64(0.040999999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.13513514, 0.13513514, 0.18918919, 0.24324324, 0.24324324,\n",
       "            0.94594595, 0.94594595, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.04742987, 0.04310222, 0.03824898, 0.02739656,\n",
       "            0.0247178 , 0.02296673, 0.02289196, 0.02007098, 0.01935935,\n",
       "            0.0095686 , 0.00918789, 0.00904228])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9490000000000001),\n",
       "                                     1: np.float64(0.05099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.13513514, 0.13513514, 0.18918919, 0.24324324, 0.24324324,\n",
       "            0.94594595, 0.94594595, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.06193638, 0.05675398, 0.05010665, 0.03443398,\n",
       "            0.03121524, 0.02866055, 0.02865129, 0.02496783, 0.02366302,\n",
       "            0.0112225 , 0.01077891, 0.01054422])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9390000000000001),\n",
       "                                     1: np.float64(0.06099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.13513514, 0.18918919, 0.18918919,\n",
       "            0.24324324, 0.24324324, 0.94594595, 0.94594595, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.07690338, 0.07468604, 0.06999022, 0.06966593,\n",
       "            0.06345623, 0.04162542, 0.03774695, 0.03484306, 0.03433944,\n",
       "            0.03014305, 0.02843402, 0.01282137, 0.0124952 , 0.01206914])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.929), 1: np.float64(0.071)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.18918919, 0.18918919, 0.27027027, 0.27027027, 0.94594595,\n",
       "            0.94594595, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.61538462, 0.61538462, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.09208413, 0.09099827, 0.08400784, 0.0819871 ,\n",
       "            0.07626067, 0.05325823, 0.05003254, 0.04873516, 0.04427195,\n",
       "            0.04075038, 0.04009513, 0.03304233, 0.03253769, 0.01436702,\n",
       "            0.01416458, 0.0136006 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.919),\n",
       "                                     1: np.float64(0.08099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.18918919, 0.18918919, 0.2972973 , 0.2972973 , 0.94594595,\n",
       "            0.94594595, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.61538462, 0.61538462, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.10896069, 0.1053442 , 0.098098  , 0.09447721,\n",
       "            0.08871614, 0.06152172, 0.0584563 , 0.05532003, 0.05096369,\n",
       "            0.04691125, 0.04564091, 0.03738128, 0.0368323 , 0.01591418,\n",
       "            0.01570753, 0.0149918 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.909),\n",
       "                                     1: np.float64(0.09099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.18918919, 0.18918919, 0.32432432, 0.32432432, 0.91891892,\n",
       "            0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.61538462, 0.61538462, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.12707311, 0.11878969, 0.11069265, 0.10573397,\n",
       "            0.10226833, 0.06966214, 0.0674754 , 0.06204188, 0.05711629,\n",
       "            0.0527202 , 0.05088395, 0.04122375, 0.04113623, 0.02122086,\n",
       "            0.0175193 , 0.01652812])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.899),\n",
       "                                     1: np.float64(0.10099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.18918919, 0.18918919, 0.32432432,\n",
       "            0.32432432, 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.61538462, 0.61538462, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.14558471, 0.13261559, 0.12414393, 0.1172595 ,\n",
       "            0.11599873, 0.07823112, 0.0767806 , 0.06949377, 0.06919298,\n",
       "            0.06862264, 0.06370436, 0.05886459, 0.05641784, 0.04615773,\n",
       "            0.04546778, 0.02319771, 0.01913845, 0.01780716])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.889),\n",
       "                                     1: np.float64(0.11099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.18918919, 0.18918919, 0.32432432, 0.32432432, 0.91891892,\n",
       "            0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.61538462,\n",
       "            0.61538462, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.16419178, 0.14496113, 0.1290073 , 0.08666274,\n",
       "            0.08646593, 0.07648147, 0.07644189, 0.07504142, 0.06994066,\n",
       "            0.06490132, 0.06172466, 0.05123744, 0.04976561, 0.02536981,\n",
       "            0.02098857, 0.01919507])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.879),\n",
       "                                     1: np.float64(0.12099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.18918919, 0.18918919, 0.32432432, 0.32432432, 0.91891892,\n",
       "            0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.53846154,\n",
       "            0.53846154, 0.61538462, 0.61538462, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.18294543, 0.15684583, 0.14196359, 0.09661189,\n",
       "            0.09652786, 0.09540137, 0.08393894, 0.08175048, 0.07626984,\n",
       "            0.07124298, 0.0672559 , 0.05647843, 0.05427734, 0.02756474,\n",
       "            0.022877  , 0.02054125])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.869),\n",
       "                                     1: np.float64(0.13099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.18918919, 0.18918919, 0.32432432, 0.32432432, 0.91891892,\n",
       "            0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.46153846,\n",
       "            0.46153846, 0.61538462, 0.61538462, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.20053034, 0.16901226, 0.15495682, 0.10709888,\n",
       "            0.10631937, 0.10420537, 0.09157802, 0.08836615, 0.08284483,\n",
       "            0.07784058, 0.07269136, 0.06097016, 0.05892851, 0.02983063,\n",
       "            0.02485518, 0.02206295])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.859), 1: np.float64(0.141)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.18918919, 0.21621622, 0.21621622, 0.32432432, 0.32432432,\n",
       "            0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.38461538,\n",
       "            0.38461538, 0.61538462, 0.61538462, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.21950786, 0.18113947, 0.1686602 , 0.12735776,\n",
       "            0.1163024 , 0.11163317, 0.09832845, 0.0945812 , 0.08877878,\n",
       "            0.08348902, 0.07866251, 0.07738727, 0.06458105, 0.06298716,\n",
       "            0.03186769, 0.02671357, 0.02335437])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.849),\n",
       "                                     1: np.float64(0.15099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.18918919, 0.21621622, 0.21621622, 0.32432432, 0.32432432,\n",
       "            0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.38461538,\n",
       "            0.38461538, 0.61538462, 0.61538462, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.23771513, 0.19296281, 0.18189932, 0.13503568,\n",
       "            0.1268447 , 0.11925712, 0.1059106 , 0.10104807, 0.09534914,\n",
       "            0.08994484, 0.08636305, 0.08279018, 0.06885313, 0.06751433,\n",
       "            0.03423723, 0.0288131 , 0.0248552 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.839),\n",
       "                                     1: np.float64(0.16099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.18918919, 0.21621622, 0.21621622, 0.32432432, 0.32432432,\n",
       "            0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.38461538,\n",
       "            0.38461538, 0.61538462, 0.61538462, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.25639768, 0.20318994, 0.19214874, 0.1413161 ,\n",
       "            0.13743407, 0.1265627 , 0.11289533, 0.10793202, 0.10093596,\n",
       "            0.09613726, 0.09386594, 0.08758025, 0.07261794, 0.07204699,\n",
       "            0.03645458, 0.0309833 , 0.02619699])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.829),\n",
       "                                     1: np.float64(0.17099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.18918919, 0.21621622, 0.21621622, 0.2972973 , 0.2972973 ,\n",
       "            0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.38461538,\n",
       "            0.38461538, 0.61538462, 0.61538462, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.27345692, 0.21481305, 0.20290157, 0.14865194,\n",
       "            0.14774607, 0.13410808, 0.12023606, 0.11469941, 0.10749398,\n",
       "            0.10248328, 0.10122598, 0.09284844, 0.08203846, 0.07680498,\n",
       "            0.03855412, 0.03309997, 0.0276401 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.8190000000000001),\n",
       "                                     1: np.float64(0.18099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.21621622, 0.21621622, 0.2972973 , 0.2972973 , 0.91891892,\n",
       "            0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.61538462, 0.61538462, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.29068966, 0.22550093, 0.21284877, 0.19514365,\n",
       "            0.15832299, 0.14145612, 0.12744547, 0.12137052, 0.10894783,\n",
       "            0.10882914, 0.09789726, 0.08708395, 0.081457  , 0.04075382,\n",
       "            0.03533383, 0.02908114])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.809),\n",
       "                                     1: np.float64(0.19099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.21621622, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.61538462, 0.61538462, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.3078022 , 0.23540854, 0.22210664, 0.20358856,\n",
       "            0.16903129, 0.1486705 , 0.13433056, 0.12801069, 0.11686967,\n",
       "            0.11529119, 0.10399671, 0.10280865, 0.09198557, 0.08609796,\n",
       "            0.04305864, 0.03776582, 0.03055949])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.799),\n",
       "                                     1: np.float64(0.20099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.21621622, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.61538462, 0.61538462, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.32430306, 0.24654046, 0.23199055, 0.2126608 ,\n",
       "            0.17978864, 0.1562595 , 0.14197678, 0.13474555, 0.12504418,\n",
       "            0.12178778, 0.11047253, 0.10802499, 0.09726002, 0.09090285,\n",
       "            0.04538549, 0.04007016, 0.03201701])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.789),\n",
       "                                     1: np.float64(0.21099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.21621622, 0.24324324, 0.24324324,\n",
       "            0.2972973 , 0.2972973 , 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.34054695, 0.30393792, 0.25763741, 0.25658164,\n",
       "            0.24170033, 0.22172263, 0.19060245, 0.14924256, 0.149002  ,\n",
       "            0.141378  , 0.13221184, 0.12826228, 0.11689386, 0.11313293,\n",
       "            0.10223835, 0.09563929, 0.04748869, 0.04244447, 0.03348752])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.779),\n",
       "                                     1: np.float64(0.22099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.21621622, 0.24324324, 0.24324324,\n",
       "            0.2972973 , 0.2972973 , 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.35653986, 0.3172106 , 0.26966976, 0.26653119,\n",
       "            0.25124654, 0.23073426, 0.20135625, 0.15677807, 0.15645729,\n",
       "            0.1484188 , 0.13859449, 0.13499359, 0.12349947, 0.11834486,\n",
       "            0.10738242, 0.10059117, 0.04986399, 0.04494753, 0.03499947])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.769),\n",
       "                                     1: np.float64(0.23099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.21621622, 0.24324324, 0.24324324,\n",
       "            0.2972973 , 0.2972973 , 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.37171729, 0.33085834, 0.28130041, 0.27687699,\n",
       "            0.25928995, 0.23894765, 0.21224756, 0.16478845, 0.16320964,\n",
       "            0.15537407, 0.14409692, 0.14160952, 0.13037912, 0.12326073,\n",
       "            0.11224385, 0.10557844, 0.05211802, 0.04756659, 0.03648316])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.759),\n",
       "                                     1: np.float64(0.24099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.21621622, 0.24324324, 0.24324324,\n",
       "            0.2972973 , 0.2972973 , 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.38711777, 0.34402939, 0.29367079, 0.28673178,\n",
       "            0.26909812, 0.24831716, 0.22307299, 0.17259908, 0.17056223,\n",
       "            0.16218097, 0.15081896, 0.14809782, 0.13714578, 0.12844706,\n",
       "            0.11740727, 0.11034332, 0.05441843, 0.05008362, 0.03800978])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7490000000000001),\n",
       "                                     1: np.float64(0.25099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.21621622, 0.24324324, 0.24324324,\n",
       "            0.2972973 , 0.2972973 , 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.40147415, 0.35642937, 0.3048928 , 0.29605867,\n",
       "            0.27756808, 0.25655978, 0.23395103, 0.18035409, 0.17762308,\n",
       "            0.16891691, 0.15688485, 0.15475808, 0.14412294, 0.13355624,\n",
       "            0.12255656, 0.11529916, 0.05696396, 0.0529137 , 0.03967078])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7390000000000001),\n",
       "                                     1: np.float64(0.26099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.21621622, 0.24324324, 0.24324324,\n",
       "            0.2972973 , 0.2972973 , 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.41565174, 0.36944692, 0.31712165, 0.30626252,\n",
       "            0.2862364 , 0.26561833, 0.24474169, 0.18891352, 0.18466968,\n",
       "            0.1763683 , 0.16308401, 0.16162487, 0.1511704 , 0.13894147,\n",
       "            0.12746666, 0.12064781, 0.05921122, 0.05570293, 0.04122682])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7290000000000001),\n",
       "                                     1: np.float64(0.27099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.21621622, 0.24324324, 0.24324324,\n",
       "            0.2972973 , 0.2972973 , 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.43073594, 0.38143219, 0.3279825 , 0.31569769,\n",
       "            0.29405305, 0.27386037, 0.25626903, 0.19718239, 0.19195482,\n",
       "            0.18384765, 0.16904887, 0.16856278, 0.15870524, 0.1440295 ,\n",
       "            0.13269877, 0.12590421, 0.06174362, 0.05871699, 0.04281669])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7190000000000001),\n",
       "                                     1: np.float64(0.28099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.24324324, 0.24324324, 0.2972973 ,\n",
       "            0.2972973 , 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.44425336, 0.39389525, 0.33955848, 0.32524771,\n",
       "            0.30217477, 0.2825568 , 0.26696413, 0.20542408, 0.19119277,\n",
       "            0.19115285, 0.17535537, 0.16595096, 0.14910671, 0.13766618,\n",
       "            0.13117524, 0.06396933, 0.06164139, 0.04440047])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7090000000000001),\n",
       "                                     1: np.float64(0.291)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.24324324, 0.24324324, 0.2972973 ,\n",
       "            0.2972973 , 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.45712075, 0.40676279, 0.35081146, 0.33493553,\n",
       "            0.31068403, 0.29117815, 0.27793282, 0.21388369, 0.2000633 ,\n",
       "            0.19804573, 0.18236852, 0.17324476, 0.15452824, 0.14292563,\n",
       "            0.13645163, 0.06608709, 0.06450166, 0.04599535])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6990000000000001),\n",
       "                                     1: np.float64(0.30099999999999993)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.24324324, 0.24324324, 0.2972973 ,\n",
       "            0.2972973 , 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.47061592, 0.41750509, 0.36154842, 0.34396505,\n",
       "            0.31898344, 0.30007689, 0.28895093, 0.22235658, 0.20866413,\n",
       "            0.20574845, 0.1894531 , 0.18094126, 0.15992371, 0.14816722,\n",
       "            0.14187649, 0.06829296, 0.06778225, 0.04778915])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6890000000000001),\n",
       "                                     1: np.float64(0.31099999999999994)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.24324324, 0.24324324, 0.2972973 ,\n",
       "            0.2972973 , 0.89189189, 0.89189189, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.4829823 , 0.43007441, 0.37263681, 0.35379062,\n",
       "            0.32669762, 0.30871793, 0.29964162, 0.23089712, 0.21740241,\n",
       "            0.21300155, 0.19633643, 0.18857262, 0.16504469, 0.15323523,\n",
       "            0.14730096, 0.07172483, 0.07099375, 0.04950784])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.679),\n",
       "                                     1: np.float64(0.32099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.24324324, 0.24324324, 0.2972973 ,\n",
       "            0.2972973 , 0.89189189, 0.89189189, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.49569804, 0.44139906, 0.38385873, 0.36301098,\n",
       "            0.33529174, 0.31785844, 0.31065532, 0.23969491, 0.22610521,\n",
       "            0.22056282, 0.20355892, 0.19624684, 0.17066161, 0.15838425,\n",
       "            0.15278306, 0.07431891, 0.07425967, 0.05125529])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.669),\n",
       "                                     1: np.float64(0.33099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.07692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.27027027, 0.27027027, 0.32432432,\n",
       "            0.32432432, 0.86486486, 0.86486486, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.50790458, 0.45207233, 0.39484304, 0.37173256,\n",
       "            0.34402857, 0.32682438, 0.32163737, 0.24857216, 0.23491775,\n",
       "            0.22790453, 0.210658  , 0.17660123, 0.17643035, 0.15968789,\n",
       "            0.15823926, 0.07932096, 0.0776184 , 0.05310293])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.659),\n",
       "                                     1: np.float64(0.34099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.07692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.27027027, 0.27027027, 0.32432432,\n",
       "            0.32432432, 0.86486486, 0.86486486, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.52002133, 0.46353045, 0.40533217, 0.38109339,\n",
       "            0.35196417, 0.33564845, 0.33249947, 0.25723308, 0.24267202,\n",
       "            0.23557482, 0.21792419, 0.18296621, 0.1817936 , 0.16716529,\n",
       "            0.16395189, 0.0813448 , 0.08099045, 0.05482549])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.649),\n",
       "                                     1: np.float64(0.3509999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.07692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.27027027, 0.27027027, 0.32432432,\n",
       "            0.32432432, 0.83783784, 0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.53206519, 0.47519371, 0.41610993, 0.39072582,\n",
       "            0.35995898, 0.34452521, 0.34374613, 0.26386244, 0.25024721,\n",
       "            0.2432575 , 0.22526855, 0.18972981, 0.18749368, 0.174589  ,\n",
       "            0.16976215, 0.08829255, 0.0844706 , 0.05658945])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.639),\n",
       "                                     1: np.float64(0.36099999999999993)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.07692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.18918919,\n",
       "            0.27027027, 0.27027027, 0.32432432, 0.32432432, 0.83783784,\n",
       "            0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.54272649, 0.48578609, 0.42657055, 0.39955629,\n",
       "            0.35440777, 0.26992665, 0.25766673, 0.25037135, 0.23229135,\n",
       "            0.19603139, 0.19317763, 0.18009205, 0.17526353, 0.0916433 ,\n",
       "            0.08797718, 0.05858263])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.629),\n",
       "                                     1: np.float64(0.37099999999999994)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.07692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.18918919,\n",
       "            0.27027027, 0.27027027, 0.32432432, 0.32432432, 0.83783784,\n",
       "            0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.55241241, 0.49772384, 0.43698661, 0.41005117,\n",
       "            0.3641177 , 0.27672952, 0.26399666, 0.25829472, 0.23977607,\n",
       "            0.20241844, 0.19872697, 0.18480887, 0.18132816, 0.09489341,\n",
       "            0.09171934, 0.06048692])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.619),\n",
       "                                     1: np.float64(0.38099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.18918919,\n",
       "            0.27027027, 0.27027027, 0.32432432, 0.32432432, 0.83783784,\n",
       "            0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.56311278, 0.50790269, 0.44697418, 0.41899162,\n",
       "            0.37482579, 0.28325512, 0.27155868, 0.26594029, 0.24719437,\n",
       "            0.20915929, 0.20455904, 0.19035324, 0.18721341, 0.09841492,\n",
       "            0.09556007, 0.06250359])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.609),\n",
       "                                     1: np.float64(0.39099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.18918919,\n",
       "            0.27027027, 0.27027027, 0.32432432, 0.32432432, 0.83783784,\n",
       "            0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.57432376, 0.51856106, 0.45680712, 0.42835834,\n",
       "            0.38610015, 0.29009738, 0.27892609, 0.27395719, 0.25439924,\n",
       "            0.21615234, 0.21035931, 0.19588627, 0.19300837, 0.10186399,\n",
       "            0.09930479, 0.06438949])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5990000000000001),\n",
       "                                     1: np.float64(0.4009999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.27027027, 0.27027027, 0.35135135,\n",
       "            0.35135135, 0.83783784, 0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.61538462, 0.61538462, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.58419473, 0.52939582, 0.46759759, 0.43772683,\n",
       "            0.39634368, 0.29840386, 0.29701596, 0.29657218, 0.28620778,\n",
       "            0.28171414, 0.26184648, 0.22277695, 0.21647382, 0.19911639,\n",
       "            0.19907152, 0.1055823 , 0.10329859, 0.06655137])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5890000000000001),\n",
       "                                     1: np.float64(0.4109999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.13513514, 0.16216216, 0.21621622, 0.27027027, 0.27027027,\n",
       "            0.32432432, 0.32432432, 0.83783784, 0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.59515446, 0.53913994, 0.47700776, 0.44654643,\n",
       "            0.40709483, 0.31999831, 0.30621113, 0.30356746, 0.29442697,\n",
       "            0.29045231, 0.2704203 , 0.2699957 , 0.23000077, 0.2226147 ,\n",
       "            0.20721759, 0.20560911, 0.10921613, 0.10744495, 0.06860601])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5790000000000001),\n",
       "                                     1: np.float64(0.42099999999999993)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.13513514, 0.16216216, 0.21621622, 0.2972973 , 0.2972973 ,\n",
       "            0.37837838, 0.37837838, 0.83783784, 0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.60512946, 0.54831108, 0.4865146 , 0.45495127,\n",
       "            0.41609387, 0.32803584, 0.31575177, 0.31028983, 0.30234304,\n",
       "            0.29840756, 0.27934416, 0.27789337, 0.23111154, 0.22900689,\n",
       "            0.2120032 , 0.21190996, 0.11257914, 0.11185341, 0.07089677])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5690000000000001),\n",
       "                                     1: np.float64(0.43099999999999994)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.13513514, 0.16216216, 0.21621622, 0.2972973 , 0.2972973 ,\n",
       "            0.37837838, 0.37837838, 0.81081081, 0.81081081, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.61488642, 0.55808897, 0.49634089, 0.46432741,\n",
       "            0.4243835 , 0.33678225, 0.32467322, 0.31727943, 0.31014321,\n",
       "            0.3068179 , 0.28843592, 0.28590541, 0.23953813, 0.23531172,\n",
       "            0.21877873, 0.21834502, 0.11705152, 0.11613215, 0.07310859])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.559),\n",
       "                                     1: np.float64(0.44099999999999995)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.13513514, 0.16216216, 0.21621622, 0.2972973 , 0.2972973 ,\n",
       "            0.35135135, 0.35135135, 0.81081081, 0.81081081, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.62416538, 0.56863422, 0.50568917, 0.47452666,\n",
       "            0.4323021 , 0.34591794, 0.33342504, 0.32407552, 0.31738222,\n",
       "            0.31538483, 0.29734948, 0.29372097, 0.24778   , 0.24145299,\n",
       "            0.22635805, 0.22479515, 0.12090566, 0.1204904 , 0.07537463])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.549),\n",
       "                                     1: np.float64(0.45099999999999996)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.13513514, 0.16216216, 0.21621622, 0.2972973 , 0.2972973 ,\n",
       "            0.35135135, 0.35135135, 0.78378378, 0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.63338231, 0.57808337, 0.51513129, 0.48363672,\n",
       "            0.44048884, 0.35450314, 0.34269513, 0.33086527, 0.32521131,\n",
       "            0.32368111, 0.30652528, 0.30174408, 0.25660619, 0.24795773,\n",
       "            0.23354709, 0.2313475 , 0.14030194, 0.12511083, 0.07780356])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5390000000000001),\n",
       "                                     1: np.float64(0.4609999999999999)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.13513514, 0.16216216, 0.21621622, 0.2972973 , 0.2972973 ,\n",
       "            0.35135135, 0.35135135, 0.78378378, 0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.64185717, 0.58839598, 0.52405389, 0.49275519,\n",
       "            0.44831624, 0.36286781, 0.35236345, 0.33746714, 0.33292638,\n",
       "            0.33141407, 0.31541811, 0.30938462, 0.26571782, 0.25458846,\n",
       "            0.24081435, 0.23774954, 0.14469839, 0.12967385, 0.08026646])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5290000000000001),\n",
       "                                     1: np.float64(0.4709999999999999)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.23076923076923078),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.21621622,\n",
       "            0.2972973 , 0.2972973 , 0.35135135, 0.35135135, 0.78378378,\n",
       "            0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.65070099, 0.59793558, 0.53337329, 0.50234192,\n",
       "            0.46945971, 0.45826075, 0.45698381, 0.37185786, 0.3612937 ,\n",
       "            0.34448905, 0.3408444 , 0.33991619, 0.32461572, 0.31751164,\n",
       "            0.27442316, 0.26125935, 0.24813622, 0.24434682, 0.14861498,\n",
       "            0.13425122, 0.08273086])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5190000000000001),\n",
       "                                     1: np.float64(0.4809999999999999)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.23076923076923078),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.21621622,\n",
       "            0.2972973 , 0.2972973 , 0.35135135, 0.35135135, 0.78378378,\n",
       "            0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.65954448, 0.60711084, 0.54257612, 0.51159022,\n",
       "            0.47979468, 0.46818607, 0.46531851, 0.38074457, 0.3705802 ,\n",
       "            0.35144289, 0.3489033 , 0.34855929, 0.3340919 , 0.32579215,\n",
       "            0.28227383, 0.26808921, 0.2556515 , 0.25121416, 0.15276104,\n",
       "            0.1392076 , 0.08532671])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5090000000000001),\n",
       "                                     1: np.float64(0.49099999999999994)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.23076923076923078),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.21621622, 0.2972973 , 0.2972973 ,\n",
       "            0.35135135, 0.35135135, 0.78378378, 0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.53846154, 0.53846154,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.66805535, 0.61569522, 0.5518299 , 0.5208387 ,\n",
       "            0.49006695, 0.47811886, 0.47373156, 0.38982183, 0.37991748,\n",
       "            0.35735767, 0.34396824, 0.33440091, 0.29009086, 0.27501202,\n",
       "            0.26348712, 0.25835978, 0.15688794, 0.14444598, 0.08809386])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4990000000000001),\n",
       "                                     1: np.float64(0.5009999999999999)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.23076923076923078),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.21621622, 0.2972973 , 0.2972973 ,\n",
       "            0.35135135, 0.35135135, 0.78378378, 0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.53846154, 0.53846154,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.67679832, 0.6256224 , 0.56054345, 0.52999993,\n",
       "            0.4999505 , 0.488329  , 0.48193982, 0.39887805, 0.38900361,\n",
       "            0.36565954, 0.35327749, 0.34277394, 0.29831598, 0.28193687,\n",
       "            0.27085478, 0.26544831, 0.16138172, 0.14953207, 0.09072534])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4890000000000001),\n",
       "                                     1: np.float64(0.5109999999999999)}),\n",
       "    'fpr': np.float64(0.05405405405405406),\n",
       "    'tpr': np.float64(0.23076923076923078),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.21621622,\n",
       "            0.2972973 , 0.2972973 , 0.35135135, 0.35135135, 0.78378378,\n",
       "            0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.68547469, 0.63371772, 0.56990837, 0.53911532,\n",
       "            0.51067408, 0.4984138 , 0.49075055, 0.40805392, 0.39849958,\n",
       "            0.37558691, 0.37404366, 0.37294111, 0.36351258, 0.35150527,\n",
       "            0.30650398, 0.28931547, 0.27886878, 0.27285537, 0.1656452 ,\n",
       "            0.15506938, 0.09365939])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4790000000000001),\n",
       "                                     1: np.float64(0.5209999999999999)}),\n",
       "    'fpr': np.float64(0.05405405405405406),\n",
       "    'tpr': np.float64(0.3076923076923077),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.21621622,\n",
       "            0.2972973 , 0.2972973 , 0.35135135, 0.35135135, 0.78378378,\n",
       "            0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.69423901, 0.64300192, 0.57853193, 0.54836435,\n",
       "            0.52118717, 0.50844294, 0.49894838, 0.41713091, 0.40792628,\n",
       "            0.38474365, 0.38259209, 0.38004268, 0.37326152, 0.36002134,\n",
       "            0.31535453, 0.29668307, 0.28657895, 0.28018193, 0.17027509,\n",
       "            0.16051005, 0.09636234])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4690000000000001),\n",
       "                                     1: np.float64(0.5309999999999999)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.3076923076923077),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.21621622,\n",
       "            0.2972973 , 0.2972973 , 0.35135135, 0.35135135, 0.78378378,\n",
       "            0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.70094392, 0.65362211, 0.58691005, 0.55860144,\n",
       "            0.53005233, 0.51963387, 0.50755642, 0.42700075, 0.41688713,\n",
       "            0.39313821, 0.39041526, 0.38724194, 0.38272494, 0.36806327,\n",
       "            0.32352533, 0.30402957, 0.29477665, 0.28727303, 0.17539755,\n",
       "            0.16585253, 0.09950161])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4590000000000001),\n",
       "                                     1: np.float64(0.5409999999999999)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.38461538461538464),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.21621622,\n",
       "            0.2972973 , 0.2972973 , 0.35135135, 0.35135135, 0.78378378,\n",
       "            0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.70876329, 0.66202775, 0.59536417, 0.56788115,\n",
       "            0.54011716, 0.52972661, 0.5156681 , 0.43628151, 0.42629834,\n",
       "            0.40228597, 0.39891763, 0.39449031, 0.39286632, 0.37689888,\n",
       "            0.33218365, 0.31155336, 0.30310443, 0.29491386, 0.18027246,\n",
       "            0.17167997, 0.10257362])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.44900000000000007),\n",
       "                                     1: np.float64(0.5509999999999999)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.38461538461538464),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.16216216, 0.21621622, 0.2972973 ,\n",
       "            0.2972973 , 0.35135135, 0.35135135, 0.78378378, 0.78378378,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.71651844, 0.67029965, 0.60385296, 0.57712888,\n",
       "            0.5501604 , 0.53990946, 0.52394785, 0.44561047, 0.43572469,\n",
       "            0.41156461, 0.40312037, 0.40184621, 0.38582714, 0.3409259 ,\n",
       "            0.31923431, 0.31155247, 0.30268335, 0.18526355, 0.17766085,\n",
       "            0.10575887])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.43900000000000006),\n",
       "                                     1: np.float64(0.5609999999999999)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.38461538461538464),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.16216216, 0.21621622, 0.32432432,\n",
       "            0.32432432, 0.37837838, 0.37837838, 0.78378378, 0.78378378,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.72411763, 0.67851651, 0.61230273, 0.58641962,\n",
       "            0.56012373, 0.55020486, 0.53236332, 0.45504611, 0.44519503,\n",
       "            0.42091379, 0.41347795, 0.40929748, 0.39483658, 0.32818089,\n",
       "            0.32705516, 0.31137435, 0.3105662 , 0.19039672, 0.18380289,\n",
       "            0.10907706])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.42900000000000005),\n",
       "                                     1: np.float64(0.571)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.38461538461538464),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.16216216, 0.21621622, 0.32432432,\n",
       "            0.32432432, 0.37837838, 0.37837838, 0.78378378, 0.78378378,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.73342493, 0.6848198 , 0.62121561, 0.59508582,\n",
       "            0.57169275, 0.55943238, 0.54088523, 0.4638242 , 0.45555491,\n",
       "            0.43116644, 0.42473322, 0.4167867 , 0.40458169, 0.33877653,\n",
       "            0.33498517, 0.32033366, 0.31887119, 0.19548707, 0.19062281,\n",
       "            0.11246294])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.41900000000000004),\n",
       "                                     1: np.float64(0.581)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.46153846153846156),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.16216216, 0.21621622, 0.32432432,\n",
       "            0.32432432, 0.37837838, 0.37837838, 0.78378378, 0.78378378,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.73977743, 0.6944763 , 0.63000976, 0.60587502,\n",
       "            0.58069039, 0.57103049, 0.55036953, 0.47453239, 0.46493101,\n",
       "            0.44007103, 0.43396314, 0.42428669, 0.41316361, 0.3480655 ,\n",
       "            0.34310294, 0.3296733 , 0.32657778, 0.2013458 , 0.19688744,\n",
       "            0.11605773])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.40900000000000014),\n",
       "                                     1: np.float64(0.5909999999999999)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.46153846153846156),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.16216216, 0.21621622, 0.32432432,\n",
       "            0.32432432, 0.37837838, 0.37837838, 0.78378378, 0.78378378,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.74734655, 0.70201399, 0.63893555, 0.61541048,\n",
       "            0.59063545, 0.58138527, 0.55892822, 0.48436486, 0.47429296,\n",
       "            0.45030542, 0.44278348, 0.43194928, 0.42280985, 0.35834719,\n",
       "            0.35112143, 0.33918624, 0.33523317, 0.20683325, 0.20388671,\n",
       "            0.11981478])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.39900000000000013),\n",
       "                                     1: np.float64(0.6009999999999999)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.46153846153846156),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.16216216, 0.21621622, 0.32432432,\n",
       "            0.32432432, 0.37837838, 0.37837838, 0.78378378, 0.78378378,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.30769231, 0.30769231, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.75452159, 0.70971225, 0.647063  , 0.62472339,\n",
       "            0.60046616, 0.59148821, 0.56744896, 0.49393764, 0.4840757 ,\n",
       "            0.45988943, 0.45186272, 0.43954381, 0.4321647 , 0.3687069 ,\n",
       "            0.3593917 , 0.34869783, 0.34359012, 0.21276912, 0.21095556,\n",
       "            0.12374463])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3890000000000001),\n",
       "                                     1: np.float64(0.6109999999999999)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.5384615384615384),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.16216216, 0.21621622, 0.32432432,\n",
       "            0.32432432, 0.37837838, 0.37837838, 0.78378378, 0.78378378,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.76188752, 0.71755385, 0.65534869, 0.63417278,\n",
       "            0.6104402 , 0.57657126, 0.57645785, 0.50398143, 0.49388296,\n",
       "            0.46996136, 0.46119267, 0.44761182, 0.44181441, 0.37920456,\n",
       "            0.36801536, 0.35857699, 0.35220687, 0.21873612, 0.21817452,\n",
       "            0.12773265])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3790000000000001),\n",
       "                                     1: np.float64(0.6209999999999999)}),\n",
       "    'fpr': np.float64(0.10810810810810811),\n",
       "    'tpr': np.float64(0.5384615384615384),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.16216216, 0.21621622, 0.32432432,\n",
       "            0.32432432, 0.37837838, 0.37837838, 0.78378378, 0.78378378,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.76865207, 0.72686686, 0.66330967, 0.64437022,\n",
       "            0.61996263, 0.58659317, 0.58614022, 0.51479493, 0.50350448,\n",
       "            0.47995191, 0.47117702, 0.45604732, 0.45110884, 0.38987649,\n",
       "            0.37757238, 0.36871989, 0.36103307, 0.22556456, 0.22524749,\n",
       "            0.13173468])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3690000000000001),\n",
       "                                     1: np.float64(0.6309999999999999)}),\n",
       "    'fpr': np.float64(0.10810810810810811),\n",
       "    'tpr': np.float64(0.5384615384615384),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.16216216, 0.21621622, 0.32432432,\n",
       "            0.32432432, 0.37837838, 0.37837838, 0.75675676, 0.75675676,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.77567058, 0.73445791, 0.67135575, 0.65367094,\n",
       "            0.62979888, 0.59720253, 0.59476039, 0.52476835, 0.51331137,\n",
       "            0.49010087, 0.4806963 , 0.46402344, 0.46088998, 0.40099827,\n",
       "            0.38650946, 0.37910976, 0.37008199, 0.25799969, 0.23311931,\n",
       "            0.1360238 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3590000000000001),\n",
       "                                     1: np.float64(0.6409999999999999)}),\n",
       "    'fpr': np.float64(0.13513513513513514),\n",
       "    'tpr': np.float64(0.6923076923076923),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.16216216,\n",
       "            0.21621622, 0.32432432, 0.32432432, 0.37837838, 0.37837838,\n",
       "            0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.78265094, 0.74177151, 0.6796197 , 0.66309691,\n",
       "            0.6399792 , 0.60811569, 0.60390094, 0.5349792 , 0.52374378,\n",
       "            0.50768529, 0.50107598, 0.5004347 , 0.49038806, 0.47250637,\n",
       "            0.47115587, 0.41198222, 0.39581032, 0.38941313, 0.37939109,\n",
       "            0.26622053, 0.24109301, 0.14061417])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3490000000000001),\n",
       "                                     1: np.float64(0.6509999999999999)}),\n",
       "    'fpr': np.float64(0.16216216216216217),\n",
       "    'tpr': np.float64(0.6923076923076923),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.21621622,\n",
       "            0.21621622, 0.35135135, 0.35135135, 0.37837838, 0.37837838,\n",
       "            0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.78947349, 0.74977669, 0.6879038 , 0.67316013,\n",
       "            0.64938543, 0.61880012, 0.61330946, 0.54573478, 0.5333036 ,\n",
       "            0.5188638 , 0.51255383, 0.51112445, 0.50024797, 0.48118997,\n",
       "            0.48107708, 0.40524612, 0.40511607, 0.40006998, 0.38883631,\n",
       "            0.27488267, 0.24919402, 0.14531228])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3390000000000001),\n",
       "                                     1: np.float64(0.6609999999999999)}),\n",
       "    'fpr': np.float64(0.16216216216216217),\n",
       "    'tpr': np.float64(0.6923076923076923),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.21621622,\n",
       "            0.21621622, 0.35135135, 0.35135135, 0.37837838, 0.37837838,\n",
       "            0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.79621268, 0.75734528, 0.69593517, 0.68287926,\n",
       "            0.65895788, 0.62951066, 0.62255728, 0.55632948, 0.54308096,\n",
       "            0.52987111, 0.52411207, 0.52189213, 0.51031196, 0.49137602,\n",
       "            0.48977152, 0.41545459, 0.41473522, 0.41096067, 0.39852517,\n",
       "            0.28385392, 0.2576871 , 0.15026231])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.32900000000000007),\n",
       "                                     1: np.float64(0.6709999999999999)}),\n",
       "    'fpr': np.float64(0.21621621621621623),\n",
       "    'tpr': np.float64(0.6923076923076923),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.21621622,\n",
       "            0.21621622, 0.35135135, 0.35135135, 0.37837838, 0.37837838,\n",
       "            0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.80263993, 0.76526061, 0.70416165, 0.69288768,\n",
       "            0.668226  , 0.63998634, 0.63193598, 0.56725669, 0.55257071,\n",
       "            0.54157898, 0.53566042, 0.53275474, 0.52042008, 0.50161766,\n",
       "            0.49855395, 0.42582254, 0.42473011, 0.42223102, 0.40852855,\n",
       "            0.29340046, 0.26644325, 0.15537378])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.31900000000000006),\n",
       "                                     1: np.float64(0.6809999999999999)}),\n",
       "    'fpr': np.float64(0.21621621621621623),\n",
       "    'tpr': np.float64(0.7692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.21621622,\n",
       "            0.21621622, 0.35135135, 0.35135135, 0.37837838, 0.37837838,\n",
       "            0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.80978078, 0.7717989 , 0.71161369, 0.70229459,\n",
       "            0.67843659, 0.65128216, 0.64100315, 0.57777741, 0.5630223 ,\n",
       "            0.55226353, 0.54763186, 0.54434462, 0.53104565, 0.51238638,\n",
       "            0.50787493, 0.4364604 , 0.43469567, 0.43342776, 0.41886195,\n",
       "            0.30288251, 0.27568815, 0.16094736])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.30900000000000005),\n",
       "                                     1: np.float64(0.691)}),\n",
       "    'fpr': np.float64(0.24324324324324326),\n",
       "    'tpr': np.float64(0.7692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.21621622,\n",
       "            0.21621622, 0.35135135, 0.35135135, 0.40540541, 0.40540541,\n",
       "            0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.30769231,\n",
       "            0.30769231, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.8156891 , 0.78009527, 0.71981055, 0.68910256,\n",
       "            0.68747479, 0.66157048, 0.65097976, 0.58925989, 0.57278285,\n",
       "            0.56488065, 0.5592547 , 0.55517909, 0.54182876, 0.52307418,\n",
       "            0.51726563, 0.44756732, 0.44572161, 0.43133299, 0.42939884,\n",
       "            0.31303652, 0.28499331, 0.16652708])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.29900000000000015),\n",
       "                                     1: np.float64(0.7009999999999998)}),\n",
       "    'fpr': np.float64(0.2702702702702703),\n",
       "    'tpr': np.float64(0.7692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.21621622,\n",
       "            0.21621622, 0.37837838, 0.37837838, 0.43243243, 0.43243243,\n",
       "            0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.30769231,\n",
       "            0.30769231, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.82206305, 0.78708828, 0.72752131, 0.69976175,\n",
       "            0.6970964 , 0.67233412, 0.66047905, 0.60024768, 0.58309053,\n",
       "            0.57658375, 0.57126986, 0.56664433, 0.55252637, 0.53393623,\n",
       "            0.52690545, 0.45689624, 0.45645248, 0.44143603, 0.44016331,\n",
       "            0.32353643, 0.29480022, 0.17274847])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.28900000000000015),\n",
       "                                     1: np.float64(0.7109999999999999)}),\n",
       "    'fpr': np.float64(0.2972972972972973),\n",
       "    'tpr': np.float64(0.7692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.21621622,\n",
       "            0.21621622, 0.37837838, 0.37837838, 0.43243243, 0.43243243,\n",
       "            0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.30769231,\n",
       "            0.30769231, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.8286993 , 0.79445159, 0.73565495, 0.71073975,\n",
       "            0.70643833, 0.68337922, 0.67030686, 0.61158006, 0.59277605,\n",
       "            0.58876762, 0.58345882, 0.57853727, 0.56375172, 0.54527904,\n",
       "            0.53668267, 0.46951882, 0.46747998, 0.45431047, 0.45123569,\n",
       "            0.33401233, 0.30525209, 0.17893907])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.27900000000000014),\n",
       "                                     1: np.float64(0.7209999999999999)}),\n",
       "    'fpr': np.float64(0.32432432432432434),\n",
       "    'tpr': np.float64(0.7692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.21621622,\n",
       "            0.21621622, 0.37837838, 0.37837838, 0.43243243, 0.43243243,\n",
       "            0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.30769231,\n",
       "            0.30769231, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.834723  , 0.80198413, 0.7435791 , 0.72165933,\n",
       "            0.71596198, 0.69384629, 0.68023869, 0.6230492 , 0.60322783,\n",
       "            0.6014748 , 0.59563085, 0.58995881, 0.57491541, 0.55614705,\n",
       "            0.54666944, 0.48168739, 0.47911128, 0.46701406, 0.46245508,\n",
       "            0.34573129, 0.31546745, 0.18561557])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.26900000000000013),\n",
       "                                     1: np.float64(0.7309999999999999)}),\n",
       "    'fpr': np.float64(0.32432432432432434),\n",
       "    'tpr': np.float64(0.7692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.16216216, 0.21621622, 0.21621622, 0.37837838,\n",
       "            0.37837838, 0.43243243, 0.43243243, 0.75675676, 0.75675676,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.38461538, 0.38461538, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.84141359, 0.75166445, 0.7515806 , 0.73190781,\n",
       "            0.72527905, 0.70534068, 0.68951387, 0.61305378, 0.60840658,\n",
       "            0.6025419 , 0.58607493, 0.56774979, 0.55678302, 0.49299793,\n",
       "            0.4896209 , 0.48064489, 0.47413131, 0.35740047, 0.32656766,\n",
       "            0.19268555])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2590000000000001),\n",
       "                                     1: np.float64(0.7409999999999999)}),\n",
       "    'fpr': np.float64(0.40540540540540543),\n",
       "    'tpr': np.float64(0.8461538461538461),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.16216216, 0.21621622, 0.21621622, 0.37837838,\n",
       "            0.37837838, 0.43243243, 0.43243243, 0.75675676, 0.75675676,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.38461538, 0.38461538, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.84705158, 0.76161951, 0.75957976, 0.74287022,\n",
       "            0.73471305, 0.71553968, 0.69967399, 0.62622654, 0.62054596,\n",
       "            0.61397833, 0.59750263, 0.57902931, 0.56719714, 0.50557743,\n",
       "            0.5021938 , 0.49372202, 0.48594274, 0.36988152, 0.33756664,\n",
       "            0.19996762])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2490000000000001),\n",
       "                                     1: np.float64(0.7509999999999999)}),\n",
       "    'fpr': np.float64(0.43243243243243246),\n",
       "    'tpr': np.float64(0.8461538461538461),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.16216216, 0.21621622, 0.21621622, 0.40540541,\n",
       "            0.40540541, 0.43243243, 0.43243243, 0.75675676, 0.75675676,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.38461538, 0.38461538, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.85336841, 0.7710282 , 0.76751106, 0.75351537,\n",
       "            0.74407964, 0.7270362 , 0.70977058, 0.63867044, 0.63327476,\n",
       "            0.62718339, 0.60992386, 0.59168808, 0.57852414, 0.51534455,\n",
       "            0.51449456, 0.50791162, 0.4989755 , 0.38220191, 0.34979557,\n",
       "            0.20785044])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2390000000000001),\n",
       "                                     1: np.float64(0.7609999999999999)}),\n",
       "    'fpr': np.float64(0.4594594594594595),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.16216216, 0.21621622, 0.21621622, 0.40540541,\n",
       "            0.40540541, 0.43243243, 0.43243243, 0.75675676, 0.75675676,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.38461538, 0.38461538, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.85919179, 0.78107186, 0.77506465, 0.76464622,\n",
       "            0.75327946, 0.73752104, 0.72040404, 0.6525799 , 0.64430255,\n",
       "            0.63932098, 0.62255293, 0.60347419, 0.589919  , 0.53057996,\n",
       "            0.52793075, 0.5218369 , 0.51129894, 0.39535469, 0.36198042,\n",
       "            0.21643596])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2290000000000001),\n",
       "                                     1: np.float64(0.7709999999999999)}),\n",
       "    'fpr': np.float64(0.4594594594594595),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.16216216, 0.21621622, 0.24324324, 0.24324324,\n",
       "            0.40540541, 0.40540541, 0.45945946, 0.45945946, 0.75675676,\n",
       "            0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.38461538, 0.38461538, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.86511102, 0.79082493, 0.78299914, 0.77521855,\n",
       "            0.76259931, 0.74840326, 0.73061424, 0.66578538, 0.65481759,\n",
       "            0.6522067 , 0.63493669, 0.61583836, 0.60244122, 0.60154125,\n",
       "            0.54357673, 0.54110454, 0.52541027, 0.52452301, 0.40931123,\n",
       "            0.37486276, 0.22546381])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.21900000000000008),\n",
       "                                     1: np.float64(0.7809999999999999)}),\n",
       "    'fpr': np.float64(0.5135135135135135),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.21621622, 0.24324324, 0.24324324,\n",
       "            0.40540541, 0.40540541, 0.45945946, 0.45945946, 0.75675676,\n",
       "            0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.38461538, 0.38461538, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.87159983, 0.80054444, 0.79074653, 0.78534433,\n",
       "            0.77237895, 0.75993281, 0.74044387, 0.67842255, 0.67199858,\n",
       "            0.66585939, 0.64757414, 0.62867218, 0.61516596, 0.6135177 ,\n",
       "            0.55661008, 0.55380222, 0.54036182, 0.53826208, 0.42388871,\n",
       "            0.38862489, 0.23503565])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.20900000000000007),\n",
       "                                     1: np.float64(0.7909999999999999)}),\n",
       "    'fpr': np.float64(0.5945945945945946),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.21621622, 0.24324324, 0.24324324,\n",
       "            0.40540541, 0.40540541, 0.45945946, 0.45945946, 0.75675676,\n",
       "            0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.38461538, 0.38461538, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.87702662, 0.81025713, 0.79890526, 0.79615227,\n",
       "            0.78131931, 0.77053406, 0.75128018, 0.69254291, 0.68490192,\n",
       "            0.67886254, 0.66073565, 0.64159016, 0.62880645, 0.62603326,\n",
       "            0.57048345, 0.56849453, 0.55648242, 0.55234538, 0.4390475 ,\n",
       "            0.4026796 , 0.24551804])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.19900000000000018),\n",
       "                                     1: np.float64(0.8009999999999998)}),\n",
       "    'fpr': np.float64(0.6486486486486487),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.21621622, 0.24324324, 0.24324324,\n",
       "            0.40540541, 0.40540541, 0.45945946, 0.45945946, 0.75675676,\n",
       "            0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.46153846, 0.46153846, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.88274552, 0.81974007, 0.80697456, 0.80631577,\n",
       "            0.79049738, 0.76185503, 0.76153666, 0.70584208, 0.69794911,\n",
       "            0.69288398, 0.67383166, 0.654994  , 0.64243447, 0.63880192,\n",
       "            0.58413107, 0.58275185, 0.57267975, 0.56745716, 0.45510896,\n",
       "            0.41743411, 0.25641422])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.18900000000000017),\n",
       "                                     1: np.float64(0.8109999999999998)}),\n",
       "    'fpr': np.float64(0.6486486486486487),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.21621622, 0.24324324, 0.24324324, 0.43243243, 0.43243243,\n",
       "            0.45945946, 0.45945946, 0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.46153846,\n",
       "            0.46153846, 0.61538462, 0.61538462, 0.69230769, 0.69230769,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.88872525, 0.8165469 , 0.79998875, 0.77404041,\n",
       "            0.77207305, 0.71964851, 0.71145146, 0.70666745, 0.68760322,\n",
       "            0.66827995, 0.65640295, 0.65214297, 0.5983394 , 0.59763685,\n",
       "            0.58924144, 0.58230254, 0.47190657, 0.43295355, 0.26851985])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.17900000000000016),\n",
       "                                     1: np.float64(0.8209999999999998)}),\n",
       "    'fpr': np.float64(0.7027027027027027),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.21621622, 0.24324324, 0.24324324, 0.40540541, 0.40540541,\n",
       "            0.45945946, 0.45945946, 0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.46153846,\n",
       "            0.46153846, 0.61538462, 0.61538462, 0.69230769, 0.69230769,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.89417774, 0.82683627, 0.80905887, 0.78609075,\n",
       "            0.78291012, 0.73376796, 0.72483719, 0.72069393, 0.70172557,\n",
       "            0.68213783, 0.67103839, 0.66619051, 0.61538347, 0.61348378,\n",
       "            0.60665672, 0.59804066, 0.48930241, 0.44907055, 0.28171201])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.16900000000000015),\n",
       "                                     1: np.float64(0.8309999999999998)}),\n",
       "    'fpr': np.float64(0.7567567567567568),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.21621622, 0.24324324, 0.24324324, 0.40540541, 0.40540541,\n",
       "            0.45945946, 0.45945946, 0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.46153846,\n",
       "            0.46153846, 0.61538462, 0.61538462, 0.69230769, 0.69230769,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.8997837 , 0.83701261, 0.8183111 , 0.79812892,\n",
       "            0.79386064, 0.74769547, 0.73827735, 0.73522371, 0.71584749,\n",
       "            0.69642446, 0.6859203 , 0.68038692, 0.6322577 , 0.62942102,\n",
       "            0.62423409, 0.61453099, 0.50584425, 0.46607504, 0.29553076])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.15900000000000014),\n",
       "                                     1: np.float64(0.8409999999999999)}),\n",
       "    'fpr': np.float64(0.7567567567567568),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.21621622, 0.24324324, 0.24324324, 0.40540541, 0.40540541,\n",
       "            0.45945946, 0.45945946, 0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.46153846,\n",
       "            0.46153846, 0.61538462, 0.61538462, 0.69230769, 0.69230769,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.9053626 , 0.84693561, 0.82752614, 0.8101273 ,\n",
       "            0.80455459, 0.76178698, 0.75213698, 0.74972084, 0.73036973,\n",
       "            0.7108344 , 0.70086774, 0.69533819, 0.64967566, 0.64584475,\n",
       "            0.64248658, 0.63120365, 0.5232041 , 0.48415045, 0.31126813])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.14900000000000013),\n",
       "                                     1: np.float64(0.8509999999999999)}),\n",
       "    'fpr': np.float64(0.7567567567567568),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.21621622, 0.24324324, 0.24324324, 0.40540541, 0.40540541,\n",
       "            0.45945946, 0.45945946, 0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.46153846,\n",
       "            0.46153846, 0.61538462, 0.61538462, 0.69230769, 0.69230769,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.91073973, 0.85676194, 0.83655803, 0.82212859,\n",
       "            0.81568046, 0.77614623, 0.76588895, 0.76441221, 0.74251695,\n",
       "            0.72566014, 0.71650572, 0.71071734, 0.66764708, 0.66315065,\n",
       "            0.65976584, 0.64868418, 0.54159312, 0.50323759, 0.32870873])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.13900000000000012),\n",
       "                                     1: np.float64(0.8609999999999999)}),\n",
       "    'fpr': np.float64(0.7837837837837838),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.16216216, 0.21621622, 0.27027027, 0.27027027,\n",
       "            0.40540541, 0.40540541, 0.45945946, 0.45945946, 0.75675676,\n",
       "            0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.38461538,\n",
       "            0.38461538, 0.46153846, 0.46153846, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.91598688, 0.86664369, 0.85586472, 0.84714436,\n",
       "            0.84567498, 0.83396938, 0.8269395 , 0.79069267, 0.77970944,\n",
       "            0.77926579, 0.75422712, 0.74079284, 0.72744427, 0.72696275,\n",
       "            0.6855757 , 0.68139137, 0.67641506, 0.66681642, 0.56104837,\n",
       "            0.52290716, 0.34744672])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.12900000000000011),\n",
       "                                     1: np.float64(0.8709999999999999)}),\n",
       "    'fpr': np.float64(0.8108108108108109),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.16216216,\n",
       "            0.21621622, 0.27027027, 0.27027027, 0.43243243, 0.43243243,\n",
       "            0.45945946, 0.45945946, 0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.38461538,\n",
       "            0.38461538, 0.46153846, 0.46153846, 0.69230769, 0.69230769,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.92136246, 0.87626143, 0.86426527, 0.8580731 ,\n",
       "            0.85496235, 0.84590871, 0.83801666, 0.79463354, 0.76610682,\n",
       "            0.75634468, 0.74518163, 0.74380859, 0.7007687 , 0.70001045,\n",
       "            0.69336241, 0.68591022, 0.58177435, 0.54410469, 0.36826942])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1190000000000001),\n",
       "                                     1: np.float64(0.8809999999999999)}),\n",
       "    'fpr': np.float64(0.8378378378378378),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.16216216,\n",
       "            0.21621622, 0.27027027, 0.27027027, 0.43243243, 0.43243243,\n",
       "            0.45945946, 0.45945946, 0.78378378, 0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.38461538,\n",
       "            0.38461538, 0.46153846, 0.46153846, 0.69230769, 0.69230769,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.92651113, 0.88600794, 0.87297332, 0.86898356,\n",
       "            0.86402155, 0.85774247, 0.84982519, 0.81015034, 0.77803214,\n",
       "            0.77252627, 0.76309453, 0.76135909, 0.72077111, 0.71925441,\n",
       "            0.71115759, 0.70570157, 0.56915235, 0.56641468, 0.39191969])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1090000000000001),\n",
       "                                     1: np.float64(0.8909999999999999)}),\n",
       "    'fpr': np.float64(0.8648648648648649),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.16216216,\n",
       "            0.21621622, 0.27027027, 0.27027027, 0.40540541, 0.40540541,\n",
       "            0.45945946, 0.45945946, 0.78378378, 0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.38461538,\n",
       "            0.38461538, 0.46153846, 0.46153846, 0.69230769, 0.69230769,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.93183354, 0.89530183, 0.88158956, 0.87952958,\n",
       "            0.87353258, 0.8694934 , 0.86148285, 0.82566867, 0.79103203,\n",
       "            0.78868995, 0.78142592, 0.77920623, 0.74221581, 0.73975299,\n",
       "            0.72965955, 0.72613838, 0.59704223, 0.59044511, 0.41829423])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.09900000000000009),\n",
       "                                     1: np.float64(0.9009999999999999)}),\n",
       "    'fpr': np.float64(0.9459459459459459),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.18918919, 0.27027027, 0.27027027, 0.40540541, 0.40540541,\n",
       "            0.45945946, 0.45945946, 0.78378378, 0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.38461538,\n",
       "            0.38461538, 0.46153846, 0.46153846, 0.69230769, 0.69230769,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.93696089, 0.90431817, 0.89027732, 0.89019025,\n",
       "            0.88289542, 0.88106139, 0.87274465, 0.84138732, 0.82479666,\n",
       "            0.80570952, 0.79996964, 0.79805365, 0.76355294, 0.7607537 ,\n",
       "            0.74908117, 0.74774678, 0.62741037, 0.61648349, 0.44852746])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.08900000000000019),\n",
       "                                     1: np.float64(0.9109999999999998)}),\n",
       "    'fpr': np.float64(0.972972972972973),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.18918919, 0.27027027,\n",
       "            0.27027027, 0.40540541, 0.40540541, 0.78378378, 0.78378378,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.46153846,\n",
       "            0.46153846, 0.69230769, 0.69230769, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.94182409, 0.90068395, 0.8991532 , 0.89235267,\n",
       "            0.88449386, 0.85712466, 0.84175209, 0.82319416, 0.81777235,\n",
       "            0.81736551, 0.78409616, 0.77035368, 0.65939165, 0.64354786,\n",
       "            0.4822949 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.07900000000000018),\n",
       "                                     1: np.float64(0.9209999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.18918919, 0.21621622,\n",
       "            0.21621622, 0.40540541, 0.40540541, 0.78378378, 0.78378378,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.46153846,\n",
       "            0.46153846, 0.69230769, 0.69230769, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.94689991, 0.91108804, 0.90841789, 0.90370786,\n",
       "            0.89645271, 0.87288432, 0.85868844, 0.84090043, 0.83924774,\n",
       "            0.83742949, 0.80496853, 0.79323225, 0.69386042, 0.67311164,\n",
       "            0.52162631])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.06900000000000017),\n",
       "                                     1: np.float64(0.9309999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.18918919, 0.21621622,\n",
       "            0.21621622, 0.35135135, 0.35135135, 0.40540541, 0.40540541,\n",
       "            0.78378378, 0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.46153846,\n",
       "            0.46153846, 0.69230769, 0.69230769, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.9519483 , 0.92136898, 0.91793251, 0.91502195,\n",
       "            0.9081942 , 0.88881369, 0.87571654, 0.85920311, 0.8581728 ,\n",
       "            0.85803898, 0.83251968, 0.82836118, 0.82694382, 0.8174124 ,\n",
       "            0.73085079, 0.70561198, 0.56685507])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.05900000000000016),\n",
       "                                     1: np.float64(0.9409999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.16216216,\n",
       "            0.21621622, 0.35135135, 0.35135135, 0.40540541, 0.40540541,\n",
       "            0.78378378, 0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.46153846,\n",
       "            0.46153846, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.95674617, 0.93129896, 0.92765873, 0.92600865,\n",
       "            0.92060887, 0.9046138 , 0.89297715, 0.87870877, 0.87820812,\n",
       "            0.87790415, 0.85624497, 0.85273583, 0.84909351, 0.84272725,\n",
       "            0.76945105, 0.74030019, 0.61874258])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.049000000000000155),\n",
       "                                     1: np.float64(0.9509999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.16216216,\n",
       "            0.21621622, 0.35135135, 0.35135135, 0.40540541, 0.40540541,\n",
       "            0.81081081, 0.81081081, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.46153846,\n",
       "            0.46153846, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.96182486, 0.94159341, 0.93785729, 0.93717779,\n",
       "            0.93115648, 0.92036822, 0.91059031, 0.90016751, 0.89827772,\n",
       "            0.89750768, 0.87829412, 0.87754413, 0.87265392, 0.86876917,\n",
       "            0.7792231 , 0.77872234, 0.67883143])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.039000000000000146),\n",
       "                                     1: np.float64(0.9609999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.16216216,\n",
       "            0.21621622, 0.2972973 , 0.2972973 , 0.40540541, 0.40540541,\n",
       "            0.81081081, 0.81081081, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.46153846,\n",
       "            0.46153846, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.96684249, 0.95149027, 0.94858316, 0.94822337,\n",
       "            0.94177091, 0.93599106, 0.92672178, 0.92131687, 0.91885324,\n",
       "            0.91735305, 0.90564227, 0.90323403, 0.89660999, 0.89570058,\n",
       "            0.82915181, 0.82072304, 0.74684992])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.029000000000000137),\n",
       "                                     1: np.float64(0.9709999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.16216216, 0.21621622, 0.27027027, 0.27027027,\n",
       "            0.32432432, 0.32432432, 0.81081081, 0.81081081, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.97225325, 0.96162016, 0.95969397, 0.95928539,\n",
       "            0.95836399, 0.95355149, 0.9532137 , 0.95158576, 0.9430499 ,\n",
       "            0.94230735, 0.93949372, 0.93783904, 0.93051967, 0.92896501,\n",
       "            0.92456121, 0.92326267, 0.88020759, 0.866629  , 0.82110136])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.019000000000000128),\n",
       "                                     1: np.float64(0.9809999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.10810811, 0.10810811, 0.16216216, 0.21621622, 0.27027027,\n",
       "            0.27027027, 0.2972973 , 0.2972973 , 0.86486486, 0.86486486,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.69230769,\n",
       "            0.69230769, 0.76923077, 0.76923077, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.97846173, 0.97220584, 0.97156208, 0.96726648,\n",
       "            0.96341494, 0.96275297, 0.96028958, 0.9588379 , 0.95535062,\n",
       "            0.95482574, 0.95206525, 0.95123315, 0.91700739, 0.91583348,\n",
       "            0.89616255])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.009000000000000119),\n",
       "                                     1: np.float64(0.9909999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.13513514, 0.18918919, 0.21621622, 0.21621622, 0.27027027,\n",
       "            0.27027027, 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.76923077,\n",
       "            0.76923077, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.98762109, 0.98663105, 0.98497847, 0.98219378,\n",
       "            0.98084812, 0.98016459, 0.97969054, 0.97940005, 0.97833853,\n",
       "            0.97802497, 0.96520977, 0.96514948, 0.96180673])}}],\n",
       "  [{'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.28125, 0.28125, 0.34375, 0.34375,\n",
       "            0.375  , 0.375  , 0.4375 , 0.4375 , 0.53125, 0.53125, 0.625  ,\n",
       "            0.625  , 0.65625, 0.6875 , 0.71875, 0.90625, 0.90625, 0.9375 ,\n",
       "            0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.27777778, 0.27777778,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.5       , 0.5       , 0.55555556, 0.55555556,\n",
       "            0.61111111, 0.61111111, 0.66666667, 0.66666667, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.00044167, 0.00042859, 0.00042362, 0.00041738,\n",
       "            0.00041508, 0.0004145 , 0.00041346, 0.00041168, 0.00041118,\n",
       "            0.00040746, 0.00040699, 0.00040572, 0.00040364, 0.00040351,\n",
       "            0.00040328, 0.00039899, 0.00039887, 0.00039179, 0.00039147,\n",
       "            0.00039109, 0.00039103, 0.00039082, 0.00039069, 0.00038997,\n",
       "            0.00037756, 0.00037711, 0.00037705, 0.00037541, 0.0003734 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.989), 1: np.float64(0.011)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.1875 ,\n",
       "            0.1875 , 0.28125, 0.28125, 0.375  , 0.375  , 0.46875, 0.46875,\n",
       "            0.5625 , 0.5625 , 0.625  , 0.65625, 0.71875, 0.75   , 0.90625,\n",
       "            0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.27777778, 0.27777778,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.61111111, 0.61111111, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.00881182, 0.00723628, 0.00640479, 0.0060242 ,\n",
       "            0.00593577, 0.00530241, 0.00526197, 0.00521534, 0.00518466,\n",
       "            0.00479332, 0.00462865, 0.00424769, 0.00398559, 0.00390196,\n",
       "            0.0037891 , 0.0037636 , 0.00375879, 0.00360633, 0.00358115,\n",
       "            0.00293784, 0.0028731 , 0.00271779, 0.00269346, 0.00260163])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.979),\n",
       "                                     1: np.float64(0.020999999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.28125, 0.28125, 0.34375,\n",
       "            0.34375, 0.375  , 0.375  , 0.46875, 0.46875, 0.5625 , 0.5625 ,\n",
       "            0.625  , 0.65625, 0.71875, 0.75   , 0.90625, 0.90625, 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.02474753, 0.0190535 , 0.01404238, 0.01097176,\n",
       "            0.01088303, 0.01068301, 0.01046163, 0.00931078, 0.00883132,\n",
       "            0.00798107, 0.00737155, 0.00701822, 0.00669546, 0.00662266,\n",
       "            0.00657891, 0.00619259, 0.00602019, 0.00457791, 0.00439646,\n",
       "            0.00401005, 0.00389051, 0.00370184])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.969),\n",
       "                                     1: np.float64(0.030999999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.28125, 0.28125, 0.34375,\n",
       "            0.34375, 0.375  , 0.375  , 0.40625, 0.40625, 0.46875, 0.46875,\n",
       "            0.5625 , 0.5625 , 0.625  , 0.65625, 0.71875, 0.75   , 0.90625,\n",
       "            0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.55555556,\n",
       "            0.55555556, 0.61111111, 0.61111111, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.04695904, 0.03521251, 0.02359176, 0.01705472,\n",
       "            0.01698723, 0.01636361, 0.01512198, 0.01342086, 0.01301629,\n",
       "            0.0129393 , 0.01255257, 0.01148701, 0.01053817, 0.00967415,\n",
       "            0.00921265, 0.00903686, 0.00893378, 0.00828946, 0.00787601,\n",
       "            0.00578424, 0.00543035, 0.00483079, 0.00457813, 0.00432961])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.959),\n",
       "                                     1: np.float64(0.040999999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.28125,\n",
       "            0.28125, 0.34375, 0.34375, 0.40625, 0.40625, 0.4375 , 0.4375 ,\n",
       "            0.46875, 0.46875, 0.5625 , 0.5625 , 0.625  , 0.65625, 0.71875,\n",
       "            0.75   , 0.90625, 0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.55555556, 0.55555556, 0.61111111, 0.61111111,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.07309482, 0.05332233, 0.03644029, 0.03510568,\n",
       "            0.03238039, 0.02311806, 0.02309035, 0.02198131, 0.01895048,\n",
       "            0.0168775 , 0.01633931, 0.01621719, 0.01567318, 0.01480226,\n",
       "            0.01309549, 0.01207558, 0.01149419, 0.01120074, 0.01101953,\n",
       "            0.01011075, 0.00936336, 0.00680545, 0.00627907, 0.00544242,\n",
       "            0.0050551 , 0.00475818])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9490000000000001),\n",
       "                                     1: np.float64(0.05099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.34375, 0.34375, 0.40625, 0.40625, 0.4375 , 0.4375 ,\n",
       "            0.46875, 0.46875, 0.5625 , 0.5625 , 0.625  , 0.65625, 0.71875,\n",
       "            0.75   , 0.90625, 0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.5       , 0.5       , 0.61111111, 0.61111111,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.10075767, 0.0728521 , 0.04954043, 0.04777206,\n",
       "            0.04109825, 0.03498186, 0.02961722, 0.02781721, 0.0228846 ,\n",
       "            0.02042936, 0.02040725, 0.01999513, 0.01876814, 0.01824728,\n",
       "            0.01528684, 0.01411372, 0.01382303, 0.01328177, 0.01307454,\n",
       "            0.01182805, 0.01082074, 0.00785539, 0.00696234, 0.00601485,\n",
       "            0.00552466, 0.00519962])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9390000000000001),\n",
       "                                     1: np.float64(0.06099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.34375, 0.34375, 0.4375 , 0.4375 , 0.46875, 0.46875,\n",
       "            0.5625 , 0.5625 , 0.625  , 0.65625, 0.71875, 0.75   , 0.90625,\n",
       "            0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.55555556, 0.55555556, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.12899591, 0.09251551, 0.06407283, 0.06158936,\n",
       "            0.04876652, 0.043542  , 0.03587162, 0.0333235 , 0.02590482,\n",
       "            0.02384808, 0.02224585, 0.02163259, 0.01758698, 0.0161462 ,\n",
       "            0.01600149, 0.01522746, 0.01491639, 0.01340937, 0.01205186,\n",
       "            0.00877605, 0.00770442, 0.0065139 , 0.00591229, 0.00558284])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.929), 1: np.float64(0.071)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.34375, 0.34375, 0.4375 , 0.4375 , 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.625  , 0.65625, 0.71875,\n",
       "            0.75   , 0.90625, 0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.5       , 0.5       , 0.66666667, 0.66666667,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.15678228, 0.11251949, 0.07901376, 0.07596024,\n",
       "            0.05608917, 0.05222785, 0.04206312, 0.03871796, 0.02875644,\n",
       "            0.02684368, 0.02624441, 0.02494731, 0.02296416, 0.01963449,\n",
       "            0.01961414, 0.01955359, 0.01811097, 0.01711258, 0.01672682,\n",
       "            0.01490476, 0.01321004, 0.00967246, 0.00837461, 0.00696697,\n",
       "            0.00628456, 0.00592389])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.919),\n",
       "                                     1: np.float64(0.08099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.21875, 0.21875, 0.34375, 0.34375, 0.4375 , 0.4375 ,\n",
       "            0.46875, 0.46875, 0.53125, 0.53125, 0.625  , 0.65625, 0.71875,\n",
       "            0.75   , 0.90625, 0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.27777778, 0.27777778, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.66666667, 0.66666667, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.18290524, 0.13246524, 0.0944377 , 0.09110119,\n",
       "            0.06796566, 0.06351437, 0.06270827, 0.06094843, 0.04815953,\n",
       "            0.04370313, 0.03142753, 0.02989926, 0.02927736, 0.02829383,\n",
       "            0.02630298, 0.0218508 , 0.02027104, 0.01899579, 0.01859633,\n",
       "            0.01640225, 0.01433886, 0.0106387 , 0.00900708, 0.00744044,\n",
       "            0.00667725, 0.00628146])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.909),\n",
       "                                     1: np.float64(0.09099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.40625, 0.40625, 0.4375 , 0.4375 , 0.46875, 0.46875,\n",
       "            0.53125, 0.53125, 0.625  , 0.65625, 0.71875, 0.75   , 0.90625,\n",
       "            0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.27777778, 0.27777778, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.5       , 0.5       , 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.20933623, 0.15203123, 0.11057025, 0.1062271 ,\n",
       "            0.07597903, 0.07022349, 0.05435371, 0.03380833, 0.03378307,\n",
       "            0.03267045, 0.03181971, 0.03163902, 0.02848511, 0.0240354 ,\n",
       "            0.02231623, 0.02084229, 0.02029309, 0.01779284, 0.01540884,\n",
       "            0.01141856, 0.0096544 , 0.00784075, 0.00699779, 0.00656553])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.899),\n",
       "                                     1: np.float64(0.10099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.40625, 0.40625, 0.46875, 0.46875, 0.53125, 0.53125,\n",
       "            0.625  , 0.65625, 0.71875, 0.75   , 0.90625, 0.90625, 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.27777778, 0.27777778, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.23366128, 0.17115326, 0.12641273, 0.12159507,\n",
       "            0.08356928, 0.07799799, 0.06037079, 0.03697747, 0.03620126,\n",
       "            0.03499205, 0.03067037, 0.0262871 , 0.02440451, 0.02262909,\n",
       "            0.02208999, 0.01921303, 0.01648576, 0.01227955, 0.010301  ,\n",
       "            0.00828613, 0.00737878, 0.00689988])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.889),\n",
       "                                     1: np.float64(0.11099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.4375 , 0.4375 , 0.46875, 0.46875, 0.53125, 0.53125,\n",
       "            0.625  , 0.65625, 0.71875, 0.75   , 0.90625, 0.90625, 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.27777778, 0.27777778, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.25697865, 0.19039694, 0.14283399, 0.13782319,\n",
       "            0.09096521, 0.08575421, 0.06636868, 0.03847779, 0.03847463,\n",
       "            0.03822595, 0.03282452, 0.02841376, 0.0265042 , 0.02438172,\n",
       "            0.02386473, 0.02058935, 0.017539  , 0.01291068, 0.01097938,\n",
       "            0.00868808, 0.00775453, 0.00721776])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.879),\n",
       "                                     1: np.float64(0.12099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.21875, 0.21875, 0.46875, 0.46875, 0.53125, 0.53125,\n",
       "            0.625  , 0.65625, 0.75   , 0.78125, 0.90625, 0.90625, 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.38888889,\n",
       "            0.38888889, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.2785051 , 0.20813722, 0.1587849 , 0.15329048,\n",
       "            0.11402578, 0.10007868, 0.09781279, 0.09293866, 0.07235502,\n",
       "            0.04093965, 0.03490284, 0.0307191 , 0.02858917, 0.0260931 ,\n",
       "            0.02566676, 0.01859538, 0.0185853 , 0.01354329, 0.01164837,\n",
       "            0.00914724, 0.00814917, 0.00755341])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.869),\n",
       "                                     1: np.float64(0.13099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.1875 ,\n",
       "            0.1875 , 0.21875, 0.21875, 0.46875, 0.46875, 0.53125, 0.53125,\n",
       "            0.625  , 0.65625, 0.75   , 0.78125, 0.90625, 0.90625, 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.38888889,\n",
       "            0.38888889, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.29888738, 0.22621478, 0.17566237, 0.17017725,\n",
       "            0.12371972, 0.10687309, 0.10442498, 0.10049424, 0.07840172,\n",
       "            0.04365648, 0.03698191, 0.03285639, 0.03047785, 0.02787647,\n",
       "            0.02751429, 0.02030908, 0.01965602, 0.01419152, 0.01238675,\n",
       "            0.00957734, 0.00857692, 0.00789572])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.859), 1: np.float64(0.141)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.1875 ,\n",
       "            0.1875 , 0.21875, 0.21875, 0.4375 , 0.4375 , 0.46875, 0.46875,\n",
       "            0.53125, 0.53125, 0.625  , 0.65625, 0.75   , 0.78125, 0.90625,\n",
       "            0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.38888889,\n",
       "            0.38888889, 0.44444444, 0.44444444, 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.31916511, 0.24442195, 0.19134194, 0.18647247,\n",
       "            0.13355576, 0.11578239, 0.11152497, 0.10818601, 0.0842893 ,\n",
       "            0.04916174, 0.04695143, 0.04623722, 0.03946854, 0.03503107,\n",
       "            0.03244146, 0.02964162, 0.02936171, 0.0218929 , 0.02075182,\n",
       "            0.01486653, 0.01313995, 0.01001089, 0.00901566, 0.00825788])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.849),\n",
       "                                     1: np.float64(0.15099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.1875 ,\n",
       "            0.1875 , 0.21875, 0.21875, 0.4375 , 0.4375 , 0.46875, 0.46875,\n",
       "            0.53125, 0.53125, 0.625  , 0.65625, 0.75   , 0.78125, 0.90625,\n",
       "            0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.38888889,\n",
       "            0.38888889, 0.44444444, 0.44444444, 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.33760803, 0.26120868, 0.20804924, 0.20300156,\n",
       "            0.14273753, 0.12506547, 0.11789636, 0.1155637 , 0.0904488 ,\n",
       "            0.0527704 , 0.05086311, 0.04901199, 0.04157348, 0.03723645,\n",
       "            0.03423586, 0.03133067, 0.03121221, 0.02369133, 0.02176627,\n",
       "            0.01550623, 0.01388644, 0.0104652 , 0.00945993, 0.0086102 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.839),\n",
       "                                     1: np.float64(0.16099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.1875 ,\n",
       "            0.1875 , 0.21875, 0.21875, 0.4375 , 0.4375 , 0.46875, 0.46875,\n",
       "            0.53125, 0.53125, 0.625  , 0.65625, 0.75   , 0.78125, 0.90625,\n",
       "            0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.38888889,\n",
       "            0.38888889, 0.44444444, 0.44444444, 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.35406452, 0.27700784, 0.22318272, 0.2193297 ,\n",
       "            0.15187632, 0.134234  , 0.12374678, 0.12273444, 0.0962238 ,\n",
       "            0.05588952, 0.05474021, 0.05168586, 0.04363401, 0.03933759,\n",
       "            0.03604442, 0.03302473, 0.03302296, 0.02549513, 0.02278892,\n",
       "            0.01613471, 0.01465567, 0.0108958 , 0.00989938, 0.00895312])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.829),\n",
       "                                     1: np.float64(0.17099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.4375 , 0.4375 , 0.46875, 0.46875, 0.53125, 0.53125,\n",
       "            0.59375, 0.625  , 0.75   , 0.78125, 0.90625, 0.90625, 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.37152705, 0.29328865, 0.23769195, 0.23602297,\n",
       "            0.16135416, 0.13003797, 0.10256343, 0.05935708, 0.05869206,\n",
       "            0.05433564, 0.04615294, 0.04163353, 0.03805645, 0.03615065,\n",
       "            0.03502732, 0.02740747, 0.02391817, 0.01685074, 0.01553745,\n",
       "            0.0114132 , 0.01044346, 0.00936814])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.8190000000000001),\n",
       "                                     1: np.float64(0.18099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.40625, 0.40625, 0.46875, 0.46875, 0.53125, 0.53125,\n",
       "            0.59375, 0.625  , 0.75   , 0.78125, 0.90625, 0.90625, 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.38657527, 0.30789224, 0.25189508, 0.25135727,\n",
       "            0.16981007, 0.13704321, 0.10847215, 0.06439155, 0.06271432,\n",
       "            0.05716345, 0.04828943, 0.04387439, 0.03987601, 0.03805399,\n",
       "            0.03681464, 0.02922358, 0.02491887, 0.01747216, 0.0162846 ,\n",
       "            0.01185988, 0.01087019, 0.00970412])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.809),\n",
       "                                     1: np.float64(0.19099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.40625, 0.40625, 0.46875, 0.46875, 0.53125, 0.53125,\n",
       "            0.59375, 0.625  , 0.75   , 0.78125, 0.90625, 0.90625, 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.11111111, 0.11111111,\n",
       "            0.22222222, 0.22222222, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.40200066, 0.32325059, 0.2713448 , 0.26772345,\n",
       "            0.17919972, 0.14441425, 0.11459564, 0.0683875 , 0.06679862,\n",
       "            0.05989552, 0.05083194, 0.04615933, 0.04192924, 0.04015243,\n",
       "            0.03883417, 0.03119868, 0.02605629, 0.01819499, 0.017197  ,\n",
       "            0.01236453, 0.01142213, 0.01011332])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.799),\n",
       "                                     1: np.float64(0.20099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.40625, 0.40625, 0.46875, 0.46875, 0.53125, 0.53125,\n",
       "            0.59375, 0.625  , 0.75   , 0.78125, 0.90625, 0.90625, 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.11111111, 0.11111111,\n",
       "            0.22222222, 0.22222222, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.41600251, 0.33832716, 0.28524007, 0.2823434 ,\n",
       "            0.18830754, 0.1524064 , 0.12019004, 0.0724002 , 0.07063662,\n",
       "            0.0628803 , 0.05360006, 0.04861995, 0.04429217, 0.04237126,\n",
       "            0.04088309, 0.03303861, 0.02736408, 0.01900454, 0.01815457,\n",
       "            0.0128643 , 0.01195306, 0.010541  ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.789),\n",
       "                                     1: np.float64(0.21099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.40625, 0.40625, 0.46875, 0.46875, 0.53125, 0.53125,\n",
       "            0.59375, 0.625  , 0.75   , 0.78125, 0.90625, 0.90625, 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.11111111, 0.11111111,\n",
       "            0.22222222, 0.22222222, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.42949952, 0.35171911, 0.30061274, 0.2983898 ,\n",
       "            0.19715849, 0.15893417, 0.125947  , 0.076006  , 0.07504121,\n",
       "            0.06561199, 0.05560263, 0.05097633, 0.0458424 , 0.04435195,\n",
       "            0.04283229, 0.03429082, 0.0282741 , 0.01955535, 0.0189704 ,\n",
       "            0.01335053, 0.01245752, 0.01088304])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.779),\n",
       "                                     1: np.float64(0.22099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.40625, 0.40625, 0.46875, 0.46875, 0.53125, 0.53125,\n",
       "            0.59375, 0.625  , 0.75   , 0.78125, 0.90625, 0.90625, 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.11111111, 0.11111111,\n",
       "            0.22222222, 0.22222222, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.44240877, 0.36553519, 0.31570812, 0.31403592,\n",
       "            0.20558025, 0.16629178, 0.13216934, 0.0803884 , 0.07939457,\n",
       "            0.06844771, 0.05832019, 0.05328792, 0.04811313, 0.04652851,\n",
       "            0.04484179, 0.03572148, 0.02945994, 0.02031839, 0.01995716,\n",
       "            0.01386913, 0.01302611, 0.01130834])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.769),\n",
       "                                     1: np.float64(0.23099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.40625, 0.40625, 0.46875, 0.46875, 0.53125, 0.53125,\n",
       "            0.59375, 0.625  , 0.75   , 0.78125, 0.90625, 0.90625, 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.11111111, 0.11111111,\n",
       "            0.22222222, 0.22222222, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.45493169, 0.37929795, 0.32971883, 0.32930791,\n",
       "            0.21457269, 0.17375024, 0.13791006, 0.08445203, 0.08369598,\n",
       "            0.07134736, 0.06098851, 0.0557379 , 0.05026903, 0.04876486,\n",
       "            0.04697106, 0.03715751, 0.03064617, 0.02105854, 0.02095579,\n",
       "            0.01438312, 0.01361214, 0.01172504])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.759),\n",
       "                                     1: np.float64(0.24099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.125  , 0.125  , 0.21875, 0.21875, 0.40625,\n",
       "            0.40625, 0.46875, 0.46875, 0.53125, 0.53125, 0.59375, 0.625  ,\n",
       "            0.78125, 0.8125 , 0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.22222222, 0.22222222,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.66666667,\n",
       "            0.66666667, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.46687633, 0.34406719, 0.22340124, 0.18098243,\n",
       "            0.14407111, 0.08871206, 0.08831824, 0.07448383, 0.06367108,\n",
       "            0.05822435, 0.05250433, 0.05105261, 0.04910754, 0.03193133,\n",
       "            0.03185526, 0.02606461, 0.02200545, 0.01495926, 0.01424336,\n",
       "            0.0121716 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7490000000000001),\n",
       "                                     1: np.float64(0.25099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.375  , 0.375  , 0.46875, 0.46875, 0.53125, 0.53125, 0.5625 ,\n",
       "            0.5625 , 0.59375, 0.625  , 0.78125, 0.8125 , 0.875  , 0.875  ,\n",
       "            0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.66666667, 0.66666667, 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.48053961, 0.47756781, 0.35878847, 0.23253458,\n",
       "            0.18811017, 0.14884734, 0.09664227, 0.0928064 , 0.07750775,\n",
       "            0.06631858, 0.06067009, 0.05816546, 0.05462482, 0.05452577,\n",
       "            0.05329271, 0.05129107, 0.03338978, 0.03296795, 0.02723656,\n",
       "            0.0230443 , 0.01551717, 0.01489721, 0.01261461])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7390000000000001),\n",
       "                                     1: np.float64(0.26099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.375  , 0.375  , 0.46875, 0.46875, 0.53125, 0.53125, 0.5625 ,\n",
       "            0.5625 , 0.59375, 0.625  , 0.78125, 0.8125 , 0.875  , 0.875  ,\n",
       "            0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.66666667, 0.66666667, 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.49571923, 0.48900019, 0.37311987, 0.24075187,\n",
       "            0.19529454, 0.15283989, 0.10056618, 0.0974187 , 0.08072495,\n",
       "            0.06918898, 0.06307949, 0.06062689, 0.05703195, 0.05685377,\n",
       "            0.0555344 , 0.05329152, 0.03473436, 0.0341473 , 0.02828959,\n",
       "            0.02407423, 0.0161118 , 0.01550395, 0.01307554])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7290000000000001),\n",
       "                                     1: np.float64(0.27099999999999996)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.375  , 0.375  , 0.46875, 0.46875, 0.53125, 0.53125, 0.5625 ,\n",
       "            0.5625 , 0.59375, 0.625  , 0.78125, 0.8125 , 0.875  , 0.875  ,\n",
       "            0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.66666667, 0.66666667, 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.50888296, 0.49899616, 0.38754949, 0.24948879,\n",
       "            0.20237439, 0.15759285, 0.10501383, 0.10224805, 0.0837626 ,\n",
       "            0.07203537, 0.06581248, 0.06322187, 0.05970325, 0.05918875,\n",
       "            0.05799802, 0.05562999, 0.03631223, 0.03539698, 0.02954606,\n",
       "            0.02527798, 0.01671019, 0.01620805, 0.01354519])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7190000000000001),\n",
       "                                     1: np.float64(0.28099999999999997)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.375  , 0.375  , 0.46875, 0.46875, 0.53125,\n",
       "            0.53125, 0.5625 , 0.5625 , 0.59375, 0.625  , 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.66666667, 0.66666667, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.52301442, 0.50892841, 0.40166651, 0.25831759,\n",
       "            0.2100166 , 0.16785128, 0.16353575, 0.16176037, 0.10908796,\n",
       "            0.10711232, 0.08711706, 0.07504934, 0.06831485, 0.0658072 ,\n",
       "            0.06233511, 0.0616357 , 0.06044228, 0.05789377, 0.03774986,\n",
       "            0.03666916, 0.03072485, 0.02645158, 0.01729186, 0.01691901,\n",
       "            0.01401849])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7090000000000001),\n",
       "                                     1: np.float64(0.291)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.375  , 0.375  , 0.46875, 0.46875, 0.53125,\n",
       "            0.53125, 0.5625 , 0.5625 , 0.59375, 0.625  , 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.66666667, 0.66666667, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.53585681, 0.51875842, 0.41517084, 0.26707297,\n",
       "            0.21761444, 0.17333947, 0.1695673 , 0.16638223, 0.11351892,\n",
       "            0.11176023, 0.09042115, 0.0777564 , 0.07105189, 0.06846247,\n",
       "            0.06508324, 0.06403082, 0.06292829, 0.0602353 , 0.03931318,\n",
       "            0.03795384, 0.03197555, 0.02767609, 0.01790505, 0.01764005,\n",
       "            0.01450283])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6990000000000001),\n",
       "                                     1: np.float64(0.30099999999999993)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.375  , 0.375  , 0.46875, 0.46875, 0.53125,\n",
       "            0.53125, 0.5625 , 0.5625 , 0.59375, 0.625  , 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.66666667, 0.66666667, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.54870502, 0.52785483, 0.42834162, 0.27533968,\n",
       "            0.22493723, 0.1796859 , 0.17630218, 0.17068323, 0.11787828,\n",
       "            0.11676945, 0.09383249, 0.08027269, 0.07374303, 0.07120915,\n",
       "            0.06795511, 0.06682056, 0.06556918, 0.06257899, 0.04088982,\n",
       "            0.03939277, 0.03326349, 0.02902091, 0.01858673, 0.01842732,\n",
       "            0.01505483])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6890000000000001),\n",
       "                                     1: np.float64(0.31099999999999994)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.28125, 0.28125, 0.375  , 0.375  , 0.46875, 0.46875, 0.53125,\n",
       "            0.53125, 0.5625 , 0.5625 , 0.59375, 0.625  , 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.66666667, 0.66666667, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.56111137, 0.53698416, 0.44203915, 0.28426471,\n",
       "            0.23253001, 0.18605057, 0.17667496, 0.17514121, 0.12220425,\n",
       "            0.12205308, 0.09751748, 0.08279563, 0.07652102, 0.07404189,\n",
       "            0.07088068, 0.06941867, 0.06818706, 0.06498658, 0.04250355,\n",
       "            0.04067461, 0.0345491 , 0.03034833, 0.01928164, 0.01923252,\n",
       "            0.0156023 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.679),\n",
       "                                     1: np.float64(0.32099999999999995)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.28125, 0.28125, 0.34375, 0.34375, 0.46875, 0.46875, 0.53125,\n",
       "            0.53125, 0.5625 , 0.5625 , 0.59375, 0.625  , 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.66666667, 0.66666667, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.57277283, 0.54540084, 0.45541945, 0.29404305,\n",
       "            0.24023922, 0.19149996, 0.18285213, 0.18009699, 0.15858709,\n",
       "            0.12721056, 0.10101034, 0.08563499, 0.07926161, 0.07679069,\n",
       "            0.07392171, 0.07200992, 0.07095674, 0.06766833, 0.0442237 ,\n",
       "            0.04209116, 0.03597664, 0.03175992, 0.02380091, 0.02011422,\n",
       "            0.01611929])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.669),\n",
       "                                     1: np.float64(0.33099999999999996)}),\n",
       "    'fpr': np.float64(0.0625),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.28125, 0.28125, 0.34375, 0.34375, 0.46875, 0.46875, 0.53125,\n",
       "            0.53125, 0.5625 , 0.5625 , 0.59375, 0.625  , 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.66666667, 0.66666667, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.58514821, 0.55394135, 0.46737999, 0.30120192,\n",
       "            0.24764029, 0.19792749, 0.18895897, 0.18384629, 0.16370961,\n",
       "            0.1322491 , 0.10475883, 0.08791699, 0.08212861, 0.07977192,\n",
       "            0.07694459, 0.07498376, 0.07366254, 0.06986318, 0.04577229,\n",
       "            0.04353155, 0.03719755, 0.03315624, 0.02471575, 0.02086088,\n",
       "            0.01669754])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.659),\n",
       "                                     1: np.float64(0.34099999999999997)}),\n",
       "    'fpr': np.float64(0.09375),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.28125, 0.28125, 0.34375, 0.34375, 0.46875, 0.46875, 0.53125,\n",
       "            0.53125, 0.5625 , 0.5625 , 0.59375, 0.625  , 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.66666667, 0.66666667, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.59544566, 0.5629633 , 0.48056919, 0.31095971,\n",
       "            0.25501012, 0.20392111, 0.195256  , 0.18924677, 0.16828331,\n",
       "            0.13768305, 0.10831955, 0.09093923, 0.08507617, 0.0826441 ,\n",
       "            0.08014283, 0.07759882, 0.07662568, 0.072829  , 0.04779134,\n",
       "            0.044974  , 0.03882535, 0.03467846, 0.02552365, 0.02188512,\n",
       "            0.01726671])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.649),\n",
       "                                     1: np.float64(0.3509999999999999)}),\n",
       "    'fpr': np.float64(0.09375),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.28125, 0.28125, 0.34375, 0.34375, 0.46875, 0.46875, 0.53125,\n",
       "            0.53125, 0.5625 , 0.5625 , 0.59375, 0.625  , 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.66666667, 0.66666667, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.60632124, 0.57068214, 0.49289731, 0.31930152,\n",
       "            0.2627062 , 0.21036349, 0.20160608, 0.19391567, 0.17309296,\n",
       "            0.14334342, 0.11229797, 0.09367605, 0.08812455, 0.08566848,\n",
       "            0.08354869, 0.08066536, 0.07954511, 0.07537607, 0.04956136,\n",
       "            0.04649133, 0.04022475, 0.03626477, 0.02643096, 0.02279968,\n",
       "            0.01788228])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.639),\n",
       "                                     1: np.float64(0.36099999999999993)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.28125, 0.28125, 0.34375, 0.34375, 0.46875, 0.46875, 0.53125,\n",
       "            0.53125, 0.5625 , 0.5625 , 0.59375, 0.625  , 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.66666667, 0.66666667, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.61712403, 0.57849119, 0.50501712, 0.32804362,\n",
       "            0.27048502, 0.21639996, 0.20796796, 0.19848012, 0.17789098,\n",
       "            0.14879335, 0.11624731, 0.09652458, 0.09111338, 0.08876965,\n",
       "            0.0869066 , 0.08367316, 0.08256014, 0.07807683, 0.0513834 ,\n",
       "            0.04801775, 0.04171084, 0.03787065, 0.02733329, 0.02375982,\n",
       "            0.01849407])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.629),\n",
       "                                     1: np.float64(0.37099999999999994)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.28125, 0.28125, 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.53125, 0.53125, 0.5625 , 0.5625 , 0.59375, 0.625  ,\n",
       "            0.78125, 0.8125 , 0.875  , 0.875  , 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.66666667,\n",
       "            0.66666667, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.62758358, 0.58618607, 0.51713349, 0.33727753,\n",
       "            0.27835212, 0.23521815, 0.22284574, 0.22238464, 0.21433774,\n",
       "            0.20333823, 0.18263902, 0.15427565, 0.1202207 , 0.09947526,\n",
       "            0.09409282, 0.09185169, 0.0903118 , 0.08669004, 0.08558126,\n",
       "            0.08081726, 0.05320415, 0.04953009, 0.04320241, 0.0395017 ,\n",
       "            0.02821413, 0.02474188, 0.01909244])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.619),\n",
       "                                     1: np.float64(0.38099999999999995)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.28125, 0.28125, 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.53125, 0.53125, 0.5625 , 0.5625 , 0.59375, 0.625  ,\n",
       "            0.78125, 0.8125 , 0.875  , 0.875  , 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.66666667,\n",
       "            0.66666667, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.63775254, 0.59360591, 0.52865032, 0.34611654,\n",
       "            0.28618158, 0.24051958, 0.23005859, 0.22866359, 0.22080936,\n",
       "            0.20814994, 0.18780979, 0.16003169, 0.12444537, 0.10264895,\n",
       "            0.09728241, 0.09520932, 0.09402401, 0.09004868, 0.08894068,\n",
       "            0.08380661, 0.05525287, 0.05125935, 0.04489261, 0.04134066,\n",
       "            0.02922989, 0.02585691, 0.01979464])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.609),\n",
       "                                     1: np.float64(0.39099999999999996)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.53125, 0.53125, 0.5625 , 0.5625 , 0.59375, 0.625  ,\n",
       "            0.78125, 0.8125 , 0.875  , 0.875  , 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.66666667,\n",
       "            0.66666667, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.64802623, 0.60078608, 0.53993676, 0.35488824,\n",
       "            0.29419534, 0.24588859, 0.2374976 , 0.23481271, 0.21292749,\n",
       "            0.21273788, 0.19295718, 0.16566591, 0.12870118, 0.10586788,\n",
       "            0.10034051, 0.09853112, 0.09772706, 0.09349873, 0.09227814,\n",
       "            0.08670292, 0.05719316, 0.05299117, 0.04652435, 0.04318517,\n",
       "            0.03022576, 0.02695007, 0.0204808 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5990000000000001),\n",
       "                                     1: np.float64(0.4009999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.5625 , 0.5625 ,\n",
       "            0.59375, 0.625  , 0.78125, 0.8125 , 0.875  , 0.875  , 0.9375 ,\n",
       "            0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.65739325, 0.607519  , 0.55119119, 0.36307756,\n",
       "            0.30231277, 0.2512797 , 0.24526102, 0.24142149, 0.2193487 ,\n",
       "            0.21744184, 0.19795836, 0.17165602, 0.13320053, 0.11728776,\n",
       "            0.10888653, 0.10880746, 0.10374047, 0.10195507, 0.10153749,\n",
       "            0.09694229, 0.09546198, 0.08939009, 0.05910516, 0.05464442,\n",
       "            0.04804167, 0.04504289, 0.03129321, 0.02800362, 0.02119337])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5890000000000001),\n",
       "                                     1: np.float64(0.4109999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.5625 , 0.5625 ,\n",
       "            0.59375, 0.625  , 0.78125, 0.8125 , 0.875  , 0.875  , 0.9375 ,\n",
       "            0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.66700186, 0.61456947, 0.56204054, 0.37231753,\n",
       "            0.31040681, 0.256998  , 0.25293982, 0.24762795, 0.22634837,\n",
       "            0.22236016, 0.20341091, 0.17744216, 0.13776189, 0.12131277,\n",
       "            0.11259906, 0.11228577, 0.10705306, 0.10562367, 0.1055065 ,\n",
       "            0.10058492, 0.09911357, 0.09259982, 0.06128129, 0.05647732,\n",
       "            0.04988446, 0.04708994, 0.03238761, 0.02925038, 0.02197181])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5790000000000001),\n",
       "                                     1: np.float64(0.42099999999999993)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 , 0.59375, 0.625  ,\n",
       "            0.78125, 0.8125 , 0.875  , 0.875  , 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.67563499, 0.62124826, 0.57292417, 0.38052825,\n",
       "            0.31860218, 0.26200119, 0.26055146, 0.25444714, 0.23318894,\n",
       "            0.22767128, 0.20846788, 0.18386926, 0.14244699, 0.12538441,\n",
       "            0.11627769, 0.11562389, 0.10971014, 0.10429738, 0.10256862,\n",
       "            0.09554705, 0.06340404, 0.05834776, 0.05155012, 0.04913643,\n",
       "            0.03349956, 0.03044312, 0.02271178])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5690000000000001),\n",
       "                                     1: np.float64(0.43099999999999994)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 , 0.59375, 0.625  ,\n",
       "            0.78125, 0.8125 , 0.875  , 0.875  , 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.68430336, 0.62778153, 0.58336807, 0.52218706,\n",
       "            0.38939011, 0.38908302, 0.2683985 , 0.26109831, 0.2402622 ,\n",
       "            0.23292645, 0.21382296, 0.19024772, 0.14734559, 0.12965045,\n",
       "            0.12014265, 0.11919893, 0.1140747 , 0.10820531, 0.10631991,\n",
       "            0.09875355, 0.06567715, 0.06033467, 0.05339614, 0.05134093,\n",
       "            0.03468644, 0.0317516 , 0.02352934])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.559),\n",
       "                                     1: np.float64(0.44099999999999995)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 , 0.59375, 0.625  ,\n",
       "            0.78125, 0.8125 , 0.875  , 0.875  , 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.69343112, 0.63448212, 0.5936134 , 0.53133261,\n",
       "            0.3989133 , 0.3984343 , 0.2765734 , 0.26749538, 0.24740973,\n",
       "            0.23775949, 0.21956895, 0.19610815, 0.15219274, 0.13372025,\n",
       "            0.12389296, 0.12281175, 0.11764002, 0.11209323, 0.11018509,\n",
       "            0.102042  , 0.06792294, 0.06220727, 0.05532008, 0.05356084,\n",
       "            0.03584885, 0.03308546, 0.02436689])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.549),\n",
       "                                     1: np.float64(0.45099999999999996)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 , 0.59375, 0.625  ,\n",
       "            0.78125, 0.8125 , 0.875  , 0.875  , 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.70200276, 0.64083448, 0.60191456, 0.53985138,\n",
       "            0.40874418, 0.40702953, 0.28479913, 0.27430557, 0.25452275,\n",
       "            0.24286648, 0.22521173, 0.2025679 , 0.15737336, 0.13802899,\n",
       "            0.12782323, 0.12646674, 0.1213653 , 0.11619827, 0.11417302,\n",
       "            0.10533181, 0.07027515, 0.0642706 , 0.05724512, 0.05588861,\n",
       "            0.03710679, 0.0344484 , 0.02523424])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5390000000000001),\n",
       "                                     1: np.float64(0.4609999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 , 0.59375, 0.625  ,\n",
       "            0.78125, 0.8125 , 0.875  , 0.875  , 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.71025991, 0.64710585, 0.60992134, 0.54823273,\n",
       "            0.41861124, 0.41569295, 0.29314268, 0.28128323, 0.26197622,\n",
       "            0.24832752, 0.23035772, 0.20944236, 0.16265081, 0.14255998,\n",
       "            0.13171714, 0.13022338, 0.12507726, 0.12032984, 0.11801507,\n",
       "            0.10853265, 0.07255252, 0.06626363, 0.05907351, 0.0582507 ,\n",
       "            0.03828926, 0.03583548, 0.02607041])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5290000000000001),\n",
       "                                     1: np.float64(0.4709999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 , 0.59375, 0.625  ,\n",
       "            0.78125, 0.8125 , 0.875  , 0.875  , 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.71871948, 0.65327585, 0.61799288, 0.55693496,\n",
       "            0.42847582, 0.42459275, 0.30172424, 0.2883721 , 0.2694498 ,\n",
       "            0.25352594, 0.23627841, 0.21620758, 0.16813261, 0.14713694,\n",
       "            0.13578786, 0.13421036, 0.12886783, 0.12478174, 0.12230057,\n",
       "            0.11200838, 0.07502356, 0.06845074, 0.06113253, 0.06080684,\n",
       "            0.03960107, 0.03733   , 0.02700712])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5190000000000001),\n",
       "                                     1: np.float64(0.4809999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.5625 , 0.5625 ,\n",
       "            0.59375, 0.625  , 0.78125, 0.8125 , 0.84375, 0.84375, 0.9375 ,\n",
       "            0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.72633251, 0.65933968, 0.62591089, 0.56476211,\n",
       "            0.43821227, 0.43355818, 0.31038249, 0.29521179, 0.27722106,\n",
       "            0.25925932, 0.24200661, 0.22293014, 0.17369059, 0.15191622,\n",
       "            0.14001278, 0.13837633, 0.13722075, 0.1329958 , 0.13286436,\n",
       "            0.12926999, 0.12657739, 0.11560928, 0.07759751, 0.07068928,\n",
       "            0.06702861, 0.06347739, 0.04098372, 0.03894072, 0.02798989])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5090000000000001),\n",
       "                                     1: np.float64(0.49099999999999994)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.5625 , 0.5625 ,\n",
       "            0.59375, 0.625  , 0.78125, 0.8125 , 0.84375, 0.84375, 0.9375 ,\n",
       "            0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.73371592, 0.66505324, 0.63374698, 0.57243693,\n",
       "            0.44784064, 0.44326668, 0.31882434, 0.30207967, 0.28511361,\n",
       "            0.26539118, 0.24796558, 0.22988882, 0.17923917, 0.15688813,\n",
       "            0.1444398 , 0.14277369, 0.1424703 , 0.13734261, 0.13692543,\n",
       "            0.13400654, 0.13108136, 0.11945567, 0.08032469, 0.07307973,\n",
       "            0.06963093, 0.06638723, 0.04243754, 0.04069378, 0.02901327])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4990000000000001),\n",
       "                                     1: np.float64(0.5009999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.53125, 0.53125, 0.5625 , 0.5625 , 0.59375, 0.625  ,\n",
       "            0.78125, 0.8125 , 0.84375, 0.84375, 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.74103052, 0.67138428, 0.64153027, 0.5803771 ,\n",
       "            0.4577447 , 0.45214919, 0.32768818, 0.3093042 , 0.29290837,\n",
       "            0.27161791, 0.25433956, 0.23702971, 0.18557585, 0.16223955,\n",
       "            0.14789043, 0.14205752, 0.14132012, 0.13891414, 0.13588547,\n",
       "            0.12336474, 0.08316751, 0.07559942, 0.07232768, 0.06925058,\n",
       "            0.04395038, 0.04243936, 0.03011207])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4890000000000001),\n",
       "                                     1: np.float64(0.5109999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.53125, 0.53125, 0.5625 , 0.5625 , 0.59375, 0.625  ,\n",
       "            0.78125, 0.8125 , 0.84375, 0.84375, 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.74872529, 0.67719881, 0.64948374, 0.58798301,\n",
       "            0.46789748, 0.46138237, 0.33660511, 0.31540282, 0.3010547 ,\n",
       "            0.27740168, 0.26058564, 0.24424779, 0.19161108, 0.16750749,\n",
       "            0.15348533, 0.14675289, 0.14551561, 0.14399015, 0.1408418 ,\n",
       "            0.12740288, 0.08604551, 0.0781679 , 0.07504178, 0.07235119,\n",
       "            0.04545671, 0.04427795, 0.03119197])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4790000000000001),\n",
       "                                     1: np.float64(0.5209999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.53125, 0.53125, 0.5625 , 0.5625 , 0.625  , 0.65625,\n",
       "            0.78125, 0.8125 , 0.84375, 0.84375, 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.75600451, 0.68307492, 0.6570209 , 0.59597152,\n",
       "            0.47806595, 0.47025794, 0.34639074, 0.32202812, 0.3095754 ,\n",
       "            0.28332741, 0.26704573, 0.25169543, 0.1979444 , 0.1727367 ,\n",
       "            0.15843047, 0.15172751, 0.1500169 , 0.14926156, 0.13208505,\n",
       "            0.13144088, 0.0890738 , 0.08080933, 0.07797577, 0.07559981,\n",
       "            0.04714958, 0.04623699, 0.03241842])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4690000000000001),\n",
       "                                     1: np.float64(0.5309999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.53125, 0.53125, 0.625  , 0.65625, 0.78125, 0.8125 ,\n",
       "            0.84375, 0.84375, 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.76275025, 0.68859033, 0.66430195, 0.60349652,\n",
       "            0.48772258, 0.47961951, 0.35556367, 0.32838004, 0.31780569,\n",
       "            0.28993545, 0.27346302, 0.25916045, 0.20448386, 0.17832975,\n",
       "            0.16320232, 0.15471132, 0.13669887, 0.13554304, 0.09207423,\n",
       "            0.0835357 , 0.08102261, 0.07896297, 0.04881482, 0.04823108,\n",
       "            0.03362098])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4590000000000001),\n",
       "                                     1: np.float64(0.5409999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875,\n",
       "            0.46875, 0.53125, 0.53125, 0.625  , 0.65625, 0.78125, 0.8125 ,\n",
       "            0.84375, 0.84375, 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.76984636, 0.69436061, 0.67198979, 0.61146272,\n",
       "            0.49757776, 0.48938909, 0.36530878, 0.33551782, 0.32652689,\n",
       "            0.29652954, 0.28031964, 0.2667012 , 0.21136496, 0.18418342,\n",
       "            0.16814869, 0.16046124, 0.14146607, 0.13993474, 0.09524088,\n",
       "            0.0864765 , 0.08422907, 0.08249967, 0.0505869 , 0.05038201,\n",
       "            0.03492886])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.44900000000000007),\n",
       "                                     1: np.float64(0.5509999999999999)}),\n",
       "    'fpr': np.float64(0.15625),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.28125, 0.28125, 0.3125 , 0.3125 , 0.34375,\n",
       "            0.34375, 0.46875, 0.46875, 0.53125, 0.53125, 0.625  , 0.65625,\n",
       "            0.78125, 0.8125 , 0.84375, 0.84375, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.27777778, 0.27777778,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.61111111, 0.61111111, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.77608411, 0.70021113, 0.67935124, 0.61797231,\n",
       "            0.50782495, 0.49846853, 0.37463662, 0.34690954, 0.34199548,\n",
       "            0.34184867, 0.33516952, 0.30369039, 0.28706017, 0.27447662,\n",
       "            0.21813404, 0.19014122, 0.17348601, 0.16618044, 0.14630209,\n",
       "            0.144424  , 0.09862609, 0.08946397, 0.08749508, 0.08618173,\n",
       "            0.06252988, 0.05259458, 0.0362108 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.43900000000000006),\n",
       "                                     1: np.float64(0.5609999999999999)}),\n",
       "    'fpr': np.float64(0.15625),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.28125, 0.28125, 0.3125 , 0.3125 , 0.375  ,\n",
       "            0.375  , 0.46875, 0.46875, 0.53125, 0.53125, 0.625  , 0.65625,\n",
       "            0.78125, 0.8125 , 0.84375, 0.84375, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.27777778, 0.27777778,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.61111111, 0.61111111, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.78250104, 0.7058693 , 0.68669998, 0.62537354,\n",
       "            0.5178431 , 0.50827631, 0.38437051, 0.35511732, 0.35006394,\n",
       "            0.34871035, 0.34421355, 0.31112193, 0.28359101, 0.28277782,\n",
       "            0.2254389 , 0.19658413, 0.1789345 , 0.17240161, 0.15145832,\n",
       "            0.14913502, 0.10211618, 0.09267957, 0.09101891, 0.09013451,\n",
       "            0.06493809, 0.05500787, 0.03762105])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.42900000000000005),\n",
       "                                     1: np.float64(0.571)}),\n",
       "    'fpr': np.float64(0.15625),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.28125, 0.28125, 0.3125 , 0.3125 ,\n",
       "            0.375  , 0.375  , 0.46875, 0.46875, 0.5    , 0.5    , 0.53125,\n",
       "            0.53125, 0.625  , 0.65625, 0.78125, 0.8125 , 0.84375, 0.84375,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.61111111, 0.61111111, 0.66666667,\n",
       "            0.66666667, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.78940636, 0.71186422, 0.71135562, 0.69422106,\n",
       "            0.63329787, 0.52783262, 0.51793675, 0.39488881, 0.36277932,\n",
       "            0.35805535, 0.35641214, 0.35339917, 0.3176645 , 0.29236757,\n",
       "            0.29055352, 0.23294803, 0.20277142, 0.19120838, 0.1844018 ,\n",
       "            0.18417818, 0.17848279, 0.15675965, 0.15394569, 0.1053322 ,\n",
       "            0.0959415 , 0.09466392, 0.09413308, 0.06745749, 0.05746584,\n",
       "            0.0391444 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.41900000000000004),\n",
       "                                     1: np.float64(0.581)}),\n",
       "    'fpr': np.float64(0.15625),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.28125, 0.28125, 0.3125 , 0.3125 ,\n",
       "            0.375  , 0.375  , 0.46875, 0.46875, 0.5    , 0.5    , 0.53125,\n",
       "            0.53125, 0.625  , 0.65625, 0.78125, 0.8125 , 0.8125 , 0.90625,\n",
       "            0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.61111111, 0.61111111, 0.66666667,\n",
       "            0.66666667, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.79510963, 0.72005731, 0.71688913, 0.70145143,\n",
       "            0.63958846, 0.53768311, 0.52812738, 0.40435084, 0.37060625,\n",
       "            0.36621322, 0.36277922, 0.36271037, 0.32607529, 0.30268613,\n",
       "            0.2988288 , 0.24015884, 0.20948052, 0.1986592 , 0.19059753,\n",
       "            0.18997376, 0.18399347, 0.16201719, 0.15898859, 0.10837059,\n",
       "            0.09958848, 0.09856927, 0.06989465, 0.06011356, 0.04057701])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.40900000000000014),\n",
       "                                     1: np.float64(0.5909999999999999)}),\n",
       "    'fpr': np.float64(0.15625),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  , 0.375  ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.625  ,\n",
       "            0.65625, 0.78125, 0.8125 , 0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.61111111, 0.61111111, 0.66666667, 0.66666667, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.80153057, 0.72764574, 0.72234432, 0.70840998,\n",
       "            0.647493  , 0.54804482, 0.53733296, 0.41531749, 0.37938295,\n",
       "            0.37201888, 0.33308595, 0.31204665, 0.30749926, 0.24849072,\n",
       "            0.21615461, 0.20587239, 0.19688504, 0.19571475, 0.19045218,\n",
       "            0.16790625, 0.16402025, 0.11192611, 0.10312445, 0.10297412,\n",
       "            0.07273351, 0.06284732, 0.04233748])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.39900000000000013),\n",
       "                                     1: np.float64(0.6009999999999999)}),\n",
       "    'fpr': np.float64(0.1875),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  , 0.375  ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.625  ,\n",
       "            0.65625, 0.78125, 0.78125, 0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.61111111, 0.61111111, 0.66666667, 0.66666667, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.80751   , 0.73531462, 0.72781647, 0.71543217,\n",
       "            0.6543955 , 0.5582129 , 0.54712162, 0.42601726, 0.38767975,\n",
       "            0.38164886, 0.34121584, 0.32221262, 0.31600992, 0.25661084,\n",
       "            0.22303007, 0.21356469, 0.20341333, 0.20159453, 0.19673805,\n",
       "            0.17364668, 0.16920897, 0.11534609, 0.10770224, 0.10717777,\n",
       "            0.07551053, 0.06568598, 0.04402754])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3890000000000001),\n",
       "                                     1: np.float64(0.6109999999999999)}),\n",
       "    'fpr': np.float64(0.1875),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  , 0.375  ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.625  ,\n",
       "            0.65625, 0.78125, 0.78125, 0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.61111111, 0.61111111, 0.66666667, 0.66666667, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.8132858 , 0.74289107, 0.73316892, 0.7226244 ,\n",
       "            0.66116776, 0.56811392, 0.55741854, 0.4365495 , 0.3958601 ,\n",
       "            0.39152496, 0.34965023, 0.3319241 , 0.32466707, 0.26491574,\n",
       "            0.23047226, 0.22164349, 0.21060818, 0.20780021, 0.20318359,\n",
       "            0.17952887, 0.17485709, 0.11899337, 0.11280892, 0.11134502,\n",
       "            0.07854322, 0.06883037, 0.0458217 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3790000000000001),\n",
       "                                     1: np.float64(0.6209999999999999)}),\n",
       "    'fpr': np.float64(0.21875),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  , 0.375  ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.625  ,\n",
       "            0.65625, 0.78125, 0.78125, 0.8125 , 0.84375, 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.61111111, 0.61111111, 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.81900703, 0.75029074, 0.73855768, 0.72971545,\n",
       "            0.66823552, 0.57834673, 0.56704209, 0.44741249, 0.40453494,\n",
       "            0.40049739, 0.35774834, 0.34001605, 0.3338573 , 0.27382628,\n",
       "            0.23819054, 0.23006723, 0.21453241, 0.21430642, 0.2100745 ,\n",
       "            0.18584987, 0.18067122, 0.1228738 , 0.11812755, 0.11581452,\n",
       "            0.11549007, 0.08176059, 0.07211267, 0.04776896])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3690000000000001),\n",
       "                                     1: np.float64(0.6309999999999999)}),\n",
       "    'fpr': np.float64(0.21875),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  , 0.375  ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.625  ,\n",
       "            0.65625, 0.78125, 0.78125, 0.8125 , 0.84375, 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.61111111, 0.61111111, 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.82452099, 0.75736435, 0.74396887, 0.73615943,\n",
       "            0.6753438 , 0.58862517, 0.57627908, 0.45833744, 0.41361194,\n",
       "            0.40965348, 0.3657846 , 0.34821834, 0.34329327, 0.28305696,\n",
       "            0.24606281, 0.23860902, 0.22229947, 0.22105467, 0.2172662 ,\n",
       "            0.1924295 , 0.18663224, 0.12696729, 0.12357572, 0.12068379,\n",
       "            0.11961541, 0.08514593, 0.07553907, 0.04985322])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3590000000000001),\n",
       "                                     1: np.float64(0.6409999999999999)}),\n",
       "    'fpr': np.float64(0.21875),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  , 0.375  ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.625  ,\n",
       "            0.65625, 0.78125, 0.78125, 0.8125 , 0.84375, 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.61111111, 0.61111111, 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.83001039, 0.76451625, 0.7496926 , 0.7428214 ,\n",
       "            0.68203745, 0.59896958, 0.58601483, 0.46947912, 0.42256691,\n",
       "            0.4190708 , 0.37462724, 0.35688476, 0.3527018 , 0.29252891,\n",
       "            0.25444837, 0.2476258 , 0.23063636, 0.22810333, 0.22459973,\n",
       "            0.19891124, 0.19295029, 0.13112868, 0.12936254, 0.12580883,\n",
       "            0.12430544, 0.08863785, 0.07916773, 0.05193601])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3490000000000001),\n",
       "                                     1: np.float64(0.6509999999999999)}),\n",
       "    'fpr': np.float64(0.21875),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.28125, 0.28125, 0.3125 , 0.3125 , 0.375  , 0.375  ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.625  ,\n",
       "            0.65625, 0.78125, 0.78125, 0.8125 , 0.84375, 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.61111111, 0.61111111, 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.83578256, 0.77149288, 0.75517665, 0.74915747,\n",
       "            0.6902432 , 0.60933415, 0.59566904, 0.43281861, 0.43263947,\n",
       "            0.42844298, 0.38283548, 0.36576931, 0.36274806, 0.30282356,\n",
       "            0.26296744, 0.25675704, 0.23925707, 0.23516595, 0.23264661,\n",
       "            0.20631345, 0.19938534, 0.13592012, 0.13548346, 0.13142619,\n",
       "            0.1287044 , 0.09275193, 0.08312047, 0.05449811])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3390000000000001),\n",
       "                                     1: np.float64(0.6609999999999999)}),\n",
       "    'fpr': np.float64(0.21875),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.28125, 0.28125, 0.3125 , 0.3125 , 0.375  , 0.375  ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.625  ,\n",
       "            0.65625, 0.75   , 0.75   , 0.8125 , 0.84375, 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.61111111, 0.61111111, 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.84110443, 0.77887917, 0.76060509, 0.75589956,\n",
       "            0.69669287, 0.61918996, 0.60745365, 0.44448236, 0.44176031,\n",
       "            0.43751742, 0.39388722, 0.37534397, 0.37222339, 0.31244645,\n",
       "            0.27184352, 0.26679195, 0.24910626, 0.24245454, 0.24017653,\n",
       "            0.21319218, 0.20614932, 0.1456581 , 0.14234798, 0.13729155,\n",
       "            0.13449657, 0.0966986 , 0.08736902, 0.05686487])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.32900000000000007),\n",
       "                                     1: np.float64(0.6709999999999999)}),\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.28125, 0.28125, 0.3125 , 0.3125 , 0.375  , 0.375  ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 , 0.625  ,\n",
       "            0.65625, 0.75   , 0.75   , 0.8125 , 0.84375, 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.61111111, 0.61111111, 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.84627894, 0.78547729, 0.76594874, 0.76216541,\n",
       "            0.70359034, 0.62937655, 0.6176136 , 0.45527224, 0.45110038,\n",
       "            0.44728995, 0.40338893, 0.38455752, 0.38219197, 0.32285171,\n",
       "            0.28066793, 0.27675117, 0.25832281, 0.24874943, 0.24846862,\n",
       "            0.22058378, 0.21319941, 0.15126011, 0.14916766, 0.14336524,\n",
       "            0.13952931, 0.10098843, 0.09173652, 0.05951038])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.31900000000000006),\n",
       "                                     1: np.float64(0.6809999999999999)}),\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.28125, 0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.375  , 0.375  , 0.46875, 0.46875, 0.5    , 0.5    , 0.5625 ,\n",
       "            0.5625 , 0.625  , 0.65625, 0.75   , 0.75   , 0.8125 , 0.84375,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.61111111, 0.61111111, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.8514607 , 0.77151781, 0.77130288, 0.76838068,\n",
       "            0.71075828, 0.63962321, 0.62790889, 0.46652547, 0.46112776,\n",
       "            0.45721999, 0.44712008, 0.41327278, 0.41314959, 0.39394971,\n",
       "            0.39273298, 0.3337137 , 0.28937095, 0.28702806, 0.26805467,\n",
       "            0.25803618, 0.2570664 , 0.22847956, 0.22042252, 0.15698068,\n",
       "            0.15631998, 0.14970574, 0.14529135, 0.10538705, 0.09636355,\n",
       "            0.0622254 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.30900000000000005),\n",
       "                                     1: np.float64(0.691)}),\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.28125, 0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.375  , 0.375  , 0.46875, 0.46875, 0.5    , 0.5    , 0.5625 ,\n",
       "            0.5625 , 0.625  , 0.65625, 0.71875, 0.71875, 0.8125 , 0.84375,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.61111111, 0.61111111, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.85647734, 0.77827869, 0.77694666, 0.7750126 ,\n",
       "            0.71777552, 0.64995244, 0.63800823, 0.47839189, 0.47165288,\n",
       "            0.46723898, 0.45717048, 0.4259703 , 0.42387567, 0.40434778,\n",
       "            0.40348789, 0.34522207, 0.29866301, 0.29822787, 0.27880091,\n",
       "            0.26643391, 0.26611301, 0.23659984, 0.22812115, 0.20226394,\n",
       "            0.16421946, 0.15597988, 0.1516528 , 0.11051071, 0.10144341,\n",
       "            0.06538543])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.29900000000000015),\n",
       "                                     1: np.float64(0.7009999999999998)}),\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.28125, 0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.375  , 0.375  , 0.46875, 0.46875, 0.5    , 0.5    , 0.53125,\n",
       "            0.53125, 0.625  , 0.65625, 0.71875, 0.71875, 0.8125 , 0.84375,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.55555556, 0.55555556, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.86155197, 0.78515279, 0.78248624, 0.78125953,\n",
       "            0.7248963 , 0.66023964, 0.64870979, 0.49029174, 0.48207009,\n",
       "            0.47761899, 0.46738735, 0.43872828, 0.43491622, 0.41469016,\n",
       "            0.41449433, 0.35695371, 0.3110122 , 0.309473  , 0.28966406,\n",
       "            0.27822791, 0.27558274, 0.2450345 , 0.23626615, 0.21005172,\n",
       "            0.1723262 , 0.16185196, 0.15841829, 0.11575182, 0.10676548,\n",
       "            0.06858204])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.28900000000000015),\n",
       "                                     1: np.float64(0.7109999999999999)}),\n",
       "    'fpr': np.float64(0.28125),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.28125, 0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.625  ,\n",
       "            0.65625, 0.71875, 0.71875, 0.8125 , 0.84375, 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.27777778,\n",
       "            0.27777778, 0.33333333, 0.33333333, 0.44444444, 0.44444444,\n",
       "            0.55555556, 0.55555556, 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.86628201, 0.7919218 , 0.78794514, 0.78743879,\n",
       "            0.73189239, 0.67035104, 0.65889045, 0.50227946, 0.49252543,\n",
       "            0.48830884, 0.47781178, 0.45185057, 0.42546918, 0.36921942,\n",
       "            0.3219141 , 0.32125353, 0.30085985, 0.28883605, 0.28545356,\n",
       "            0.25380773, 0.24471685, 0.21795466, 0.18100739, 0.16806892,\n",
       "            0.16493256, 0.12143679, 0.11256483, 0.07217726])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.27900000000000014),\n",
       "                                     1: np.float64(0.7209999999999999)}),\n",
       "    'fpr': np.float64(0.28125),\n",
       "    'tpr': np.float64(0.2777777777777778),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.15625, 0.15625, 0.28125,\n",
       "            0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.625  , 0.65625, 0.71875,\n",
       "            0.71875, 0.8125 , 0.84375, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.33333333,\n",
       "            0.33333333, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.87093761, 0.79359887, 0.73901481, 0.6804681 ,\n",
       "            0.66944886, 0.51463071, 0.50332005, 0.49958995, 0.48885692,\n",
       "            0.46540322, 0.43680394, 0.38216237, 0.35347092, 0.33341664,\n",
       "            0.31258819, 0.29989357, 0.29590199, 0.26306852, 0.2535872 ,\n",
       "            0.22628573, 0.19005931, 0.17444829, 0.17221699, 0.12733094,\n",
       "            0.11869985, 0.07594675])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.26900000000000013),\n",
       "                                     1: np.float64(0.7309999999999999)}),\n",
       "    'fpr': np.float64(0.3125),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.15625, 0.15625, 0.28125,\n",
       "            0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.625  , 0.65625, 0.71875,\n",
       "            0.71875, 0.8125 , 0.84375, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.33333333,\n",
       "            0.33333333, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.87598473, 0.8001793 , 0.74682547, 0.69110589,\n",
       "            0.68056421, 0.52761858, 0.51529922, 0.51055688, 0.5004325 ,\n",
       "            0.47883886, 0.44897261, 0.39527095, 0.36666924, 0.34614585,\n",
       "            0.3248687 , 0.3119098 , 0.30664978, 0.27270969, 0.26316182,\n",
       "            0.23539524, 0.19980775, 0.1817782 , 0.17975001, 0.13409826,\n",
       "            0.12543138, 0.08007401])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2590000000000001),\n",
       "                                     1: np.float64(0.7409999999999999)}),\n",
       "    'fpr': np.float64(0.3125),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.15625, 0.15625, 0.28125,\n",
       "            0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.625  , 0.65625, 0.71875,\n",
       "            0.71875, 0.8125 , 0.84375, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.33333333,\n",
       "            0.33333333, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.88058914, 0.80660016, 0.75410971, 0.70122294,\n",
       "            0.6911594 , 0.54050801, 0.52698708, 0.52154397, 0.51153208,\n",
       "            0.49287473, 0.46113979, 0.40870665, 0.37954548, 0.35951418,\n",
       "            0.3379008 , 0.32366875, 0.31744556, 0.28270109, 0.27250298,\n",
       "            0.2448854 , 0.21011252, 0.18893763, 0.18804539, 0.1409429 ,\n",
       "            0.13234556, 0.08440725])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2490000000000001),\n",
       "                                     1: np.float64(0.7509999999999999)}),\n",
       "    'fpr': np.float64(0.34375),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.15625, 0.15625, 0.28125,\n",
       "            0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.625  , 0.65625, 0.71875,\n",
       "            0.71875, 0.78125, 0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.33333333,\n",
       "            0.33333333, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.88514867, 0.81293021, 0.76115191, 0.71140026,\n",
       "            0.70197393, 0.55400767, 0.53880222, 0.53290457, 0.52320884,\n",
       "            0.50749282, 0.47352158, 0.42272998, 0.39326427, 0.37353053,\n",
       "            0.35184274, 0.33635266, 0.32899249, 0.29309208, 0.28272542,\n",
       "            0.2552482 , 0.22125869, 0.20825552, 0.197425  , 0.14848254,\n",
       "            0.14001412, 0.08916929])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2390000000000001),\n",
       "                                     1: np.float64(0.7609999999999999)}),\n",
       "    'fpr': np.float64(0.34375),\n",
       "    'tpr': np.float64(0.3888888888888889),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.15625, 0.15625, 0.28125,\n",
       "            0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.625  , 0.65625, 0.71875,\n",
       "            0.71875, 0.78125, 0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.33333333,\n",
       "            0.33333333, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.88960112, 0.81937387, 0.76825465, 0.7216132 ,\n",
       "            0.7130216 , 0.56773803, 0.55089867, 0.544816  , 0.53552986,\n",
       "            0.52230961, 0.48601936, 0.43722116, 0.40760789, 0.38786283,\n",
       "            0.36607425, 0.34952425, 0.34110521, 0.3038065 , 0.29358054,\n",
       "            0.26604823, 0.23283671, 0.21745439, 0.20711569, 0.15646887,\n",
       "            0.14821348, 0.09427887])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2290000000000001),\n",
       "                                     1: np.float64(0.7709999999999999)}),\n",
       "    'fpr': np.float64(0.34375),\n",
       "    'tpr': np.float64(0.3888888888888889),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.15625, 0.15625, 0.28125,\n",
       "            0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.625  , 0.65625, 0.71875,\n",
       "            0.71875, 0.78125, 0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.33333333,\n",
       "            0.33333333, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.89405521, 0.82558894, 0.77604892, 0.73192667,\n",
       "            0.72379639, 0.58115097, 0.56375467, 0.55733115, 0.54832889,\n",
       "            0.53688207, 0.49962845, 0.45273329, 0.42242142, 0.40298909,\n",
       "            0.3806965 , 0.36360899, 0.35405682, 0.31553154, 0.30505722,\n",
       "            0.2774662 , 0.24519538, 0.22724956, 0.21703971, 0.16549417,\n",
       "            0.15704764, 0.10004737])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.21900000000000008),\n",
       "                                     1: np.float64(0.7809999999999999)}),\n",
       "    'fpr': np.float64(0.375),\n",
       "    'tpr': np.float64(0.4444444444444444),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.15625, 0.15625, 0.28125,\n",
       "            0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.625  , 0.65625, 0.71875,\n",
       "            0.71875, 0.78125, 0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.33333333,\n",
       "            0.33333333, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.89835279, 0.83196545, 0.7834138 , 0.74208551,\n",
       "            0.73465066, 0.59547019, 0.57672518, 0.56984462, 0.56156982,\n",
       "            0.55212004, 0.51304724, 0.46852374, 0.43806874, 0.41870702,\n",
       "            0.39636412, 0.37818453, 0.36736719, 0.32735681, 0.31728529,\n",
       "            0.28962966, 0.25842297, 0.23773768, 0.22806213, 0.17510769,\n",
       "            0.16675007, 0.10621126])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.20900000000000007),\n",
       "                                     1: np.float64(0.7909999999999999)}),\n",
       "    'fpr': np.float64(0.40625),\n",
       "    'tpr': np.float64(0.4444444444444444),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.15625, 0.15625, 0.28125,\n",
       "            0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.625  , 0.65625, 0.71875,\n",
       "            0.71875, 0.78125, 0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.33333333,\n",
       "            0.33333333, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.90260864, 0.8385408 , 0.79115812, 0.75219559,\n",
       "            0.74604281, 0.61028109, 0.59054648, 0.58243955, 0.57517481,\n",
       "            0.56786895, 0.52705435, 0.48476478, 0.45468573, 0.43502588,\n",
       "            0.41288095, 0.39305883, 0.38107344, 0.34007519, 0.32983848,\n",
       "            0.30291279, 0.27246839, 0.24890457, 0.24017567, 0.18544772,\n",
       "            0.17715682, 0.11299806])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.19900000000000018),\n",
       "                                     1: np.float64(0.8009999999999998)}),\n",
       "    'fpr': np.float64(0.46875),\n",
       "    'tpr': np.float64(0.4444444444444444),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.15625, 0.15625, 0.28125,\n",
       "            0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.625  , 0.65625, 0.71875,\n",
       "            0.71875, 0.78125, 0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.33333333,\n",
       "            0.33333333, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.90688199, 0.84501349, 0.79880939, 0.76248331,\n",
       "            0.75716878, 0.62511153, 0.60434831, 0.59568783, 0.58898754,\n",
       "            0.58394898, 0.54169669, 0.50169986, 0.47151969, 0.45232985,\n",
       "            0.43025387, 0.40903617, 0.39575614, 0.35355537, 0.34343504,\n",
       "            0.31707612, 0.2876847 , 0.26093189, 0.2532463 , 0.19669769,\n",
       "            0.1884737 , 0.12038268])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.18900000000000017),\n",
       "                                     1: np.float64(0.8109999999999998)}),\n",
       "    'fpr': np.float64(0.46875),\n",
       "    'tpr': np.float64(0.4444444444444444),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.15625, 0.15625, 0.28125,\n",
       "            0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.625  , 0.65625, 0.71875,\n",
       "            0.71875, 0.78125, 0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.33333333,\n",
       "            0.33333333, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.91096346, 0.85142717, 0.80651699, 0.77235344,\n",
       "            0.76862407, 0.64078657, 0.61864038, 0.60890603, 0.60391231,\n",
       "            0.60014101, 0.55607018, 0.5192098 , 0.4898367 , 0.46985787,\n",
       "            0.44829991, 0.42556012, 0.41103462, 0.36734532, 0.35791886,\n",
       "            0.33248283, 0.3036737 , 0.27387639, 0.26771846, 0.20927935,\n",
       "            0.20102167, 0.12876692])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.17900000000000016),\n",
       "                                     1: np.float64(0.8209999999999998)}),\n",
       "    'fpr': np.float64(0.46875),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.15625, 0.15625, 0.28125,\n",
       "            0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375, 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.625  , 0.65625, 0.71875,\n",
       "            0.71875, 0.78125, 0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.33333333,\n",
       "            0.33333333, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.91514048, 0.85788633, 0.81469684, 0.78261114,\n",
       "            0.77965627, 0.65615607, 0.63357419, 0.62318489, 0.61927382,\n",
       "            0.61651988, 0.5716736 , 0.53786403, 0.50831208, 0.48841871,\n",
       "            0.46556416, 0.44312   , 0.42735989, 0.38222225, 0.37326912,\n",
       "            0.34836472, 0.32059889, 0.28765272, 0.28262273, 0.22293519,\n",
       "            0.21437931, 0.13788553])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.16900000000000015),\n",
       "                                     1: np.float64(0.8309999999999998)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.5555555555555556),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.15625, 0.15625, 0.28125,\n",
       "            0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375, 0.375  , 0.375  ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.625  ,\n",
       "            0.65625, 0.71875, 0.71875, 0.78125, 0.8125 , 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.5       , 0.5       , 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.91895878, 0.86433998, 0.82281564, 0.79252637,\n",
       "            0.79021159, 0.67176355, 0.64908088, 0.63756691, 0.63529574,\n",
       "            0.63275946, 0.6195479 , 0.58831072, 0.58763357, 0.55659923,\n",
       "            0.52768645, 0.50782168, 0.48395678, 0.46142521, 0.44454595,\n",
       "            0.39809973, 0.38981069, 0.36573272, 0.33890782, 0.30283402,\n",
       "            0.29906622, 0.23854896, 0.22926798, 0.14858995])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.15900000000000014),\n",
       "                                     1: np.float64(0.8409999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.7222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.15625, 0.15625, 0.28125,\n",
       "            0.28125, 0.3125 , 0.3125 , 0.34375, 0.34375, 0.375  , 0.375  ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.625  ,\n",
       "            0.65625, 0.71875, 0.71875, 0.78125, 0.8125 , 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.27777778, 0.27777778, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.5       , 0.5       , 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.92318413, 0.87088415, 0.83125712, 0.80266723,\n",
       "            0.8024846 , 0.6884483 , 0.66467016, 0.65277835, 0.65184375,\n",
       "            0.65036851, 0.63852375, 0.60549456, 0.60385062, 0.57337864,\n",
       "            0.54864181, 0.52784725, 0.50330567, 0.48067525, 0.46256114,\n",
       "            0.41452363, 0.40748794, 0.38463994, 0.35832807, 0.31885663,\n",
       "            0.31721546, 0.25477202, 0.24549971, 0.15968566])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.14900000000000013),\n",
       "                                     1: np.float64(0.8509999999999999)}),\n",
       "    'fpr': np.float64(0.53125),\n",
       "    'tpr': np.float64(0.7222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.28125, 0.28125, 0.34375,\n",
       "            0.34375, 0.375  , 0.375  , 0.46875, 0.46875, 0.5    , 0.5    ,\n",
       "            0.53125, 0.53125, 0.625  , 0.65625, 0.71875, 0.71875, 0.75   ,\n",
       "            0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.22222222, 0.22222222,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.5       , 0.5       , 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.92708529, 0.87751816, 0.81382704, 0.7052399 ,\n",
       "            0.66889204, 0.66781011, 0.65786133, 0.62367748, 0.62084548,\n",
       "            0.59115126, 0.5702659 , 0.5489158 , 0.52367516, 0.50095075,\n",
       "            0.48150464, 0.43216258, 0.42660705, 0.40512074, 0.37940783,\n",
       "            0.36166821, 0.33719365, 0.27342086, 0.26368096, 0.17274261])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.13900000000000012),\n",
       "                                     1: np.float64(0.8609999999999999)}),\n",
       "    'fpr': np.float64(0.53125),\n",
       "    'tpr': np.float64(0.7777777777777778),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.28125, 0.28125, 0.34375,\n",
       "            0.34375, 0.375  , 0.375  , 0.46875, 0.46875, 0.5    , 0.5    ,\n",
       "            0.53125, 0.53125, 0.625  , 0.65625, 0.71875, 0.71875, 0.75   ,\n",
       "            0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.22222222, 0.22222222,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.55555556, 0.55555556, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.93086946, 0.88405077, 0.82490474, 0.72206601,\n",
       "            0.68680769, 0.68405761, 0.67743577, 0.64238388, 0.63855647,\n",
       "            0.60954508, 0.57184741, 0.57085007, 0.54571954, 0.52220129,\n",
       "            0.50190963, 0.45145666, 0.44705493, 0.42696178, 0.40195017,\n",
       "            0.38514331, 0.35864413, 0.29438055, 0.28369481, 0.18791972])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.12900000000000011),\n",
       "                                     1: np.float64(0.8709999999999999)}),\n",
       "    'fpr': np.float64(0.5625),\n",
       "    'tpr': np.float64(0.7777777777777778),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.28125, 0.28125, 0.34375,\n",
       "            0.34375, 0.375  , 0.375  , 0.46875, 0.46875, 0.5    , 0.5    ,\n",
       "            0.53125, 0.53125, 0.625  , 0.65625, 0.71875, 0.71875, 0.75   ,\n",
       "            0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.22222222, 0.22222222,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.55555556, 0.55555556, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.93473571, 0.89078139, 0.83656686, 0.73965749,\n",
       "            0.70551773, 0.70065916, 0.69851023, 0.66219808, 0.65680549,\n",
       "            0.6288673 , 0.5987646 , 0.59376219, 0.5691529 , 0.54459968,\n",
       "            0.52328277, 0.47151951, 0.46931904, 0.45105713, 0.426066  ,\n",
       "            0.41039945, 0.38275998, 0.31755891, 0.30592741, 0.2048051 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1190000000000001),\n",
       "                                     1: np.float64(0.8809999999999999)}),\n",
       "    'fpr': np.float64(0.59375),\n",
       "    'tpr': np.float64(0.7777777777777778),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.125  , 0.125  , 0.28125, 0.28125, 0.3125 ,\n",
       "            0.3125 , 0.375  , 0.375  , 0.46875, 0.46875, 0.5    , 0.5    ,\n",
       "            0.53125, 0.53125, 0.59375, 0.625  , 0.71875, 0.71875, 0.75   ,\n",
       "            0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.22222222, 0.22222222,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.55555556, 0.55555556, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.93856721, 0.89753874, 0.84821358, 0.75766313,\n",
       "            0.72498764, 0.72195519, 0.72017363, 0.68283849, 0.67568742,\n",
       "            0.64897902, 0.62694103, 0.61757562, 0.59408804, 0.5682124 ,\n",
       "            0.54605867, 0.52344375, 0.49342308, 0.47719505, 0.45201313,\n",
       "            0.43800462, 0.40934288, 0.34357537, 0.33078731, 0.22431167])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1090000000000001),\n",
       "                                     1: np.float64(0.8909999999999999)}),\n",
       "    'fpr': np.float64(0.71875),\n",
       "    'tpr': np.float64(0.8333333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.09375, 0.09375, 0.125  , 0.125  , 0.28125,\n",
       "            0.28125, 0.375  , 0.375  , 0.46875, 0.46875, 0.5    , 0.5    ,\n",
       "            0.53125, 0.53125, 0.59375, 0.625  , 0.71875, 0.71875, 0.75   ,\n",
       "            0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.22222222, 0.22222222, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.61111111, 0.61111111, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.94243916, 0.91204798, 0.90459187, 0.9045773 ,\n",
       "            0.85966983, 0.77613177, 0.7422893 , 0.70446238, 0.69534453,\n",
       "            0.67016478, 0.64252319, 0.64248442, 0.62036133, 0.59328674,\n",
       "            0.57011471, 0.54868799, 0.51964879, 0.50515844, 0.47996959,\n",
       "            0.46785177, 0.43821037, 0.3732389 , 0.35874538, 0.24704872])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.09900000000000009),\n",
       "                                     1: np.float64(0.9009999999999999)}),\n",
       "    'fpr': np.float64(0.75),\n",
       "    'tpr': np.float64(0.8888888888888888),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.09375, 0.09375, 0.125  , 0.125  , 0.28125,\n",
       "            0.28125, 0.375  , 0.375  , 0.4375 , 0.4375 , 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.59375, 0.625  , 0.71875,\n",
       "            0.71875, 0.75   , 0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.22222222, 0.22222222, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.5       , 0.5       , 0.61111111, 0.61111111,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.94613235, 0.91715452, 0.91213219, 0.91122611,\n",
       "            0.87152235, 0.7948106 , 0.76533254, 0.72711879, 0.71558651,\n",
       "            0.70586703, 0.69497492, 0.69201489, 0.67069136, 0.66820124,\n",
       "            0.64888631, 0.6197099 , 0.59655972, 0.57617647, 0.54839333,\n",
       "            0.53662643, 0.5103862 , 0.50150716, 0.4713568 , 0.40656654,\n",
       "            0.3903085 , 0.2740515 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.08900000000000019),\n",
       "                                     1: np.float64(0.9109999999999998)}),\n",
       "    'fpr': np.float64(0.78125),\n",
       "    'tpr': np.float64(0.9444444444444444),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.09375, 0.09375, 0.125  , 0.125  , 0.28125,\n",
       "            0.28125, 0.40625, 0.40625, 0.4375 , 0.4375 , 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.59375, 0.625  , 0.71875,\n",
       "            0.71875, 0.75   , 0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.22222222, 0.22222222, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.55555556, 0.55555556, 0.61111111, 0.61111111,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.94981675, 0.92229608, 0.92014907, 0.91820369,\n",
       "            0.8833282 , 0.81393612, 0.7883195 , 0.73856872, 0.73712641,\n",
       "            0.72939375, 0.71952762, 0.71545008, 0.70100918, 0.69549176,\n",
       "            0.6796175 , 0.64774869, 0.62458712, 0.60629169, 0.57996502,\n",
       "            0.56853622, 0.54318179, 0.53807547, 0.50794253, 0.44466096,\n",
       "            0.42615715, 0.30592218])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.07900000000000018),\n",
       "                                     1: np.float64(0.9209999999999998)}),\n",
       "    'fpr': np.float64(0.84375),\n",
       "    'tpr': np.float64(0.9444444444444444),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.28125,\n",
       "            0.28125, 0.40625, 0.40625, 0.4375 , 0.4375 , 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.59375, 0.625  , 0.71875,\n",
       "            0.71875, 0.75   , 0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.22222222, 0.22222222, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.55555556, 0.55555556, 0.61111111, 0.61111111,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.9537081 , 0.93262303, 0.92838122, 0.92541882,\n",
       "            0.894816  , 0.83363609, 0.81121552, 0.76501833, 0.75968883,\n",
       "            0.75459002, 0.75219956, 0.74008993, 0.73224938, 0.7235897 ,\n",
       "            0.71159767, 0.67779139, 0.65491879, 0.63857131, 0.61453235,\n",
       "            0.59937581, 0.57862653, 0.5776383 , 0.54850515, 0.48757887,\n",
       "            0.46660164, 0.34381426])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.06900000000000017),\n",
       "                                     1: np.float64(0.9309999999999998)}),\n",
       "    'fpr': np.float64(0.90625),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.28125,\n",
       "            0.28125, 0.40625, 0.40625, 0.46875, 0.46875, 0.5    , 0.5    ,\n",
       "            0.53125, 0.53125, 0.59375, 0.625  , 0.75   , 0.75   , 0.78125,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.22222222, 0.22222222, 0.38888889, 0.38888889, 0.55555556,\n",
       "            0.55555556, 0.61111111, 0.61111111, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.95749469, 0.93934498, 0.93675197, 0.93268879,\n",
       "            0.90657727, 0.85344138, 0.83501367, 0.79278856, 0.78298477,\n",
       "            0.76643759, 0.7654362 , 0.75326617, 0.74620663, 0.71016706,\n",
       "            0.68825189, 0.67466766, 0.65313785, 0.62152461, 0.61734695,\n",
       "            0.59418298, 0.53113506, 0.51312353, 0.39022157])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.05900000000000016),\n",
       "                                     1: np.float64(0.9409999999999998)}),\n",
       "    'fpr': np.float64(0.9375),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.28125,\n",
       "            0.28125, 0.40625, 0.40625, 0.4375 , 0.4375 , 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.59375, 0.625  , 0.75   ,\n",
       "            0.75   , 0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.22222222, 0.22222222, 0.38888889, 0.38888889, 0.5       ,\n",
       "            0.5       , 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.96150823, 0.94633636, 0.94521966, 0.93889553,\n",
       "            0.91861345, 0.87411383, 0.8573183 , 0.82143154, 0.81458103,\n",
       "            0.80864818, 0.79965892, 0.79395189, 0.78448246, 0.78397037,\n",
       "            0.78258836, 0.74537114, 0.7252641 , 0.71371237, 0.69610389,\n",
       "            0.6701466 , 0.66024956, 0.64535126, 0.58187126, 0.56721623,\n",
       "            0.44770643])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.049000000000000155),\n",
       "                                     1: np.float64(0.9509999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.28125, 0.28125,\n",
       "            0.375  , 0.375  , 0.40625, 0.40625, 0.4375 , 0.4375 , 0.46875,\n",
       "            0.46875, 0.5625 , 0.5625 , 0.59375, 0.625  , 0.75   , 0.75   ,\n",
       "            0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.5       , 0.5       , 0.61111111, 0.61111111, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.96531958, 0.95348603, 0.94478558, 0.93071934,\n",
       "            0.8940419 , 0.88003356, 0.85678548, 0.85416834, 0.85043524,\n",
       "            0.84673288, 0.83758969, 0.83476211, 0.82398342, 0.81940213,\n",
       "            0.76616583, 0.76460046, 0.7567842 , 0.74265442, 0.71320337,\n",
       "            0.70766502, 0.70188973, 0.63942598, 0.62819785, 0.51788271])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.039000000000000146),\n",
       "                                     1: np.float64(0.9609999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.28125, 0.28125,\n",
       "            0.34375, 0.34375, 0.40625, 0.40625, 0.4375 , 0.4375 , 0.46875,\n",
       "            0.46875, 0.5625 , 0.5625 , 0.625  , 0.65625, 0.71875, 0.75   ,\n",
       "            0.78125, 0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.55555556, 0.55555556, 0.66666667, 0.66666667, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.96948008, 0.9619451 , 0.9513436 , 0.94286336,\n",
       "            0.91444005, 0.90319997, 0.8882425 , 0.88737048, 0.88076974,\n",
       "            0.87061614, 0.86807762, 0.85958443, 0.8562698 , 0.85562187,\n",
       "            0.81244685, 0.80888916, 0.79511636, 0.79404561, 0.77917071,\n",
       "            0.76365877, 0.76171144, 0.75987342, 0.70641299, 0.69801908,\n",
       "            0.60441258])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.029000000000000137),\n",
       "                                     1: np.float64(0.9709999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.28125, 0.28125, 0.40625, 0.40625, 0.4375 ,\n",
       "            0.4375 , 0.5625 , 0.5625 , 0.625  , 0.65625, 0.71875, 0.75   ,\n",
       "            0.75   , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.33333333, 0.33333333,\n",
       "            0.44444444, 0.44444444, 0.55555556, 0.55555556, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.97397675, 0.97027312, 0.95890142, 0.95358243,\n",
       "            0.93868462, 0.93650342, 0.93480164, 0.93387993, 0.93378794,\n",
       "            0.91919292, 0.91142866, 0.90599248, 0.90038089, 0.89289433,\n",
       "            0.86202937, 0.85773782, 0.85131822, 0.84955026, 0.83941351,\n",
       "            0.83014658, 0.81838314, 0.78309081, 0.77654602, 0.70922188])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.019000000000000128),\n",
       "                                     1: np.float64(0.9809999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.09375, 0.09375, 0.125  , 0.125  ,\n",
       "            0.15625, 0.15625, 0.28125, 0.28125, 0.375  , 0.375  , 0.40625,\n",
       "            0.40625, 0.4375 , 0.4375 , 0.59375, 0.59375, 0.625  , 0.65625,\n",
       "            0.71875, 0.75   , 0.8125 , 0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.61111111,\n",
       "            0.61111111, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.97927299, 0.97869101, 0.97322   , 0.96824869,\n",
       "            0.96816732, 0.96561987, 0.96421066, 0.95784099, 0.95421826,\n",
       "            0.94901078, 0.94266797, 0.94201327, 0.94183647, 0.93721389,\n",
       "            0.93434974, 0.92991626, 0.9104286 , 0.91023668, 0.90850914,\n",
       "            0.90722602, 0.90112016, 0.89766229, 0.88588843, 0.8828653 ,\n",
       "            0.86647909, 0.86144084, 0.8266931 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.009000000000000119),\n",
       "                                     1: np.float64(0.9909999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.15625, 0.15625, 0.28125,\n",
       "            0.28125, 0.375  , 0.375  , 0.4375 , 0.4375 , 0.46875, 0.46875,\n",
       "            0.625  , 0.625  , 0.65625, 0.71875, 0.75   , 0.8125 , 0.8125 ,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.44444444, 0.44444444, 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.98755825, 0.98436413, 0.98270467, 0.98104161,\n",
       "            0.98016565, 0.97670675, 0.9759771 , 0.9734617 , 0.97249379,\n",
       "            0.96972849, 0.96892269, 0.96811491, 0.96736809, 0.96263031,\n",
       "            0.9624777 , 0.96217556, 0.9598491 , 0.95981808, 0.95663918,\n",
       "            0.95124863, 0.94849657, 0.94594608, 0.93847418])}}],\n",
       "  [{'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08823529, 0.08823529,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.26470588, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.67647059, 0.67647059, 0.73529412,\n",
       "            0.76470588, 0.79411765, 0.79411765, 0.91176471, 0.91176471,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.25  , 0.25  , 0.4375, 0.4375, 0.5   , 0.5   ,\n",
       "            0.5625, 0.5625, 0.625 , 0.6875, 0.6875, 0.8125, 0.8125, 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.00046391, 0.00045898, 0.00044882, 0.00044458,\n",
       "            0.00044024, 0.00043927, 0.0004387 , 0.00043609, 0.00043465,\n",
       "            0.00043464, 0.0004332 , 0.00041772, 0.00041723, 0.0004169 ,\n",
       "            0.00041626, 0.00041585, 0.00040969, 0.00040018, 0.00039999,\n",
       "            0.00039988, 0.00039855])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.989), 1: np.float64(0.011)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02941176, 0.02941176,\n",
       "            0.11764706, 0.11764706, 0.17647059, 0.17647059, 0.23529412,\n",
       "            0.26470588, 0.29411765, 0.29411765, 0.32352941, 0.32352941,\n",
       "            0.35294118, 0.73529412, 0.73529412, 0.76470588, 0.82352941,\n",
       "            0.82352941, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.375 , 0.375 ,\n",
       "            0.4375, 0.4375, 0.5   , 0.5   , 0.5625, 0.5625, 0.625 , 0.6875,\n",
       "            0.6875, 0.8125, 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.00846552, 0.00778272, 0.00774879, 0.00772226,\n",
       "            0.00675502, 0.00642383, 0.00628816, 0.00615786, 0.00607215,\n",
       "            0.0060185 , 0.00589568, 0.00588415, 0.00585287, 0.0058175 ,\n",
       "            0.00576406, 0.00426388, 0.00424   , 0.00423836, 0.00347437,\n",
       "            0.00342224, 0.00310401, 0.00306143, 0.00302529, 0.00299582])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.979),\n",
       "                                     1: np.float64(0.020999999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02941176, 0.02941176,\n",
       "            0.11764706, 0.11764706, 0.14705882, 0.14705882, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.32352941, 0.35294118, 0.70588235, 0.73529412, 0.73529412,\n",
       "            0.82352941, 0.82352941, 0.91176471, 0.91176471, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.3125, 0.3125,\n",
       "            0.375 , 0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.625 , 0.625 ,\n",
       "            0.6875, 0.6875, 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.02198711, 0.0207902 , 0.01898614, 0.01844858,\n",
       "            0.01636115, 0.01483519, 0.01445774, 0.0144357 , 0.01392223,\n",
       "            0.01345824, 0.01342367, 0.01313526, 0.01279255, 0.01249774,\n",
       "            0.01244793, 0.01237088, 0.00781798, 0.00776108, 0.00767951,\n",
       "            0.00593518, 0.00550122, 0.00489063, 0.00467535, 0.00457986,\n",
       "            0.00453703])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.969),\n",
       "                                     1: np.float64(0.030999999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02941176, 0.02941176,\n",
       "            0.14705882, 0.14705882, 0.17647059, 0.17647059, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.29411765, 0.29411765, 0.32352941,\n",
       "            0.67647059, 0.70588235, 0.73529412, 0.73529412, 0.82352941,\n",
       "            0.82352941, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.3125, 0.3125,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.5   , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.03967341, 0.03580644, 0.03265048, 0.03108302,\n",
       "            0.02382635, 0.02375561, 0.02361601, 0.02360235, 0.02168467,\n",
       "            0.02158728, 0.02099876, 0.0204013 , 0.01981113, 0.0196508 ,\n",
       "            0.01111389, 0.01108743, 0.01107302, 0.01084549, 0.00814616,\n",
       "            0.00714897, 0.0063324 , 0.0058694 , 0.00571887, 0.0056486 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.959),\n",
       "                                     1: np.float64(0.040999999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02941176, 0.02941176,\n",
       "            0.17647059, 0.17647059, 0.20588235, 0.20588235, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.29411765, 0.29411765, 0.32352941,\n",
       "            0.64705882, 0.67647059, 0.73529412, 0.73529412, 0.82352941,\n",
       "            0.82352941, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.3125, 0.3125,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.5   , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.06027768, 0.05163049, 0.0475147 , 0.04420504,\n",
       "            0.0332566 , 0.03324473, 0.0330513 , 0.0328235 , 0.03045877,\n",
       "            0.02995162, 0.02932469, 0.02839129, 0.02747324, 0.02726598,\n",
       "            0.01499026, 0.01435209, 0.01408448, 0.01384398, 0.01031998,\n",
       "            0.00858   , 0.00763118, 0.00686717, 0.00665568, 0.00657225])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9490000000000001),\n",
       "                                     1: np.float64(0.05099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05882353, 0.05882353,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.26470588,\n",
       "            0.29411765, 0.29411765, 0.32352941, 0.64705882, 0.67647059,\n",
       "            0.73529412, 0.73529412, 0.82352941, 0.82352941, 0.91176471,\n",
       "            0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.375 , 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "            0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.08343991, 0.06781044, 0.05844825, 0.0575809 ,\n",
       "            0.04320344, 0.04223338, 0.03970175, 0.03827929, 0.03827609,\n",
       "            0.03680397, 0.03545377, 0.03520946, 0.01824496, 0.01769606,\n",
       "            0.01702693, 0.0167997 , 0.01242871, 0.00989613, 0.0088143 ,\n",
       "            0.00775597, 0.00746796, 0.00739488])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9390000000000001),\n",
       "                                     1: np.float64(0.06099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.11764706, 0.11764706,\n",
       "            0.17647059, 0.17647059, 0.20588235, 0.20588235, 0.23529412,\n",
       "            0.26470588, 0.26470588, 0.29411765, 0.29411765, 0.32352941,\n",
       "            0.64705882, 0.67647059, 0.73529412, 0.73529412, 0.82352941,\n",
       "            0.82352941, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.3125, 0.3125,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.5   , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.10845024, 0.08298342, 0.07184771, 0.07043321,\n",
       "            0.05547016, 0.05314162, 0.05280751, 0.05128374, 0.04861749,\n",
       "            0.04731089, 0.04676791, 0.04519792, 0.04420084, 0.0429843 ,\n",
       "            0.02137323, 0.0212593 , 0.0200498 , 0.01974025, 0.01470274,\n",
       "            0.01138121, 0.0100895 , 0.0086482 , 0.00830147, 0.00827244])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.929), 1: np.float64(0.071)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.11764706, 0.11764706,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.26470588, 0.26470588,\n",
       "            0.29411765, 0.29411765, 0.32352941, 0.61764706, 0.64705882,\n",
       "            0.73529412, 0.73529412, 0.82352941, 0.82352941, 0.91176471,\n",
       "            0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.375 , 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "            0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.13328477, 0.09793345, 0.08812195, 0.08305064,\n",
       "            0.06319946, 0.06016156, 0.05837388, 0.05639853, 0.0548893 ,\n",
       "            0.05403896, 0.0521959 , 0.05147146, 0.02628749, 0.02468399,\n",
       "            0.02277578, 0.02247792, 0.01690509, 0.01248225, 0.01124172,\n",
       "            0.00942026, 0.00898394, 0.00895548])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.919),\n",
       "                                     1: np.float64(0.08099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.11764706, 0.11764706,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.61764706, 0.64705882, 0.73529412,\n",
       "            0.73529412, 0.82352941, 0.82352941, 0.91176471, 0.91176471,\n",
       "            0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.375 , 0.375 ,\n",
       "            0.4375, 0.4375, 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.15838931, 0.11206135, 0.1050585 , 0.09474106,\n",
       "            0.07275768, 0.06956572, 0.06777858, 0.06608848, 0.06295584,\n",
       "            0.06074325, 0.05949991, 0.02984599, 0.02835459, 0.02564781,\n",
       "            0.02527302, 0.01907222, 0.01377214, 0.01230327, 0.0102154 ,\n",
       "            0.00974276, 0.00968206])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.909),\n",
       "                                     1: np.float64(0.09099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.11764706, 0.11764706,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.61764706, 0.64705882, 0.73529412,\n",
       "            0.73529412, 0.85294118, 0.85294118, 0.91176471, 0.91176471,\n",
       "            0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.375 , 0.375 ,\n",
       "            0.4375, 0.4375, 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.18553373, 0.12654899, 0.12185795, 0.10669528,\n",
       "            0.08259972, 0.07861046, 0.07730813, 0.0755783 , 0.07162318,\n",
       "            0.06943275, 0.06761174, 0.03350953, 0.03182266, 0.02843946,\n",
       "            0.02816479, 0.01506711, 0.0150408 , 0.01337672, 0.0110227 ,\n",
       "            0.01048442, 0.0104497 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.899),\n",
       "                                     1: np.float64(0.10099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.08823529, 0.08823529, 0.11764706,\n",
       "            0.11764706, 0.20588235, 0.20588235, 0.23529412, 0.26470588,\n",
       "            0.29411765, 0.29411765, 0.32352941, 0.35294118, 0.61764706,\n",
       "            0.64705882, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.4375, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.20968195, 0.13953308, 0.13924013, 0.13794559,\n",
       "            0.11690682, 0.09170905, 0.08815594, 0.08724856, 0.08547474,\n",
       "            0.08090628, 0.0778666 , 0.07650053, 0.07592009, 0.03723891,\n",
       "            0.03556844, 0.03121999, 0.03085218, 0.01646915, 0.01622761,\n",
       "            0.01439716, 0.01178719, 0.01121806, 0.01109253])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.889),\n",
       "                                     1: np.float64(0.11099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.61764706, 0.64705882,\n",
       "            0.73529412, 0.73529412, 0.85294118, 0.85294118, 0.91176471,\n",
       "            0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.25  , 0.25  , 0.375 , 0.375 , 0.4375,\n",
       "            0.4375, 0.5625, 0.5625, 0.625 , 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "            0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.2348092 , 0.15355076, 0.12705686, 0.10091788,\n",
       "            0.09740639, 0.09696962, 0.09538881, 0.09015262, 0.08663188,\n",
       "            0.08640002, 0.08500783, 0.08423953, 0.04099567, 0.03943803,\n",
       "            0.03409007, 0.03361149, 0.01799014, 0.01746652, 0.01540083,\n",
       "            0.01256678, 0.01195653, 0.01177331])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.879),\n",
       "                                     1: np.float64(0.12099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.23529412, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.35294118,\n",
       "            0.61764706, 0.64705882, 0.73529412, 0.73529412, 0.85294118,\n",
       "            0.85294118, 0.91176471, 0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.25  , 0.25  , 0.3125, 0.3125, 0.375 ,\n",
       "            0.4375, 0.4375, 0.5   , 0.5   , 0.5625, 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.26041228, 0.16985665, 0.13752174, 0.11062122,\n",
       "            0.10894105, 0.10730235, 0.10658074, 0.10528862, 0.09964184,\n",
       "            0.09852371, 0.09643498, 0.09552387, 0.09320195, 0.09268778,\n",
       "            0.04518082, 0.04336128, 0.03714137, 0.036576  , 0.0195935 ,\n",
       "            0.01875505, 0.01644854, 0.01343338, 0.01270148, 0.01255668])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.869),\n",
       "                                     1: np.float64(0.13099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.23529412, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.35294118,\n",
       "            0.61764706, 0.64705882, 0.73529412, 0.73529412, 0.85294118,\n",
       "            0.85294118, 0.91176471, 0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.25  , 0.25  , 0.3125, 0.3125, 0.375 ,\n",
       "            0.4375, 0.4375, 0.5   , 0.5   , 0.5625, 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.28523137, 0.18454091, 0.14706711, 0.11980803,\n",
       "            0.11766279, 0.11724115, 0.11567885, 0.11513335, 0.1089847 ,\n",
       "            0.10748769, 0.10679569, 0.10401119, 0.10170042, 0.0996301 ,\n",
       "            0.04906244, 0.04726267, 0.03992144, 0.03932994, 0.02111615,\n",
       "            0.01992637, 0.01743269, 0.01420218, 0.01339494, 0.01324737])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.859), 1: np.float64(0.141)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.32352941, 0.32352941,\n",
       "            0.35294118, 0.35294118, 0.61764706, 0.64705882, 0.73529412,\n",
       "            0.73529412, 0.85294118, 0.85294118, 0.91176471, 0.91176471,\n",
       "            0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.25  , 0.25  , 0.3125, 0.375 , 0.4375,\n",
       "            0.4375, 0.5625, 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.30821965, 0.19843309, 0.15655698, 0.12734314,\n",
       "            0.12634282, 0.12568227, 0.12550491, 0.11782702, 0.11343927,\n",
       "            0.11034312, 0.10677858, 0.05321183, 0.05155199, 0.04312178,\n",
       "            0.04235603, 0.02289252, 0.02139081, 0.01854668, 0.01511066,\n",
       "            0.01424109, 0.01405585])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.849),\n",
       "                                     1: np.float64(0.15099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.26470588, 0.26470588, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.38235294, 0.38235294, 0.61764706, 0.64705882, 0.73529412,\n",
       "            0.73529412, 0.85294118, 0.85294118, 0.91176471, 0.91176471,\n",
       "            0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.25  , 0.25  , 0.3125, 0.4375, 0.4375,\n",
       "            0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.33234696, 0.2121087 , 0.16604492, 0.13729978,\n",
       "            0.13576937, 0.13521371, 0.12832606, 0.12278023, 0.11893755,\n",
       "            0.11485174, 0.1140501 , 0.05732202, 0.05564971, 0.04631122,\n",
       "            0.04532898, 0.02459683, 0.02278302, 0.01960304, 0.01598874,\n",
       "            0.01502912, 0.01485794])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.839),\n",
       "                                     1: np.float64(0.16099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.14705882,\n",
       "            0.14705882, 0.23529412, 0.26470588, 0.26470588, 0.32352941,\n",
       "            0.32352941, 0.35294118, 0.38235294, 0.38235294, 0.61764706,\n",
       "            0.64705882, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.3125,\n",
       "            0.4375, 0.4375, 0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.3543287 , 0.22493822, 0.17456519, 0.17456465,\n",
       "            0.17448962, 0.14612522, 0.14533961, 0.14372992, 0.13793897,\n",
       "            0.13138958, 0.12758347, 0.12315704, 0.1208976 , 0.06156084,\n",
       "            0.06005453, 0.04936532, 0.04802141, 0.02624225, 0.0240862 ,\n",
       "            0.02065892, 0.01686098, 0.01581386, 0.01559162])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.829),\n",
       "                                     1: np.float64(0.17099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.17647059,\n",
       "            0.17647059, 0.20588235, 0.23529412, 0.26470588, 0.26470588,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.38235294, 0.38235294,\n",
       "            0.61764706, 0.64705882, 0.73529412, 0.73529412, 0.85294118,\n",
       "            0.85294118, 0.91176471, 0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.3125,\n",
       "            0.3125, 0.4375, 0.4375, 0.5625, 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.37622485, 0.23831832, 0.21801596, 0.18535023,\n",
       "            0.18301411, 0.1573581 , 0.15567739, 0.15484801, 0.1520952 ,\n",
       "            0.14779202, 0.14041417, 0.13625251, 0.13190882, 0.12759218,\n",
       "            0.06550671, 0.06438624, 0.05243105, 0.05091805, 0.02791585,\n",
       "            0.02539633, 0.02168332, 0.0177006 , 0.0165727 , 0.01634792])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.8190000000000001),\n",
       "                                     1: np.float64(0.18099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.17647059,\n",
       "            0.17647059, 0.20588235, 0.23529412, 0.26470588, 0.26470588,\n",
       "            0.29411765, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.38235294, 0.38235294, 0.61764706, 0.64705882, 0.73529412,\n",
       "            0.73529412, 0.85294118, 0.85294118, 0.91176471, 0.91176471,\n",
       "            0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.4375, 0.5625, 0.625 , 0.625 ,\n",
       "            0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375,\n",
       "            1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.39747107, 0.25150088, 0.22834204, 0.19714617,\n",
       "            0.19115811, 0.16739046, 0.16590426, 0.16407743, 0.16384796,\n",
       "            0.16350111, 0.16060009, 0.15750224, 0.14932782, 0.1448082 ,\n",
       "            0.1407101 , 0.13420998, 0.06926196, 0.06884768, 0.05550499,\n",
       "            0.05396111, 0.02971056, 0.02678031, 0.0228009 , 0.01861637,\n",
       "            0.01739093, 0.01720017])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.809),\n",
       "                                     1: np.float64(0.19099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.17647059,\n",
       "            0.17647059, 0.23529412, 0.26470588, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.58823529, 0.61764706, 0.73529412, 0.73529412,\n",
       "            0.85294118, 0.85294118, 0.91176471, 0.91176471, 0.97058824,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.3125,\n",
       "            0.375 , 0.375 , 0.4375, 0.4375, 0.5625, 0.625 , 0.625 , 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.41723991, 0.26378482, 0.23800007, 0.20798605,\n",
       "            0.19866157, 0.17606673, 0.17594299, 0.17349233, 0.17172701,\n",
       "            0.16882484, 0.16716187, 0.15859474, 0.15340636, 0.14962943,\n",
       "            0.1408692 , 0.07429125, 0.07326709, 0.05877613, 0.05709761,\n",
       "            0.03159526, 0.0282578 , 0.0239034 , 0.01957783, 0.01821605,\n",
       "            0.01809772])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.799),\n",
       "                                     1: np.float64(0.20099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.17647059,\n",
       "            0.17647059, 0.23529412, 0.26470588, 0.26470588, 0.32352941,\n",
       "            0.32352941, 0.35294118, 0.38235294, 0.38235294, 0.58823529,\n",
       "            0.61764706, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.3125,\n",
       "            0.375 , 0.375 , 0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.43534562, 0.27606504, 0.24734096, 0.21872045,\n",
       "            0.20561828, 0.18767612, 0.18650008, 0.18355735, 0.17731761,\n",
       "            0.16802253, 0.16241475, 0.15855614, 0.14726648, 0.07883539,\n",
       "            0.07779379, 0.06206984, 0.06029597, 0.03348454, 0.02973998,\n",
       "            0.02491343, 0.02051025, 0.01895801, 0.01895585])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.789),\n",
       "                                     1: np.float64(0.21099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.17647059,\n",
       "            0.17647059, 0.23529412, 0.26470588, 0.26470588, 0.32352941,\n",
       "            0.32352941, 0.35294118, 0.38235294, 0.38235294, 0.58823529,\n",
       "            0.61764706, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.3125,\n",
       "            0.375 , 0.375 , 0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.45441419, 0.28837374, 0.25678048, 0.23031351,\n",
       "            0.21336585, 0.19765221, 0.19642997, 0.19328303, 0.18725449,\n",
       "            0.1765511 , 0.17097754, 0.16733602, 0.15377837, 0.08321199,\n",
       "            0.08265024, 0.065217  , 0.06319522, 0.03526325, 0.03110621,\n",
       "            0.02612571, 0.02149112, 0.01987464, 0.01983145])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.779),\n",
       "                                     1: np.float64(0.22099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.17647059,\n",
       "            0.17647059, 0.23529412, 0.26470588, 0.26470588, 0.32352941,\n",
       "            0.32352941, 0.35294118, 0.38235294, 0.38235294, 0.58823529,\n",
       "            0.61764706, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.3125,\n",
       "            0.375 , 0.375 , 0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.4724642 , 0.30088398, 0.26617919, 0.24078287,\n",
       "            0.2210359 , 0.207601  , 0.2063447 , 0.20322692, 0.19683798,\n",
       "            0.18519897, 0.17965162, 0.17619887, 0.1602463 , 0.08763475,\n",
       "            0.08758743, 0.06846029, 0.06612643, 0.03705752, 0.03250314,\n",
       "            0.02725772, 0.02245347, 0.0207335 , 0.02069265])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.769),\n",
       "                                     1: np.float64(0.23099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.17647059,\n",
       "            0.17647059, 0.23529412, 0.26470588, 0.26470588, 0.32352941,\n",
       "            0.32352941, 0.35294118, 0.38235294, 0.38235294, 0.58823529,\n",
       "            0.61764706, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.3125,\n",
       "            0.375 , 0.375 , 0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.49038618, 0.31257293, 0.27558714, 0.2513235 ,\n",
       "            0.22873196, 0.21741141, 0.21567336, 0.21304845, 0.20486726,\n",
       "            0.19484646, 0.18836642, 0.18570131, 0.16745055, 0.09241344,\n",
       "            0.09231269, 0.07206288, 0.06920864, 0.03898632, 0.03407883,\n",
       "            0.02844249, 0.02349635, 0.02164531, 0.02162696])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.759),\n",
       "                                     1: np.float64(0.24099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.17647059,\n",
       "            0.17647059, 0.20588235, 0.20588235, 0.23529412, 0.26470588,\n",
       "            0.26470588, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.55882353, 0.58823529, 0.73529412, 0.73529412,\n",
       "            0.85294118, 0.85294118, 0.91176471, 0.91176471, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.375 , 0.375 , 0.5625, 0.625 , 0.625 , 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.50523527, 0.32385532, 0.28381578, 0.26209448,\n",
       "            0.2399856 , 0.23902402, 0.23415214, 0.22737298, 0.22615567,\n",
       "            0.22306275, 0.21290915, 0.20401567, 0.1969084 , 0.19466449,\n",
       "            0.17309694, 0.10969781, 0.09718708, 0.07529446, 0.07269772,\n",
       "            0.0411234 , 0.03568166, 0.02958897, 0.02453469, 0.02266021,\n",
       "            0.02245803])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7490000000000001),\n",
       "                                     1: np.float64(0.25099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.26470588, 0.26470588, 0.32352941,\n",
       "            0.32352941, 0.35294118, 0.38235294, 0.38235294, 0.55882353,\n",
       "            0.58823529, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.3125,\n",
       "            0.375 , 0.375 , 0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.52050039, 0.33555787, 0.29260052, 0.25202846,\n",
       "            0.24068738, 0.23759389, 0.23627326, 0.23329065, 0.2212162 ,\n",
       "            0.2131969 , 0.20591892, 0.20388737, 0.17934657, 0.11413427,\n",
       "            0.10223166, 0.07880416, 0.07602187, 0.04313461, 0.0372426 ,\n",
       "            0.03069742, 0.02559444, 0.02363816, 0.02328866])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7390000000000001),\n",
       "                                     1: np.float64(0.26099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.23529412, 0.26470588, 0.26470588,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.38235294, 0.38235294,\n",
       "            0.55882353, 0.58823529, 0.73529412, 0.73529412, 0.85294118,\n",
       "            0.85294118, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.3125, 0.375 , 0.375 , 0.5625, 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.53550241, 0.34748472, 0.3015499 , 0.26578001,\n",
       "            0.25549619, 0.24759217, 0.24739981, 0.24627573, 0.24336701,\n",
       "            0.2294532 , 0.22215077, 0.21478782, 0.21295597, 0.18580525,\n",
       "            0.11854598, 0.10739419, 0.08219847, 0.07934136, 0.0452011 ,\n",
       "            0.03880614, 0.03196186, 0.02671246, 0.02469739, 0.02424123])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7290000000000001),\n",
       "                                     1: np.float64(0.27099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.26470588, 0.26470588, 0.32352941,\n",
       "            0.32352941, 0.35294118, 0.38235294, 0.38235294, 0.55882353,\n",
       "            0.58823529, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.54881107, 0.35800216, 0.30934899, 0.2785522 ,\n",
       "            0.26206747, 0.25720738, 0.25552449, 0.25325235, 0.23685347,\n",
       "            0.23074933, 0.22310337, 0.22226483, 0.19179496, 0.12257381,\n",
       "            0.11276918, 0.08572654, 0.08235075, 0.04713368, 0.04035954,\n",
       "            0.03317308, 0.02782878, 0.02566067, 0.02517901])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7190000000000001),\n",
       "                                     1: np.float64(0.28099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.26470588, 0.26470588, 0.32352941,\n",
       "            0.32352941, 0.35294118, 0.38235294, 0.38235294, 0.55882353,\n",
       "            0.58823529, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.5625, 0.5625, 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.56280815, 0.36981202, 0.31839237, 0.29210709,\n",
       "            0.26999194, 0.26696624, 0.26547091, 0.2602147 , 0.24494526,\n",
       "            0.23948692, 0.23197633, 0.23169463, 0.19828786, 0.12718763,\n",
       "            0.11813931, 0.08933308, 0.08576187, 0.0492767 , 0.04205542,\n",
       "            0.03444432, 0.02898712, 0.02675124, 0.02615062])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7090000000000001),\n",
       "                                     1: np.float64(0.291)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.26470588, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.55882353, 0.58823529, 0.73529412, 0.73529412,\n",
       "            0.85294118, 0.85294118, 0.91176471, 0.91176471, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.3125, 0.3125, 0.375 , 0.375 , 0.5625, 0.5625, 0.625 , 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.57456382, 0.38062854, 0.32664002, 0.30433622,\n",
       "            0.2778011 , 0.27684827, 0.27539589, 0.27437731, 0.26701645,\n",
       "            0.26583409, 0.25306288, 0.24830759, 0.24165773, 0.24049929,\n",
       "            0.20432974, 0.13204403, 0.12356033, 0.09329264, 0.08966412,\n",
       "            0.0516837 , 0.04398601, 0.03570897, 0.03030207, 0.02802172,\n",
       "            0.02712241])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6990000000000001),\n",
       "                                     1: np.float64(0.30099999999999993)}),\n",
       "    'fpr': np.float64(0.029411764705882353),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.26470588, 0.26470588, 0.29411765, 0.29411765, 0.32352941,\n",
       "            0.32352941, 0.35294118, 0.38235294, 0.38235294, 0.55882353,\n",
       "            0.58823529, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.3125, 0.3125,\n",
       "            0.375 , 0.375 , 0.5625, 0.5625, 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.58635628, 0.39137308, 0.33439585, 0.28622994,\n",
       "            0.28466513, 0.28398998, 0.27682898, 0.27181492, 0.26079306,\n",
       "            0.25587158, 0.25075869, 0.24882514, 0.21049247, 0.13628112,\n",
       "            0.12930985, 0.09680634, 0.09292832, 0.05386573, 0.04568056,\n",
       "            0.03710159, 0.03155278, 0.02916137, 0.02819642])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6890000000000001),\n",
       "                                     1: np.float64(0.31099999999999994)}),\n",
       "    'fpr': np.float64(0.029411764705882353),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.38235294, 0.38235294,\n",
       "            0.55882353, 0.58823529, 0.73529412, 0.73529412, 0.85294118,\n",
       "            0.85294118, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.25  , 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.5625, 0.5625, 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.5989042 , 0.40241582, 0.34340749, 0.29587212,\n",
       "            0.29447214, 0.29410664, 0.2928474 , 0.2863532 , 0.27799643,\n",
       "            0.26911335, 0.26400419, 0.26031389, 0.25740733, 0.21673073,\n",
       "            0.14125165, 0.13456742, 0.10058907, 0.09668481, 0.05608738,\n",
       "            0.04743329, 0.03825286, 0.0327824 , 0.0303746 , 0.02905672])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.679),\n",
       "                                     1: np.float64(0.32099999999999995)}),\n",
       "    'fpr': np.float64(0.029411764705882353),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.38235294, 0.38235294,\n",
       "            0.55882353, 0.58823529, 0.73529412, 0.73529412, 0.85294118,\n",
       "            0.85294118, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.25  , 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.5625, 0.5625, 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.60862244, 0.41297928, 0.35074086, 0.30505003,\n",
       "            0.30435904, 0.3036355 , 0.29967933, 0.29594519, 0.28337483,\n",
       "            0.27694555, 0.2714661 , 0.27002721, 0.26550526, 0.22238801,\n",
       "            0.14584585, 0.14070619, 0.10439137, 0.10041944, 0.05863558,\n",
       "            0.04943477, 0.03972822, 0.03423937, 0.03172028, 0.03022695])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.669),\n",
       "                                     1: np.float64(0.33099999999999996)}),\n",
       "    'fpr': np.float64(0.029411764705882353),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.55882353, 0.58823529, 0.73529412, 0.73529412,\n",
       "            0.85294118, 0.85294118, 0.91176471, 0.91176471, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.25  , 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.5   , 0.5   , 0.5625, 0.625 , 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.62036475, 0.42364426, 0.35977493, 0.31508767,\n",
       "            0.31501564, 0.31275393, 0.30719847, 0.30637204, 0.29023365,\n",
       "            0.28481576, 0.28058429, 0.27920298, 0.27914796, 0.27459656,\n",
       "            0.22944881, 0.1504245 , 0.14633182, 0.10827522, 0.10379689,\n",
       "            0.06062673, 0.0510748 , 0.04117728, 0.03551136, 0.0329168 ,\n",
       "            0.03132536])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.659),\n",
       "                                     1: np.float64(0.34099999999999997)}),\n",
       "    'fpr': np.float64(0.029411764705882353),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.55882353,\n",
       "            0.58823529, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.4375, 0.4375, 0.5625, 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.6295543 , 0.36859677, 0.36719367, 0.36086467,\n",
       "            0.32501981, 0.3240856 , 0.32235387, 0.31562353, 0.29360277,\n",
       "            0.28931044, 0.28691543, 0.28243869, 0.23480368, 0.15522614,\n",
       "            0.15259455, 0.11207058, 0.10774207, 0.06330027, 0.05316468,\n",
       "            0.04255811, 0.03700569, 0.03431459, 0.03241806])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.649),\n",
       "                                     1: np.float64(0.3509999999999999)}),\n",
       "    'fpr': np.float64(0.029411764705882353),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.55882353,\n",
       "            0.58823529, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.4375, 0.4375, 0.5625, 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.63950665, 0.37943694, 0.37569661, 0.37027259,\n",
       "            0.33568935, 0.33365961, 0.33166174, 0.3256003 , 0.30138849,\n",
       "            0.29900467, 0.29462527, 0.29102595, 0.24129671, 0.16005308,\n",
       "            0.15864166, 0.11610533, 0.11155683, 0.06567657, 0.05511004,\n",
       "            0.04407219, 0.03846593, 0.03570541, 0.03359469])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.639),\n",
       "                                     1: np.float64(0.36099999999999993)}),\n",
       "    'fpr': np.float64(0.029411764705882353),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.52941176,\n",
       "            0.55882353, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.375 , 0.375 , 0.5625, 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.64885603, 0.39008911, 0.38372771, 0.37966444,\n",
       "            0.34587224, 0.34306213, 0.34084496, 0.33533208, 0.31123613,\n",
       "            0.30870784, 0.30234938, 0.29942642, 0.24742581, 0.17317211,\n",
       "            0.16491328, 0.12002281, 0.11531369, 0.06809723, 0.05704534,\n",
       "            0.045545  , 0.03995279, 0.03708785, 0.03474407])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.629),\n",
       "                                     1: np.float64(0.37099999999999994)}),\n",
       "    'fpr': np.float64(0.058823529411764705),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.52941176,\n",
       "            0.55882353, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.375 , 0.375 , 0.5625, 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.65791576, 0.40013346, 0.3920049 , 0.38891734,\n",
       "            0.35643049, 0.35238695, 0.34995234, 0.3451503 , 0.32013846,\n",
       "            0.31673961, 0.30997903, 0.3078241 , 0.25392176, 0.17833228,\n",
       "            0.17126205, 0.12420134, 0.11924894, 0.07062049, 0.05911878,\n",
       "            0.04718284, 0.04154524, 0.03860086, 0.03603592])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.619),\n",
       "                                     1: np.float64(0.38099999999999995)}),\n",
       "    'fpr': np.float64(0.058823529411764705),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.52941176,\n",
       "            0.55882353, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.375 , 0.375 , 0.5625, 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.66642772, 0.41073966, 0.39981607, 0.39811784,\n",
       "            0.36645106, 0.36150182, 0.35885282, 0.354692  , 0.32866153,\n",
       "            0.3247365 , 0.31763474, 0.31599999, 0.26009743, 0.18263141,\n",
       "            0.17782478, 0.1282466 , 0.12306624, 0.07315958, 0.0611731 ,\n",
       "            0.0487824 , 0.04316014, 0.04009088, 0.03730307])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.609),\n",
       "                                     1: np.float64(0.39099999999999996)}),\n",
       "    'fpr': np.float64(0.058823529411764705),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.52941176, 0.55882353, 0.73529412, 0.73529412,\n",
       "            0.85294118, 0.85294118, 0.91176471, 0.91176471, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.3125, 0.375 , 0.375 , 0.5625, 0.625 , 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.67523674, 0.42090431, 0.40827987, 0.40745351,\n",
       "            0.37711648, 0.3711025 , 0.36787536, 0.36483951, 0.35098816,\n",
       "            0.3380964 , 0.33756403, 0.33268647, 0.32529535, 0.32470587,\n",
       "            0.266899  , 0.18718269, 0.18435552, 0.13244095, 0.12694472,\n",
       "            0.07560642, 0.06317407, 0.05048367, 0.04476259, 0.04160722,\n",
       "            0.03862381])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5990000000000001),\n",
       "                                     1: np.float64(0.4009999999999999)}),\n",
       "    'fpr': np.float64(0.08823529411764706),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.23529412,\n",
       "            0.26470588, 0.29411765, 0.29411765, 0.32352941, 0.32352941,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.52941176,\n",
       "            0.55882353, 0.73529412, 0.73529412, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.5   , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.6830703 , 0.41661397, 0.38749323, 0.38026727,\n",
       "            0.37684079, 0.37454431, 0.35812269, 0.34802588, 0.34621911,\n",
       "            0.34055299, 0.33512048, 0.33294241, 0.27330532, 0.19164899,\n",
       "            0.19119809, 0.1366962 , 0.13095604, 0.07823861, 0.06534845,\n",
       "            0.05224981, 0.04650205, 0.04322978, 0.04003716])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5890000000000001),\n",
       "                                     1: np.float64(0.4109999999999999)}),\n",
       "    'fpr': np.float64(0.11764705882352941),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.23529412,\n",
       "            0.26470588, 0.29411765, 0.29411765, 0.32352941, 0.32352941,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.5       ,\n",
       "            0.52941176, 0.76470588, 0.76470588, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.5   , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.6909569 , 0.42578555, 0.3981189 , 0.3894776 ,\n",
       "            0.38578114, 0.38421983, 0.36569268, 0.35811735, 0.35501886,\n",
       "            0.348581  , 0.34271487, 0.34123103, 0.27987947, 0.20341332,\n",
       "            0.19796464, 0.13558577, 0.13506539, 0.08085977, 0.06755053,\n",
       "            0.05398502, 0.04824984, 0.04488386, 0.04141936])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5790000000000001),\n",
       "                                     1: np.float64(0.42099999999999993)}),\n",
       "    'fpr': np.float64(0.11764705882352941),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.23529412,\n",
       "            0.26470588, 0.29411765, 0.29411765, 0.32352941, 0.32352941,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.5       ,\n",
       "            0.52941176, 0.76470588, 0.76470588, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.5   , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.69807306, 0.43461188, 0.40851001, 0.39835088,\n",
       "            0.39450694, 0.39346431, 0.37316059, 0.3683206 , 0.36376437,\n",
       "            0.35658701, 0.35027429, 0.34928113, 0.28618332, 0.20984513,\n",
       "            0.20503188, 0.14085548, 0.13953565, 0.08384024, 0.07007123,\n",
       "            0.0558229 , 0.05023531, 0.04676578, 0.04290542])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5690000000000001),\n",
       "                                     1: np.float64(0.43099999999999994)}),\n",
       "    'fpr': np.float64(0.11764705882352941),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.23529412,\n",
       "            0.26470588, 0.29411765, 0.29411765, 0.32352941, 0.32352941,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.5       ,\n",
       "            0.52941176, 0.76470588, 0.76470588, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.5   , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.70512865, 0.44325426, 0.41891801, 0.40711156,\n",
       "            0.40311993, 0.4029639 , 0.38035694, 0.37811599, 0.37205183,\n",
       "            0.36431255, 0.35740433, 0.3572554 , 0.29298879, 0.21665387,\n",
       "            0.21241859, 0.14642576, 0.14356336, 0.08646135, 0.0723514 ,\n",
       "            0.05781795, 0.05215034, 0.04851178, 0.0445586 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.559),\n",
       "                                     1: np.float64(0.44099999999999995)}),\n",
       "    'fpr': np.float64(0.11764705882352941),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.26470588,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.5       , 0.52941176, 0.79411765, 0.79411765,\n",
       "            0.88235294, 0.88235294, 0.91176471, 0.91176471, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 ,\n",
       "            0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.71296618, 0.45238758, 0.42970385, 0.41293837,\n",
       "            0.41164518, 0.38788702, 0.3805847 , 0.37229793, 0.36581684,\n",
       "            0.30041727, 0.22304967, 0.21948423, 0.14822072, 0.14754818,\n",
       "            0.07485351, 0.07439943, 0.05983986, 0.05396421, 0.05022323,\n",
       "            0.04613573])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.549),\n",
       "                                     1: np.float64(0.45099999999999996)}),\n",
       "    'fpr': np.float64(0.14705882352941177),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.26470588,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.5       , 0.52941176, 0.79411765, 0.79411765,\n",
       "            0.88235294, 0.88235294, 0.91176471, 0.91176471, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 ,\n",
       "            0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.71942841, 0.4613154 , 0.44005553, 0.42229692,\n",
       "            0.42039441, 0.39797516, 0.38921952, 0.38043246, 0.37385424,\n",
       "            0.30710554, 0.23009068, 0.22708778, 0.15322581, 0.1522161 ,\n",
       "            0.07767643, 0.07703086, 0.06194973, 0.0561439 , 0.05229299,\n",
       "            0.0478719 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5390000000000001),\n",
       "                                     1: np.float64(0.4609999999999999)}),\n",
       "    'fpr': np.float64(0.14705882352941177),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.26470588,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.5       , 0.52941176, 0.79411765, 0.79411765,\n",
       "            0.88235294, 0.88235294, 0.91176471, 0.91176471, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 ,\n",
       "            0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.72573206, 0.47060978, 0.45004798, 0.43150645,\n",
       "            0.42904957, 0.40807662, 0.39776239, 0.38875209, 0.38186872,\n",
       "            0.31371281, 0.23691414, 0.23448768, 0.15820584, 0.15687566,\n",
       "            0.08051545, 0.07957827, 0.06403756, 0.05834375, 0.05437687,\n",
       "            0.04954908])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5290000000000001),\n",
       "                                     1: np.float64(0.4709999999999999)}),\n",
       "    'fpr': np.float64(0.17647058823529413),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.26470588,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.5       , 0.52941176, 0.79411765, 0.79411765,\n",
       "            0.88235294, 0.88235294, 0.91176471, 0.91176471, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 ,\n",
       "            0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.73169321, 0.47999741, 0.46101056, 0.44136346,\n",
       "            0.43815379, 0.41910225, 0.40708508, 0.39731665, 0.39016531,\n",
       "            0.3203097 , 0.24401201, 0.24217155, 0.16324237, 0.16147064,\n",
       "            0.08313981, 0.08235727, 0.06602078, 0.06047383, 0.05638383,\n",
       "            0.05117075])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5190000000000001),\n",
       "                                     1: np.float64(0.4809999999999999)}),\n",
       "    'fpr': np.float64(0.17647058823529413),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.26470588,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.5       , 0.52941176,\n",
       "            0.79411765, 0.79411765, 0.88235294, 0.88235294, 0.91176471,\n",
       "            0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "            0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.7377975 , 0.48871915, 0.47158018, 0.45082653,\n",
       "            0.44662104, 0.42924265, 0.41567443, 0.40557651, 0.39840841,\n",
       "            0.38117033, 0.32830538, 0.32748063, 0.25122832, 0.25007173,\n",
       "            0.16857714, 0.16620772, 0.08613875, 0.08506955, 0.06830037,\n",
       "            0.06279665, 0.05858532, 0.05304306])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5090000000000001),\n",
       "                                     1: np.float64(0.49099999999999994)}),\n",
       "    'fpr': np.float64(0.17647058823529413),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.26470588,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.5       , 0.52941176,\n",
       "            0.79411765, 0.79411765, 0.88235294, 0.88235294, 0.91176471,\n",
       "            0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "            0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.74371952, 0.49755815, 0.48214444, 0.46035263,\n",
       "            0.45516687, 0.43954283, 0.42433299, 0.41384285, 0.40662684,\n",
       "            0.38789197, 0.33683487, 0.33470484, 0.25868979, 0.25817231,\n",
       "            0.17400575, 0.17102336, 0.0892201 , 0.08786527, 0.07068475,\n",
       "            0.06521505, 0.0608682 , 0.05502441])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4990000000000001),\n",
       "                                     1: np.float64(0.5009999999999999)}),\n",
       "    'fpr': np.float64(0.20588235294117646),\n",
       "    'tpr': np.float64(0.125),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.26470588,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.47058824, 0.5       ,\n",
       "            0.79411765, 0.79411765, 0.88235294, 0.88235294, 0.91176471,\n",
       "            0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "            0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.74950118, 0.50647412, 0.49260326, 0.46981082,\n",
       "            0.46367211, 0.44991165, 0.43301918, 0.42222453, 0.41481583,\n",
       "            0.39466726, 0.34552974, 0.34200341, 0.28966449, 0.26641282,\n",
       "            0.17954473, 0.17594015, 0.09240223, 0.09075346, 0.07314131,\n",
       "            0.06773276, 0.06324005, 0.05707023])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4890000000000001),\n",
       "                                     1: np.float64(0.5109999999999999)}),\n",
       "    'fpr': np.float64(0.20588235294117646),\n",
       "    'tpr': np.float64(0.1875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.26470588,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.47058824, 0.5       ,\n",
       "            0.79411765, 0.79411765, 0.88235294, 0.88235294, 0.91176471,\n",
       "            0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "            0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.7546622 , 0.51530114, 0.5028752 , 0.47803957,\n",
       "            0.47220116, 0.46077379, 0.44201663, 0.43093988, 0.42241023,\n",
       "            0.40029793, 0.35496875, 0.34852749, 0.29834834, 0.27478469,\n",
       "            0.18514442, 0.18131582, 0.09565693, 0.09423475, 0.07547655,\n",
       "            0.07048291, 0.06584792, 0.05902289])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4790000000000001),\n",
       "                                     1: np.float64(0.5209999999999999)}),\n",
       "    'fpr': np.float64(0.20588235294117646),\n",
       "    'tpr': np.float64(0.1875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.26470588,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.47058824, 0.5       ,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.91176471,\n",
       "            0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "            0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.76002524, 0.52408846, 0.51316998, 0.48669752,\n",
       "            0.48049377, 0.47114647, 0.45060284, 0.43943551, 0.43048099,\n",
       "            0.40716227, 0.3641287 , 0.35594406, 0.30720411, 0.28336742,\n",
       "            0.18700396, 0.18645035, 0.0990899 , 0.09737225, 0.07814086,\n",
       "            0.07325717, 0.06844128, 0.06124471])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4690000000000001),\n",
       "                                     1: np.float64(0.5309999999999999)}),\n",
       "    'fpr': np.float64(0.20588235294117646),\n",
       "    'tpr': np.float64(0.1875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.26470588,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.47058824, 0.5       ,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.91176471,\n",
       "            0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "            0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.7657268 , 0.53314598, 0.52402739, 0.49583825,\n",
       "            0.48889661, 0.48165217, 0.45888223, 0.44771828, 0.43896122,\n",
       "            0.4154652 , 0.37254997, 0.36432143, 0.31632848, 0.29196359,\n",
       "            0.19287635, 0.19124867, 0.10245788, 0.10017223, 0.08105125,\n",
       "            0.07592903, 0.07091421, 0.06370068])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4590000000000001),\n",
       "                                     1: np.float64(0.5409999999999999)}),\n",
       "    'fpr': np.float64(0.2647058823529412),\n",
       "    'tpr': np.float64(0.1875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.26470588,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.47058824, 0.5       ,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.91176471,\n",
       "            0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "            0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.77082122, 0.5420811 , 0.53452946, 0.50437055,\n",
       "            0.4973221 , 0.49238868, 0.4672933 , 0.45633737, 0.44691747,\n",
       "            0.4223983 , 0.38191022, 0.37186258, 0.32557912, 0.30081068,\n",
       "            0.1991994 , 0.19664426, 0.10599382, 0.10360904, 0.0838499 ,\n",
       "            0.07888445, 0.07369996, 0.06606595])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.44900000000000007),\n",
       "                                     1: np.float64(0.5509999999999999)}),\n",
       "    'fpr': np.float64(0.3235294117647059),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.26470588,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.47058824, 0.5       ,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.91176471,\n",
       "            0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "            0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.7760859 , 0.55094354, 0.54429219, 0.5129192 ,\n",
       "            0.50574883, 0.50324241, 0.47552595, 0.46474019, 0.45473633,\n",
       "            0.4300052 , 0.39131889, 0.37961782, 0.33508266, 0.30985807,\n",
       "            0.20556891, 0.20209155, 0.10966281, 0.10698418, 0.0868606 ,\n",
       "            0.08204547, 0.07659371, 0.06870823])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.43900000000000006),\n",
       "                                     1: np.float64(0.5609999999999999)}),\n",
       "    'fpr': np.float64(0.3235294117647059),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.38235294, 0.38235294,\n",
       "            0.41176471, 0.41176471, 0.47058824, 0.5       , 0.82352941,\n",
       "            0.82352941, 0.88235294, 0.88235294, 0.91176471, 0.91176471,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.375 , 0.375 ,\n",
       "            0.4375, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.78075527, 0.55954622, 0.55266478, 0.5140993 ,\n",
       "            0.51387287, 0.48392205, 0.47344797, 0.46248757, 0.43715693,\n",
       "            0.4009461 , 0.38716094, 0.34434364, 0.31914918, 0.21232047,\n",
       "            0.20747825, 0.11349159, 0.1107691 , 0.09001373, 0.08532309,\n",
       "            0.0795716 , 0.07140126])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.42900000000000005),\n",
       "                                     1: np.float64(0.571)}),\n",
       "    'fpr': np.float64(0.3235294117647059),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.38235294, 0.38235294,\n",
       "            0.41176471, 0.41176471, 0.47058824, 0.5       , 0.82352941,\n",
       "            0.82352941, 0.88235294, 0.88235294, 0.91176471, 0.91176471,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.375 , 0.375 ,\n",
       "            0.4375, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.7854365 , 0.56838055, 0.56106499, 0.52489685,\n",
       "            0.52203457, 0.49255994, 0.48241329, 0.47016637, 0.44439008,\n",
       "            0.41117014, 0.39468054, 0.35384122, 0.32861318, 0.21924063,\n",
       "            0.2130478 , 0.11741285, 0.11464846, 0.0931812 , 0.08875262,\n",
       "            0.08265233, 0.07412518])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.41900000000000004),\n",
       "                                     1: np.float64(0.581)}),\n",
       "    'fpr': np.float64(0.3235294117647059),\n",
       "    'tpr': np.float64(0.375),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.20588235, 0.20588235, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.38235294, 0.38235294,\n",
       "            0.41176471, 0.41176471, 0.47058824, 0.5       , 0.82352941,\n",
       "            0.82352941, 0.88235294, 0.88235294, 0.91176471, 0.91176471,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.375 , 0.375 ,\n",
       "            0.4375, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.78989322, 0.57716047, 0.56971276, 0.53577127,\n",
       "            0.53048194, 0.50160103, 0.49145809, 0.47821167, 0.4514034 ,\n",
       "            0.42116563, 0.40236044, 0.36389994, 0.33825694, 0.22637645,\n",
       "            0.21915161, 0.12147309, 0.11882829, 0.09641505, 0.09233583,\n",
       "            0.08602267, 0.07691212])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.40900000000000014),\n",
       "                                     1: np.float64(0.5909999999999999)}),\n",
       "    'fpr': np.float64(0.35294117647058826),\n",
       "    'tpr': np.float64(0.375),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.38235294, 0.38235294, 0.41176471, 0.41176471, 0.47058824,\n",
       "            0.5       , 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.4375, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.79448198, 0.62352859, 0.586092  , 0.58607318,\n",
       "            0.57883256, 0.54648191, 0.53907344, 0.51115259, 0.50068497,\n",
       "            0.48625362, 0.45872884, 0.43146564, 0.41021307, 0.37446939,\n",
       "            0.34787582, 0.23360454, 0.22568795, 0.12561638, 0.12309521,\n",
       "            0.09964571, 0.09613603, 0.08961532, 0.07975352])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.39900000000000013),\n",
       "                                     1: np.float64(0.6009999999999999)}),\n",
       "    'fpr': np.float64(0.35294117647058826),\n",
       "    'tpr': np.float64(0.375),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.41176471, 0.41176471,\n",
       "            0.47058824, 0.5       , 0.82352941, 0.82352941, 0.88235294,\n",
       "            0.88235294, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.79812874, 0.63323911, 0.59678747, 0.59430138,\n",
       "            0.58697813, 0.55448185, 0.54736093, 0.52037567, 0.50944251,\n",
       "            0.49424115, 0.49377501, 0.46516084, 0.44210736, 0.41751509,\n",
       "            0.38456846, 0.35808027, 0.24139538, 0.23220565, 0.12994861,\n",
       "            0.12816787, 0.10325685, 0.10020043, 0.09344744, 0.08289863])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3890000000000001),\n",
       "                                     1: np.float64(0.6109999999999999)}),\n",
       "    'fpr': np.float64(0.38235294117647056),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.5       , 0.82352941, 0.82352941, 0.88235294,\n",
       "            0.88235294, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.80252841, 0.64330018, 0.60707369, 0.60315518,\n",
       "            0.59578391, 0.56307262, 0.55571875, 0.52893344, 0.51854607,\n",
       "            0.50292188, 0.5022161 , 0.47296742, 0.42683462, 0.42581442,\n",
       "            0.39508383, 0.36829115, 0.2489854 , 0.23854006, 0.13451842,\n",
       "            0.13247975, 0.10697676, 0.10415418, 0.0971329 , 0.08610632])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3790000000000001),\n",
       "                                     1: np.float64(0.6209999999999999)}),\n",
       "    'fpr': np.float64(0.38235294117647056),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.38235294, 0.38235294, 0.44117647, 0.44117647, 0.47058824,\n",
       "            0.5       , 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.4375, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.80681142, 0.65304495, 0.61743385, 0.61221821,\n",
       "            0.60557279, 0.57229308, 0.56416003, 0.53637422, 0.527275  ,\n",
       "            0.51096536, 0.48254726, 0.43848853, 0.4351165 , 0.4060158 ,\n",
       "            0.37880038, 0.25639956, 0.24466179, 0.13915103, 0.13614639,\n",
       "            0.11126512, 0.10827677, 0.10079817, 0.08990671])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3690000000000001),\n",
       "                                     1: np.float64(0.6309999999999999)}),\n",
       "    'fpr': np.float64(0.38235294117647056),\n",
       "    'tpr': np.float64(0.5625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.5       , 0.82352941, 0.82352941, 0.88235294,\n",
       "            0.88235294, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.81127018, 0.66272778, 0.62816135, 0.62133342,\n",
       "            0.61548848, 0.58077652, 0.57257263, 0.54528196, 0.53614384,\n",
       "            0.5199481 , 0.51917675, 0.49135457, 0.44989195, 0.44456354,\n",
       "            0.41703653, 0.38928361, 0.26411907, 0.25145044, 0.14402905,\n",
       "            0.14084342, 0.11555953, 0.11258834, 0.10494358, 0.09366841])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3590000000000001),\n",
       "                                     1: np.float64(0.6409999999999999)}),\n",
       "    'fpr': np.float64(0.38235294117647056),\n",
       "    'tpr': np.float64(0.5625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.5       , 0.82352941, 0.82352941, 0.88235294,\n",
       "            0.88235294, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.81545987, 0.67252534, 0.63855422, 0.63043741,\n",
       "            0.62500168, 0.58929887, 0.58100332, 0.55475685, 0.54551509,\n",
       "            0.52913309, 0.52748044, 0.49976039, 0.46157531, 0.45379102,\n",
       "            0.42838989, 0.40010263, 0.27217689, 0.25862659, 0.14915516,\n",
       "            0.14601835, 0.11996865, 0.11724535, 0.10943785, 0.09754178])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3490000000000001),\n",
       "                                     1: np.float64(0.6509999999999999)}),\n",
       "    'fpr': np.float64(0.38235294117647056),\n",
       "    'tpr': np.float64(0.625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.5       , 0.82352941, 0.82352941, 0.88235294,\n",
       "            0.88235294, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.81948144, 0.68266403, 0.64898964, 0.63968588,\n",
       "            0.63448999, 0.59734336, 0.58967502, 0.56473519, 0.55476464,\n",
       "            0.53844148, 0.53490146, 0.50825055, 0.47395609, 0.46262549,\n",
       "            0.43975718, 0.41123927, 0.2796741 , 0.26589983, 0.15407315,\n",
       "            0.15177237, 0.12454313, 0.12230556, 0.11408253, 0.10173671])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3390000000000001),\n",
       "                                     1: np.float64(0.6609999999999999)}),\n",
       "    'fpr': np.float64(0.4117647058823529),\n",
       "    'tpr': np.float64(0.625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.5       , 0.82352941, 0.82352941, 0.88235294,\n",
       "            0.88235294, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.82349241, 0.69252957, 0.65908273, 0.6481456 ,\n",
       "            0.64371964, 0.60566786, 0.59802383, 0.57487674, 0.56470161,\n",
       "            0.54773921, 0.54324364, 0.51735626, 0.48605785, 0.47167502,\n",
       "            0.45110434, 0.42274535, 0.28802409, 0.27337459, 0.15956476,\n",
       "            0.15764334, 0.12926758, 0.1276105 , 0.11890076, 0.10604393])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.32900000000000007),\n",
       "                                     1: np.float64(0.6709999999999999)}),\n",
       "    'fpr': np.float64(0.4117647058823529),\n",
       "    'tpr': np.float64(0.625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.5       , 0.82352941, 0.82352941, 0.88235294,\n",
       "            0.88235294, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.82754954, 0.70232095, 0.66935412, 0.65747204,\n",
       "            0.65368622, 0.61410258, 0.60660613, 0.58475321, 0.57391271,\n",
       "            0.5573725 , 0.55156315, 0.52674096, 0.49830871, 0.48177054,\n",
       "            0.46323074, 0.43429048, 0.2967129 , 0.28128006, 0.16522879,\n",
       "            0.16362238, 0.13442057, 0.13300938, 0.12414214, 0.11074103])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.31900000000000006),\n",
       "                                     1: np.float64(0.6809999999999999)}),\n",
       "    'fpr': np.float64(0.4411764705882353),\n",
       "    'tpr': np.float64(0.625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.5       , 0.82352941, 0.82352941, 0.88235294,\n",
       "            0.88235294, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.83153654, 0.71189619, 0.6797942 , 0.6666399 ,\n",
       "            0.66377651, 0.62277569, 0.61515996, 0.59440209, 0.58362039,\n",
       "            0.56694202, 0.56016045, 0.53676526, 0.51059267, 0.49203358,\n",
       "            0.47526389, 0.4459233 , 0.30567433, 0.28921373, 0.17114694,\n",
       "            0.16982206, 0.13995654, 0.13869384, 0.12949839, 0.11572903])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.30900000000000005),\n",
       "                                     1: np.float64(0.691)}),\n",
       "    'fpr': np.float64(0.4411764705882353),\n",
       "    'tpr': np.float64(0.6875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.5       , 0.82352941, 0.82352941, 0.88235294,\n",
       "            0.88235294, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.83532175, 0.7215893 , 0.69000729, 0.67522042,\n",
       "            0.67330578, 0.63108156, 0.6236803 , 0.60341999, 0.59343476,\n",
       "            0.57622425, 0.56835157, 0.54658436, 0.52335297, 0.50151164,\n",
       "            0.48697726, 0.45803622, 0.31452241, 0.29732795, 0.17730174,\n",
       "            0.17642545, 0.14568958, 0.14488671, 0.13500626, 0.12099675])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.29900000000000015),\n",
       "                                     1: np.float64(0.7009999999999998)}),\n",
       "    'fpr': np.float64(0.4411764705882353),\n",
       "    'tpr': np.float64(0.6875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.5       , 0.82352941, 0.82352941, 0.88235294,\n",
       "            0.88235294, 0.91176471, 0.91176471, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.83935231, 0.73124209, 0.70000711, 0.68456718,\n",
       "            0.68380324, 0.63969464, 0.63229698, 0.61297573, 0.60310414,\n",
       "            0.58639823, 0.5769176 , 0.5565461 , 0.53592686, 0.51254974,\n",
       "            0.49969273, 0.47004815, 0.32392457, 0.30602475, 0.18376579,\n",
       "            0.18317554, 0.15182071, 0.15141121, 0.14105648, 0.1267264 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.28900000000000015),\n",
       "                                     1: np.float64(0.7109999999999999)}),\n",
       "    'fpr': np.float64(0.47058823529411764),\n",
       "    'tpr': np.float64(0.6875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.20588235,\n",
       "            0.20588235, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.5       , 0.82352941, 0.82352941, 0.88235294,\n",
       "            0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.84335277, 0.74076081, 0.71039914, 0.69355684,\n",
       "            0.69341573, 0.64843047, 0.64133946, 0.62252464, 0.61306673,\n",
       "            0.5958612 , 0.58559376, 0.56484166, 0.54917937, 0.52241106,\n",
       "            0.51239884, 0.48275381, 0.33361224, 0.31500211, 0.19044783,\n",
       "            0.15823896, 0.14733899, 0.13254931])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.27900000000000014),\n",
       "                                     1: np.float64(0.7209999999999999)}),\n",
       "    'fpr': np.float64(0.47058823529411764),\n",
       "    'tpr': np.float64(0.6875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.5       , 0.82352941, 0.82352941, 0.85294118,\n",
       "            0.85294118, 0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.375 , 0.375 ,\n",
       "            0.4375, 0.5   , 0.5625, 0.5625, 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.84701616, 0.74970859, 0.70362461, 0.65722489,\n",
       "            0.65012623, 0.6319032 , 0.62350258, 0.60582306, 0.59452334,\n",
       "            0.5779874 , 0.57668349, 0.57335376, 0.56193971, 0.53311161,\n",
       "            0.52517892, 0.49519589, 0.34400272, 0.32461216, 0.21297829,\n",
       "            0.19845497, 0.19758944, 0.16562245, 0.15429523, 0.13889172])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.26900000000000013),\n",
       "                                     1: np.float64(0.7309999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.41176471, 0.41176471, 0.44117647, 0.44117647, 0.47058824,\n",
       "            0.5       , 0.82352941, 0.82352941, 0.85294118, 0.85294118,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.375 , 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.85081763, 0.75937208, 0.71345419, 0.66612303,\n",
       "            0.65929699, 0.6416983 , 0.63342217, 0.61554017, 0.60331856,\n",
       "            0.58914432, 0.58162176, 0.57554119, 0.5437936 , 0.53812368,\n",
       "            0.5082757 , 0.35407674, 0.33380078, 0.22012392, 0.20628872,\n",
       "            0.2048085 , 0.1731254 , 0.16107494, 0.14579035])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2590000000000001),\n",
       "                                     1: np.float64(0.7409999999999999)}),\n",
       "    'fpr': np.float64(0.5294117647058824),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.41176471, 0.41176471, 0.44117647, 0.44117647, 0.47058824,\n",
       "            0.5       , 0.82352941, 0.82352941, 0.85294118, 0.85294118,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.375 , 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.85520307, 0.76907732, 0.72422092, 0.67499992,\n",
       "            0.66797687, 0.65177961, 0.64409957, 0.62663986, 0.61273527,\n",
       "            0.60147582, 0.5901571 , 0.58860331, 0.55620453, 0.55132105,\n",
       "            0.52151965, 0.36507054, 0.34352316, 0.22749643, 0.21475716,\n",
       "            0.21271776, 0.181106  , 0.1683316 , 0.15292418])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2490000000000001),\n",
       "                                     1: np.float64(0.7509999999999999)}),\n",
       "    'fpr': np.float64(0.5294117647058824),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.17647059, 0.17647059, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.41176471, 0.41176471, 0.44117647, 0.44117647, 0.47058824,\n",
       "            0.5       , 0.82352941, 0.82352941, 0.85294118, 0.85294118,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.375 , 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.5625, 0.5625, 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.85852311, 0.77802644, 0.73419803, 0.68347575,\n",
       "            0.67744481, 0.66141815, 0.65411317, 0.63670401, 0.62102793,\n",
       "            0.61496488, 0.61191232, 0.60252437, 0.56657514, 0.56478367,\n",
       "            0.53497199, 0.37591068, 0.35470121, 0.23602742, 0.22481251,\n",
       "            0.22059319, 0.19030635, 0.17685434, 0.16099386])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2390000000000001),\n",
       "                                     1: np.float64(0.7609999999999999)}),\n",
       "    'fpr': np.float64(0.5294117647058824),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.17647059, 0.17647059,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.35294118,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.5       , 0.82352941, 0.82352941, 0.85294118,\n",
       "            0.85294118, 0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.5   , 0.5   , 0.5625, 0.5625, 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.86395722, 0.86240797, 0.78728669, 0.74454676,\n",
       "            0.69259175, 0.6867264 , 0.67137774, 0.66483508, 0.64732771,\n",
       "            0.63040172, 0.62800763, 0.62394927, 0.61625146, 0.57839479,\n",
       "            0.57828467, 0.54868132, 0.3874846 , 0.36552384, 0.24445744,\n",
       "            0.23464263, 0.2291338 , 0.19957152, 0.18526315, 0.1693785 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2290000000000001),\n",
       "                                     1: np.float64(0.7709999999999999)}),\n",
       "    'fpr': np.float64(0.5294117647058824),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.17647059, 0.17647059,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.35294118,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.47058824, 0.5       , 0.82352941, 0.82352941,\n",
       "            0.85294118, 0.85294118, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.4375, 0.5   , 0.5625, 0.5625, 0.625 , 0.625 ,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.87075318, 0.86625542, 0.79621423, 0.75537646,\n",
       "            0.7018074 , 0.69615972, 0.68131548, 0.67553323, 0.65802058,\n",
       "            0.64110783, 0.63992893, 0.63668151, 0.63003823, 0.61784655,\n",
       "            0.59204726, 0.59065184, 0.56254987, 0.39958116, 0.37710639,\n",
       "            0.25313269, 0.24488429, 0.23807026, 0.20939777, 0.1943215 ,\n",
       "            0.17838986])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.21900000000000008),\n",
       "                                     1: np.float64(0.7809999999999999)}),\n",
       "    'fpr': np.float64(0.5588235294117647),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.17647059, 0.17647059,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.35294118,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.47058824, 0.5       , 0.82352941, 0.82352941,\n",
       "            0.85294118, 0.85294118, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.4375, 0.5   , 0.5625, 0.5625, 0.625 , 0.625 ,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.87743509, 0.87006888, 0.80475624, 0.76545227,\n",
       "            0.71091481, 0.70584116, 0.69158862, 0.68636833, 0.66892368,\n",
       "            0.65452405, 0.64941502, 0.64889868, 0.64404326, 0.62744077,\n",
       "            0.60605168, 0.60269797, 0.57678625, 0.41201941, 0.38916128,\n",
       "            0.2629895 , 0.25637484, 0.24768243, 0.2202728 , 0.20410795,\n",
       "            0.1883256 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.20900000000000007),\n",
       "                                     1: np.float64(0.7909999999999999)}),\n",
       "    'fpr': np.float64(0.6176470588235294),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.17647059, 0.17647059,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.35294118,\n",
       "            0.38235294, 0.38235294, 0.41176471, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.47058824, 0.5       , 0.82352941, 0.82352941,\n",
       "            0.85294118, 0.85294118, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.375 ,\n",
       "            0.375 , 0.4375, 0.4375, 0.5   , 0.5625, 0.5625, 0.625 , 0.625 ,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.88396857, 0.87391684, 0.81240821, 0.77592974,\n",
       "            0.72021711, 0.7156458 , 0.70198037, 0.69739021, 0.68002734,\n",
       "            0.66809903, 0.66197   , 0.65931613, 0.6581747 , 0.63735235,\n",
       "            0.62004694, 0.61536189, 0.59142998, 0.42512625, 0.40176376,\n",
       "            0.27322755, 0.26854105, 0.25776599, 0.23163323, 0.21446573,\n",
       "            0.19895487])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.19900000000000018),\n",
       "                                     1: np.float64(0.8009999999999998)}),\n",
       "    'fpr': np.float64(0.6470588235294118),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.17647059, 0.17647059,\n",
       "            0.29411765, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.41176471, 0.44117647,\n",
       "            0.44117647, 0.47058824, 0.47058824, 0.5       , 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.3125,\n",
       "            0.375 , 0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.5625, 0.625 ,\n",
       "            0.625 , 0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375,\n",
       "            1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.89045249, 0.87787981, 0.82004178, 0.78667885,\n",
       "            0.72979724, 0.72700907, 0.72571798, 0.71240589, 0.70850608,\n",
       "            0.69137511, 0.68190083, 0.67549078, 0.67244646, 0.66934745,\n",
       "            0.64782789, 0.63454065, 0.62841941, 0.60609142, 0.43858847,\n",
       "            0.41517252, 0.28388648, 0.28119481, 0.26832663, 0.24391155,\n",
       "            0.22560203, 0.210482  ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.18900000000000017),\n",
       "                                     1: np.float64(0.8109999999999998)}),\n",
       "    'fpr': np.float64(0.6764705882352942),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.17647059, 0.17647059,\n",
       "            0.29411765, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.41176471, 0.44117647,\n",
       "            0.44117647, 0.47058824, 0.47058824, 0.5       , 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.3125,\n",
       "            0.375 , 0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.5625, 0.625 ,\n",
       "            0.625 , 0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375,\n",
       "            1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.89675489, 0.88166642, 0.82738372, 0.79730415,\n",
       "            0.73933176, 0.73906309, 0.73569652, 0.72290891, 0.71970217,\n",
       "            0.70298491, 0.69597369, 0.68930117, 0.68682967, 0.67945752,\n",
       "            0.65840213, 0.64911368, 0.64192204, 0.62107669, 0.45278079,\n",
       "            0.42934119, 0.29561849, 0.29531876, 0.27985065, 0.25743281,\n",
       "            0.23788901, 0.2233191 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.17900000000000016),\n",
       "                                     1: np.float64(0.8209999999999998)}),\n",
       "    'fpr': np.float64(0.7352941176470589),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.17647059, 0.17647059,\n",
       "            0.26470588, 0.26470588, 0.29411765, 0.32352941, 0.32352941,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.41176471,\n",
       "            0.44117647, 0.44117647, 0.47058824, 0.47058824, 0.5       ,\n",
       "            0.82352941, 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  ,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.5625,\n",
       "            0.625 , 0.625 , 0.6875, 0.75  , 0.75  , 0.875 , 0.9375, 0.9375,\n",
       "            1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.9030058 , 0.88592339, 0.83502519, 0.80822362,\n",
       "            0.76348008, 0.75226215, 0.7490053 , 0.7461693 , 0.73405874,\n",
       "            0.73148185, 0.71547677, 0.71050303, 0.70359014, 0.7011814 ,\n",
       "            0.69006613, 0.66970672, 0.66393778, 0.65594867, 0.63646276,\n",
       "            0.46782455, 0.44461582, 0.31103604, 0.29198346, 0.27177797,\n",
       "            0.25115979, 0.23668197])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.16900000000000015),\n",
       "                                     1: np.float64(0.8309999999999998)}),\n",
       "    'fpr': np.float64(0.7352941176470589),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.17647059, 0.17647059,\n",
       "            0.26470588, 0.26470588, 0.29411765, 0.32352941, 0.32352941,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.41176471,\n",
       "            0.44117647, 0.44117647, 0.47058824, 0.47058824, 0.5       ,\n",
       "            0.82352941, 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  ,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.5625,\n",
       "            0.625 , 0.625 , 0.6875, 0.75  , 0.75  , 0.875 , 0.9375, 0.9375,\n",
       "            1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.90895461, 0.88981753, 0.84263861, 0.8185748 ,\n",
       "            0.77319764, 0.76389856, 0.75883551, 0.75666602, 0.74474337,\n",
       "            0.74285026, 0.72702495, 0.72469501, 0.71783284, 0.71583716,\n",
       "            0.70066939, 0.68103206, 0.67867249, 0.6696408 , 0.65205554,\n",
       "            0.48315385, 0.46023944, 0.32688421, 0.30522144, 0.28750181,\n",
       "            0.26511886, 0.25202694])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.15900000000000014),\n",
       "                                     1: np.float64(0.8409999999999999)}),\n",
       "    'fpr': np.float64(0.7941176470588235),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.17647059, 0.17647059,\n",
       "            0.26470588, 0.26470588, 0.29411765, 0.32352941, 0.32352941,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.41176471,\n",
       "            0.44117647, 0.47058824, 0.47058824, 0.5       , 0.82352941,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  ,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.5625,\n",
       "            0.5625, 0.6875, 0.75  , 0.75  , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.91483531, 0.8940304 , 0.85030811, 0.82939719,\n",
       "            0.7832788 , 0.77667686, 0.76918294, 0.76758511, 0.75585873,\n",
       "            0.75496983, 0.73940926, 0.73930536, 0.73292512, 0.73056724,\n",
       "            0.71207822, 0.69383841, 0.68421177, 0.66803209, 0.49967533,\n",
       "            0.47715333, 0.34442333, 0.31934055, 0.30444373, 0.28042642,\n",
       "            0.2684267 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.14900000000000013),\n",
       "                                     1: np.float64(0.8509999999999999)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.17647059, 0.17647059,\n",
       "            0.26470588, 0.26470588, 0.29411765, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.41176471, 0.44117647,\n",
       "            0.47058824, 0.47058824, 0.5       , 0.82352941, 0.82352941,\n",
       "            0.82352941, 0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  ,\n",
       "            0.3125, 0.3125, 0.375 , 0.375 , 0.5   , 0.5   , 0.5625, 0.5625,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.92051914, 0.89805477, 0.8578953 , 0.83995271,\n",
       "            0.79317961, 0.78934116, 0.77956625, 0.77864911, 0.76701519,\n",
       "            0.76697857, 0.75424015, 0.74804771, 0.74566526, 0.72358679,\n",
       "            0.70942425, 0.69894497, 0.68456018, 0.51712023, 0.49553014,\n",
       "            0.36383987, 0.33490639, 0.32356846, 0.29772803, 0.28702954])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.13900000000000012),\n",
       "                                     1: np.float64(0.8609999999999999)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(0.875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.17647059, 0.17647059,\n",
       "            0.26470588, 0.26470588, 0.29411765, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.41176471, 0.44117647,\n",
       "            0.47058824, 0.47058824, 0.5       , 0.82352941, 0.82352941,\n",
       "            0.82352941, 0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  ,\n",
       "            0.3125, 0.3125, 0.375 , 0.375 , 0.5   , 0.5   , 0.5625, 0.5625,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.92616938, 0.90232752, 0.8654113 , 0.85052115,\n",
       "            0.80340162, 0.80202969, 0.79001955, 0.78998192, 0.77922841,\n",
       "            0.77865453, 0.76915087, 0.76390878, 0.76057094, 0.73543213,\n",
       "            0.72473417, 0.71428951, 0.70122318, 0.53513443, 0.51446954,\n",
       "            0.38486676, 0.35160926, 0.34398836, 0.31578885, 0.30749258])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.12900000000000011),\n",
       "                                     1: np.float64(0.8709999999999999)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(0.875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.17647059, 0.17647059,\n",
       "            0.23529412, 0.23529412, 0.26470588, 0.29411765, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.41176471, 0.44117647,\n",
       "            0.47058824, 0.47058824, 0.5       , 0.82352941, 0.82352941,\n",
       "            0.82352941, 0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  ,\n",
       "            0.3125, 0.3125, 0.375 , 0.375 , 0.5   , 0.5   , 0.5625, 0.5625,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.93178594, 0.90689212, 0.87309658, 0.86150105,\n",
       "            0.8436386 , 0.81511671, 0.81358277, 0.80175992, 0.79185782,\n",
       "            0.79041725, 0.78436512, 0.77819817, 0.77573795, 0.74781667,\n",
       "            0.74101489, 0.73027802, 0.71797577, 0.55419482, 0.53531717,\n",
       "            0.4070845 , 0.36971909, 0.36668215, 0.33602329, 0.32996737])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1190000000000001),\n",
       "                                     1: np.float64(0.8809999999999999)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(0.875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.05882353, 0.05882353, 0.17647059,\n",
       "            0.17647059, 0.23529412, 0.23529412, 0.26470588, 0.29411765,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.41176471,\n",
       "            0.44117647, 0.47058824, 0.47058824, 0.5       , 0.52941176,\n",
       "            0.82352941, 0.82352941, 0.82352941, 0.85294118, 0.85294118,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.3125, 0.375 , 0.375 , 0.5   , 0.5   , 0.5625,\n",
       "            0.5625, 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.9375, 0.9375,\n",
       "            1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.93693124, 0.91290976, 0.91138576, 0.88074779,\n",
       "            0.87213637, 0.85360899, 0.82837971, 0.82445624, 0.81395349,\n",
       "            0.80476797, 0.8026958 , 0.79956816, 0.79181519, 0.79070819,\n",
       "            0.76098953, 0.75689904, 0.74675686, 0.73594433, 0.73514324,\n",
       "            0.57499289, 0.55757417, 0.43265185, 0.41039829, 0.39137533,\n",
       "            0.35874389, 0.35509562])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1090000000000001),\n",
       "                                     1: np.float64(0.8909999999999999)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(0.875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.05882353, 0.05882353, 0.14705882,\n",
       "            0.14705882, 0.17647059, 0.17647059, 0.23529412, 0.23529412,\n",
       "            0.26470588, 0.29411765, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.44117647, 0.47058824,\n",
       "            0.47058824, 0.5       , 0.52941176, 0.82352941, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875,\n",
       "            0.1875, 0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.375 , 0.4375,\n",
       "            0.4375, 0.5   , 0.5625, 0.5625, 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.94207467, 0.91965283, 0.91622137, 0.89881493,\n",
       "            0.88859119, 0.88854766, 0.88284379, 0.86362894, 0.84186375,\n",
       "            0.83539861, 0.82654049, 0.81804942, 0.81535611, 0.81502055,\n",
       "            0.81304338, 0.80593633, 0.80592071, 0.77468767, 0.77337826,\n",
       "            0.76348734, 0.75586654, 0.75279596, 0.5970804 , 0.58181708,\n",
       "            0.46048307, 0.43424047, 0.41901297, 0.38395088, 0.38315561])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.09900000000000009),\n",
       "                                     1: np.float64(0.9009999999999999)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(0.875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.05882353, 0.05882353, 0.14705882,\n",
       "            0.14705882, 0.17647059, 0.17647059, 0.23529412, 0.23529412,\n",
       "            0.26470588, 0.29411765, 0.38235294, 0.38235294, 0.41176471,\n",
       "            0.41176471, 0.44117647, 0.47058824, 0.47058824, 0.5       ,\n",
       "            0.52941176, 0.82352941, 0.82352941, 0.82352941, 0.85294118,\n",
       "            0.85294118, 0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875,\n",
       "            0.1875, 0.25  , 0.25  , 0.3125, 0.3125, 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.5625, 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.9375,\n",
       "            0.9375, 1.    , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.94696445, 0.9261849 , 0.92116879, 0.90659476,\n",
       "            0.89787872, 0.896268  , 0.89343666, 0.87363783, 0.85534713,\n",
       "            0.84640735, 0.83946028, 0.83039662, 0.82829918, 0.82110368,\n",
       "            0.82038917, 0.79024898, 0.78896583, 0.78009567, 0.77615818,\n",
       "            0.77062815, 0.62070535, 0.60827432, 0.49112554, 0.46095085,\n",
       "            0.45012452, 0.43813505, 0.41496654, 0.41249806])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.08900000000000019),\n",
       "                                     1: np.float64(0.9109999999999998)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(0.9375),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.05882353, 0.05882353, 0.14705882,\n",
       "            0.14705882, 0.17647059, 0.17647059, 0.23529412, 0.23529412,\n",
       "            0.26470588, 0.29411765, 0.32352941, 0.32352941, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.44117647, 0.47058824,\n",
       "            0.47058824, 0.5       , 0.52941176, 0.82352941, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.91176471, 0.97058824,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875,\n",
       "            0.1875, 0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.375 , 0.4375,\n",
       "            0.4375, 0.5   , 0.5   , 0.5625, 0.6875, 0.6875, 0.75  , 0.75  ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.95157093, 0.9326116 , 0.92635624, 0.9142846 ,\n",
       "            0.90719098, 0.90433667, 0.90417028, 0.88414087, 0.86945246,\n",
       "            0.85830192, 0.85283716, 0.84911422, 0.84740638, 0.84564588,\n",
       "            0.84139728, 0.83665967, 0.83504261, 0.80744266, 0.80460396,\n",
       "            0.79755673, 0.7969084 , 0.78938669, 0.64658939, 0.63641839,\n",
       "            0.52506248, 0.49084552, 0.48393542, 0.46592052, 0.45072393,\n",
       "            0.44484315])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.07900000000000018),\n",
       "                                     1: np.float64(0.9209999999999998)}),\n",
       "    'fpr': np.float64(0.8823529411764706),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.05882353, 0.05882353, 0.14705882,\n",
       "            0.14705882, 0.23529412, 0.23529412, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.38235294, 0.38235294, 0.41176471, 0.41176471,\n",
       "            0.44117647, 0.47058824, 0.47058824, 0.5       , 0.5       ,\n",
       "            0.52941176, 0.82352941, 0.82352941, 0.85294118, 0.85294118,\n",
       "            0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.375 , 0.375 , 0.4375, 0.4375, 0.5   , 0.5   ,\n",
       "            0.5625, 0.625 , 0.625 , 0.6875, 0.75  , 0.75  , 0.9375, 0.9375,\n",
       "            1.    , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.95624336, 0.93901057, 0.93187692, 0.92206169,\n",
       "            0.91474395, 0.89477985, 0.88338824, 0.87014561, 0.86660221,\n",
       "            0.86496613, 0.85976184, 0.85540657, 0.85213648, 0.850672  ,\n",
       "            0.82503611, 0.82058536, 0.81921523, 0.81791027, 0.8159756 ,\n",
       "            0.80828106, 0.6739652 , 0.56299131, 0.52496707, 0.52233271,\n",
       "            0.49801864, 0.49150769, 0.48135936])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.06900000000000017),\n",
       "                                     1: np.float64(0.9309999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.05882353, 0.05882353, 0.14705882,\n",
       "            0.14705882, 0.23529412, 0.23529412, 0.26470588, 0.29411765,\n",
       "            0.38235294, 0.38235294, 0.41176471, 0.41176471, 0.47058824,\n",
       "            0.47058824, 0.5       , 0.5       , 0.52941176, 0.82352941,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.5625,\n",
       "            0.625 , 0.6875, 0.75  , 0.75  , 0.875 , 1.    , 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.96069061, 0.9453617 , 0.9377727 , 0.92974527,\n",
       "            0.92528142, 0.90552011, 0.88274686, 0.88270941, 0.8810491 ,\n",
       "            0.87469926, 0.86991388, 0.86791162, 0.86669578, 0.83970174,\n",
       "            0.83921431, 0.83810893, 0.83593462, 0.82794271, 0.70437947,\n",
       "            0.70104973, 0.5658499 , 0.55463926, 0.53793025, 0.52348324])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.05900000000000016),\n",
       "                                     1: np.float64(0.9409999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.05882353, 0.05882353, 0.14705882,\n",
       "            0.14705882, 0.23529412, 0.23529412, 0.26470588, 0.38235294,\n",
       "            0.38235294, 0.47058824, 0.47058824, 0.52941176, 0.79411765,\n",
       "            0.79411765, 0.82352941, 0.82352941, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.3125,\n",
       "            0.375 , 0.375 , 0.5   , 0.5   , 0.625 , 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 1.    , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.96502494, 0.95166954, 0.94415658, 0.93740229,\n",
       "            0.9346228 , 0.91653737, 0.90021492, 0.89607553, 0.89006568,\n",
       "            0.88390277, 0.86149977, 0.85742832, 0.84779338, 0.74469087,\n",
       "            0.73881046, 0.73795124, 0.61538719, 0.60414049, 0.59027028,\n",
       "            0.57281326])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.049000000000000155),\n",
       "                                     1: np.float64(0.9509999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.05882353, 0.05882353, 0.08823529,\n",
       "            0.08823529, 0.14705882, 0.14705882, 0.23529412, 0.23529412,\n",
       "            0.26470588, 0.38235294, 0.38235294, 0.47058824, 0.47058824,\n",
       "            0.52941176, 0.79411765, 0.79411765, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875,\n",
       "            0.1875, 0.3125, 0.375 , 0.375 , 0.5   , 0.5   , 0.625 , 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 1.    , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.96906498, 0.95781923, 0.95087475, 0.94625952,\n",
       "            0.94600156, 0.94498919, 0.94375443, 0.92802007, 0.91809794,\n",
       "            0.91160605, 0.90621616, 0.90095077, 0.88234875, 0.87973404,\n",
       "            0.86904374, 0.77915779, 0.77890834, 0.77496555, 0.67088542,\n",
       "            0.66161502, 0.65132283, 0.62990859])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.039000000000000146),\n",
       "                                     1: np.float64(0.9609999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.05882353, 0.05882353, 0.11764706,\n",
       "            0.11764706, 0.20588235, 0.20588235, 0.23529412, 0.23529412,\n",
       "            0.26470588, 0.38235294, 0.38235294, 0.44117647, 0.44117647,\n",
       "            0.47058824, 0.52941176, 0.76470588, 0.76470588, 0.82352941,\n",
       "            0.82352941, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.375 , 0.375 , 0.5   , 0.5   , 0.625 , 0.625 ,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 1.    , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.97303725, 0.96411083, 0.95623771, 0.95347106,\n",
       "            0.9529231 , 0.94557485, 0.94048015, 0.93997637, 0.93565828,\n",
       "            0.92773679, 0.92301573, 0.9185089 , 0.90667422, 0.90347958,\n",
       "            0.90342307, 0.89122658, 0.82849905, 0.82310198, 0.8166447 ,\n",
       "            0.7337124 , 0.72283793, 0.71976873, 0.69577357])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.029000000000000137),\n",
       "                                     1: np.float64(0.9709999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.05882353, 0.05882353, 0.08823529,\n",
       "            0.08823529, 0.20588235, 0.20588235, 0.23529412, 0.26470588,\n",
       "            0.38235294, 0.38235294, 0.44117647, 0.44117647, 0.47058824,\n",
       "            0.52941176, 0.76470588, 0.76470588, 0.82352941, 0.82352941,\n",
       "            0.85294118, 0.91176471, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.5   , 0.5   , 0.625 , 0.625 , 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 1.    , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.97693638, 0.97066346, 0.96638419, 0.96258172,\n",
       "            0.96232708, 0.95570362, 0.95275575, 0.9525846 , 0.94465508,\n",
       "            0.94086336, 0.93718717, 0.92981893, 0.92852377, 0.92586342,\n",
       "            0.9150234 , 0.87163955, 0.87091022, 0.86048593, 0.80390128,\n",
       "            0.80064239, 0.79548714, 0.77227596])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.019000000000000128),\n",
       "                                     1: np.float64(0.9809999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.05882353, 0.05882353, 0.08823529,\n",
       "            0.08823529, 0.14705882, 0.14705882, 0.23529412, 0.26470588,\n",
       "            0.32352941, 0.32352941, 0.38235294, 0.38235294, 0.44117647,\n",
       "            0.47058824, 0.58823529, 0.61764706, 0.73529412, 0.73529412,\n",
       "            0.82352941, 0.82352941, 0.85294118, 0.91176471, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.4375, 0.625 , 0.625 , 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 1.    , 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.98106134, 0.97771522, 0.97592297, 0.97235929,\n",
       "            0.97232053, 0.97033001, 0.96909526, 0.96610539, 0.9621631 ,\n",
       "            0.95991126, 0.95928177, 0.95864147, 0.95388741, 0.95250642,\n",
       "            0.95038375, 0.94223324, 0.94132664, 0.92869367, 0.92027067,\n",
       "            0.90875286, 0.8794016 , 0.87907131, 0.87585155, 0.86052326])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.009000000000000119),\n",
       "                                     1: np.float64(0.9909999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.05882353, 0.05882353,\n",
       "            0.08823529, 0.08823529, 0.23529412, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.35294118, 0.35294118, 0.41176471, 0.44117647,\n",
       "            0.61764706, 0.64705882, 0.73529412, 0.73529412, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.91176471, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.25  , 0.25  , 0.3125, 0.3125,\n",
       "            0.375 , 0.375 , 0.4375, 0.4375, 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.98702019, 0.98687729, 0.98654237, 0.98457995,\n",
       "            0.98436553, 0.98418501, 0.98122759, 0.98080667, 0.98060981,\n",
       "            0.98022048, 0.97955452, 0.97866812, 0.9776517 , 0.97727968,\n",
       "            0.97228008, 0.97155111, 0.96949474, 0.96731894, 0.96060729,\n",
       "            0.95775264, 0.95384661, 0.95318615, 0.95246105, 0.94863206])}}],\n",
       "  [{'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.05263158, 0.05263158, 0.10526316,\n",
       "            0.10526316, 0.23684211, 0.23684211, 0.26315789, 0.26315789,\n",
       "            0.34210526, 0.34210526, 0.44736842, 0.47368421, 0.68421053,\n",
       "            0.68421053, 0.81578947, 0.81578947, 0.84210526, 0.89473684,\n",
       "            1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.08333333, 0.08333333,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.00050077, 0.00049863, 0.0004974 , 0.00049529,\n",
       "            0.00048843, 0.00047847, 0.00047795, 0.00047786, 0.00047029,\n",
       "            0.00046451, 0.00046421, 0.000461  , 0.00046068, 0.00044635,\n",
       "            0.00044573, 0.00044447, 0.00044407, 0.00044403, 0.00044396,\n",
       "            0.00044165, 0.00044156])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.989), 1: np.float64(0.011)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.05263158, 0.05263158, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.36842105, 0.36842105, 0.42105263, 0.44736842, 0.63157895,\n",
       "            0.63157895, 0.81578947, 0.86842105, 0.86842105, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.00841185, 0.00818985, 0.00798251, 0.00769505,\n",
       "            0.00704068, 0.00703409, 0.00691097, 0.00598538, 0.00517986,\n",
       "            0.00466459, 0.00459894, 0.00451738, 0.00449488, 0.0035092 ,\n",
       "            0.00344737, 0.0033262 , 0.00332458, 0.00326369, 0.00314082,\n",
       "            0.00305889])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.979),\n",
       "                                     1: np.float64(0.020999999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.05263158, 0.05263158, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.36842105, 0.36842105, 0.42105263, 0.44736842, 0.63157895,\n",
       "            0.63157895, 0.76315789, 0.81578947, 0.86842105, 0.86842105,\n",
       "            1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.02009367, 0.02007565, 0.01921073, 0.0181052 ,\n",
       "            0.01599012, 0.01595083, 0.0148192 , 0.0119637 , 0.00978559,\n",
       "            0.00841716, 0.00831305, 0.00793665, 0.00788577, 0.00552445,\n",
       "            0.00532552, 0.00503038, 0.00502249, 0.00491689, 0.00480439,\n",
       "            0.0044824 , 0.0042763 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.969),\n",
       "                                     1: np.float64(0.030999999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.15789474, 0.15789474, 0.26315789, 0.26315789,\n",
       "            0.34210526, 0.34210526, 0.42105263, 0.44736842, 0.65789474,\n",
       "            0.65789474, 0.73684211, 0.78947368, 0.86842105, 0.86842105,\n",
       "            1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.03496841, 0.03338654, 0.03301988, 0.02637529,\n",
       "            0.02539628, 0.02311588, 0.0230286 , 0.01777071, 0.01420972,\n",
       "            0.01210294, 0.01194893, 0.0109574 , 0.01087565, 0.00687507,\n",
       "            0.00686523, 0.00636205, 0.00633918, 0.00596754, 0.00595247,\n",
       "            0.00538183, 0.00503766])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.959),\n",
       "                                     1: np.float64(0.040999999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.13157895, 0.13157895,\n",
       "            0.18421053, 0.18421053, 0.26315789, 0.26315789, 0.31578947,\n",
       "            0.31578947, 0.42105263, 0.44736842, 0.68421053, 0.68421053,\n",
       "            0.71052632, 0.76315789, 0.84210526, 0.84210526, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.05146024, 0.0482054 , 0.03766684, 0.03504359,\n",
       "            0.03181302, 0.03150791, 0.02377017, 0.01849506, 0.01557145,\n",
       "            0.01545751, 0.0137941 , 0.01363053, 0.0082816 , 0.00827509,\n",
       "            0.00758276, 0.00746763, 0.00706919, 0.0069262 , 0.00604919,\n",
       "            0.00555463])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9490000000000001),\n",
       "                                     1: np.float64(0.05099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.13157895, 0.13157895,\n",
       "            0.18421053, 0.18421053, 0.26315789, 0.26315789, 0.31578947,\n",
       "            0.31578947, 0.42105263, 0.44736842, 0.65789474, 0.65789474,\n",
       "            0.71052632, 0.76315789, 0.84210526, 0.84210526, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.06901713, 0.06454402, 0.04982944, 0.04407043,\n",
       "            0.04076499, 0.03954801, 0.02963616, 0.02260015, 0.01933103,\n",
       "            0.01927351, 0.01655894, 0.01620576, 0.00989774, 0.00982532,\n",
       "            0.00880853, 0.0086797 , 0.00808173, 0.00799188, 0.00671644,\n",
       "            0.00604006])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9390000000000001),\n",
       "                                     1: np.float64(0.06099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.13157895, 0.13157895,\n",
       "            0.18421053, 0.18421053, 0.26315789, 0.26315789, 0.31578947,\n",
       "            0.31578947, 0.42105263, 0.44736842, 0.65789474, 0.65789474,\n",
       "            0.71052632, 0.76315789, 0.84210526, 0.84210526, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.0863838 , 0.0805221 , 0.06169283, 0.05310249,\n",
       "            0.04926038, 0.04765799, 0.03556681, 0.02667381, 0.02279459,\n",
       "            0.02276479, 0.01925044, 0.01870986, 0.01137263, 0.01123707,\n",
       "            0.00993349, 0.00974948, 0.00896874, 0.00892605, 0.00733605,\n",
       "            0.006497  ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.929), 1: np.float64(0.071)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.13157895, 0.13157895,\n",
       "            0.15789474, 0.15789474, 0.18421053, 0.18421053, 0.26315789,\n",
       "            0.26315789, 0.28947368, 0.28947368, 0.42105263, 0.44736842,\n",
       "            0.65789474, 0.65789474, 0.71052632, 0.76315789, 0.81578947,\n",
       "            0.81578947, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.33333333, 0.33333333, 0.41666667, 0.41666667,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
       "            0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.10312945, 0.0960113 , 0.07339974, 0.07211174,\n",
       "            0.06249847, 0.06194589, 0.0575392 , 0.05579075, 0.04166548,\n",
       "            0.03046972, 0.03012973, 0.02600999, 0.02182409, 0.02101636,\n",
       "            0.01269675, 0.01251303, 0.01094219, 0.01067511, 0.01008573,\n",
       "            0.00978477, 0.00788285, 0.00689997])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.919),\n",
       "                                     1: np.float64(0.08099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.13157895, 0.13157895,\n",
       "            0.15789474, 0.15789474, 0.21052632, 0.21052632, 0.26315789,\n",
       "            0.26315789, 0.28947368, 0.28947368, 0.31578947, 0.31578947,\n",
       "            0.44736842, 0.47368421, 0.65789474, 0.65789474, 0.71052632,\n",
       "            0.76315789, 0.81578947, 0.81578947, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.33333333, 0.33333333, 0.41666667, 0.41666667,\n",
       "            0.5       , 0.5       , 0.58333333, 0.58333333, 0.66666667,\n",
       "            0.66666667, 0.75      , 0.75      , 0.83333333, 0.83333333,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.12049522, 0.11205754, 0.08512038, 0.08417451,\n",
       "            0.07288788, 0.07034736, 0.06438251, 0.06347293, 0.04742119,\n",
       "            0.04182603, 0.03449092, 0.03448064, 0.02943825, 0.02943057,\n",
       "            0.02353195, 0.0234165 , 0.01421929, 0.01397482, 0.01207998,\n",
       "            0.01171622, 0.01099649, 0.0107329 , 0.00852222, 0.0073549 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.909),\n",
       "                                     1: np.float64(0.09099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.13157895,\n",
       "            0.13157895, 0.15789474, 0.15789474, 0.21052632, 0.21052632,\n",
       "            0.26315789, 0.26315789, 0.28947368, 0.28947368, 0.44736842,\n",
       "            0.47368421, 0.65789474, 0.65789474, 0.71052632, 0.76315789,\n",
       "            0.81578947, 0.81578947, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.13822134, 0.13669867, 0.12736119, 0.09667432,\n",
       "            0.09600828, 0.08380958, 0.07828725, 0.07340116, 0.07124056,\n",
       "            0.05352467, 0.04682737, 0.03897229, 0.03300647, 0.02617359,\n",
       "            0.02580113, 0.01582397, 0.01550651, 0.01329676, 0.01280553,\n",
       "            0.01189559, 0.01177428, 0.00921571, 0.00785943])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.899),\n",
       "                                     1: np.float64(0.10099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.13157895,\n",
       "            0.13157895, 0.15789474, 0.15789474, 0.21052632, 0.21052632,\n",
       "            0.26315789, 0.26315789, 0.28947368, 0.28947368, 0.31578947,\n",
       "            0.31578947, 0.44736842, 0.47368421, 0.65789474, 0.65789474,\n",
       "            0.71052632, 0.76315789, 0.78947368, 0.78947368, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.15736549, 0.15276025, 0.14254359, 0.1080308 ,\n",
       "            0.10789821, 0.09490557, 0.08623405, 0.08131253, 0.07899671,\n",
       "            0.05971908, 0.05177646, 0.04348453, 0.04231958, 0.03671848,\n",
       "            0.03637367, 0.02883017, 0.028174  , 0.01733212, 0.01699934,\n",
       "            0.01446078, 0.01380231, 0.0133079 , 0.01277037, 0.00988254,\n",
       "            0.00832719])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.889),\n",
       "                                     1: np.float64(0.11099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.15789474, 0.15789474, 0.21052632, 0.21052632,\n",
       "            0.26315789, 0.26315789, 0.28947368, 0.28947368, 0.31578947,\n",
       "            0.31578947, 0.44736842, 0.47368421, 0.65789474, 0.65789474,\n",
       "            0.71052632, 0.76315789, 0.78947368, 0.78947368, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.17709187, 0.16863749, 0.15720244, 0.13432876,\n",
       "            0.11986956, 0.10631845, 0.09427896, 0.08876313, 0.08690968,\n",
       "            0.06623491, 0.0567171 , 0.0481815 , 0.04621854, 0.04050474,\n",
       "            0.03957098, 0.03161421, 0.03052043, 0.01881575, 0.01847286,\n",
       "            0.01563465, 0.01475555, 0.01423748, 0.01374017, 0.01035278,\n",
       "            0.00877809])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.879),\n",
       "                                     1: np.float64(0.12099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.15789474, 0.15789474, 0.21052632, 0.21052632,\n",
       "            0.26315789, 0.26315789, 0.28947368, 0.28947368, 0.34210526,\n",
       "            0.34210526, 0.44736842, 0.47368421, 0.65789474, 0.65789474,\n",
       "            0.71052632, 0.76315789, 0.78947368, 0.78947368, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.19658018, 0.18381066, 0.17116523, 0.14531234,\n",
       "            0.13169053, 0.11765654, 0.10187681, 0.09593799, 0.09474231,\n",
       "            0.0728759 , 0.06168909, 0.05299376, 0.05010883, 0.04302153,\n",
       "            0.04278926, 0.03450212, 0.03280336, 0.02037543, 0.02001785,\n",
       "            0.01690335, 0.01574561, 0.01518443, 0.01477608, 0.01082875,\n",
       "            0.00926964])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.869),\n",
       "                                     1: np.float64(0.13099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.18421053, 0.18421053, 0.21052632, 0.21052632,\n",
       "            0.26315789, 0.26315789, 0.28947368, 0.28947368, 0.34210526,\n",
       "            0.34210526, 0.44736842, 0.47368421, 0.65789474, 0.65789474,\n",
       "            0.71052632, 0.76315789, 0.78947368, 0.78947368, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.21542395, 0.1984067 , 0.18559534, 0.15638036,\n",
       "            0.14329166, 0.11115464, 0.10931524, 0.10345648, 0.10255647,\n",
       "            0.07949405, 0.06683554, 0.05777775, 0.05405242, 0.04645352,\n",
       "            0.0462568 , 0.0373284 , 0.03520292, 0.02196622, 0.02169396,\n",
       "            0.01820291, 0.01679412, 0.01620605, 0.01593533, 0.01136048,\n",
       "            0.009807  ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.859), 1: np.float64(0.141)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.18421053, 0.18421053, 0.21052632, 0.21052632,\n",
       "            0.26315789, 0.26315789, 0.28947368, 0.28947368, 0.34210526,\n",
       "            0.34210526, 0.44736842, 0.47368421, 0.65789474, 0.65789474,\n",
       "            0.71052632, 0.76315789, 0.78947368, 0.78947368, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.23474951, 0.2128891 , 0.19935397, 0.1675374 ,\n",
       "            0.15503369, 0.12056233, 0.11671965, 0.11066986, 0.11040555,\n",
       "            0.08621053, 0.07215241, 0.06255338, 0.05801514, 0.04981504,\n",
       "            0.04955782, 0.04029685, 0.03758067, 0.02349753, 0.02326445,\n",
       "            0.01948972, 0.01777542, 0.01719616, 0.01700413, 0.01187253,\n",
       "            0.01033942])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.849),\n",
       "                                     1: np.float64(0.15099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.18421053, 0.18421053, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.47368421, 0.65789474, 0.65789474, 0.71052632, 0.76315789,\n",
       "            0.78947368, 0.78947368, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.25359347, 0.22676971, 0.21228114, 0.17766775,\n",
       "            0.16664357, 0.1296922 , 0.1181037 , 0.09311836, 0.07755005,\n",
       "            0.06753518, 0.06189547, 0.05341023, 0.05291849, 0.04342908,\n",
       "            0.03988376, 0.02513724, 0.02493074, 0.02088221, 0.01879456,\n",
       "            0.01821418, 0.01817184, 0.01240625, 0.01090297])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.839),\n",
       "                                     1: np.float64(0.16099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.18421053, 0.18421053, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.47368421, 0.63157895, 0.63157895, 0.71052632, 0.76315789,\n",
       "            0.76315789, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.83333333,\n",
       "            0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.27244894, 0.24007566, 0.22549513, 0.18813358,\n",
       "            0.17802959, 0.13958622, 0.12616437, 0.10010844, 0.08232635,\n",
       "            0.07257504, 0.06611945, 0.05701358, 0.05580192, 0.04651459,\n",
       "            0.0421836 , 0.02845116, 0.02675226, 0.02234358, 0.01977962,\n",
       "            0.01940658, 0.01288056, 0.01147382])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.829),\n",
       "                                     1: np.float64(0.17099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.18421053, 0.18421053, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.47368421, 0.63157895, 0.63157895, 0.71052632, 0.76315789,\n",
       "            0.76315789, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.83333333,\n",
       "            0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.29101948, 0.25329406, 0.23850008, 0.1985638 ,\n",
       "            0.18954814, 0.14925055, 0.13413426, 0.10722576, 0.08775193,\n",
       "            0.07768984, 0.07022874, 0.06061541, 0.05913349, 0.04971741,\n",
       "            0.0445936 , 0.02992084, 0.02857198, 0.02383644, 0.02083449,\n",
       "            0.02068838, 0.01342829, 0.0120885 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.8190000000000001),\n",
       "                                     1: np.float64(0.18099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.18421053, 0.18421053, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.47368421, 0.63157895, 0.63157895, 0.73684211, 0.78947368,\n",
       "            0.78947368, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.83333333,\n",
       "            0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.30884767, 0.26656139, 0.25104605, 0.20898755,\n",
       "            0.20081165, 0.15836654, 0.14179839, 0.11432127, 0.09414433,\n",
       "            0.08269326, 0.07408309, 0.06416956, 0.06310313, 0.05270984,\n",
       "            0.04709229, 0.03147828, 0.03019927, 0.02206238, 0.02188938,\n",
       "            0.02183395, 0.01403688, 0.01270155])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.809),\n",
       "                                     1: np.float64(0.19099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.18421053, 0.18421053, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.47368421, 0.63157895, 0.63157895, 0.73684211, 0.73684211,\n",
       "            0.78947368, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.32710683, 0.27860935, 0.26288597, 0.21924491,\n",
       "            0.21212024, 0.16786955, 0.15003498, 0.12171696, 0.0993577 ,\n",
       "            0.08786861, 0.07837637, 0.06776405, 0.06590466, 0.05534087,\n",
       "            0.04945948, 0.03295081, 0.03210899, 0.0235403 , 0.02320682,\n",
       "            0.02291429, 0.01459064, 0.01337413])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.799),\n",
       "                                     1: np.float64(0.20099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.18421053, 0.18421053, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.47368421, 0.63157895, 0.63157895, 0.73684211, 0.73684211,\n",
       "            0.78947368, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.34467878, 0.29132616, 0.27456946, 0.22898214,\n",
       "            0.22354354, 0.17676304, 0.15779817, 0.12908196, 0.10580466,\n",
       "            0.09312268, 0.08230752, 0.07151618, 0.06972804, 0.05800177,\n",
       "            0.0519281 , 0.03449848, 0.03384115, 0.02507237, 0.02444041,\n",
       "            0.02398834, 0.01520723, 0.01403206])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.789),\n",
       "                                     1: np.float64(0.21099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.18421053, 0.18421053, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.47368421, 0.63157895, 0.63157895, 0.73684211, 0.73684211,\n",
       "            0.78947368, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.36167105, 0.3016904 , 0.28501823, 0.23707917,\n",
       "            0.23379916, 0.18603141, 0.16406181, 0.13696974, 0.11170693,\n",
       "            0.09836032, 0.08646342, 0.075299  , 0.07283819, 0.06087651,\n",
       "            0.05425937, 0.0360396 , 0.03573192, 0.02677719, 0.02585891,\n",
       "            0.02507412, 0.01585332, 0.01479415])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.779),\n",
       "                                     1: np.float64(0.22099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.18421053, 0.18421053, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.47368421, 0.60526316, 0.60526316, 0.73684211, 0.73684211,\n",
       "            0.78947368, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.37847869, 0.31420411, 0.29719374, 0.24563325,\n",
       "            0.24534557, 0.19526193, 0.17092447, 0.14446964, 0.11791581,\n",
       "            0.10366017, 0.09058729, 0.07909495, 0.07643845, 0.06363571,\n",
       "            0.05671179, 0.04145479, 0.03768898, 0.02835358, 0.02731023,\n",
       "            0.02615883, 0.01647806, 0.01549075])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.769),\n",
       "                                     1: np.float64(0.23099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.07894737,\n",
       "            0.07894737, 0.18421053, 0.18421053, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.47368421, 0.60526316, 0.60526316, 0.73684211, 0.73684211,\n",
       "            0.78947368, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.39428891, 0.30890302, 0.30840177, 0.2588184 ,\n",
       "            0.25609825, 0.20429802, 0.17737952, 0.15220378, 0.12452902,\n",
       "            0.10903402, 0.09484433, 0.08311301, 0.08011472, 0.06649072,\n",
       "            0.05924973, 0.0435316 , 0.03969123, 0.03014871, 0.02881026,\n",
       "            0.02729641, 0.01720391, 0.01629561])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.759),\n",
       "                                     1: np.float64(0.24099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.07894737,\n",
       "            0.07894737, 0.18421053, 0.18421053, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.47368421, 0.60526316, 0.60526316, 0.73684211, 0.73684211,\n",
       "            0.76315789, 0.81578947, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.41148453, 0.32228089, 0.31906747, 0.26941449,\n",
       "            0.26720346, 0.21306353, 0.18364301, 0.16011841, 0.13108358,\n",
       "            0.11428015, 0.09927402, 0.08677813, 0.08340337, 0.06928732,\n",
       "            0.06179067, 0.04568657, 0.04159874, 0.03195189, 0.03027522,\n",
       "            0.02840836, 0.02831851, 0.01782915, 0.01709112])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7490000000000001),\n",
       "                                     1: np.float64(0.25099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.07894737,\n",
       "            0.07894737, 0.18421053, 0.18421053, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.47368421, 0.60526316, 0.60526316, 0.73684211, 0.73684211,\n",
       "            0.76315789, 0.81578947, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.42744138, 0.33571804, 0.33027581, 0.27949192,\n",
       "            0.27816877, 0.222007  , 0.18995072, 0.16799947, 0.13809329,\n",
       "            0.11967256, 0.103587  , 0.09073973, 0.08711019, 0.07214174,\n",
       "            0.06438407, 0.04782215, 0.04359962, 0.03384774, 0.03179337,\n",
       "            0.02982039, 0.02942423, 0.01854551, 0.01791753])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7390000000000001),\n",
       "                                     1: np.float64(0.26099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.07894737,\n",
       "            0.07894737, 0.18421053, 0.18421053, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.34210526, 0.34210526, 0.47368421,\n",
       "            0.5       , 0.60526316, 0.60526316, 0.73684211, 0.73684211,\n",
       "            0.78947368, 0.84210526, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.44288809, 0.34806906, 0.34010806, 0.28908615,\n",
       "            0.28867214, 0.23116094, 0.19641501, 0.17622787, 0.144553  ,\n",
       "            0.12534864, 0.10804152, 0.0945869 , 0.09040642, 0.06717132,\n",
       "            0.06701181, 0.05008042, 0.04579038, 0.03582595, 0.0334876 ,\n",
       "            0.03066081, 0.03062602, 0.01925313, 0.01879034])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7290000000000001),\n",
       "                                     1: np.float64(0.27099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.26315789, 0.26315789, 0.28947368, 0.28947368,\n",
       "            0.34210526, 0.34210526, 0.47368421, 0.5       , 0.60526316,\n",
       "            0.60526316, 0.73684211, 0.73684211, 0.78947368, 0.84210526,\n",
       "            1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.45813756, 0.36112674, 0.29943682, 0.23994108,\n",
       "            0.20280395, 0.18447172, 0.15164916, 0.1309663 , 0.11242554,\n",
       "            0.09863366, 0.09404109, 0.07095621, 0.06962919, 0.05235171,\n",
       "            0.04789235, 0.03772353, 0.03512482, 0.031929  , 0.03177875,\n",
       "            0.0199904 , 0.01967017])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7190000000000001),\n",
       "                                     1: np.float64(0.28099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.26315789, 0.26315789, 0.28947368, 0.28947368,\n",
       "            0.34210526, 0.34210526, 0.47368421, 0.5       , 0.60526316,\n",
       "            0.60526316, 0.73684211, 0.73684211, 0.78947368, 0.84210526,\n",
       "            1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.47222498, 0.37403216, 0.30998437, 0.24834241,\n",
       "            0.20949797, 0.19281515, 0.15949299, 0.13654664, 0.11646254,\n",
       "            0.10300102, 0.09815083, 0.07473534, 0.07220541, 0.05468739,\n",
       "            0.04980173, 0.03908539, 0.03664133, 0.03318507, 0.03294864,\n",
       "            0.0208174 , 0.02059794])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7090000000000001),\n",
       "                                     1: np.float64(0.291)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.26315789, 0.26315789, 0.28947368, 0.28947368,\n",
       "            0.34210526, 0.34210526, 0.47368421, 0.5       , 0.60526316,\n",
       "            0.60526316, 0.73684211, 0.73684211, 0.78947368, 0.84210526,\n",
       "            1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.48693473, 0.38710136, 0.32084662, 0.25709363,\n",
       "            0.2157288 , 0.20094108, 0.16695994, 0.14220847, 0.12098533,\n",
       "            0.10710639, 0.10194532, 0.07870384, 0.07492712, 0.05701275,\n",
       "            0.05205273, 0.04037929, 0.03840666, 0.03453789, 0.03414335,\n",
       "            0.02158845, 0.02154316])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6990000000000001),\n",
       "                                     1: np.float64(0.30099999999999993)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.34210526, 0.34210526, 0.47368421, 0.5       , 0.60526316,\n",
       "            0.60526316, 0.73684211, 0.73684211, 0.78947368, 0.84210526,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.50061067, 0.39923324, 0.33083472, 0.26559378,\n",
       "            0.22195782, 0.20904448, 0.17489466, 0.12562785, 0.1254607 ,\n",
       "            0.11141911, 0.10581572, 0.08290585, 0.07764429, 0.0596567 ,\n",
       "            0.05424153, 0.04175709, 0.04022769, 0.03591238, 0.03538984,\n",
       "            0.03103786, 0.02260948, 0.02248249])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6890000000000001),\n",
       "                                     1: np.float64(0.31099999999999994)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.34210526, 0.34210526, 0.47368421, 0.5       , 0.60526316,\n",
       "            0.60526316, 0.73684211, 0.73684211, 0.81578947, 0.86842105,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.51460692, 0.40962836, 0.3418129 , 0.27391475,\n",
       "            0.2287534 , 0.21653415, 0.18256756, 0.13070299, 0.13015873,\n",
       "            0.11577351, 0.10947658, 0.08709466, 0.08049166, 0.06212872,\n",
       "            0.05647723, 0.04313886, 0.04201072, 0.03715386, 0.03664706,\n",
       "            0.03217252, 0.02366549, 0.02336711])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.679),\n",
       "                                     1: np.float64(0.32099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.34210526, 0.34210526, 0.47368421, 0.5       , 0.60526316,\n",
       "            0.60526316, 0.73684211, 0.73684211, 0.81578947, 0.86842105,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.52832656, 0.41937071, 0.35208661, 0.28224166,\n",
       "            0.23489311, 0.22447588, 0.19109023, 0.13571768, 0.13468819,\n",
       "            0.12045736, 0.11324958, 0.09151084, 0.08301872, 0.06475182,\n",
       "            0.05864552, 0.04442972, 0.04384707, 0.03860834, 0.03777481,\n",
       "            0.03330736, 0.02475496, 0.02428622])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.669),\n",
       "                                     1: np.float64(0.33099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.34210526, 0.34210526, 0.47368421, 0.5       , 0.60526316,\n",
       "            0.60526316, 0.73684211, 0.73684211, 0.81578947, 0.86842105,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.54076886, 0.42855969, 0.36207743, 0.29063372,\n",
       "            0.24143835, 0.23259943, 0.19955223, 0.14085158, 0.1391887 ,\n",
       "            0.12517332, 0.11731127, 0.09611418, 0.08576831, 0.06750858,\n",
       "            0.06097746, 0.04596572, 0.04583809, 0.04002912, 0.03909755,\n",
       "            0.03454605, 0.02592966, 0.0252611 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.659),\n",
       "                                     1: np.float64(0.34099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.21052632, 0.21052632, 0.26315789, 0.26315789,\n",
       "            0.31578947, 0.31578947, 0.36842105, 0.36842105, 0.47368421,\n",
       "            0.5       , 0.60526316, 0.60526316, 0.71052632, 0.71052632,\n",
       "            0.81578947, 0.86842105, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.55403939, 0.43828787, 0.37272666, 0.29869237,\n",
       "            0.27852764, 0.24785379, 0.24771589, 0.24027058, 0.20798423,\n",
       "            0.14616135, 0.14412697, 0.12150592, 0.12110881, 0.1008015 ,\n",
       "            0.08863866, 0.07026947, 0.06341842, 0.05497844, 0.04787301,\n",
       "            0.04153473, 0.04038149, 0.03572868, 0.02714394, 0.02625784])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.649),\n",
       "                                     1: np.float64(0.3509999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.21052632, 0.21052632, 0.26315789, 0.26315789,\n",
       "            0.31578947, 0.31578947, 0.39473684, 0.39473684, 0.47368421,\n",
       "            0.5       , 0.60526316, 0.60526316, 0.71052632, 0.71052632,\n",
       "            0.81578947, 0.86842105, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.56663863, 0.44788738, 0.38323355, 0.3068478 ,\n",
       "            0.28771024, 0.25513238, 0.25425004, 0.24816234, 0.21666614,\n",
       "            0.15152956, 0.14898176, 0.12575317, 0.12509331, 0.10438238,\n",
       "            0.09154775, 0.07311455, 0.06588487, 0.05786019, 0.04996242,\n",
       "            0.04306661, 0.04171949, 0.03696244, 0.02840436, 0.0272964 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.639),\n",
       "                                     1: np.float64(0.36099999999999993)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.23684211, 0.23684211, 0.26315789, 0.26315789,\n",
       "            0.31578947, 0.31578947, 0.39473684, 0.39473684, 0.47368421,\n",
       "            0.5       , 0.60526316, 0.60526316, 0.71052632, 0.71052632,\n",
       "            0.84210526, 0.89473684, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.57887003, 0.45724931, 0.39361152, 0.31502904,\n",
       "            0.29702335, 0.26245776, 0.26087096, 0.25619624, 0.22553386,\n",
       "            0.15698241, 0.15387513, 0.13111645, 0.12913554, 0.10797099,\n",
       "            0.0945179 , 0.07606719, 0.06840902, 0.06085547, 0.05212831,\n",
       "            0.04343751, 0.04309408, 0.0382256 , 0.0297223 , 0.0283768 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.629),\n",
       "                                     1: np.float64(0.37099999999999994)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.23684211, 0.23684211, 0.26315789, 0.26315789,\n",
       "            0.31578947, 0.31578947, 0.39473684, 0.39473684, 0.47368421,\n",
       "            0.5       , 0.60526316, 0.60526316, 0.71052632, 0.71052632,\n",
       "            0.84210526, 0.89473684, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.59092393, 0.46640361, 0.40410478, 0.32296201,\n",
       "            0.30588317, 0.26989331, 0.26716675, 0.26400843, 0.23459078,\n",
       "            0.16263396, 0.15874979, 0.1365875 , 0.13327369, 0.11147078,\n",
       "            0.09758086, 0.07907643, 0.07104733, 0.06403609, 0.05438452,\n",
       "            0.04576989, 0.04451691, 0.03953904, 0.03112767, 0.02952032])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.619),\n",
       "                                     1: np.float64(0.38099999999999995)}),\n",
       "    'fpr': np.float64(0.02631578947368421),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.23684211, 0.23684211, 0.26315789, 0.26315789,\n",
       "            0.31578947, 0.31578947, 0.39473684, 0.39473684, 0.47368421,\n",
       "            0.5       , 0.60526316, 0.60526316, 0.71052632, 0.71052632,\n",
       "            0.84210526, 0.89473684, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.60203386, 0.4756506 , 0.4138718 , 0.33084545,\n",
       "            0.31561393, 0.27698142, 0.27382876, 0.27213137, 0.24413874,\n",
       "            0.16794105, 0.16364947, 0.14235071, 0.13742344, 0.11531025,\n",
       "            0.10041112, 0.08215989, 0.07348413, 0.06632019, 0.0565812 ,\n",
       "            0.04781524, 0.04582288, 0.04082348, 0.03251158, 0.03068887])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.609),\n",
       "                                     1: np.float64(0.39099999999999996)}),\n",
       "    'fpr': np.float64(0.02631578947368421),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.23684211, 0.23684211, 0.26315789, 0.26315789,\n",
       "            0.31578947, 0.31578947, 0.39473684, 0.39473684, 0.47368421,\n",
       "            0.5       , 0.60526316, 0.60526316, 0.71052632, 0.71052632,\n",
       "            0.84210526, 0.89473684, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.61352866, 0.48510462, 0.42448352, 0.33862639,\n",
       "            0.32494491, 0.28468889, 0.28060381, 0.28000941, 0.25359414,\n",
       "            0.17354726, 0.16873475, 0.1482795 , 0.14160458, 0.11905711,\n",
       "            0.10348603, 0.08532626, 0.0761635 , 0.06842433, 0.05893117,\n",
       "            0.04950391, 0.04727092, 0.04221398, 0.03401162, 0.03194063])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5990000000000001),\n",
       "                                     1: np.float64(0.4009999999999999)}),\n",
       "    'fpr': np.float64(0.02631578947368421),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.42105263, 0.42105263, 0.47368421, 0.5       , 0.60526316,\n",
       "            0.60526316, 0.71052632, 0.71052632, 0.84210526, 0.89473684,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.62467302, 0.49342428, 0.43409639, 0.34695603,\n",
       "            0.33482161, 0.28864032, 0.26292399, 0.179506  , 0.1742057 ,\n",
       "            0.1464743 , 0.14554822, 0.12292603, 0.1067577 , 0.08872785,\n",
       "            0.07906845, 0.07053196, 0.06153599, 0.05127785, 0.04874227,\n",
       "            0.04349175, 0.03555977, 0.03312664])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5890000000000001),\n",
       "                                     1: np.float64(0.4109999999999999)}),\n",
       "    'fpr': np.float64(0.05263157894736842),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.42105263, 0.42105263, 0.47368421, 0.5       , 0.60526316,\n",
       "            0.60526316, 0.71052632, 0.71052632, 0.84210526, 0.89473684,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.63509678, 0.50226702, 0.44409775, 0.35492272,\n",
       "            0.34439279, 0.29700228, 0.2727981 , 0.1853833 , 0.17928248,\n",
       "            0.15170819, 0.14994069, 0.12695691, 0.10997226, 0.09215512,\n",
       "            0.0818826 , 0.07267995, 0.0640929 , 0.05306648, 0.05028847,\n",
       "            0.04496794, 0.03721627, 0.03449245])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5790000000000001),\n",
       "                                     1: np.float64(0.42099999999999993)}),\n",
       "    'fpr': np.float64(0.05263157894736842),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.42105263, 0.42105263, 0.47368421, 0.5       , 0.60526316,\n",
       "            0.60526316, 0.71052632, 0.71052632, 0.84210526, 0.89473684,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.64552053, 0.51107272, 0.45406107, 0.36273935,\n",
       "            0.35417819, 0.30533155, 0.28287856, 0.19122722, 0.1845448 ,\n",
       "            0.15692426, 0.15424513, 0.13103145, 0.11318033, 0.09565291,\n",
       "            0.08471727, 0.07479559, 0.06670411, 0.05484674, 0.05178826,\n",
       "            0.04640071, 0.03890179, 0.03587038])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5690000000000001),\n",
       "                                     1: np.float64(0.43099999999999994)}),\n",
       "    'fpr': np.float64(0.05263157894736842),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.42105263, 0.42105263, 0.47368421, 0.5       , 0.60526316,\n",
       "            0.60526316, 0.71052632, 0.71052632, 0.84210526, 0.89473684,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.6552179 , 0.52046617, 0.46459606, 0.37003242,\n",
       "            0.3635133 , 0.31321214, 0.29339782, 0.19672407, 0.18907972,\n",
       "            0.16216812, 0.15907762, 0.13522493, 0.11615318, 0.09909709,\n",
       "            0.0873428 , 0.07698183, 0.06916502, 0.05655388, 0.05334803,\n",
       "            0.04803747, 0.0406496 , 0.03742214])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.559),\n",
       "                                     1: np.float64(0.44099999999999995)}),\n",
       "    'fpr': np.float64(0.05263157894736842),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.42105263, 0.42105263, 0.47368421, 0.5       , 0.60526316,\n",
       "            0.60526316, 0.71052632, 0.71052632, 0.84210526, 0.89473684,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.66541342, 0.52919489, 0.4746885 , 0.37788818,\n",
       "            0.37342739, 0.32168061, 0.30383221, 0.20286349, 0.19453547,\n",
       "            0.16762553, 0.16350393, 0.13945973, 0.11951554, 0.10278538,\n",
       "            0.09036724, 0.07920808, 0.07197788, 0.0584594 , 0.05493532,\n",
       "            0.04956341, 0.04249371, 0.03890563])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.549),\n",
       "                                     1: np.float64(0.45099999999999996)}),\n",
       "    'fpr': np.float64(0.05263157894736842),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.42105263, 0.42105263, 0.47368421, 0.5       , 0.63157895,\n",
       "            0.63157895, 0.71052632, 0.71052632, 0.84210526, 0.89473684,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.67559117, 0.53766944, 0.48478208, 0.38563403,\n",
       "            0.38338032, 0.33006274, 0.31435809, 0.20907363, 0.20017228,\n",
       "            0.1731647 , 0.16787485, 0.14371858, 0.12301015, 0.0942885 ,\n",
       "            0.09348784, 0.08148811, 0.07488445, 0.06045206, 0.05656438,\n",
       "            0.05112382, 0.04443062, 0.04044355])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5390000000000001),\n",
       "                                     1: np.float64(0.4609999999999999)}),\n",
       "    'fpr': np.float64(0.05263157894736842),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.15789474,\n",
       "            0.15789474, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.42105263, 0.42105263, 0.47368421, 0.5       , 0.63157895,\n",
       "            0.63157895, 0.71052632, 0.71052632, 0.84210526, 0.89473684,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.68475262, 0.54626248, 0.49421882, 0.41564461,\n",
       "            0.39397982, 0.3386443 , 0.32549508, 0.21520712, 0.20614989,\n",
       "            0.17887878, 0.17252912, 0.14845406, 0.12644728, 0.09891957,\n",
       "            0.0966872 , 0.0838463 , 0.07801536, 0.06244575, 0.05819938,\n",
       "            0.05272181, 0.04645819, 0.04207707])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5290000000000001),\n",
       "                                     1: np.float64(0.4709999999999999)}),\n",
       "    'fpr': np.float64(0.05263157894736842),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.15789474,\n",
       "            0.15789474, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.42105263, 0.42105263, 0.47368421, 0.5       , 0.63157895,\n",
       "            0.63157895, 0.71052632, 0.71052632, 0.89473684, 0.94736842,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.69411729, 0.55489383, 0.50415062, 0.42168711,\n",
       "            0.40405749, 0.34706763, 0.33583198, 0.22148379, 0.21191138,\n",
       "            0.18460087, 0.17720741, 0.15292106, 0.1300633 , 0.10356113,\n",
       "            0.0998565 , 0.08606843, 0.08104807, 0.06003724, 0.05989042,\n",
       "            0.05430262, 0.04853501, 0.04375078])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5190000000000001),\n",
       "                                     1: np.float64(0.4809999999999999)}),\n",
       "    'fpr': np.float64(0.07894736842105263),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.15789474,\n",
       "            0.15789474, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.42105263, 0.42105263, 0.47368421, 0.5       , 0.65789474,\n",
       "            0.65789474, 0.76315789, 0.76315789, 0.89473684, 0.94736842,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.70380168, 0.56273348, 0.51386793, 0.42804953,\n",
       "            0.41501146, 0.35537914, 0.3430402 , 0.22773799, 0.21796777,\n",
       "            0.19019706, 0.18207467, 0.15786663, 0.13375244, 0.10425151,\n",
       "            0.10313567, 0.08431594, 0.08420462, 0.06207062, 0.06168962,\n",
       "            0.05598998, 0.05076146, 0.04547048])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5090000000000001),\n",
       "                                     1: np.float64(0.49099999999999994)}),\n",
       "    'fpr': np.float64(0.07894736842105263),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.15789474,\n",
       "            0.15789474, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.44736842, 0.44736842, 0.47368421, 0.5       , 0.65789474,\n",
       "            0.65789474, 0.76315789, 0.76315789, 0.89473684, 0.94736842,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.71213678, 0.57140532, 0.52373776, 0.43473672,\n",
       "            0.42499207, 0.36342424, 0.35035754, 0.23433247, 0.22363003,\n",
       "            0.18776066, 0.18692316, 0.16275386, 0.13733232, 0.10841867,\n",
       "            0.10663194, 0.08797141, 0.08763505, 0.06424374, 0.06355302,\n",
       "            0.05785333, 0.05307597, 0.04737905])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4990000000000001),\n",
       "                                     1: np.float64(0.5009999999999999)}),\n",
       "    'fpr': np.float64(0.10526315789473684),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.15789474,\n",
       "            0.15789474, 0.26315789, 0.26315789, 0.31578947, 0.31578947,\n",
       "            0.44736842, 0.44736842, 0.47368421, 0.5       , 0.65789474,\n",
       "            0.65789474, 0.76315789, 0.76315789, 0.89473684, 0.94736842,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.72046591, 0.57987248, 0.53353915, 0.44152279,\n",
       "            0.43518097, 0.37183611, 0.35789897, 0.24095251, 0.2294032 ,\n",
       "            0.19475296, 0.19190906, 0.16777517, 0.14108522, 0.11277486,\n",
       "            0.11013094, 0.09176455, 0.09112273, 0.06647017, 0.06544432,\n",
       "            0.05974745, 0.05552246, 0.04940874])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4890000000000001),\n",
       "                                     1: np.float64(0.5109999999999999)}),\n",
       "    'fpr': np.float64(0.13157894736842105),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.15789474,\n",
       "            0.15789474, 0.23684211, 0.23684211, 0.26315789, 0.26315789,\n",
       "            0.31578947, 0.31578947, 0.44736842, 0.44736842, 0.47368421,\n",
       "            0.5       , 0.65789474, 0.65789474, 0.76315789, 0.76315789,\n",
       "            0.89473684, 0.94736842, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.72897957, 0.58826288, 0.54341673, 0.4479225 ,\n",
       "            0.4455832 , 0.3819774 , 0.38170384, 0.38055376, 0.36557153,\n",
       "            0.24741495, 0.23554456, 0.2019992 , 0.19652783, 0.17278738,\n",
       "            0.14484814, 0.11735154, 0.11364151, 0.0956762 , 0.0946581 ,\n",
       "            0.06868139, 0.06728864, 0.06164351, 0.05805285, 0.05149247])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4790000000000001),\n",
       "                                     1: np.float64(0.5209999999999999)}),\n",
       "    'fpr': np.float64(0.13157894736842105),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.21052632, 0.21052632, 0.26315789, 0.26315789,\n",
       "            0.31578947, 0.31578947, 0.44736842, 0.44736842, 0.47368421,\n",
       "            0.5       , 0.65789474, 0.65789474, 0.76315789, 0.76315789,\n",
       "            0.89473684, 0.94736842, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.7372816 , 0.59686278, 0.55302835, 0.51611373,\n",
       "            0.45626155, 0.42265624, 0.39348828, 0.38945961, 0.37316755,\n",
       "            0.25404682, 0.24229961, 0.20902179, 0.20115536, 0.1777601 ,\n",
       "            0.14877258, 0.1219892 , 0.11730162, 0.09857095, 0.09837819,\n",
       "            0.07089186, 0.06904064, 0.0634035 , 0.06061995, 0.05356057])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4690000000000001),\n",
       "                                     1: np.float64(0.5309999999999999)}),\n",
       "    'fpr': np.float64(0.13157894736842105),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.21052632, 0.21052632, 0.26315789, 0.26315789,\n",
       "            0.31578947, 0.31578947, 0.44736842, 0.44736842, 0.47368421,\n",
       "            0.5       , 0.65789474, 0.65789474, 0.73684211, 0.73684211,\n",
       "            0.89473684, 0.94736842, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.74522487, 0.60495934, 0.56286602, 0.52438319,\n",
       "            0.46676703, 0.43317453, 0.40516984, 0.39805547, 0.38096408,\n",
       "            0.26114095, 0.2485228 , 0.21697191, 0.20646213, 0.18348217,\n",
       "            0.15294245, 0.12708942, 0.12125649, 0.10417207, 0.10237502,\n",
       "            0.07353272, 0.07129352, 0.06569284, 0.06356988, 0.05596419])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4590000000000001),\n",
       "                                     1: np.float64(0.5409999999999999)}),\n",
       "    'fpr': np.float64(0.13157894736842105),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.21052632, 0.21052632, 0.26315789, 0.26315789,\n",
       "            0.34210526, 0.34210526, 0.44736842, 0.44736842, 0.47368421,\n",
       "            0.5       , 0.65789474, 0.65789474, 0.73684211, 0.73684211,\n",
       "            0.89473684, 0.94736842, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.75305074, 0.61342861, 0.57268683, 0.53272958,\n",
       "            0.47739364, 0.44384482, 0.41718489, 0.40713149, 0.38886094,\n",
       "            0.25513373, 0.25509765, 0.22487349, 0.21179871, 0.18906691,\n",
       "            0.1571331 , 0.13228645, 0.12524663, 0.10873809, 0.10644581,\n",
       "            0.07611372, 0.07343564, 0.06783432, 0.06652205, 0.05836498])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.44900000000000007),\n",
       "                                     1: np.float64(0.5509999999999999)}),\n",
       "    'fpr': np.float64(0.13157894736842105),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.21052632, 0.21052632, 0.26315789, 0.26315789,\n",
       "            0.34210526, 0.34210526, 0.44736842, 0.44736842, 0.47368421,\n",
       "            0.5       , 0.65789474, 0.65789474, 0.76315789, 0.76315789,\n",
       "            0.89473684, 0.94736842, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.76065271, 0.62183456, 0.58237153, 0.54095375,\n",
       "            0.48810651, 0.45460533, 0.42925182, 0.4162547 , 0.39679243,\n",
       "            0.26374896, 0.26179331, 0.23282962, 0.21706899, 0.1948016 ,\n",
       "            0.16131969, 0.13757207, 0.12930025, 0.11121917, 0.11065494,\n",
       "            0.07868899, 0.07557413, 0.07000678, 0.069589  , 0.0608716 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.43900000000000006),\n",
       "                                     1: np.float64(0.5609999999999999)}),\n",
       "    'fpr': np.float64(0.13157894736842105),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.21052632, 0.21052632, 0.26315789, 0.26315789,\n",
       "            0.36842105, 0.36842105, 0.44736842, 0.44736842, 0.5       ,\n",
       "            0.52631579, 0.65789474, 0.65789474, 0.76315789, 0.76315789,\n",
       "            0.89473684, 0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.76813784, 0.63038294, 0.59206995, 0.54904408,\n",
       "            0.49882659, 0.46535794, 0.44170325, 0.42555346, 0.40478673,\n",
       "            0.26995366, 0.26857455, 0.24076037, 0.22243515, 0.16616006,\n",
       "            0.16550992, 0.14290639, 0.13333004, 0.11664765, 0.11489388,\n",
       "            0.08122462, 0.07764013, 0.07273384, 0.06347066])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.42900000000000005),\n",
       "                                     1: np.float64(0.571)}),\n",
       "    'fpr': np.float64(0.13157894736842105),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.21052632, 0.21052632, 0.26315789, 0.26315789,\n",
       "            0.36842105, 0.36842105, 0.44736842, 0.44736842, 0.5       ,\n",
       "            0.52631579, 0.65789474, 0.65789474, 0.76315789, 0.76315789,\n",
       "            0.89473684, 0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.77534677, 0.63861843, 0.60164915, 0.55734385,\n",
       "            0.50942701, 0.47627648, 0.45379112, 0.43495037, 0.41293469,\n",
       "            0.27894003, 0.27564984, 0.24918309, 0.22778862, 0.17155902,\n",
       "            0.16996556, 0.1486438 , 0.1378724 , 0.12247058, 0.11962503,\n",
       "            0.08396758, 0.07992379, 0.07612801, 0.06621838])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.41900000000000004),\n",
       "                                     1: np.float64(0.581)}),\n",
       "    'fpr': np.float64(0.13157894736842105),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.21052632, 0.21052632, 0.26315789, 0.26315789,\n",
       "            0.36842105, 0.36842105, 0.44736842, 0.44736842, 0.5       ,\n",
       "            0.52631579, 0.65789474, 0.65789474, 0.76315789, 0.76315789,\n",
       "            0.89473684, 0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.78243719, 0.64665823, 0.6113939 , 0.56555769,\n",
       "            0.52034188, 0.48420063, 0.46651363, 0.44403923, 0.42122966,\n",
       "            0.28798946, 0.28215814, 0.25722803, 0.23401589, 0.17727417,\n",
       "            0.17462395, 0.15465641, 0.14227345, 0.12857973, 0.12435042,\n",
       "            0.087121  , 0.08258578, 0.0798825 , 0.06934307])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.40900000000000014),\n",
       "                                     1: np.float64(0.5909999999999999)}),\n",
       "    'fpr': np.float64(0.15789473684210525),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.21052632, 0.21052632, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.44736842, 0.44736842, 0.5       ,\n",
       "            0.52631579, 0.65789474, 0.65789474, 0.76315789, 0.76315789,\n",
       "            0.89473684, 0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.78965117, 0.6550572 , 0.62110968, 0.57351889,\n",
       "            0.53118328, 0.4917734 , 0.47879583, 0.45399702, 0.42973895,\n",
       "            0.28985665, 0.28972086, 0.26473161, 0.23941692, 0.18269455,\n",
       "            0.17937498, 0.16080036, 0.14688611, 0.13415074, 0.12920789,\n",
       "            0.09006186, 0.08497483, 0.08359999, 0.07237647])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.39900000000000013),\n",
       "                                     1: np.float64(0.6009999999999999)}),\n",
       "    'fpr': np.float64(0.18421052631578946),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.21052632, 0.21052632, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.44736842, 0.44736842, 0.52631579,\n",
       "            0.55263158, 0.65789474, 0.65789474, 0.76315789, 0.76315789,\n",
       "            0.89473684, 0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.79636095, 0.66325603, 0.63108086, 0.58190874,\n",
       "            0.54166968, 0.49987271, 0.49121599, 0.46428546, 0.43881587,\n",
       "            0.29876497, 0.29659035, 0.27242256, 0.24602587, 0.18577677,\n",
       "            0.18442538, 0.16743175, 0.15194436, 0.14014877, 0.13447449,\n",
       "            0.09344331, 0.08787323, 0.08762003, 0.07573284])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3890000000000001),\n",
       "                                     1: np.float64(0.6109999999999999)}),\n",
       "    'fpr': np.float64(0.21052631578947367),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.21052632, 0.21052632, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.44736842, 0.44736842, 0.52631579,\n",
       "            0.55263158, 0.65789474, 0.65789474, 0.76315789, 0.76315789,\n",
       "            0.89473684, 0.89473684, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.80305428, 0.67179977, 0.64032148, 0.58984506,\n",
       "            0.5529592 , 0.50720275, 0.50396666, 0.47369763, 0.44713812,\n",
       "            0.307603  , 0.30500228, 0.2806806 , 0.25116091, 0.19425655,\n",
       "            0.18930017, 0.17361383, 0.15671665, 0.14531382, 0.13980089,\n",
       "            0.09631888, 0.09173942, 0.0901521 , 0.07909997])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3790000000000001),\n",
       "                                     1: np.float64(0.6209999999999999)}),\n",
       "    'fpr': np.float64(0.21052631578947367),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.18421053, 0.18421053, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.44736842, 0.44736842, 0.55263158,\n",
       "            0.57894737, 0.68421053, 0.68421053, 0.76315789, 0.76315789,\n",
       "            0.89473684, 0.89473684, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.80958023, 0.6795679 , 0.64974406, 0.59821326,\n",
       "            0.56377772, 0.52301542, 0.51652068, 0.48363402, 0.45605486,\n",
       "            0.31659247, 0.31225298, 0.28867639, 0.25740631, 0.19466691,\n",
       "            0.19448002, 0.16252298, 0.16192013, 0.15037479, 0.14545924,\n",
       "            0.09982477, 0.09618135, 0.09304459, 0.08276545])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3690000000000001),\n",
       "                                     1: np.float64(0.6309999999999999)}),\n",
       "    'fpr': np.float64(0.21052631578947367),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.18421053, 0.18421053, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.44736842, 0.44736842, 0.55263158,\n",
       "            0.57894737, 0.68421053, 0.68421053, 0.76315789, 0.76315789,\n",
       "            0.89473684, 0.89473684, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.81589696, 0.68826747, 0.65970808, 0.60649662,\n",
       "            0.57467771, 0.53126187, 0.52968732, 0.49350585, 0.46553424,\n",
       "            0.32654559, 0.32043627, 0.29730408, 0.26418784, 0.20168847,\n",
       "            0.20003214, 0.17003443, 0.1675528 , 0.15575248, 0.15158393,\n",
       "            0.10341425, 0.10098346, 0.09601885, 0.08689495])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3590000000000001),\n",
       "                                     1: np.float64(0.6409999999999999)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.15789474, 0.15789474, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.44736842, 0.44736842, 0.55263158,\n",
       "            0.57894737, 0.68421053, 0.68421053, 0.76315789, 0.76315789,\n",
       "            0.89473684, 0.89473684, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.8218594 , 0.69664144, 0.66902705, 0.61480386,\n",
       "            0.58538965, 0.55363735, 0.54223921, 0.50288928, 0.47453971,\n",
       "            0.33663897, 0.32898466, 0.30642935, 0.27046979, 0.20870764,\n",
       "            0.20534594, 0.17788566, 0.17339777, 0.16079126, 0.15801353,\n",
       "            0.10684297, 0.10577933, 0.09880541, 0.09085601])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3490000000000001),\n",
       "                                     1: np.float64(0.6509999999999999)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.15789474, 0.15789474, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.44736842, 0.44736842, 0.55263158,\n",
       "            0.57894737, 0.71052632, 0.71052632, 0.76315789, 0.76315789,\n",
       "            0.84210526, 0.84210526, 0.89473684, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.82800438, 0.70474368, 0.67807774, 0.62266529,\n",
       "            0.59690741, 0.5648776 , 0.55489532, 0.51291805, 0.48363186,\n",
       "            0.34647334, 0.33844877, 0.31547652, 0.27655901, 0.216327  ,\n",
       "            0.21124362, 0.18029771, 0.17936813, 0.16649093, 0.16462731,\n",
       "            0.11221754, 0.11111309, 0.11069393, 0.10193286, 0.09513829])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3390000000000001),\n",
       "                                     1: np.float64(0.6609999999999999)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.15789474, 0.15789474, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.44736842, 0.44736842, 0.55263158,\n",
       "            0.57894737, 0.71052632, 0.71052632, 0.76315789, 0.76315789,\n",
       "            0.81578947, 0.81578947, 0.89473684, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.8339902 , 0.71292854, 0.68761791, 0.63096588,\n",
       "            0.60788786, 0.576356  , 0.5672273 , 0.5231082 , 0.49328522,\n",
       "            0.35685199, 0.34690363, 0.32446335, 0.28299032, 0.22420531,\n",
       "            0.21715897, 0.18905811, 0.18493639, 0.1724702 , 0.17097973,\n",
       "            0.12037179, 0.11668902, 0.11410958, 0.10524799, 0.09985162])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.32900000000000007),\n",
       "                                     1: np.float64(0.6709999999999999)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.15789474, 0.15789474, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.44736842, 0.44736842, 0.55263158,\n",
       "            0.57894737, 0.71052632, 0.71052632, 0.76315789, 0.76315789,\n",
       "            0.81578947, 0.81578947, 0.89473684, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.83956905, 0.72147554, 0.69697991, 0.63908677,\n",
       "            0.61862251, 0.58738848, 0.57979683, 0.53339697, 0.50315208,\n",
       "            0.36755337, 0.35557183, 0.33383608, 0.29024748, 0.23217152,\n",
       "            0.22355281, 0.19814164, 0.19092674, 0.1788107 , 0.17771475,\n",
       "            0.12479924, 0.12249426, 0.11771425, 0.10882083, 0.10479942])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.31900000000000006),\n",
       "                                     1: np.float64(0.6809999999999999)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.15789474, 0.15789474, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.44736842, 0.44736842, 0.55263158,\n",
       "            0.57894737, 0.71052632, 0.71052632, 0.76315789, 0.76315789,\n",
       "            0.81578947, 0.81578947, 0.89473684, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.84549793, 0.72922509, 0.70515579, 0.64764617,\n",
       "            0.62984896, 0.59905356, 0.59248046, 0.54418292, 0.51340535,\n",
       "            0.37822853, 0.36437665, 0.34299923, 0.29727359, 0.24101671,\n",
       "            0.23024008, 0.20789328, 0.19712248, 0.18591347, 0.18483378,\n",
       "            0.12937651, 0.12900827, 0.12172939, 0.11274945, 0.10962148])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.30900000000000005),\n",
       "                                     1: np.float64(0.691)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.15789474, 0.15789474, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.44736842, 0.44736842, 0.57894737,\n",
       "            0.60526316, 0.73684211, 0.73684211, 0.78947368, 0.78947368,\n",
       "            0.89473684, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.85113905, 0.73759006, 0.71383145, 0.65558241,\n",
       "            0.64113625, 0.61006391, 0.60536287, 0.55413976, 0.52320414,\n",
       "            0.38931531, 0.3751195 , 0.35328897, 0.30453487, 0.23756487,\n",
       "            0.2371145 , 0.2049394 , 0.19317999, 0.1604209 , 0.1356249 ,\n",
       "            0.12552788, 0.11656838, 0.11381659])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.29900000000000015),\n",
       "                                     1: np.float64(0.7009999999999998)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.15789474, 0.15789474, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.44736842, 0.44736842, 0.60526316,\n",
       "            0.63157895, 0.73684211, 0.73684211, 0.78947368, 0.78947368,\n",
       "            0.92105263, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.85657913, 0.74571622, 0.7226195 , 0.66372592,\n",
       "            0.65213552, 0.62129321, 0.61807861, 0.56495142, 0.53354486,\n",
       "            0.40085018, 0.38499152, 0.36324636, 0.31228609, 0.24554788,\n",
       "            0.24437298, 0.21406292, 0.20147334, 0.16567562, 0.14289365,\n",
       "            0.12223261, 0.12087776, 0.11857684])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.28900000000000015),\n",
       "                                     1: np.float64(0.7109999999999999)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.07894737,\n",
       "            0.07894737, 0.13157895, 0.13157895, 0.15789474, 0.15789474,\n",
       "            0.26315789, 0.26315789, 0.39473684, 0.39473684, 0.44736842,\n",
       "            0.44736842, 0.60526316, 0.63157895, 0.73684211, 0.73684211,\n",
       "            0.78947368, 0.78947368, 0.92105263, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.91666667,\n",
       "            0.91666667, 1.        , 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.86206852, 0.75402288, 0.73431443, 0.73178915,\n",
       "            0.73112683, 0.67207712, 0.66369138, 0.6325974 , 0.63108259,\n",
       "            0.5752064 , 0.54402434, 0.41279703, 0.39600218, 0.3737464 ,\n",
       "            0.32010427, 0.25410086, 0.25183522, 0.22334264, 0.20985742,\n",
       "            0.17117962, 0.1504129 , 0.12867319, 0.12510259, 0.12346408])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.27900000000000014),\n",
       "                                     1: np.float64(0.7209999999999999)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.07894737,\n",
       "            0.07894737, 0.13157895, 0.13157895, 0.15789474, 0.15789474,\n",
       "            0.26315789, 0.26315789, 0.39473684, 0.39473684, 0.47368421,\n",
       "            0.47368421, 0.60526316, 0.63157895, 0.73684211, 0.73684211,\n",
       "            0.78947368, 0.78947368, 0.92105263, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.91666667,\n",
       "            0.91666667, 1.        , 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.8672124 , 0.7624092 , 0.74373423, 0.74155051,\n",
       "            0.73983329, 0.68068949, 0.6743525 , 0.64405756, 0.64310001,\n",
       "            0.58603032, 0.55505303, 0.42349284, 0.40681483, 0.32830733,\n",
       "            0.32801562, 0.26279135, 0.2597125 , 0.23307737, 0.21909738,\n",
       "            0.17724803, 0.15850635, 0.13578471, 0.1297625 , 0.12872031])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.26900000000000013),\n",
       "                                     1: np.float64(0.7309999999999999)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.07894737,\n",
       "            0.07894737, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.47368421, 0.47368421, 0.60526316,\n",
       "            0.63157895, 0.73684211, 0.73684211, 0.78947368, 0.78947368,\n",
       "            0.92105263, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.87219803, 0.77071503, 0.75263723, 0.75190968,\n",
       "            0.74878435, 0.68907399, 0.65594056, 0.5973696 , 0.56610481,\n",
       "            0.43462161, 0.41876423, 0.33960207, 0.3363478 , 0.27235315,\n",
       "            0.2681471 , 0.2433585 , 0.22906728, 0.18345257, 0.16721287,\n",
       "            0.14339555, 0.13460276, 0.13425952])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2590000000000001),\n",
       "                                     1: np.float64(0.7409999999999999)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.07894737,\n",
       "            0.07894737, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.47368421, 0.47368421, 0.65789474,\n",
       "            0.68421053, 0.73684211, 0.73684211, 0.78947368, 0.78947368,\n",
       "            0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.87724397, 0.77871842, 0.76182566, 0.7616017 ,\n",
       "            0.75731717, 0.69780087, 0.66837437, 0.60858065, 0.577393  ,\n",
       "            0.44585401, 0.4299254 , 0.35082242, 0.3450974 , 0.27735366,\n",
       "            0.27680082, 0.25408036, 0.23898649, 0.18997967, 0.17638651,\n",
       "            0.14023465, 0.13982805])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2490000000000001),\n",
       "                                     1: np.float64(0.7509999999999999)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.07894737, 0.07894737, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.47368421, 0.47368421, 0.65789474,\n",
       "            0.68421053, 0.73684211, 0.73684211, 0.78947368, 0.78947368,\n",
       "            0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.88207068, 0.77137758, 0.76605002, 0.74274964,\n",
       "            0.70802936, 0.70674166, 0.68096629, 0.6203881 , 0.58899907,\n",
       "            0.45764288, 0.44193567, 0.36269414, 0.35434549, 0.2907906 ,\n",
       "            0.28592706, 0.26554099, 0.24980894, 0.19675043, 0.1860542 ,\n",
       "            0.14634234, 0.14532743])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2390000000000001),\n",
       "                                     1: np.float64(0.7609999999999999)}),\n",
       "    'fpr': np.float64(0.2894736842105263),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.07894737, 0.07894737, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.5       , 0.5       , 0.65789474,\n",
       "            0.68421053, 0.73684211, 0.73684211, 0.78947368, 0.78947368,\n",
       "            0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.88676435, 0.78152501, 0.77485277, 0.7515294 ,\n",
       "            0.71926718, 0.71517635, 0.69370969, 0.6313519 , 0.60055516,\n",
       "            0.46936289, 0.455584  , 0.36742057, 0.36401149, 0.30308477,\n",
       "            0.29583117, 0.27726002, 0.26128538, 0.20427729, 0.19681925,\n",
       "            0.15332825, 0.15116714])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2290000000000001),\n",
       "                                     1: np.float64(0.7709999999999999)}),\n",
       "    'fpr': np.float64(0.34210526315789475),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.07894737, 0.07894737, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.5       , 0.5       , 0.65789474,\n",
       "            0.68421053, 0.73684211, 0.73684211, 0.78947368, 0.78947368,\n",
       "            0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.89136998, 0.7914126 , 0.78367793, 0.76027319,\n",
       "            0.73033288, 0.72414449, 0.70585646, 0.64317249, 0.61274069,\n",
       "            0.48181148, 0.46906691, 0.38283593, 0.37394727, 0.31458789,\n",
       "            0.30630744, 0.28977705, 0.27351485, 0.21247475, 0.20825258,\n",
       "            0.16084986, 0.15765098])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.21900000000000008),\n",
       "                                     1: np.float64(0.7809999999999999)}),\n",
       "    'fpr': np.float64(0.3684210526315789),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.07894737, 0.07894737, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.5       , 0.5       , 0.65789474,\n",
       "            0.68421053, 0.73684211, 0.73684211, 0.78947368, 0.78947368,\n",
       "            0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.89610368, 0.80139383, 0.79278353, 0.76925658,\n",
       "            0.74159735, 0.73319239, 0.71838599, 0.6546012 , 0.62549732,\n",
       "            0.49483739, 0.48304572, 0.39872933, 0.38468005, 0.3266071 ,\n",
       "            0.31741716, 0.30292521, 0.28567078, 0.22105338, 0.2205116 ,\n",
       "            0.16903269, 0.16466577])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.20900000000000007),\n",
       "                                     1: np.float64(0.7909999999999999)}),\n",
       "    'fpr': np.float64(0.39473684210526316),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.07894737, 0.07894737, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.5       , 0.5       , 0.65789474,\n",
       "            0.68421053, 0.73684211, 0.73684211, 0.76315789, 0.76315789,\n",
       "            0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.90053353, 0.81125748, 0.80127593, 0.77731194,\n",
       "            0.75284235, 0.74212898, 0.73088689, 0.66442922, 0.63783682,\n",
       "            0.50782597, 0.49760283, 0.41539352, 0.39541131, 0.33918037,\n",
       "            0.32905397, 0.31646689, 0.29701972, 0.28978733, 0.23376046,\n",
       "            0.17789806, 0.17188878])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.19900000000000018),\n",
       "                                     1: np.float64(0.8009999999999998)}),\n",
       "    'fpr': np.float64(0.42105263157894735),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.07894737, 0.07894737, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.5       , 0.5       , 0.65789474,\n",
       "            0.68421053, 0.73684211, 0.73684211, 0.76315789, 0.76315789,\n",
       "            0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.90489502, 0.82074789, 0.81013913, 0.78573585,\n",
       "            0.763615  , 0.75157887, 0.74294159, 0.67490047, 0.65120733,\n",
       "            0.52145576, 0.51212773, 0.43250404, 0.40767149, 0.35242982,\n",
       "            0.3417141 , 0.33092645, 0.30918726, 0.30350712, 0.24800533,\n",
       "            0.18787326, 0.18033265])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.18900000000000017),\n",
       "                                     1: np.float64(0.8109999999999998)}),\n",
       "    'fpr': np.float64(0.4473684210526316),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.07894737, 0.07894737, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.5       , 0.5       , 0.65789474,\n",
       "            0.68421053, 0.73684211, 0.73684211, 0.76315789, 0.76315789,\n",
       "            0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.90915404, 0.83070489, 0.8191559 , 0.79423501,\n",
       "            0.77504176, 0.76089444, 0.7552956 , 0.68565751, 0.66450544,\n",
       "            0.53594612, 0.52878073, 0.4492653 , 0.41999222, 0.36738932,\n",
       "            0.35536445, 0.34642108, 0.32285851, 0.31836697, 0.26353928,\n",
       "            0.198442  , 0.18914868])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.17900000000000016),\n",
       "                                     1: np.float64(0.8209999999999998)}),\n",
       "    'fpr': np.float64(0.4473684210526316),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.07894737, 0.07894737, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.5       , 0.5       , 0.65789474,\n",
       "            0.68421053, 0.73684211, 0.73684211, 0.76315789, 0.76315789,\n",
       "            0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.91332151, 0.84078817, 0.82817237, 0.80269298,\n",
       "            0.78684961, 0.76995741, 0.76814826, 0.69656167, 0.67827005,\n",
       "            0.55077923, 0.54660602, 0.46716907, 0.43362195, 0.38337752,\n",
       "            0.3701938 , 0.36256491, 0.33696208, 0.33425779, 0.28038584,\n",
       "            0.21014877, 0.19877861])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.16900000000000015),\n",
       "                                     1: np.float64(0.8309999999999998)}),\n",
       "    'fpr': np.float64(0.4473684210526316),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.07894737, 0.07894737, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.5       , 0.5       , 0.65789474,\n",
       "            0.68421053, 0.73684211, 0.73684211, 0.76315789, 0.76315789,\n",
       "            0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.9174613 , 0.85017901, 0.83685752, 0.81099147,\n",
       "            0.79778299, 0.77992274, 0.77973064, 0.70807715, 0.69237551,\n",
       "            0.56606242, 0.56375114, 0.48501474, 0.44736355, 0.39940539,\n",
       "            0.38560844, 0.37941848, 0.35213852, 0.35104716, 0.29814262,\n",
       "            0.22281959, 0.20939772])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.15900000000000014),\n",
       "                                     1: np.float64(0.8409999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.07894737, 0.07894737, 0.10526316,\n",
       "            0.10526316, 0.26315789, 0.26315789, 0.36842105, 0.36842105,\n",
       "            0.5       , 0.5       , 0.65789474, 0.68421053, 0.73684211,\n",
       "            0.73684211, 0.76315789, 0.76315789, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.92145601, 0.85986793, 0.84606268, 0.81934635,\n",
       "            0.79217737, 0.7198582 , 0.70692732, 0.60187475, 0.58386221,\n",
       "            0.50473174, 0.46219958, 0.41642081, 0.40321197, 0.39707219,\n",
       "            0.38211574, 0.36999466, 0.31809126, 0.23617515, 0.22105277])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.14900000000000013),\n",
       "                                     1: np.float64(0.8509999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.07894737, 0.07894737, 0.10526316,\n",
       "            0.10526316, 0.26315789, 0.26315789, 0.36842105, 0.36842105,\n",
       "            0.5       , 0.5       , 0.65789474, 0.68421053, 0.73684211,\n",
       "            0.73684211, 0.76315789, 0.76315789, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.92557696, 0.86785873, 0.85491144, 0.82758127,\n",
       "            0.80428161, 0.7316781 , 0.72168729, 0.616485  , 0.60339952,\n",
       "            0.52543817, 0.47842163, 0.43269833, 0.42143924, 0.41523829,\n",
       "            0.40171886, 0.38981514, 0.33969321, 0.250525  , 0.2340719 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.13900000000000012),\n",
       "                                     1: np.float64(0.8609999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.07894737, 0.07894737, 0.10526316,\n",
       "            0.10526316, 0.26315789, 0.26315789, 0.36842105, 0.36842105,\n",
       "            0.5       , 0.5       , 0.65789474, 0.68421053, 0.73684211,\n",
       "            0.73684211, 0.76315789, 0.76315789, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.92948958, 0.87582858, 0.86387837, 0.83589408,\n",
       "            0.8163298 , 0.74437122, 0.73716872, 0.63191533, 0.62440256,\n",
       "            0.54753343, 0.4958916 , 0.45036967, 0.44170973, 0.43511709,\n",
       "            0.4234248 , 0.41184667, 0.36317672, 0.266707  , 0.24880766])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.12900000000000011),\n",
       "                                     1: np.float64(0.8709999999999999)}),\n",
       "    'fpr': np.float64(0.5789473684210527),\n",
       "    'tpr': np.float64(0.6666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.07894737, 0.07894737, 0.10526316,\n",
       "            0.10526316, 0.26315789, 0.26315789, 0.36842105, 0.36842105,\n",
       "            0.52631579, 0.52631579, 0.65789474, 0.68421053, 0.73684211,\n",
       "            0.73684211, 0.76315789, 0.76315789, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.93328167, 0.88369875, 0.87260594, 0.84411393,\n",
       "            0.8280496 , 0.7574638 , 0.7531245 , 0.64849208, 0.64569508,\n",
       "            0.51869846, 0.51567932, 0.46967309, 0.46423903, 0.45680882,\n",
       "            0.44650922, 0.43621654, 0.38900944, 0.28584724, 0.26618321])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1190000000000001),\n",
       "                                     1: np.float64(0.8809999999999999)}),\n",
       "    'fpr': np.float64(0.631578947368421),\n",
       "    'tpr': np.float64(0.6666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.34210526,\n",
       "            0.34210526, 0.55263158, 0.55263158, 0.65789474, 0.68421053,\n",
       "            0.73684211, 0.73684211, 0.76315789, 0.76315789, 0.94736842,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 1.        , 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.93767302, 0.9371827 , 0.89166335, 0.85458823,\n",
       "            0.8523148 , 0.84032021, 0.77087595, 0.76936245, 0.68286136,\n",
       "            0.66815045, 0.54052556, 0.53694515, 0.49005165, 0.48844298,\n",
       "            0.48032174, 0.47148444, 0.46290031, 0.41736821, 0.30718093,\n",
       "            0.28535811])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1090000000000001),\n",
       "                                     1: np.float64(0.8909999999999999)}),\n",
       "    'fpr': np.float64(0.7368421052631579),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.23684211, 0.23684211, 0.34210526,\n",
       "            0.34210526, 0.55263158, 0.55263158, 0.63157895, 0.65789474,\n",
       "            0.73684211, 0.73684211, 0.76315789, 0.76315789, 0.94736842,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 1.        , 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.94200556, 0.94090866, 0.89951841, 0.86627753,\n",
       "            0.86053978, 0.85291005, 0.80180875, 0.7865888 , 0.70411154,\n",
       "            0.69180563, 0.56732908, 0.56108575, 0.52828163, 0.51580988,\n",
       "            0.50586914, 0.49838837, 0.49284313, 0.44830334, 0.33197795,\n",
       "            0.3078492 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.09900000000000009),\n",
       "                                     1: np.float64(0.9009999999999999)}),\n",
       "    'fpr': np.float64(0.7631578947368421),\n",
       "    'tpr': np.float64(0.9166666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.23684211, 0.23684211, 0.34210526,\n",
       "            0.34210526, 0.55263158, 0.55263158, 0.63157895, 0.65789474,\n",
       "            0.73684211, 0.73684211, 0.76315789, 0.76315789, 0.94736842,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 1.        , 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.94605555, 0.94475972, 0.90720738, 0.8774835 ,\n",
       "            0.86917046, 0.86438667, 0.81718102, 0.80410181, 0.72579783,\n",
       "            0.71642299, 0.59544505, 0.58601012, 0.55403842, 0.54551073,\n",
       "            0.53415333, 0.52791846, 0.52503392, 0.48252371, 0.36100032,\n",
       "            0.33419896])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.08900000000000019),\n",
       "                                     1: np.float64(0.9109999999999998)}),\n",
       "    'fpr': np.float64(0.7631578947368421),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.23684211, 0.23684211, 0.34210526,\n",
       "            0.34210526, 0.55263158, 0.55263158, 0.63157895, 0.65789474,\n",
       "            0.76315789, 0.76315789, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.95020198, 0.94858095, 0.91510559, 0.88890321,\n",
       "            0.87797298, 0.87638783, 0.83270945, 0.82191137, 0.74844628,\n",
       "            0.74259792, 0.6255026 , 0.61399501, 0.58176731, 0.57849581,\n",
       "            0.56067647, 0.52015495, 0.39449545, 0.36476812])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.07900000000000018),\n",
       "                                     1: np.float64(0.9209999999999998)}),\n",
       "    'fpr': np.float64(0.7894736842105263),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.23684211, 0.23684211, 0.34210526, 0.34210526, 0.55263158,\n",
       "            0.55263158, 0.60526316, 0.63157895, 0.73684211, 0.73684211,\n",
       "            0.76315789, 0.76315789, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.95423186, 0.95238532, 0.92298716, 0.88853394,\n",
       "            0.84882639, 0.8404214 , 0.77201881, 0.76983966, 0.65745581,\n",
       "            0.64555649, 0.62374525, 0.61539276, 0.59714874, 0.59477752,\n",
       "            0.59405003, 0.56143204, 0.43416291, 0.40151933])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.06900000000000017),\n",
       "                                     1: np.float64(0.9309999999999998)}),\n",
       "    'fpr': np.float64(0.8947368421052632),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.23684211, 0.23684211, 0.31578947, 0.31578947, 0.55263158,\n",
       "            0.55263158, 0.60526316, 0.63157895, 0.73684211, 0.73684211,\n",
       "            0.76315789, 0.76315789, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.95812996, 0.95624275, 0.93085705, 0.90072895,\n",
       "            0.86558804, 0.85967255, 0.80326279, 0.79806436, 0.69144294,\n",
       "            0.68073677, 0.6615303 , 0.65648481, 0.63336786, 0.63297664,\n",
       "            0.62784549, 0.60295481, 0.48133984, 0.44601576])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.05900000000000016),\n",
       "                                     1: np.float64(0.9409999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.23684211, 0.23684211, 0.31578947, 0.31578947, 0.55263158,\n",
       "            0.55263158, 0.60526316, 0.63157895, 0.71052632, 0.71052632,\n",
       "            0.76315789, 0.76315789, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.96193643, 0.96014789, 0.93876034, 0.91296761,\n",
       "            0.8828718 , 0.87951964, 0.82748992, 0.82697262, 0.72801901,\n",
       "            0.7202867 , 0.70300817, 0.70208224, 0.67820427, 0.67522999,\n",
       "            0.6666951 , 0.64627751, 0.53774447, 0.500793  ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.049000000000000155),\n",
       "                                     1: np.float64(0.9509999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.23684211, 0.23684211, 0.26315789, 0.26315789, 0.55263158,\n",
       "            0.55263158, 0.57894737, 0.60526316, 0.71052632, 0.71052632,\n",
       "            0.76315789, 0.76315789, 0.78947368, 0.78947368, 0.94736842,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        , 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.96580419, 0.96431421, 0.94695256, 0.92508807,\n",
       "            0.90077223, 0.89964601, 0.88873699, 0.85679906, 0.76734084,\n",
       "            0.76374765, 0.75256945, 0.75193101, 0.72568459, 0.72264566,\n",
       "            0.71158155, 0.71045478, 0.70219961, 0.69629002, 0.60570582,\n",
       "            0.56826659])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.039000000000000146),\n",
       "                                     1: np.float64(0.9609999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.21052632, 0.21052632, 0.26315789,\n",
       "            0.26315789, 0.52631579, 0.52631579, 0.55263158, 0.57894737,\n",
       "            0.71052632, 0.71052632, 0.73684211, 0.73684211, 0.78947368,\n",
       "            0.78947368, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.96965893, 0.96868543, 0.95533618, 0.94668773,\n",
       "            0.94109994, 0.93743   , 0.92246045, 0.92040541, 0.91007786,\n",
       "            0.88682001, 0.83027868, 0.81204195, 0.80999216, 0.80613242,\n",
       "            0.77751753, 0.77529129, 0.77151142, 0.76898524, 0.76398828,\n",
       "            0.75370182, 0.68567428, 0.65149118])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.029000000000000137),\n",
       "                                     1: np.float64(0.9709999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.18421053, 0.18421053, 0.26315789,\n",
       "            0.26315789, 0.52631579, 0.52631579, 0.55263158, 0.73684211,\n",
       "            0.73684211, 0.78947368, 0.78947368, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.91666667, 0.91666667, 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.97388319, 0.97355449, 0.96413061, 0.95852691,\n",
       "            0.95687516, 0.95056356, 0.94588553, 0.94152846, 0.93271886,\n",
       "            0.91714729, 0.86977928, 0.8644247 , 0.86298063, 0.833384  ,\n",
       "            0.83083716, 0.8238341 , 0.81786022, 0.77344314, 0.74954236])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.019000000000000128),\n",
       "                                     1: np.float64(0.9809999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.18421053, 0.18421053, 0.26315789,\n",
       "            0.26315789, 0.47368421, 0.5       , 0.5       , 0.73684211,\n",
       "            0.73684211, 0.78947368, 0.78947368, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.16666667,\n",
       "            0.16666667, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.91666667, 0.91666667, 1.        , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.97938989, 0.97932308, 0.97390586, 0.97279921,\n",
       "            0.97143183, 0.96440208, 0.96261579, 0.96246203, 0.9563844 ,\n",
       "            0.94701009, 0.92687369, 0.91919915, 0.91821576, 0.89649604,\n",
       "            0.8953021 , 0.89145315, 0.88888714, 0.86805245, 0.85712831])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.009000000000000119),\n",
       "                                     1: np.float64(0.9909999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.10526316, 0.10526316,\n",
       "            0.18421053, 0.18421053, 0.26315789, 0.26315789, 0.47368421,\n",
       "            0.5       , 0.5       , 0.78947368, 0.78947368, 0.94736842,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.75      , 0.75      , 1.        , 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.98759716, 0.98710597, 0.98520199, 0.98238543,\n",
       "            0.98128792, 0.9807538 , 0.97986773, 0.97589679, 0.96947476,\n",
       "            0.968669  , 0.96785052, 0.9584331 , 0.95778807, 0.95335149,\n",
       "            0.95191555])}}]],\n",
       " 'roc_results': {'fpr': array([0.        , 0.01666667, 0.03333333, 0.03333333, 0.05      ,\n",
       "         0.05      , 0.08333333, 0.08333333, 0.1       , 0.1       ,\n",
       "         0.11666667, 0.11666667, 0.15      , 0.15      , 0.21666667,\n",
       "         0.21666667, 0.23333333, 0.23333333, 0.25      , 0.25      ,\n",
       "         0.35      , 0.35      , 0.4       , 0.4       , 0.4       ,\n",
       "         0.43333333, 0.43333333, 0.48333333, 0.48333333, 0.51666667,\n",
       "         0.53333333, 0.53333333, 0.55      , 0.55      , 0.7       ,\n",
       "         0.7       , 0.71666667, 0.71666667, 0.76666667, 0.76666667,\n",
       "         0.8       , 0.83333333, 0.83333333, 1.        ]),\n",
       "  'tpr': array([0.        , 0.        , 0.        , 0.19230769, 0.19230769,\n",
       "         0.23076923, 0.23076923, 0.26923077, 0.26923077, 0.30769231,\n",
       "         0.30769231, 0.34615385, 0.34615385, 0.38461538, 0.38461538,\n",
       "         0.42307692, 0.42307692, 0.46153846, 0.46153846, 0.5       ,\n",
       "         0.5       , 0.53846154, 0.53846154, 0.61538462, 0.65384615,\n",
       "         0.65384615, 0.69230769, 0.69230769, 0.73076923, 0.73076923,\n",
       "         0.76923077, 0.80769231, 0.80769231, 0.84615385, 0.84615385,\n",
       "         0.88461538, 0.88461538, 0.92307692, 0.92307692, 0.96153846,\n",
       "         0.96153846, 0.96153846, 1.        , 1.        ]),\n",
       "  'thresholds': array([       inf, 0.83629369, 0.82177509, 0.68632713, 0.66155968,\n",
       "         0.65633661, 0.58996409, 0.56990748, 0.56512514, 0.55814077,\n",
       "         0.54545206, 0.53628688, 0.50547703, 0.47718351, 0.38904034,\n",
       "         0.38467429, 0.37653789, 0.37444519, 0.35709089, 0.35595508,\n",
       "         0.31069689, 0.30518179, 0.25927686, 0.25141317, 0.24946802,\n",
       "         0.23989544, 0.23780847, 0.22562992, 0.22398087, 0.22363513,\n",
       "         0.22108361, 0.19726   , 0.19640342, 0.18399211, 0.15215606,\n",
       "         0.14027111, 0.13683985, 0.1315177 , 0.10664688, 0.0972129 ,\n",
       "         0.09598703, 0.09495529, 0.08989055, 0.03477143]),\n",
       "  'name': 'Logistic Regression',\n",
       "  'auc': np.float64(0.6746794871794872),\n",
       "  'model': LogisticRegression()},\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x725f0f3b9280>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Save the data\n",
    "save_to_pickle(list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader, filename='pickle/Logistic_BreastCancer_weighted.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671d9dd3",
   "metadata": {},
   "source": [
    "# Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dd32937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Load the data\n",
    "list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader = load_from_pickle(filename='pickle/Logistic_BreastCancer_weighted.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47987f50",
   "metadata": {},
   "source": [
    "### Ensemble prediction using voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a9ef57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a single ensemble from 68 models across all folds.\n",
      "Extracting full dataset...\n",
      "Getting predictions from all models...\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Loop through all the FPR values to generate the ensemble ROC curve ---\n",
    "\n",
    "\n",
    "\n",
    "results_tuple, prior_proba = predict_ensemble_and_evaluate(list_folds_best_models=list_folds_best_models,\n",
    "    test_loader=test_loader)\n",
    "\n",
    "ensemble_results_soft = results_tuple['soft_voting']\n",
    "ensemble_results_hard = results_tuple['hard_voting']\n",
    "misclassification_risk = results_tuple['misclassification_risk']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd753c5e",
   "metadata": {},
   "source": [
    "## Calculate Neyman Pearson ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efc782bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after preprocessing: (286, 33)\n",
      "Training data shape: (200, 33), (200,)\n",
      "Test data shape: (86, 33), (86,)\n",
      "Shape of training data: (200, 34)\n",
      "Shape of test data: (86, 34)\n",
      "\n",
      "Data successfully processed and concatenated.\n",
      "Shape of final training data: (200, 34)\n",
      "Generating constrained ROC curve (Neyman-Pearson Simulation)...\n",
      "Phase 1 Complete. Model trained and scores generated.\n",
      "\n",
      "Phase 2: Calculating cutoffs for all alphas without re-training...\n",
      "Sample size is too small for the given alpha. Try a larger alpha.\n",
      "Alpha 0.00 (1/51): No valid cutoff found (sample size may be too small).\n",
      "Sample size is too small for the given alpha. Try a larger alpha.\n",
      "Alpha 0.02 (2/51): No valid cutoff found (sample size may be too small).\n",
      "Sample size is too small for the given alpha. Try a larger alpha.\n",
      "Alpha 0.04 (3/51): No valid cutoff found (sample size may be too small).\n",
      "Alpha 0.06 (4/51): FPR=0.050, TPR=0.077\n",
      "Alpha 0.08 (5/51): FPR=0.050, TPR=0.077\n",
      "Alpha 0.10 (6/51): FPR=0.050, TPR=0.077\n",
      "Alpha 0.12 (7/51): FPR=0.083, TPR=0.269\n",
      "Alpha 0.14 (8/51): FPR=0.083, TPR=0.269\n",
      "Alpha 0.16 (9/51): FPR=0.100, TPR=0.269\n",
      "Alpha 0.18 (10/51): FPR=0.117, TPR=0.269\n",
      "Alpha 0.20 (11/51): FPR=0.117, TPR=0.269\n",
      "Alpha 0.22 (12/51): FPR=0.150, TPR=0.385\n",
      "Alpha 0.24 (13/51): FPR=0.150, TPR=0.385\n",
      "Alpha 0.26 (14/51): FPR=0.200, TPR=0.538\n",
      "Alpha 0.28 (15/51): FPR=0.200, TPR=0.538\n",
      "Alpha 0.30 (16/51): FPR=0.217, TPR=0.538\n",
      "Alpha 0.32 (17/51): FPR=0.217, TPR=0.538\n",
      "Alpha 0.34 (18/51): FPR=0.283, TPR=0.538\n",
      "Alpha 0.36 (19/51): FPR=0.283, TPR=0.538\n",
      "Alpha 0.38 (20/51): FPR=0.300, TPR=0.538\n",
      "Alpha 0.40 (21/51): FPR=0.333, TPR=0.538\n",
      "Alpha 0.42 (22/51): FPR=0.333, TPR=0.538\n",
      "Alpha 0.44 (23/51): FPR=0.333, TPR=0.577\n",
      "Alpha 0.46 (24/51): FPR=0.367, TPR=0.577\n",
      "Alpha 0.48 (25/51): FPR=0.367, TPR=0.577\n",
      "Alpha 0.50 (26/51): FPR=0.383, TPR=0.615\n",
      "Alpha 0.52 (27/51): FPR=0.400, TPR=0.615\n",
      "Alpha 0.54 (28/51): FPR=0.400, TPR=0.615\n",
      "Alpha 0.56 (29/51): FPR=0.450, TPR=0.615\n",
      "Alpha 0.58 (30/51): FPR=0.467, TPR=0.615\n",
      "Alpha 0.60 (31/51): FPR=0.483, TPR=0.615\n",
      "Alpha 0.62 (32/51): FPR=0.500, TPR=0.692\n",
      "Alpha 0.64 (33/51): FPR=0.500, TPR=0.692\n",
      "Alpha 0.66 (34/51): FPR=0.517, TPR=0.692\n",
      "Alpha 0.68 (35/51): FPR=0.533, TPR=0.731\n",
      "Alpha 0.70 (36/51): FPR=0.533, TPR=0.731\n",
      "Alpha 0.72 (37/51): FPR=0.583, TPR=0.769\n",
      "Alpha 0.74 (38/51): FPR=0.583, TPR=0.769\n",
      "Alpha 0.76 (39/51): FPR=0.600, TPR=0.846\n",
      "Alpha 0.78 (40/51): FPR=0.617, TPR=0.885\n",
      "Alpha 0.80 (41/51): FPR=0.683, TPR=0.885\n",
      "Alpha 0.82 (42/51): FPR=0.700, TPR=0.923\n",
      "Alpha 0.84 (43/51): FPR=0.750, TPR=0.923\n",
      "Alpha 0.86 (44/51): FPR=0.833, TPR=1.000\n",
      "Alpha 0.88 (45/51): FPR=0.833, TPR=1.000\n",
      "Alpha 0.90 (46/51): FPR=0.833, TPR=1.000\n",
      "Alpha 0.92 (47/51): FPR=0.833, TPR=1.000\n",
      "Alpha 0.94 (48/51): FPR=0.850, TPR=1.000\n",
      "Alpha 0.96 (49/51): FPR=0.967, TPR=1.000\n",
      "Alpha 0.98 (50/51): FPR=0.983, TPR=1.000\n",
      "Alpha 1.00 (51/51): FPR=1.000, TPR=1.000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, auc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nproc import npc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_data, test_data, val_data = generate_data(\"breast_cancer\")  \n",
    "\n",
    "\n",
    "train_data_tensor = data.TensorDataset(torch.tensor(train_data[:, :-1], dtype=torch.float32),\n",
    "                                        torch.tensor(train_data[:, -1], dtype=torch.float32))\n",
    "train_loader = data.DataLoader(train_data_tensor, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) #over-write later for k-fold cross-validation\n",
    "test_data_tensor = data.TensorDataset(torch.tensor(test_data[:, :-1], dtype=torch.float32),\n",
    "                                       torch.tensor(test_data[:, -1], dtype=torch.float32))\n",
    "test_loader = data.DataLoader(test_data_tensor, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]\n",
    "print(\"Generating constrained ROC curve (Neyman-Pearson Simulation)...\")\n",
    "\n",
    "npc_instance = npc()\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "result = npc_instance.npc(\n",
    "    x=X_train, \n",
    "    y=y_train, \n",
    "    method=\"\", # Leave blank to use the provided model\n",
    "    model=model,\n",
    "    rand_seed=42\n",
    ")\n",
    "\n",
    "# Extract the essential, one-time results\n",
    "# The structure is result[fits][split_index][element_index]\n",
    "fit_results = result[0][0]\n",
    "final_model = fit_results[0] # The trained model\n",
    "y_test_calib = fit_results[1]       # The labels from the calibration set\n",
    "y_decision_values = fit_results[2]  # The scores from the single trained model\n",
    "initial_sign = fit_results[4]       # The sign indicating score direction\n",
    "\n",
    "print(\"Phase 1 Complete. Model trained and scores generated.\")\n",
    "\n",
    "# --- 3. Phase 2: Calculate All ROC Points Efficiently ---\n",
    "print(\"\\nPhase 2: Calculating cutoffs for all alphas without re-training...\")\n",
    "\n",
    "# Define the FPR constraints (alphas) we want to target\n",
    "alphas = np.linspace(0, 1, 51)\n",
    "roc_points = []\n",
    "\n",
    "# Get the model's scores on the completely separate test set\n",
    "y_test_scores = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# If the sign is True, it means lower scores are better for class 1.\n",
    "# The npc_core function expects higher scores to be better, so we invert them once.\n",
    "if initial_sign:\n",
    "    y_decision_values = -y_decision_values\n",
    "    y_test_scores = -y_test_scores\n",
    "\n",
    "for i, alpha in enumerate(alphas):\n",
    "    # Call ONLY the fast npc_core function\n",
    "    core_result = npc_instance.npc_core(\n",
    "        y_test=y_test_calib,\n",
    "        y_decision_values=y_decision_values,\n",
    "        alpha=alpha,\n",
    "        delta=0.05,\n",
    "        n_cores=1\n",
    "    )\n",
    "    \n",
    "    if not core_result or core_result[6] == True: # core_result[6] is n_small flag\n",
    "        print(f\"Alpha {alpha:.2f} ({i+1}/{len(alphas)}): No valid cutoff found (sample size may be too small).\")\n",
    "        continue\n",
    "\n",
    "    # Get the optimal cutoff for this specific alpha\n",
    "    cutoff = core_result[0]\n",
    "\n",
    "    # Manually apply the cutoff to the saved scores to get predictions\n",
    "    # Note: We already handled the sign, so higher score is always better here.\n",
    "    y_pred = (y_test_scores >= cutoff).astype(int)\n",
    "\n",
    "    # Calculate TPR and FPR for this point\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    current_fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    current_tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    roc_points.append({'fpr': current_fpr, 'tpr': current_tpr})\n",
    "    print(f\"Alpha {alpha:.2f} ({i+1}/{len(alphas)}): FPR={current_fpr:.3f}, TPR={current_tpr:.3f}\")\n",
    "\n",
    "# --- 4. Process and Plot the Results ---\n",
    "# Remove duplicate points\n",
    "unique_points_dict = {(p['fpr'], p['tpr']): p for p in roc_points}\n",
    "constrained_points = list(unique_points_dict.values())\n",
    "constrained_points = sorted(constrained_points, key=lambda x: x['fpr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "015c16e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constrained ROC curve points saved to pickle/Logistic_Breast_Cancer_NP_roc_curve.pkl\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle_constrained_roc\n",
    "\n",
    "# Save the constrained ROC curve results\n",
    "save_to_pickle_constrained_roc(constrained_points, filename='pickle/Logistic_Breast_Cancer_NP_roc_curve.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233ded62",
   "metadata": {},
   "source": [
    "## Load NP curve pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f98fdfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constrained ROC curve points loaded from pickle/Logistic_Breast_Cancer_NP_roc_curve.pkl\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import load_from_pickle_constrained_roc\n",
    "\n",
    "# Load the constrained ROC curve results\n",
    "constrained_points = load_from_pickle_constrained_roc(filename='pickle/Logistic_Breast_Cancer_NP_roc_curve.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e3a7c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Plotting all ROC curves for comparison ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "results_lists.append(constrained_points)\n",
    "results_lists.append(ensemble_results_hard)\n",
    "results_lists.append(misclassification_risk)\n",
    "\n",
    "# --- Plot the final comparison ---\n",
    "print(\"\\n--- Plotting all ROC curves for comparison ---\")\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"MaxROCFold 1\", \"MaxROCFold 2\", \"MaxROCFold 3\", \"MaxROCFold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\", \"Neyman_Pearson\", \"Ensemble_voting_hard\", \"Misclassification_Risk\"],\n",
    "    results_original_roc=results_original_roc, plot_name=\"logistic_weighted_BreastCanser\", prior_prob=prior_proba\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLlabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
