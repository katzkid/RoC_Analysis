{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b31b88",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc819711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d840881",
   "metadata": {},
   "source": [
    "## Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c24af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for displaying ROC curves of multiple classifiers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_connected_points(results_list, results_original_roc, name=\"All Classifiers\"):\n",
    "    \"\"\"\n",
    "    Creates a plot showing the performance of all classifiers as points,\n",
    "    and connects them with a line, sorted by FPR.\n",
    "\n",
    "    Args:\n",
    "        results_list: A list of dictionaries, where each dict contains 'fpr', 'tpr'.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    # Convert results to a pandas DataFrame for easy sorting\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Sort the models by their False Positive Rate to create a left-to-right line\n",
    "    df_sorted = df.sort_values(by=['fpr','tpr']).reset_index(drop=True)\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot all the individual model points as a scatter plot\n",
    "    # This helps see the actual performance of each model\n",
    "    plt.scatter(df_sorted['fpr'], df_sorted['tpr'], c='black', marker='o', \n",
    "                alpha=0.6, s=100, zorder=3) # zorder=3 puts dots on top\n",
    "\n",
    "    # Plot the line connecting the points\n",
    "    plt.plot(df_sorted['fpr'], df_sorted['tpr'], color='red', lw=1.5,\n",
    "             alpha=0.8, label=f'{name} (AUC = {auc(df_sorted[\"fpr\"], df_sorted[\"tpr\"]):.2f})')\n",
    "    \n",
    "    #plot the original ROC curve\n",
    "    plt.plot(results_original_roc[\"fpr\"], results_original_roc[\"tpr\"], color='blue', \n",
    "             label=f'{results_original_roc[\"name\"]} (AUC = {results_original_roc[\"auc\"]:.2f})')\n",
    "\n",
    "    # Plot the \"no-skill\" line for reference\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Performance Path of All Trained Classifiers')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9508c52",
   "metadata": {},
   "source": [
    "## Best ROC envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "535c203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def get_best_roc_envelope(results_list, results_original_roc=None):\n",
    "    \"\"\"\n",
    "    Constructs the upper envelope of multiple ROC curves to find the best\n",
    "    possible operating points from a collection of classifiers.\n",
    "\n",
    "    This function is guaranteed to produce a list of points that starts at\n",
    "    (FPR=0, TPR=0) and ends at (FPR=1, TPR=1), making it suitable for direct\n",
    "    plotting and AUC calculation.\n",
    "\n",
    "    Args:\n",
    "        results_list (list): A list of dictionaries. Each dictionary must\n",
    "                             contain a 'model' name and the full ROC results\n",
    "                             under the 'full_roc' key.\n",
    "        results_original_roc (dict, optional): A dictionary containing the\n",
    "                                               ROC results of a baseline model,\n",
    "                                               which will also be included in\n",
    "                                               the comparison. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of dictionaries representing the optimal ROC\n",
    "              envelope. Each dictionary includes 'model', 'fpr', 'tpr',\n",
    "              and 'threshold'.\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "\n",
    "    # Step 1: Gather all ROC points from all provided models\n",
    "    all_results = results_list[:]\n",
    "    if results_original_roc:\n",
    "        all_results.append({\n",
    "            'model': 'original_baseline',\n",
    "            'full_roc': results_original_roc\n",
    "        })\n",
    "\n",
    "    for result in all_results:\n",
    "        model_name = result.get('model', 'Unknown Model')\n",
    "        roc = result.get('full_roc')\n",
    "        if not roc: continue\n",
    "\n",
    "        fprs = roc.get('fpr', [])\n",
    "        tprs = roc.get('tpr', [])\n",
    "        thresholds = roc.get('thresholds', [])\n",
    "\n",
    "        for i in range(len(fprs)):\n",
    "            threshold = thresholds[i] if i < len(thresholds) else thresholds[-1]\n",
    "            all_points.append({\n",
    "                'model': model_name, 'fpr': fprs[i],\n",
    "                'tpr': tprs[i], 'threshold': threshold\n",
    "            })\n",
    "\n",
    "    # Handle case with no data by returning a default diagonal line\n",
    "    if not all_points:\n",
    "        return [\n",
    "            {'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf},\n",
    "            {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}\n",
    "        ]\n",
    "\n",
    "    # Step 2: Sort all points by FPR (asc), then by TPR (desc)\n",
    "    all_points.sort(key=lambda p: (p['fpr'], -p['tpr']))\n",
    "\n",
    "    # Step 3: Build the core ROC envelope\n",
    "    best_roc_envelope = []\n",
    "    max_tpr_so_far = -1.0\n",
    "    for point in all_points:\n",
    "        # Add a point only if it has a strictly higher TPR\n",
    "        if point['tpr'] > max_tpr_so_far:\n",
    "            # To prevent adding multiple points at the same FPR, check if the last point\n",
    "            # has the same FPR and replace it if so (since this one has a higher TPR)\n",
    "            if best_roc_envelope and best_roc_envelope[-1]['fpr'] == point['fpr']:\n",
    "                best_roc_envelope[-1] = point\n",
    "            else:\n",
    "                best_roc_envelope.append(point)\n",
    "            max_tpr_so_far = point['tpr']\n",
    "    \n",
    "    # Step 4: Manually add extremities if they are missing\n",
    "    \n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not best_roc_envelope or best_roc_envelope[0]['fpr'] > 0.0:\n",
    "        best_roc_envelope.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if best_roc_envelope[-1]['fpr'] < 1.0 or best_roc_envelope[-1]['tpr'] < 1.0:\n",
    "        best_roc_envelope.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return best_roc_envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b781e9",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8c3deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_data(dataset):\n",
    "    if dataset == \"data1\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [0, 2], [2, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "    elif dataset == \"data2\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [1, 2], [1, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    elif dataset == \"pneumoniaMNIST\":\n",
    "        import medmnist\n",
    "        print(medmnist.__version__)\n",
    "        # read in the PneumoniaMNIST dataset\n",
    "        from medmnist import PneumoniaMNIST\n",
    "        train_data = PneumoniaMNIST(split='train', download=True, size=224)\n",
    "        test_data = PneumoniaMNIST(split='test', download=True, size=224)\n",
    "        val_data = PneumoniaMNIST(split='val', download=True, size=224)\n",
    "        # print the dataset info\n",
    "        print(f\"Number of training samples: {len(train_data)}\")\n",
    "        print(f\"Number of test samples: {len(test_data)}\")\n",
    "        print(f\"Number of validation samples: {len(val_data)}\")\n",
    "\n",
    "    elif dataset == \"breast_cancer\":\n",
    "        from ucimlrepo import fetch_ucirepo\n",
    "        from sklearn.compose import ColumnTransformer\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        # Fetch and print columns for the dataset your code is using\n",
    "\n",
    "        # 1. Fetch data for Breast Cancer (ID 15)\n",
    "        bc = fetch_ucirepo(id=14)\n",
    "        X_df, y_df = bc.data.features, bc.data.targets\n",
    "\n",
    "        # 2. Replace '?' with a standard missing value format\n",
    "        X_df = X_df.replace('?', np.nan)\n",
    "\n",
    "        # 3. Encode the target variable\n",
    "        y = LabelEncoder().fit_transform(y_df.to_numpy().ravel())\n",
    "\n",
    "        # 4. Define column lists using the correct names for this dataset\n",
    "        categorical_features = ['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'breast', 'breast-quad', 'irradiat']\n",
    "        numeric_features = ['deg-malig']\n",
    "\n",
    "        # 5. Create preprocessing pipelines\n",
    "        numeric_pipeline = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        categorical_pipeline = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        # 6. Build the master preprocessor\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_pipeline, numeric_features),\n",
    "                ('cat', categorical_pipeline, categorical_features)\n",
    "            ])\n",
    "\n",
    "        # 7. Apply the transformations\n",
    "        X_sparse = preprocessor.fit_transform(X_df)\n",
    "\n",
    "        X = X_sparse.toarray()\n",
    "\n",
    "        # --- CRITICAL DEBUGGING STEP ---\n",
    "        print(f\"Shape of X after preprocessing: {X.shape}\")\n",
    "        # This MUST print a shape like (286, 46). If it prints (286, 0), the preprocessor failed.\n",
    "        # -----------------------------\n",
    "\n",
    "        # 8. Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, train_size=0.7, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "        y_train = y_train.reshape(-1, 1) if len(y_train.shape) == 1 else y_train\n",
    "        y_test = y_test.reshape(-1, 1) if len(y_test.shape) == 1 else y_test\n",
    "\n",
    "\n",
    "        # 9. Concatenate the data\n",
    "        train_data = np.concatenate((X_train, y_train), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test), axis=1)\n",
    "        val_data = test_data  # For simplicity, using test data as validation data\n",
    "\n",
    "        print(f\"Shape of training data: {train_data.shape}\")\n",
    "        print(f\"Shape of test data: {test_data.shape}\")\n",
    "\n",
    "        print(\"\\nData successfully processed and concatenated.\")\n",
    "        print(f\"Shape of final training data: {train_data.shape}\")\n",
    "\n",
    "\n",
    "    return train_data, test_data, val_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bfe355",
   "metadata": {},
   "source": [
    "## Calculate Statistics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af73be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_fpr_tpr(clf_model, X_test, y_test, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculates the False Positive Rate (FPR) and True Positive Rate (TPR) at a given threshold.\n",
    "\n",
    "    Args:\n",
    "        X_test: The test features.\n",
    "        y_test: The true test labels (0 or 1).\n",
    "        threshold: The probability threshold.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the FPR and TPR. Returns None if there's an error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y_prob = clf_model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  #Avoid division by zero\n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0 #Avoid division by zero\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        misclassification_rate = 1 - accuracy\n",
    "\n",
    "        return {\"fpr\": fpr, \"tpr\": tpr, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy, \"misclassification_rate\": misclassification_rate}\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error calculating FPR and TPR: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2be8897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 4\n",
    "K_FOLDS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59034e",
   "metadata": {},
   "source": [
    "## Data1: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a060ccc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after preprocessing: (286, 39)\n",
      "Training data shape: (200, 39), (200,)\n",
      "Test data shape: (86, 39), (86,)\n",
      "Shape of training data: (200, 40)\n",
      "Shape of test data: (86, 40)\n",
      "\n",
      "Data successfully processed and concatenated.\n",
      "Shape of final training data: (200, 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "train_data, test_data, val_data = generate_data(\"breast_cancer\")  # Change to \"data1\", \"data2\", \"pneumoniaMNIST\" or \"ionosphere\" as needed\n",
    "\n",
    "\n",
    "train_data_tensor = data.TensorDataset(torch.tensor(train_data[:, :-1], dtype=torch.float32),\n",
    "                                        torch.tensor(train_data[:, -1], dtype=torch.float32))\n",
    "train_loader = data.DataLoader(train_data_tensor, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) #over-write later for k-fold cross-validation\n",
    "test_data_tensor = data.TensorDataset(torch.tensor(test_data[:, :-1], dtype=torch.float32),\n",
    "                                       torch.tensor(test_data[:, -1], dtype=torch.float32))\n",
    "test_loader = data.DataLoader(test_data_tensor, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# initialize fold\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a602762",
   "metadata": {},
   "source": [
    "### Regular training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cb33b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# Logistic Regression\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]\n",
    "clf = LogisticRegression(fit_intercept=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#calculate ROC results\n",
    "fpr_roc, tpr_roc, threshold_roc = roc_curve(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "results_original_roc = {\"fpr\": fpr_roc, \"tpr\": tpr_roc, \"thresholds\": threshold_roc, \"name\": \"Logistic Regression\", \"auc\": auc(fpr_roc, tpr_roc), \"model\": clf}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6b01cb",
   "metadata": {},
   "source": [
    "## Weighted ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83d23d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Fold 1/4 ---\n",
      "--- Starting Fold 2/4 ---\n",
      "--- Starting Fold 3/4 ---\n",
      "--- Starting Fold 4/4 ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#store the weighted classifiers of all the folds\n",
    "list_folds_weighted_clfs = []  # List to store classifiers from all folds\n",
    "#store the best classfiers of all the folds \n",
    "list_folds_best_models = []  # List to store best models from all folds\n",
    "# Weight the X_train and y_train for cost-sensitive learning\n",
    "minority_class_weight = np.arange(0.001, 0.999, 0.01)\n",
    "majority_class_weight = 1.0 - minority_class_weight\n",
    "list_weighted_clfs = []\n",
    "\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_data[:, :-1], train_data[:, -1])):\n",
    "    list_weighted_clfs = [] # List to store the models trained at each stage\n",
    "    best_clfs = [] # List to store the best models from each stage\n",
    "    \n",
    "\n",
    "    print(f\"--- Starting Fold {fold + 1}/{K_FOLDS} ---\")\n",
    "    X_train_fold = train_data[train_ids][:, :-1]\n",
    "    y_train_fold = train_data[train_ids][:, -1]\n",
    "    X_test_fold = train_data[val_ids][:, :-1]\n",
    "    y_test_fold = train_data[val_ids][:, -1]\n",
    "    for w in minority_class_weight:\n",
    "        class_weights = {0: 1 - w, 1: w}\n",
    "\n",
    "        clf_weighted = LogisticRegression(fit_intercept=True, class_weight=class_weights)\n",
    "        clf_weighted.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        res = get_fpr_tpr(clf_weighted, X_test_fold, y_test_fold, threshold=0.5)\n",
    "\n",
    "        array_of_all_fprs, array_of_all_tprs, threshold_vals = roc_curve(y_test_fold, clf_weighted.predict_proba(X_test_fold)[:, 1])\n",
    "\n",
    "        current_result = {\n",
    "            \"model\": clf_weighted,\n",
    "            \"fpr\": res[\"fpr\"],\n",
    "            \"tpr\": res[\"tpr\"],\n",
    "            \"threshold\": 0.5,\n",
    "            \"full_roc\": {\"fpr\": array_of_all_fprs, \"tpr\": array_of_all_tprs, \"thresholds\": threshold_vals},\n",
    "        }\n",
    "        list_weighted_clfs.append(current_result)\n",
    "    best_clfs = get_best_roc_envelope(list_weighted_clfs, results_original_roc)\n",
    "    list_folds_weighted_clfs.append(list_weighted_clfs)\n",
    "    list_folds_best_models.append(best_clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5f6037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to pickle/Logistic_BreastCancer_weighted.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_models': [[{'model': LogisticRegression(class_weight={0: np.float64(0.1090000000000001),\n",
       "                                     1: np.float64(0.8909999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.38461538461538464),\n",
       "    'threshold': np.float64(0.8781373864463851)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.46153846153846156),\n",
       "    'threshold': np.float64(0.0005267184385905187)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.05405405405405406),\n",
       "    'tpr': np.float64(0.7692307692307693),\n",
       "    'threshold': np.float64(0.0005162991156026154)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.10810810810810811),\n",
       "    'tpr': np.float64(0.8461538461538461),\n",
       "    'threshold': np.float64(0.0005050918539825871)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.989), 1: np.float64(0.011)}),\n",
       "    'fpr': np.float64(0.21621621621621623),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': np.float64(0.005324222270938196)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.44900000000000007),\n",
       "                                     1: np.float64(0.5509999999999999)}),\n",
       "    'fpr': np.float64(0.6486486486486487),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': np.float64(0.20798005236468753)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': np.float64(0.00045153847854394056)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.016666666666666666),\n",
       "    'tpr': np.float64(0.07692307692307693),\n",
       "    'threshold': np.float64(0.8012451042555792)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7390000000000001),\n",
       "                                     1: np.float64(0.26099999999999995)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': np.float64(0.4239384494258904)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.03333333333333333),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': np.float64(0.725291047557546)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.05),\n",
       "    'tpr': np.float64(0.19230769230769232),\n",
       "    'threshold': np.float64(0.6975067087307296)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.08333333333333333),\n",
       "    'tpr': np.float64(0.2692307692307692),\n",
       "    'threshold': np.float64(0.5879227043145965)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.979),\n",
       "                                     1: np.float64(0.020999999999999998)}),\n",
       "    'fpr': np.float64(0.09375),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': np.float64(0.014606147935972032)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.11666666666666667),\n",
       "    'tpr': np.float64(0.38461538461538464),\n",
       "    'threshold': np.float64(0.4664432466138538)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.13333333333333333),\n",
       "    'tpr': np.float64(0.4230769230769231),\n",
       "    'threshold': np.float64(0.4494066926655483)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.1875),\n",
       "    'tpr': np.float64(0.4444444444444444),\n",
       "    'threshold': np.float64(0.0004240302179126542)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.46153846153846156),\n",
       "    'threshold': np.float64(0.36130677083583573)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.26666666666666666),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': np.float64(0.3105876136344161)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.2833333333333333),\n",
       "    'tpr': np.float64(0.5384615384615384),\n",
       "    'threshold': np.float64(0.30643803502554645)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.34375),\n",
       "    'tpr': np.float64(0.6111111111111112),\n",
       "    'threshold': np.float64(0.00041699438385126546)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.38333333333333336),\n",
       "    'tpr': np.float64(0.6153846153846154),\n",
       "    'threshold': np.float64(0.2637129929901855)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.4375),\n",
       "    'tpr': np.float64(0.6666666666666666),\n",
       "    'threshold': np.float64(0.00041078810976706413)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.4666666666666667),\n",
       "    'tpr': np.float64(0.6923076923076923),\n",
       "    'threshold': np.float64(0.22967816894497556)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.029000000000000137),\n",
       "                                     1: np.float64(0.9709999999999999)}),\n",
       "    'fpr': np.float64(0.46875),\n",
       "    'tpr': np.float64(0.7222222222222222),\n",
       "    'threshold': np.float64(0.8907798011877439)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.48333333333333334),\n",
       "    'tpr': np.float64(0.7307692307692307),\n",
       "    'threshold': np.float64(0.21801881051706495)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9490000000000001),\n",
       "                                     1: np.float64(0.05099999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.7777777777777778),\n",
       "    'threshold': np.float64(0.015236401626608885)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.6),\n",
       "    'tpr': np.float64(0.8076923076923077),\n",
       "    'threshold': np.float64(0.16992574430096388)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.8190000000000001),\n",
       "                                     1: np.float64(0.18099999999999997)}),\n",
       "    'fpr': np.float64(0.65625),\n",
       "    'tpr': np.float64(0.8333333333333334),\n",
       "    'threshold': np.float64(0.03536921557737319)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.6666666666666666),\n",
       "    'tpr': np.float64(0.8846153846153846),\n",
       "    'threshold': np.float64(0.12646516222523113)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.6875),\n",
       "    'tpr': np.float64(0.8888888888888888),\n",
       "    'threshold': np.float64(0.0004039638798653813)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.75),\n",
       "    'tpr': np.float64(0.9615384615384616),\n",
       "    'threshold': np.float64(0.09904212270556492)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.85),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': np.float64(0.08102901814824962)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': np.float64(0.00047625915181685356)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.08333333333333333),\n",
       "    'tpr': np.float64(0.2692307692307692),\n",
       "    'threshold': np.float64(0.5879227043145965)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.08823529411764706),\n",
       "    'tpr': np.float64(0.375),\n",
       "    'threshold': np.float64(0.0004617097613516425)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.11666666666666667),\n",
       "    'tpr': np.float64(0.38461538461538464),\n",
       "    'threshold': np.float64(0.4664432466138538)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.11764705882352941),\n",
       "    'tpr': np.float64(0.4375),\n",
       "    'threshold': np.float64(0.0004610247750036487)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.17647058823529413),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': np.float64(0.00045672746767072174)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.989), 1: np.float64(0.011)}),\n",
       "    'fpr': np.float64(0.2647058823529412),\n",
       "    'tpr': np.float64(0.5625),\n",
       "    'threshold': np.float64(0.005894941203956894)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.3235294117647059),\n",
       "    'tpr': np.float64(0.625),\n",
       "    'threshold': np.float64(0.0004518072784787467)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.969),\n",
       "                                     1: np.float64(0.030999999999999996)}),\n",
       "    'fpr': np.float64(0.35294117647058826),\n",
       "    'tpr': np.float64(0.6875),\n",
       "    'threshold': np.float64(0.0190681250823105)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.4666666666666667),\n",
       "    'tpr': np.float64(0.6923076923076923),\n",
       "    'threshold': np.float64(0.22967816894497556)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.48333333333333334),\n",
       "    'tpr': np.float64(0.7307692307692307),\n",
       "    'threshold': np.float64(0.21801881051706495)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.5166666666666667),\n",
       "    'tpr': np.float64(0.7692307692307693),\n",
       "    'threshold': np.float64(0.200997187998606)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.6),\n",
       "    'tpr': np.float64(0.8076923076923077),\n",
       "    'threshold': np.float64(0.16992574430096388)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.6666666666666666),\n",
       "    'tpr': np.float64(0.8846153846153846),\n",
       "    'threshold': np.float64(0.12646516222523113)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.75),\n",
       "    'tpr': np.float64(0.9615384615384616),\n",
       "    'threshold': np.float64(0.09904212270556492)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.19900000000000018),\n",
       "                                     1: np.float64(0.8009999999999998)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': np.float64(0.29522795529476564)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LogisticRegression(class_weight={0: np.float64(0.889),\n",
       "                                     1: np.float64(0.11099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': np.float64(0.15756228002349304)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.43900000000000006),\n",
       "                                     1: np.float64(0.5609999999999999)}),\n",
       "    'fpr': np.float64(0.02631578947368421),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': np.float64(0.58788621553668)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5690000000000001),\n",
       "                                     1: np.float64(0.43099999999999994)}),\n",
       "    'fpr': np.float64(0.05263157894736842),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': np.float64(0.4606491277643747)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.10526315789473684),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': np.float64(0.0005204896823672385)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.029000000000000137),\n",
       "                                     1: np.float64(0.9709999999999999)}),\n",
       "    'fpr': np.float64(0.13157894736842105),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': np.float64(0.9355914427422258)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.989), 1: np.float64(0.011)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': np.float64(0.0051008223213666135)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.3157894736842105),\n",
       "    'tpr': np.float64(0.6666666666666666),\n",
       "    'threshold': np.float64(0.0004949160500166294)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.4666666666666667),\n",
       "    'tpr': np.float64(0.6923076923076923),\n",
       "    'threshold': np.float64(0.22967816894497556)},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.989), 1: np.float64(0.011)}),\n",
       "    'fpr': np.float64(0.47368421052631576),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': np.float64(0.004388081049370111)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.5166666666666667),\n",
       "    'tpr': np.float64(0.7692307692307693),\n",
       "    'threshold': np.float64(0.200997187998606)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.6),\n",
       "    'tpr': np.float64(0.8076923076923077),\n",
       "    'threshold': np.float64(0.16992574430096388)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.6666666666666666),\n",
       "    'tpr': np.float64(0.8846153846153846),\n",
       "    'threshold': np.float64(0.12646516222523113)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.75),\n",
       "    'tpr': np.float64(0.9615384615384616),\n",
       "    'threshold': np.float64(0.09904212270556492)},\n",
       "   {'model': 'original_baseline',\n",
       "    'fpr': np.float64(0.85),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': np.float64(0.08102901814824962)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}]],\n",
       " 'weighted_clfs': [[{'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.10810811, 0.10810811, 0.24324324,\n",
       "            0.24324324, 0.94594595, 0.94594595, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.46153846,\n",
       "            0.46153846, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.0005462 , 0.00053316, 0.0005329 , 0.00052672,\n",
       "            0.00052635, 0.0005163 , 0.0005057 , 0.00050509, 0.00050074,\n",
       "            0.00050054, 0.0004735 , 0.00047231, 0.00047004])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.989), 1: np.float64(0.011)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.13513514, 0.13513514, 0.21621622,\n",
       "            0.21621622, 0.94594595, 0.94594595, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.38461538,\n",
       "            0.38461538, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.00803607, 0.00757003, 0.00748161, 0.00720779,\n",
       "            0.00699594, 0.00618397, 0.00568082, 0.00566629, 0.00542593,\n",
       "            0.00532422, 0.00357486, 0.00357201, 0.00348291])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.979),\n",
       "                                     1: np.float64(0.020999999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.13513514, 0.13513514, 0.24324324,\n",
       "            0.24324324, 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.38461538,\n",
       "            0.38461538, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.01913496, 0.0178853 , 0.01788055, 0.01661701,\n",
       "            0.01572672, 0.01269958, 0.01183992, 0.01151503, 0.01033146,\n",
       "            0.0103224 , 0.00614812, 0.00582456, 0.00549925])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.969),\n",
       "                                     1: np.float64(0.030999999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.13513514, 0.13513514, 0.21621622, 0.21621622,\n",
       "            0.94594595, 0.94594595, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.38461538, 0.38461538,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.03223415, 0.03096731, 0.02780119, 0.0257809 ,\n",
       "            0.01929436, 0.01839261, 0.0177861 , 0.01553932, 0.0153785 ,\n",
       "            0.00781459, 0.00780199, 0.00709506])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.959),\n",
       "                                     1: np.float64(0.040999999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.10810811, 0.10810811, 0.13513514, 0.13513514,\n",
       "            0.21621622, 0.21621622, 0.94594595, 0.94594595, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.38461538, 0.38461538,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.0463466 , 0.04596584, 0.04000615, 0.03654191,\n",
       "            0.02781993, 0.02581782, 0.02562787, 0.0250161 , 0.024187  ,\n",
       "            0.02080426, 0.02036995, 0.00965818, 0.0096361 , 0.00845339])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9490000000000001),\n",
       "                                     1: np.float64(0.05099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02702703, 0.02702703, 0.05405405, 0.05405405,\n",
       "            0.10810811, 0.10810811, 0.13513514, 0.13513514, 0.21621622,\n",
       "            0.21621622, 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.38461538, 0.38461538, 0.69230769,\n",
       "            0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.06308395, 0.05314504, 0.04848498, 0.03532106,\n",
       "            0.03296988, 0.03195337, 0.0316521 , 0.03107403, 0.02625839,\n",
       "            0.02555374, 0.01187312, 0.01155392, 0.00967707])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9390000000000001),\n",
       "                                     1: np.float64(0.06099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02702703, 0.02702703, 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.21621622,\n",
       "            0.21621622, 0.91891892, 0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.38461538, 0.38461538, 0.61538462,\n",
       "            0.61538462, 0.69230769, 0.69230769, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.0805562 , 0.06627377, 0.06034524, 0.04431036,\n",
       "            0.04301678, 0.04274494, 0.03840176, 0.03779586, 0.03180318,\n",
       "            0.03072746, 0.01361406, 0.01349346, 0.0109005 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.929), 1: np.float64(0.071)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.08108108, 0.08108108, 0.13513514, 0.13513514,\n",
       "            0.21621622, 0.21621622, 0.89189189, 0.89189189, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.38461538, 0.38461538,\n",
       "            0.53846154, 0.53846154, 0.69230769, 0.69230769, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.09970127, 0.09834763, 0.07880611, 0.07238067,\n",
       "            0.05314222, 0.05194431, 0.04998048, 0.04494308, 0.04365448,\n",
       "            0.03715886, 0.03573766, 0.01806996, 0.01543405, 0.01200924])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.919),\n",
       "                                     1: np.float64(0.08099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.08108108, 0.08108108, 0.13513514, 0.13513514,\n",
       "            0.16216216, 0.16216216, 0.24324324, 0.24324324, 0.89189189,\n",
       "            0.89189189, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.38461538, 0.38461538,\n",
       "            0.46153846, 0.46153846, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.11945398, 0.11594665, 0.09000564, 0.08453481,\n",
       "            0.0720762 , 0.06110031, 0.0572966 , 0.05161444, 0.05119389,\n",
       "            0.0496693 , 0.04933162, 0.04136468, 0.04089142, 0.0199151 ,\n",
       "            0.01737146, 0.01307948])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.909),\n",
       "                                     1: np.float64(0.09099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.08108108, 0.08108108, 0.13513514, 0.13513514,\n",
       "            0.16216216, 0.16216216, 0.24324324, 0.24324324, 0.89189189,\n",
       "            0.89189189, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.38461538, 0.38461538,\n",
       "            0.46153846, 0.46153846, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.13998818, 0.13379957, 0.10105386, 0.0971361 ,\n",
       "            0.08235109, 0.07054168, 0.06465541, 0.0582177 , 0.05789567,\n",
       "            0.05617355, 0.05498131, 0.04715695, 0.04612622, 0.02171145,\n",
       "            0.01939346, 0.01414275])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.899),\n",
       "                                     1: np.float64(0.10099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.08108108, 0.08108108, 0.13513514, 0.13513514,\n",
       "            0.16216216, 0.16216216, 0.24324324, 0.24324324, 0.89189189,\n",
       "            0.89189189, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.38461538, 0.38461538,\n",
       "            0.46153846, 0.46153846, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.16067191, 0.15129   , 0.11113216, 0.10924991,\n",
       "            0.0929158 , 0.08036485, 0.07192647, 0.06480142, 0.06476773,\n",
       "            0.06287796, 0.0604744 , 0.05220558, 0.05150113, 0.02345701,\n",
       "            0.02157597, 0.0152115 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.889),\n",
       "                                     1: np.float64(0.11099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.08108108, 0.08108108, 0.10810811, 0.10810811,\n",
       "            0.16216216, 0.16216216, 0.24324324, 0.24324324, 0.89189189,\n",
       "            0.89189189, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.30769231, 0.30769231,\n",
       "            0.46153846, 0.46153846, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.18211607, 0.16834839, 0.12876371, 0.12138715,\n",
       "            0.10341734, 0.09060814, 0.07934605, 0.07715832, 0.07155645,\n",
       "            0.06953322, 0.06609484, 0.05723702, 0.05690304, 0.02524604,\n",
       "            0.02384216, 0.01629482])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.879),\n",
       "                                     1: np.float64(0.12099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.08108108, 0.08108108, 0.10810811, 0.10810811,\n",
       "            0.16216216, 0.16216216, 0.21621622, 0.21621622, 0.89189189,\n",
       "            0.89189189, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.30769231, 0.30769231,\n",
       "            0.46153846, 0.46153846, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.2032005 , 0.18475208, 0.14005634, 0.13336578,\n",
       "            0.1136054 , 0.10094658, 0.08659923, 0.08435567, 0.07822372,\n",
       "            0.07608539, 0.07150972, 0.0670803 , 0.062249  , 0.02683823,\n",
       "            0.02620105, 0.01736586])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.869),\n",
       "                                     1: np.float64(0.13099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.08108108, 0.08108108, 0.10810811, 0.10810811,\n",
       "            0.18918919, 0.18918919, 0.21621622, 0.21621622, 0.86486486,\n",
       "            0.86486486, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.30769231, 0.30769231,\n",
       "            0.46153846, 0.46153846, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.22415006, 0.20070091, 0.15119143, 0.14580585,\n",
       "            0.12311917, 0.11133844, 0.09317607, 0.09168612, 0.08464578,\n",
       "            0.07775999, 0.07709021, 0.07323945, 0.06756041, 0.02881387,\n",
       "            0.02846054, 0.01837866])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.859), 1: np.float64(0.141)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.08108108, 0.08108108, 0.10810811, 0.10810811,\n",
       "            0.18918919, 0.18918919, 0.21621622, 0.21621622, 0.83783784,\n",
       "            0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.30769231, 0.30769231,\n",
       "            0.46153846, 0.46153846, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.24454959, 0.21664832, 0.16218631, 0.15807297,\n",
       "            0.13314814, 0.12188714, 0.09934883, 0.0992847 , 0.0913996 ,\n",
       "            0.08572853, 0.08254275, 0.07965638, 0.07313948, 0.0347533 ,\n",
       "            0.03094666, 0.01948628])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.849),\n",
       "                                     1: np.float64(0.15099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.08108108, 0.08108108, 0.10810811, 0.10810811,\n",
       "            0.18918919, 0.18918919, 0.21621622, 0.21621622, 0.83783784,\n",
       "            0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.30769231, 0.30769231,\n",
       "            0.46153846, 0.46153846, 0.61538462, 0.61538462, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.26461505, 0.23087633, 0.17260291, 0.16989769,\n",
       "            0.14256413, 0.13272351, 0.10692637, 0.10622286, 0.09783506,\n",
       "            0.09391867, 0.08856535, 0.08619253, 0.07876733, 0.03723156,\n",
       "            0.03351066, 0.0206098 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.839),\n",
       "                                     1: np.float64(0.16099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.08108108, 0.08108108, 0.10810811, 0.10810811,\n",
       "            0.18918919, 0.18918919, 0.21621622, 0.21621622, 0.83783784,\n",
       "            0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.30769231, 0.30769231,\n",
       "            0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.28375649, 0.24581135, 0.18284309, 0.18209681,\n",
       "            0.15227656, 0.14306592, 0.1166703 , 0.11393505, 0.10424731,\n",
       "            0.10193723, 0.09379852, 0.09283575, 0.08434335, 0.03931879,\n",
       "            0.03602251, 0.02163257])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.829),\n",
       "                                     1: np.float64(0.17099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.08108108, 0.08108108, 0.10810811, 0.10810811,\n",
       "            0.21621622, 0.21621622, 0.83783784, 0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.23076923, 0.23076923,\n",
       "            0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.76923077,\n",
       "            0.76923077, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.30268853, 0.26003583, 0.20528252, 0.19416547,\n",
       "            0.16158288, 0.15374462, 0.12435767, 0.12144787, 0.11060056,\n",
       "            0.09961198, 0.08993593, 0.04131076, 0.03864704, 0.02271621])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.8190000000000001),\n",
       "                                     1: np.float64(0.18099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.08108108, 0.08108108, 0.10810811, 0.10810811,\n",
       "            0.13513514, 0.13513514, 0.21621622, 0.21621622, 0.24324324,\n",
       "            0.24324324, 0.83783784, 0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.23076923, 0.23076923,\n",
       "            0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.69230769,\n",
       "            0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.32240275, 0.27228864, 0.21453177, 0.20520695,\n",
       "            0.17029181, 0.16522499, 0.13206109, 0.1278549 , 0.12396072,\n",
       "            0.11913704, 0.11691274, 0.10639724, 0.10555056, 0.09558906,\n",
       "            0.0955875 , 0.04338788, 0.04154958, 0.02389845])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.809),\n",
       "                                     1: np.float64(0.19099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.08108108, 0.08108108, 0.10810811, 0.10810811,\n",
       "            0.16216216, 0.16216216, 0.21621622, 0.21621622, 0.24324324,\n",
       "            0.24324324, 0.83783784, 0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.23076923, 0.23076923,\n",
       "            0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.69230769,\n",
       "            0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.34022584, 0.28632909, 0.22481971, 0.21645007,\n",
       "            0.17941674, 0.17610489, 0.13968073, 0.1354231 , 0.12987442,\n",
       "            0.12338258, 0.12336859, 0.11337536, 0.11111527, 0.10156225,\n",
       "            0.10083273, 0.04543181, 0.04433156, 0.02507777])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.799),\n",
       "                                     1: np.float64(0.20099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02702703, 0.02702703, 0.05405405,\n",
       "            0.05405405, 0.08108108, 0.08108108, 0.10810811, 0.10810811,\n",
       "            0.13513514, 0.13513514, 0.16216216, 0.16216216, 0.21621622,\n",
       "            0.21621622, 0.24324324, 0.24324324, 0.83783784, 0.83783784,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.07692308, 0.23076923, 0.23076923,\n",
       "            0.46153846, 0.46153846, 0.53846154, 0.53846154, 0.61538462,\n",
       "            0.61538462, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.35804677, 0.29827499, 0.23417239, 0.22849427,\n",
       "            0.18802798, 0.18734022, 0.14775375, 0.1425313 , 0.13985471,\n",
       "            0.13691643, 0.13601286, 0.12991544, 0.12980461, 0.12036575,\n",
       "            0.11740127, 0.10787233, 0.10704907, 0.04747901, 0.04730439,\n",
       "            0.02619865])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.789),\n",
       "                                     1: np.float64(0.21099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.10810811,\n",
       "            0.10810811, 0.13513514, 0.13513514, 0.16216216, 0.16216216,\n",
       "            0.21621622, 0.21621622, 0.24324324, 0.24324324, 0.81081081,\n",
       "            0.81081081, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.37589734, 0.31007509, 0.30957534, 0.24314191,\n",
       "            0.23988892, 0.20538865, 0.19833813, 0.15555806, 0.14942788,\n",
       "            0.14680504, 0.14549372, 0.14204838, 0.13634523, 0.13592358,\n",
       "            0.12731342, 0.12345072, 0.11419833, 0.11303389, 0.05064683,\n",
       "            0.05030368, 0.02738097])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.779),\n",
       "                                     1: np.float64(0.22099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.18918919, 0.21621622, 0.21621622,\n",
       "            0.24324324, 0.24324324, 0.78378378, 0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.39226278, 0.32445931, 0.32192278, 0.25337342,\n",
       "            0.25057808, 0.21360033, 0.20979477, 0.16417422, 0.15468312,\n",
       "            0.14861823, 0.14249318, 0.1423357 , 0.13513535, 0.1297714 ,\n",
       "            0.12026887, 0.11883744, 0.05483568, 0.05338576, 0.02850384])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.769),\n",
       "                                     1: np.float64(0.23099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.18918919, 0.21621622, 0.21621622,\n",
       "            0.27027027, 0.27027027, 0.78378378, 0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.40755942, 0.33864655, 0.33350386, 0.26195414,\n",
       "            0.26158182, 0.22098039, 0.22044203, 0.17160133, 0.16399767,\n",
       "            0.15410311, 0.14903753, 0.14860033, 0.1421403 , 0.13542733,\n",
       "            0.12488273, 0.12451901, 0.05753015, 0.05652771, 0.02977703])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.759),\n",
       "                                     1: np.float64(0.24099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.18918919,\n",
       "            0.18918919, 0.21621622, 0.21621622, 0.27027027, 0.27027027,\n",
       "            0.78378378, 0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.30769231,\n",
       "            0.30769231, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.42359415, 0.35218271, 0.27239664, 0.25529251,\n",
       "            0.23171843, 0.17995628, 0.17138415, 0.16034063, 0.15581028,\n",
       "            0.1547879 , 0.14972282, 0.14187577, 0.13108397, 0.13058132,\n",
       "            0.06037506, 0.05977496, 0.03098522])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7490000000000001),\n",
       "                                     1: np.float64(0.25099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.18918919,\n",
       "            0.18918919, 0.21621622, 0.21621622, 0.27027027, 0.27027027,\n",
       "            0.78378378, 0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.30769231,\n",
       "            0.30769231, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.43859547, 0.36579799, 0.28318281, 0.26372976,\n",
       "            0.24302332, 0.18812527, 0.17869172, 0.1663736 , 0.16260776,\n",
       "            0.16123472, 0.15717914, 0.14832727, 0.13754564, 0.1364809 ,\n",
       "            0.06319591, 0.0630323 , 0.03221531])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7390000000000001),\n",
       "                                     1: np.float64(0.26099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.18918919,\n",
       "            0.18918919, 0.21621622, 0.21621622, 0.27027027, 0.27027027,\n",
       "            0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.30769231,\n",
       "            0.30769231, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.45403372, 0.37888921, 0.2940017 , 0.2717701 ,\n",
       "            0.2544589 , 0.19682442, 0.18563578, 0.17276086, 0.16929709,\n",
       "            0.16744344, 0.16506622, 0.15520167, 0.14386145, 0.14278633,\n",
       "            0.07020643, 0.06655079, 0.03351597])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7290000000000001),\n",
       "                                     1: np.float64(0.27099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.18918919,\n",
       "            0.18918919, 0.21621622, 0.21621622, 0.2972973 , 0.2972973 ,\n",
       "            0.75675676, 0.75675676, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.30769231,\n",
       "            0.30769231, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.46767481, 0.39268116, 0.30475595, 0.27984999,\n",
       "            0.26538409, 0.20472772, 0.19342027, 0.17855447, 0.17590942,\n",
       "            0.17369964, 0.1725714 , 0.16148287, 0.14875797, 0.14843002,\n",
       "            0.07268035, 0.06993017, 0.03483684])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7190000000000001),\n",
       "                                     1: np.float64(0.28099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.21621622,\n",
       "            0.21621622, 0.2972973 , 0.2972973 , 0.75675676, 0.75675676,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.30769231,\n",
       "            0.30769231, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.48192881, 0.40545841, 0.31515155, 0.28796132,\n",
       "            0.27657616, 0.21374553, 0.19938812, 0.18547969, 0.18053952,\n",
       "            0.16873277, 0.15673758, 0.15503231, 0.07452547, 0.07364811,\n",
       "            0.03617552])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7090000000000001),\n",
       "                                     1: np.float64(0.291)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.21621622,\n",
       "            0.21621622, 0.2972973 , 0.2972973 , 0.72972973, 0.72972973,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.30769231,\n",
       "            0.30769231, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.49522871, 0.41798091, 0.32563607, 0.29578445,\n",
       "            0.2877027 , 0.22240764, 0.20688129, 0.19179672, 0.18852458,\n",
       "            0.17563433, 0.16343356, 0.16138969, 0.08123076, 0.07731493,\n",
       "            0.03751027])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6990000000000001),\n",
       "                                     1: np.float64(0.30099999999999993)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.07692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.21621622,\n",
       "            0.21621622, 0.2972973 , 0.2972973 , 0.72972973, 0.72972973,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.30769231,\n",
       "            0.30769231, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.50819899, 0.43016724, 0.3358229 , 0.30348002,\n",
       "            0.29885369, 0.23123773, 0.21429963, 0.1982414 , 0.19607102,\n",
       "            0.18271486, 0.17010069, 0.16781393, 0.08408641, 0.08114033,\n",
       "            0.038929  ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6890000000000001),\n",
       "                                     1: np.float64(0.31099999999999994)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.07692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.16216216,\n",
       "            0.16216216, 0.21621622, 0.21621622, 0.2972973 , 0.2972973 ,\n",
       "            0.72972973, 0.72972973, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.30769231,\n",
       "            0.30769231, 0.53846154, 0.53846154, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.5207175 , 0.44232297, 0.34577598, 0.31089817,\n",
       "            0.30987859, 0.23995039, 0.22195267, 0.21444466, 0.20483463,\n",
       "            0.20442669, 0.20300248, 0.18971629, 0.17655678, 0.17400406,\n",
       "            0.08697751, 0.08485853, 0.0402952 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.679),\n",
       "                                     1: np.float64(0.32099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.07692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.16216216,\n",
       "            0.16216216, 0.21621622, 0.21621622, 0.2972973 , 0.2972973 ,\n",
       "            0.72972973, 0.72972973, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.53846154, 0.53846154, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.53236159, 0.45497213, 0.355982  , 0.34256739,\n",
       "            0.32059875, 0.2488938 , 0.2288272 , 0.22158362, 0.21294241,\n",
       "            0.21134605, 0.20971616, 0.19719021, 0.18337017, 0.18044095,\n",
       "            0.08980736, 0.08876202, 0.04180405])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.669),\n",
       "                                     1: np.float64(0.33099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.07692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.18918919, 0.21621622, 0.21621622,\n",
       "            0.2972973 , 0.2972973 , 0.7027027 , 0.7027027 , 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.54444324, 0.46634624, 0.36555038, 0.35123097,\n",
       "            0.33191878, 0.29082116, 0.2579569 , 0.2579497 , 0.23579352,\n",
       "            0.2285764 , 0.21845368, 0.21794728, 0.21665327, 0.20460396,\n",
       "            0.19054173, 0.18695492, 0.09712789, 0.0928824 , 0.04330856])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.659),\n",
       "                                     1: np.float64(0.34099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.07692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.18918919, 0.21621622, 0.21621622,\n",
       "            0.2972973 , 0.2972973 , 0.7027027 , 0.7027027 , 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.55638323, 0.47798351, 0.37529397, 0.35968053,\n",
       "            0.34354478, 0.29817453, 0.26816002, 0.26710823, 0.24396217,\n",
       "            0.23542818, 0.22567747, 0.22418348, 0.22390473, 0.21214626,\n",
       "            0.19749216, 0.19330029, 0.10044272, 0.09688341, 0.04471839])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.649),\n",
       "                                     1: np.float64(0.3509999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.07692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.18918919, 0.21621622, 0.21621622,\n",
       "            0.24324324, 0.24324324, 0.2972973 , 0.2972973 , 0.7027027 ,\n",
       "            0.7027027 , 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.56717951, 0.49071821, 0.38511276, 0.36971668,\n",
       "            0.35392125, 0.30508083, 0.27737029, 0.27619324, 0.25037996,\n",
       "            0.24270391, 0.23281602, 0.23140232, 0.23063984, 0.22361545,\n",
       "            0.21975579, 0.21972897, 0.20438035, 0.19975886, 0.10371359,\n",
       "            0.10093398, 0.04630381])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.639),\n",
       "                                     1: np.float64(0.36099999999999993)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.13513514, 0.21621622, 0.21621622, 0.24324324, 0.24324324,\n",
       "            0.2972973 , 0.2972973 , 0.7027027 , 0.7027027 , 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.57864556, 0.50047102, 0.39474728, 0.37752122,\n",
       "            0.36557262, 0.31265774, 0.28762472, 0.28556177, 0.25858451,\n",
       "            0.24976363, 0.23788259, 0.23046766, 0.23016092, 0.22776107,\n",
       "            0.21180531, 0.20630206, 0.10729763, 0.10542307, 0.04789008])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.629),\n",
       "                                     1: np.float64(0.37099999999999994)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.18918919, 0.24324324, 0.24324324,\n",
       "            0.2972973 , 0.2972973 , 0.7027027 , 0.7027027 , 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.58780939, 0.51300555, 0.40426827, 0.38748595,\n",
       "            0.37574962, 0.31913863, 0.2970312 , 0.29449975, 0.26514538,\n",
       "            0.25687349, 0.24743903, 0.24501566, 0.23920035, 0.23563727,\n",
       "            0.2190512 , 0.21286648, 0.11093004, 0.10984848, 0.0498025 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.619),\n",
       "                                     1: np.float64(0.38099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.13513514,\n",
       "            0.13513514, 0.18918919, 0.18918919, 0.24324324, 0.24324324,\n",
       "            0.2972973 , 0.2972973 , 0.7027027 , 0.7027027 , 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.59834953, 0.52432652, 0.41390681, 0.39677618,\n",
       "            0.38635165, 0.32654752, 0.30638646, 0.30405881, 0.27250111,\n",
       "            0.26446753, 0.25492987, 0.25231521, 0.24871139, 0.24320446,\n",
       "            0.22616589, 0.21966488, 0.11437759, 0.11418741, 0.05140102])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.609),\n",
       "                                     1: np.float64(0.39099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.16216216, 0.18918919, 0.18918919, 0.24324324, 0.24324324,\n",
       "            0.2972973 , 0.2972973 , 0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.60841597, 0.53527538, 0.42358765, 0.40582036,\n",
       "            0.39705475, 0.33361707, 0.3159521 , 0.31354403, 0.27298325,\n",
       "            0.27184478, 0.26240575, 0.25943812, 0.25850087, 0.24978753,\n",
       "            0.23345248, 0.22639299, 0.12962505, 0.11865346, 0.05308437])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5990000000000001),\n",
       "                                     1: np.float64(0.4009999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.16216216, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.61846966, 0.54454828, 0.43323081, 0.41371032,\n",
       "            0.40798911, 0.34100321, 0.32585317, 0.32313537, 0.28210378,\n",
       "            0.27930975, 0.26693932, 0.2568265 , 0.24114027, 0.23344563,\n",
       "            0.13425742, 0.12360056, 0.05487818])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5890000000000001),\n",
       "                                     1: np.float64(0.4109999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.16216216, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.62719977, 0.55662092, 0.44205301, 0.42366378,\n",
       "            0.41831653, 0.34771557, 0.33560177, 0.33249105, 0.29089499,\n",
       "            0.28656051, 0.27410659, 0.26312151, 0.24859321, 0.24001924,\n",
       "            0.13791735, 0.12828976, 0.05682581])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5790000000000001),\n",
       "                                     1: np.float64(0.42099999999999993)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.16216216, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.63621876, 0.56692078, 0.45133984, 0.43281059,\n",
       "            0.42886104, 0.35467079, 0.34527591, 0.34219821, 0.29994072,\n",
       "            0.29412057, 0.28162589, 0.26990386, 0.2562439 , 0.24696802,\n",
       "            0.14219366, 0.1331576 , 0.05874179])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5690000000000001),\n",
       "                                     1: np.float64(0.43099999999999994)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.16216216, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.6452663 , 0.57684171, 0.46047557, 0.44180962,\n",
       "            0.43950103, 0.36172279, 0.35510972, 0.3520312 , 0.30918094,\n",
       "            0.30175727, 0.28927306, 0.27676382, 0.2640074 , 0.25397972,\n",
       "            0.14660767, 0.13820012, 0.06070631])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.559),\n",
       "                                     1: np.float64(0.44099999999999995)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.16216216, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.65453476, 0.58618383, 0.46971639, 0.45100499,\n",
       "            0.4502281 , 0.36878457, 0.36462245, 0.36228612, 0.31860502,\n",
       "            0.30976   , 0.29714126, 0.28367046, 0.27161541, 0.26109103,\n",
       "            0.15106894, 0.14319767, 0.0626373 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.549),\n",
       "                                     1: np.float64(0.45099999999999996)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.18918919, 0.18918919, 0.24324324,\n",
       "            0.24324324, 0.2972973 , 0.2972973 , 0.67567568, 0.67567568,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.66308385, 0.59557432, 0.4609092 , 0.37576609,\n",
       "            0.37502614, 0.37210111, 0.32039371, 0.31728176, 0.30492254,\n",
       "            0.29065645, 0.27979532, 0.26816042, 0.15582234, 0.14871894,\n",
       "            0.0648297 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5390000000000001),\n",
       "                                     1: np.float64(0.4609999999999999)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.18918919, 0.18918919, 0.21621622,\n",
       "            0.21621622, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.38461538,\n",
       "            0.38461538, 0.53846154, 0.53846154, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.67171632, 0.60557918, 0.47133929, 0.40664891,\n",
       "            0.38454935, 0.38230091, 0.33016885, 0.32527479, 0.31667005,\n",
       "            0.3130835 , 0.31290871, 0.29758559, 0.28749665, 0.27523699,\n",
       "            0.16020894, 0.1537774 , 0.06686562])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5290000000000001),\n",
       "                                     1: np.float64(0.4709999999999999)}),\n",
       "    'fpr': np.float64(0.02702702702702703),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.18918919, 0.18918919, 0.21621622,\n",
       "            0.21621622, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.38461538,\n",
       "            0.38461538, 0.53846154, 0.53846154, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.67997167, 0.61503496, 0.48163862, 0.41586609,\n",
       "            0.39407122, 0.38992711, 0.34058463, 0.33340512, 0.32480675,\n",
       "            0.32260656, 0.32110283, 0.30470542, 0.29544334, 0.28258362,\n",
       "            0.1650773 , 0.15914583, 0.06904377])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5190000000000001),\n",
       "                                     1: np.float64(0.4809999999999999)}),\n",
       "    'fpr': np.float64(0.05405405405405406),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.18918919, 0.18918919, 0.21621622,\n",
       "            0.21621622, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.38461538,\n",
       "            0.38461538, 0.53846154, 0.53846154, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.6879681 , 0.62442442, 0.49207382, 0.42485797,\n",
       "            0.40412927, 0.39685164, 0.35065172, 0.34126607, 0.3328159 ,\n",
       "            0.33194319, 0.32902975, 0.31191825, 0.30374776, 0.28979917,\n",
       "            0.16988965, 0.16485691, 0.07140941])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5090000000000001),\n",
       "                                     1: np.float64(0.49099999999999994)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.15384615384615385),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.18918919, 0.18918919, 0.21621622,\n",
       "            0.21621622, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.38461538,\n",
       "            0.38461538, 0.53846154, 0.53846154, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.69610249, 0.63422151, 0.50230724, 0.43386602,\n",
       "            0.41374715, 0.40483091, 0.3599917 , 0.34942975, 0.34135327,\n",
       "            0.34117052, 0.33822877, 0.32021623, 0.3120311 , 0.2977833 ,\n",
       "            0.17535016, 0.17074371, 0.07372466])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4990000000000001),\n",
       "                                     1: np.float64(0.5009999999999999)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.23076923076923078),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.18918919, 0.18918919, 0.24324324,\n",
       "            0.24324324, 0.2972973 , 0.2972973 , 0.67567568, 0.67567568,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.38461538,\n",
       "            0.38461538, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.70352361, 0.64397771, 0.51228534, 0.44315917,\n",
       "            0.42350574, 0.41177392, 0.36753853, 0.35053815, 0.34642403,\n",
       "            0.32739451, 0.32028214, 0.30522241, 0.18004471, 0.17650859,\n",
       "            0.07618727])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4890000000000001),\n",
       "                                     1: np.float64(0.5109999999999999)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.23076923076923078),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.18918919, 0.18918919, 0.24324324,\n",
       "            0.24324324, 0.27027027, 0.27027027, 0.2972973 , 0.2972973 ,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.71014093, 0.6541623 , 0.52204764, 0.4333152 ,\n",
       "            0.43324807, 0.41833294, 0.37517272, 0.36043741, 0.35465952,\n",
       "            0.35207285, 0.33523847, 0.33456658, 0.32867593, 0.31257357,\n",
       "            0.18483853, 0.18229639, 0.07885745])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4790000000000001),\n",
       "                                     1: np.float64(0.5209999999999999)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.23076923076923078),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.18918919, 0.18918919, 0.24324324,\n",
       "            0.24324324, 0.27027027, 0.27027027, 0.2972973 , 0.2972973 ,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.71746442, 0.66264775, 0.5321169 , 0.44394747,\n",
       "            0.44299229, 0.42552488, 0.38355683, 0.37054855, 0.36323343,\n",
       "            0.36053209, 0.34387327, 0.34207904, 0.33726339, 0.32031699,\n",
       "            0.19021452, 0.18842186, 0.08145365])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4690000000000001),\n",
       "                                     1: np.float64(0.5309999999999999)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.23076923076923078),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.18918919, 0.18918919, 0.24324324,\n",
       "            0.24324324, 0.27027027, 0.27027027, 0.2972973 , 0.2972973 ,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.72521501, 0.67041334, 0.54237727, 0.45482528,\n",
       "            0.45291119, 0.43291731, 0.39201385, 0.38078411, 0.37195932,\n",
       "            0.36904763, 0.35252607, 0.34962639, 0.34595076, 0.32808648,\n",
       "            0.19584   , 0.1947926 , 0.08411653])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4590000000000001),\n",
       "                                     1: np.float64(0.5409999999999999)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.23076923076923078),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.18918919, 0.18918919, 0.24324324,\n",
       "            0.24324324, 0.27027027, 0.27027027, 0.2972973 , 0.2972973 ,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.7326236 , 0.67832877, 0.55282062, 0.46600408,\n",
       "            0.46285739, 0.44016654, 0.40079053, 0.39139487, 0.38096315,\n",
       "            0.37767076, 0.36174094, 0.35746817, 0.3547968 , 0.33613533,\n",
       "            0.20154617, 0.2013824 , 0.08695875])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.44900000000000007),\n",
       "                                     1: np.float64(0.5509999999999999)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.3076923076923077),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.18918919, 0.18918919, 0.24324324,\n",
       "            0.24324324, 0.27027027, 0.27027027, 0.2972973 , 0.2972973 ,\n",
       "            0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.73941667, 0.68573654, 0.56274848, 0.47678138,\n",
       "            0.47264905, 0.4470151 , 0.40968891, 0.40023414, 0.38922402,\n",
       "            0.38714252, 0.37018782, 0.36484347, 0.36386995, 0.34382933,\n",
       "            0.23699631, 0.20798005, 0.09002717])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.43900000000000006),\n",
       "                                     1: np.float64(0.5609999999999999)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.38461538461538464),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.18918919, 0.18918919, 0.24324324,\n",
       "            0.24324324, 0.27027027, 0.27027027, 0.2972973 , 0.2972973 ,\n",
       "            0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.74644075, 0.69446688, 0.57264384, 0.48772045,\n",
       "            0.48216443, 0.45433457, 0.41802386, 0.40916764, 0.39832864,\n",
       "            0.39630859, 0.37969613, 0.37270266, 0.37253602, 0.35180969,\n",
       "            0.24426027, 0.21459814, 0.0930779 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.42900000000000005),\n",
       "                                     1: np.float64(0.571)}),\n",
       "    'fpr': np.float64(0.08108108108108109),\n",
       "    'tpr': np.float64(0.38461538461538464),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.18918919, 0.18918919, 0.24324324,\n",
       "            0.24324324, 0.2972973 , 0.2972973 , 0.64864865, 0.64864865,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.75334577, 0.70319047, 0.58254159, 0.49886778,\n",
       "            0.4920037 , 0.46210861, 0.42688639, 0.4182248 , 0.40811719,\n",
       "            0.40553723, 0.38154878, 0.36026731, 0.25192708, 0.22167432,\n",
       "            0.09632392])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.41900000000000004),\n",
       "                                     1: np.float64(0.581)}),\n",
       "    'fpr': np.float64(0.10810810810810811),\n",
       "    'tpr': np.float64(0.46153846153846156),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.18918919, 0.18918919, 0.24324324,\n",
       "            0.24324324, 0.2972973 , 0.2972973 , 0.64864865, 0.64864865,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.76009984, 0.71120606, 0.59110532, 0.50987986,\n",
       "            0.5020238 , 0.4692044 , 0.43550924, 0.42735411, 0.41715306,\n",
       "            0.41485741, 0.39081047, 0.36847017, 0.25947537, 0.22875765,\n",
       "            0.09963096])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.40900000000000014),\n",
       "                                     1: np.float64(0.5909999999999999)}),\n",
       "    'fpr': np.float64(0.10810810810810811),\n",
       "    'tpr': np.float64(0.46153846153846156),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.35135135, 0.35135135, 0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.766265  , 0.71843056, 0.59979578, 0.52134134,\n",
       "            0.51148131, 0.47641928, 0.46676404, 0.44727077, 0.44472029,\n",
       "            0.43668781, 0.42647233, 0.42449738, 0.40029953, 0.39737504,\n",
       "            0.37702145, 0.37685603, 0.26785944, 0.2359884 , 0.10322734])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.39900000000000013),\n",
       "                                     1: np.float64(0.6009999999999999)}),\n",
       "    'fpr': np.float64(0.10810810810810811),\n",
       "    'tpr': np.float64(0.46153846153846156),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.35135135, 0.35135135, 0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.77301316, 0.72660037, 0.60815748, 0.53262585,\n",
       "            0.52135565, 0.48425533, 0.47725762, 0.45837256, 0.45380332,\n",
       "            0.44621686, 0.43642424, 0.43430817, 0.40959811, 0.4058877 ,\n",
       "            0.38647924, 0.3854538 , 0.27605732, 0.24341983, 0.10684458])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3890000000000001),\n",
       "                                     1: np.float64(0.6109999999999999)}),\n",
       "    'fpr': np.float64(0.10810810810810811),\n",
       "    'tpr': np.float64(0.46153846153846156),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.35135135, 0.35135135, 0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.77939797, 0.73414718, 0.61635261, 0.54404941,\n",
       "            0.53104404, 0.49202436, 0.48742994, 0.46993782, 0.4629702 ,\n",
       "            0.45593932, 0.44643492, 0.44429526, 0.41900374, 0.41448324,\n",
       "            0.39596589, 0.39418914, 0.28469404, 0.25106008, 0.1107458 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3790000000000001),\n",
       "                                     1: np.float64(0.6209999999999999)}),\n",
       "    'fpr': np.float64(0.13513513513513514),\n",
       "    'tpr': np.float64(0.46153846153846156),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.16216216,\n",
       "            0.16216216, 0.18918919, 0.18918919, 0.24324324, 0.24324324,\n",
       "            0.2972973 , 0.2972973 , 0.35135135, 0.35135135, 0.64864865,\n",
       "            0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.78543357, 0.74194928, 0.63124047, 0.62526609,\n",
       "            0.6249262 , 0.55542022, 0.50021074, 0.49983169, 0.49755803,\n",
       "            0.48164578, 0.47216249, 0.4656042 , 0.45657045, 0.45447045,\n",
       "            0.42853051, 0.42327615, 0.40587571, 0.40307926, 0.29378411,\n",
       "            0.25904583, 0.11490271])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3690000000000001),\n",
       "                                     1: np.float64(0.6309999999999999)}),\n",
       "    'fpr': np.float64(0.16216216216216217),\n",
       "    'tpr': np.float64(0.5384615384615384),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.35135135, 0.35135135, 0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.79212064, 0.75018027, 0.64108941, 0.63582231,\n",
       "            0.63348072, 0.56711098, 0.50807588, 0.49340859, 0.48162687,\n",
       "            0.47601527, 0.46704511, 0.46492737, 0.43800735, 0.4321889 ,\n",
       "            0.41592981, 0.41243953, 0.30272892, 0.26706608, 0.11892222])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3590000000000001),\n",
       "                                     1: np.float64(0.6409999999999999)}),\n",
       "    'fpr': np.float64(0.16216216216216217),\n",
       "    'tpr': np.float64(0.6153846153846154),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.35135135, 0.35135135, 0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.79802476, 0.75688948, 0.65035474, 0.6461401 ,\n",
       "            0.6417497 , 0.57868548, 0.51816356, 0.50567909, 0.49061436,\n",
       "            0.48635921, 0.47683736, 0.47542619, 0.44782019, 0.44077133,\n",
       "            0.4260574 , 0.42166794, 0.31227801, 0.27565781, 0.12353196])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3490000000000001),\n",
       "                                     1: np.float64(0.6509999999999999)}),\n",
       "    'fpr': np.float64(0.1891891891891892),\n",
       "    'tpr': np.float64(0.6153846153846154),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.35135135, 0.35135135, 0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.8041721 , 0.76448325, 0.66003963, 0.65655474,\n",
       "            0.65021915, 0.59047648, 0.52863558, 0.51797067, 0.50058634,\n",
       "            0.49657922, 0.48724316, 0.48599723, 0.45787332, 0.45000794,\n",
       "            0.43616377, 0.43097736, 0.32208165, 0.2840796 , 0.128025  ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3390000000000001),\n",
       "                                     1: np.float64(0.6609999999999999)}),\n",
       "    'fpr': np.float64(0.1891891891891892),\n",
       "    'tpr': np.float64(0.6923076923076923),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.24324324, 0.24324324, 0.2972973 , 0.2972973 ,\n",
       "            0.35135135, 0.35135135, 0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.81016497, 0.77165621, 0.66952717, 0.66689034,\n",
       "            0.65869732, 0.60227989, 0.53900044, 0.53049965, 0.51061655,\n",
       "            0.50664934, 0.49738458, 0.49671637, 0.46814558, 0.4592542 ,\n",
       "            0.4464941 , 0.43999584, 0.33223446, 0.29285427, 0.13287557])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.32900000000000007),\n",
       "                                     1: np.float64(0.6709999999999999)}),\n",
       "    'fpr': np.float64(0.24324324324324326),\n",
       "    'tpr': np.float64(0.7692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.21621622, 0.21621622, 0.2972973 , 0.2972973 ,\n",
       "            0.35135135, 0.35135135, 0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.81616913, 0.77905944, 0.67891605, 0.67760763,\n",
       "            0.66727867, 0.6140849 , 0.54901498, 0.54042751, 0.5201308 ,\n",
       "            0.51795376, 0.50930794, 0.50822114, 0.47818875, 0.46901707,\n",
       "            0.45745395, 0.45019882, 0.34289634, 0.30206498, 0.13817628])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.31900000000000006),\n",
       "                                     1: np.float64(0.6809999999999999)}),\n",
       "    'fpr': np.float64(0.2702702702702703),\n",
       "    'tpr': np.float64(0.7692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.21621622, 0.21621622, 0.2972973 , 0.2972973 ,\n",
       "            0.35135135, 0.35135135, 0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.61538462, 0.61538462,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.82214779, 0.78618604, 0.68851843, 0.6880955 ,\n",
       "            0.67501104, 0.62429586, 0.55860486, 0.54957377, 0.53075368,\n",
       "            0.52908301, 0.52158958, 0.51968078, 0.48824675, 0.47927234,\n",
       "            0.46768892, 0.46035926, 0.35401859, 0.31095856, 0.14363181])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.30900000000000005),\n",
       "                                     1: np.float64(0.691)}),\n",
       "    'fpr': np.float64(0.2702702702702703),\n",
       "    'tpr': np.float64(0.7692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.16216216,\n",
       "            0.16216216, 0.18918919, 0.18918919, 0.21621622, 0.21621622,\n",
       "            0.2972973 , 0.2972973 , 0.35135135, 0.35135135, 0.64864865,\n",
       "            0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.61538462, 0.61538462, 0.69230769, 0.69230769, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.82773628, 0.79310177, 0.7046983 , 0.69863024,\n",
       "            0.6838304 , 0.63381968, 0.57875003, 0.56873899, 0.56854026,\n",
       "            0.55789752, 0.54097511, 0.53997178, 0.53270377, 0.53107476,\n",
       "            0.49881298, 0.4888715 , 0.47863843, 0.47024778, 0.36561439,\n",
       "            0.32066895, 0.14943453])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.29900000000000015),\n",
       "                                     1: np.float64(0.7009999999999998)}),\n",
       "    'fpr': np.float64(0.32432432432432434),\n",
       "    'tpr': np.float64(0.7692307692307693),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.16216216,\n",
       "            0.16216216, 0.21621622, 0.21621622, 0.32432432, 0.32432432,\n",
       "            0.35135135, 0.35135135, 0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.15384615, 0.15384615, 0.23076923,\n",
       "            0.23076923, 0.46153846, 0.46153846, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.83361656, 0.79998389, 0.71220503, 0.7093882 ,\n",
       "            0.6921254 , 0.64359713, 0.59031192, 0.58173016, 0.57840744,\n",
       "            0.55130198, 0.54406952, 0.54264721, 0.50097195, 0.4987371 ,\n",
       "            0.4897272 , 0.48015355, 0.37714336, 0.33055287, 0.15564332])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.28900000000000015),\n",
       "                                     1: np.float64(0.7109999999999999)}),\n",
       "    'fpr': np.float64(0.35135135135135137),\n",
       "    'tpr': np.float64(0.8461538461538461),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.13513514, 0.13513514, 0.16216216, 0.16216216, 0.21621622,\n",
       "            0.21621622, 0.32432432, 0.32432432, 0.35135135, 0.35135135,\n",
       "            0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.83927106, 0.72025433, 0.70106851, 0.65395739,\n",
       "            0.60213896, 0.59494936, 0.58837887, 0.56299848, 0.55619821,\n",
       "            0.55506455, 0.51353398, 0.50906691, 0.50124067, 0.49088008,\n",
       "            0.3897251 , 0.34081323, 0.16222675])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.27900000000000014),\n",
       "                                     1: np.float64(0.7209999999999999)}),\n",
       "    'fpr': np.float64(0.35135135135135137),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.13513514, 0.13513514, 0.16216216, 0.16216216, 0.21621622,\n",
       "            0.21621622, 0.32432432, 0.32432432, 0.35135135, 0.35135135,\n",
       "            0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.84483895, 0.73080659, 0.70935061, 0.66434829,\n",
       "            0.61361151, 0.60789657, 0.59842284, 0.57499075, 0.56849528,\n",
       "            0.56733544, 0.52603056, 0.52010719, 0.51279921, 0.50178911,\n",
       "            0.40214745, 0.35107477, 0.16906205])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.26900000000000013),\n",
       "                                     1: np.float64(0.7309999999999999)}),\n",
       "    'fpr': np.float64(0.3783783783783784),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.13513514, 0.13513514, 0.16216216, 0.16216216, 0.21621622,\n",
       "            0.21621622, 0.32432432, 0.32432432, 0.35135135, 0.35135135,\n",
       "            0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.85024744, 0.74143953, 0.71812023, 0.67461762,\n",
       "            0.6254856 , 0.62145796, 0.60852142, 0.58705247, 0.5807314 ,\n",
       "            0.57999626, 0.53892322, 0.53098166, 0.52460242, 0.51291519,\n",
       "            0.41560504, 0.36209128, 0.1765496 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2590000000000001),\n",
       "                                     1: np.float64(0.7409999999999999)}),\n",
       "    'fpr': np.float64(0.40540540540540543),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.13513514, 0.13513514, 0.16216216, 0.16216216, 0.21621622,\n",
       "            0.21621622, 0.32432432, 0.32432432, 0.35135135, 0.35135135,\n",
       "            0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.85596843, 0.75231725, 0.72659422, 0.68469918,\n",
       "            0.63761046, 0.63521832, 0.6178212 , 0.59951117, 0.59340599,\n",
       "            0.59259358, 0.55235962, 0.54171116, 0.53648043, 0.5239946 ,\n",
       "            0.42628673, 0.37327677, 0.18443697])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2490000000000001),\n",
       "                                     1: np.float64(0.7509999999999999)}),\n",
       "    'fpr': np.float64(0.43243243243243246),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.13513514, 0.13513514, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.32432432, 0.32432432, 0.37837838, 0.37837838,\n",
       "            0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.86129175, 0.76299694, 0.73553183, 0.69568026,\n",
       "            0.64946842, 0.64881365, 0.62750827, 0.61232654, 0.6067043 ,\n",
       "            0.60615056, 0.56441941, 0.55363548, 0.53610485, 0.53602356,\n",
       "            0.43783015, 0.38491683, 0.19297613])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2390000000000001),\n",
       "                                     1: np.float64(0.7609999999999999)}),\n",
       "    'fpr': np.float64(0.4864864864864865),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.32432432, 0.32432432, 0.37837838, 0.37837838,\n",
       "            0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.86693895, 0.77347555, 0.74404919, 0.70577256,\n",
       "            0.67578284, 0.66298631, 0.63721112, 0.62511812, 0.62000628,\n",
       "            0.6190812 , 0.57611488, 0.56547151, 0.54963108, 0.54786766,\n",
       "            0.44903151, 0.39692418, 0.20193837])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2290000000000001),\n",
       "                                     1: np.float64(0.7709999999999999)}),\n",
       "    'fpr': np.float64(0.5675675675675675),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.32432432, 0.32432432, 0.37837838, 0.37837838,\n",
       "            0.64864865, 0.64864865, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.87248797, 0.78419297, 0.75269917, 0.71620918,\n",
       "            0.6854897 , 0.67688156, 0.64708414, 0.63532804, 0.63326336,\n",
       "            0.632514  , 0.58741844, 0.57716675, 0.56301852, 0.56013989,\n",
       "            0.4609109 , 0.40919746, 0.21152818])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.21900000000000008),\n",
       "                                     1: np.float64(0.7809999999999999)}),\n",
       "    'fpr': np.float64(0.5945945945945946),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.32432432, 0.32432432, 0.37837838, 0.37837838,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.46153846,\n",
       "            0.46153846, 0.53846154, 0.53846154, 0.61538462, 0.61538462,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.87750836, 0.79495108, 0.76193523, 0.72711386,\n",
       "            0.69444049, 0.69118774, 0.65594025, 0.65239706, 0.64717807,\n",
       "            0.64653973, 0.59921173, 0.58965049, 0.57765159, 0.57278911,\n",
       "            0.42439328, 0.42194342, 0.22226545])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.20900000000000007),\n",
       "                                     1: np.float64(0.7909999999999999)}),\n",
       "    'fpr': np.float64(0.6216216216216216),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.13513514, 0.13513514, 0.18918919, 0.18918919, 0.32432432,\n",
       "            0.32432432, 0.37837838, 0.37837838, 0.67567568, 0.67567568,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.53846154,\n",
       "            0.53846154, 0.61538462, 0.61538462, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.88257879, 0.805151  , 0.77081817, 0.70499672,\n",
       "            0.6984165 , 0.6659113 , 0.66104849, 0.65775066, 0.61138531,\n",
       "            0.60250353, 0.59208536, 0.58562386, 0.44002426, 0.4355612 ,\n",
       "            0.23386797])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.19900000000000018),\n",
       "                                     1: np.float64(0.8009999999999998)}),\n",
       "    'fpr': np.float64(0.6216216216216216),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.13513514, 0.13513514, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.32432432, 0.32432432, 0.37837838, 0.37837838,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.53846154,\n",
       "            0.53846154, 0.61538462, 0.61538462, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.8880737 , 0.81593224, 0.78009493, 0.71984582,\n",
       "            0.71120397, 0.68047465, 0.67544129, 0.67520521, 0.67509847,\n",
       "            0.66937007, 0.62368854, 0.61552054, 0.60744952, 0.59924361,\n",
       "            0.45668983, 0.44955898, 0.24619592])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.18900000000000017),\n",
       "                                     1: np.float64(0.8109999999999998)}),\n",
       "    'fpr': np.float64(0.6486486486486487),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.13513514, 0.13513514, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.32432432, 0.32432432, 0.37837838, 0.37837838,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.53846154,\n",
       "            0.53846154, 0.61538462, 0.61538462, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.8936407 , 0.82645247, 0.78895541, 0.73415562,\n",
       "            0.72383441, 0.69513133, 0.68973246, 0.68969195, 0.68496475,\n",
       "            0.68111996, 0.63612933, 0.62841249, 0.62281369, 0.61289202,\n",
       "            0.47364709, 0.46419744, 0.2592925 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.17900000000000016),\n",
       "                                     1: np.float64(0.8209999999999998)}),\n",
       "    'fpr': np.float64(0.6486486486486487),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.13513514, 0.13513514, 0.16216216, 0.16216216, 0.18918919,\n",
       "            0.18918919, 0.32432432, 0.32432432, 0.40540541, 0.40540541,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.53846154,\n",
       "            0.53846154, 0.61538462, 0.61538462, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.89861169, 0.83656722, 0.79839483, 0.74859005,\n",
       "            0.73344477, 0.70988341, 0.70471889, 0.70464129, 0.69453099,\n",
       "            0.69386847, 0.64914442, 0.6429227 , 0.62823778, 0.62751371,\n",
       "            0.49180545, 0.47947696, 0.273941  ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.16900000000000015),\n",
       "                                     1: np.float64(0.8309999999999998)}),\n",
       "    'fpr': np.float64(0.6756756756756757),\n",
       "    'tpr': np.float64(0.9230769230769231),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.16216216,\n",
       "            0.16216216, 0.35135135, 0.35135135, 0.40540541, 0.40540541,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.53846154, 0.53846154, 0.61538462, 0.61538462,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.90384189, 0.84683909, 0.81814851, 0.80991671,\n",
       "            0.80758214, 0.76315846, 0.74339373, 0.72505373, 0.71981392,\n",
       "            0.70669876, 0.65701499, 0.65700308, 0.64459714, 0.64218145,\n",
       "            0.51075377, 0.49538428, 0.28984421])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.15900000000000014),\n",
       "                                     1: np.float64(0.8409999999999999)}),\n",
       "    'fpr': np.float64(0.7297297297297297),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.16216216,\n",
       "            0.16216216, 0.35135135, 0.35135135, 0.40540541, 0.40540541,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.38461538,\n",
       "            0.38461538, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.90874885, 0.85702346, 0.82697547, 0.81947473,\n",
       "            0.81744615, 0.7774855 , 0.75322611, 0.7354364 , 0.73518333,\n",
       "            0.72005446, 0.67228781, 0.67200798, 0.66112006, 0.65730879,\n",
       "            0.53036526, 0.51161421, 0.30732655])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.14900000000000013),\n",
       "                                     1: np.float64(0.8509999999999999)}),\n",
       "    'fpr': np.float64(0.7567567567567568),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.16216216,\n",
       "            0.16216216, 0.37837838, 0.37837838, 0.40540541, 0.40540541,\n",
       "            0.67567568, 0.67567568, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.38461538,\n",
       "            0.38461538, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.91378535, 0.86711096, 0.83576145, 0.83148061,\n",
       "            0.82720643, 0.79202998, 0.76316367, 0.75110624, 0.75036459,\n",
       "            0.73357584, 0.68730439, 0.68671816, 0.67827709, 0.67278853,\n",
       "            0.55128021, 0.52924728, 0.32576798])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.13900000000000012),\n",
       "                                     1: np.float64(0.8609999999999999)}),\n",
       "    'fpr': np.float64(0.7567567567567568),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.05405405, 0.05405405, 0.08108108, 0.08108108, 0.13513514,\n",
       "            0.13513514, 0.16216216, 0.16216216, 0.37837838, 0.37837838,\n",
       "            0.40540541, 0.40540541, 0.7027027 , 0.7027027 , 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.30769231,\n",
       "            0.30769231, 0.38461538, 0.38461538, 0.53846154, 0.53846154,\n",
       "            0.69230769, 0.69230769, 0.76923077, 0.76923077, 0.84615385,\n",
       "            0.84615385, 0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.91873658, 0.8768275 , 0.8503421 , 0.84563523,\n",
       "            0.8447674 , 0.84331797, 0.83698275, 0.80650627, 0.77337158,\n",
       "            0.76703347, 0.76623405, 0.74803345, 0.70321831, 0.70293212,\n",
       "            0.6957277 , 0.68932645, 0.55163396, 0.54760798, 0.34592591])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.12900000000000011),\n",
       "                                     1: np.float64(0.8709999999999999)}),\n",
       "    'fpr': np.float64(0.8108108108108109),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.16216216, 0.35135135, 0.35135135, 0.40540541, 0.40540541,\n",
       "            0.7027027 , 0.7027027 , 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.23076923, 0.23076923, 0.38461538,\n",
       "            0.38461538, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.9235645 , 0.88657694, 0.85892097, 0.85526238,\n",
       "            0.84707185, 0.82099881, 0.80180866, 0.78347974, 0.78233406,\n",
       "            0.7633165 , 0.71974171, 0.71959456, 0.71354308, 0.70673669,\n",
       "            0.57609561, 0.5669025 , 0.36803017])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1190000000000001),\n",
       "                                     1: np.float64(0.8809999999999999)}),\n",
       "    'fpr': np.float64(0.8378378378378378),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02702703, 0.02702703,\n",
       "            0.08108108, 0.08108108, 0.10810811, 0.10810811, 0.16216216,\n",
       "            0.16216216, 0.32432432, 0.32432432, 0.40540541, 0.40540541,\n",
       "            0.7027027 , 0.7027027 , 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.38461538,\n",
       "            0.38461538, 0.53846154, 0.53846154, 0.69230769, 0.69230769,\n",
       "            0.76923077, 0.76923077, 0.84615385, 0.84615385, 0.92307692,\n",
       "            0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.9285829 , 0.86907009, 0.867914  , 0.86675186,\n",
       "            0.85705435, 0.83539448, 0.81515104, 0.79960607, 0.79436428,\n",
       "            0.77872108, 0.74531401, 0.7369761 , 0.73199496, 0.72432313,\n",
       "            0.60162282, 0.58755776, 0.39310651])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1090000000000001),\n",
       "                                     1: np.float64(0.8909999999999999)}),\n",
       "    'fpr': np.float64(0.8918918918918919),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.16216216, 0.16216216, 0.32432432,\n",
       "            0.32432432, 0.40540541, 0.40540541, 0.72972973, 0.72972973,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.53846154,\n",
       "            0.53846154, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.93350448, 0.87813739, 0.86725289, 0.84981211,\n",
       "            0.82860748, 0.81595326, 0.80544279, 0.79478072, 0.76506094,\n",
       "            0.7549745 , 0.74984109, 0.74280826, 0.61139075, 0.60981619,\n",
       "            0.42131476])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.09900000000000009),\n",
       "                                     1: np.float64(0.9009999999999999)}),\n",
       "    'fpr': np.float64(0.8918918918918919),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.16216216, 0.16216216, 0.32432432,\n",
       "            0.32432432, 0.40540541, 0.40540541, 0.75675676, 0.75675676,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.53846154,\n",
       "            0.53846154, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.93844454, 0.88952023, 0.87745625, 0.86227754,\n",
       "            0.84226866, 0.83262096, 0.81690228, 0.81152043, 0.77812825,\n",
       "            0.77359589, 0.76624225, 0.76221585, 0.63708344, 0.63309384,\n",
       "            0.45312582])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.08900000000000019),\n",
       "                                     1: np.float64(0.9109999999999998)}),\n",
       "    'fpr': np.float64(0.9459459459459459),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.13513514, 0.13513514, 0.2972973 ,\n",
       "            0.2972973 , 0.40540541, 0.40540541, 0.75675676, 0.75675676,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.53846154,\n",
       "            0.53846154, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.94318507, 0.90106076, 0.88846758, 0.87480948,\n",
       "            0.85618733, 0.84984142, 0.8483801 , 0.8290799 , 0.80541841,\n",
       "            0.79337061, 0.78390299, 0.78243114, 0.66771607, 0.65815043,\n",
       "            0.48921475])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.07900000000000018),\n",
       "                                     1: np.float64(0.9209999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.13513514, 0.13513514, 0.2972973 ,\n",
       "            0.2972973 , 0.37837838, 0.37837838, 0.75675676, 0.75675676,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.61538462,\n",
       "            0.61538462, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.94799544, 0.9121645 , 0.89946414, 0.87085349,\n",
       "            0.87004635, 0.86665516, 0.86487999, 0.84685497, 0.8261015 ,\n",
       "            0.81362939, 0.8043345 , 0.80315579, 0.69887778, 0.68511088,\n",
       "            0.5298758 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.06900000000000017),\n",
       "                                     1: np.float64(0.9309999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.10810811, 0.10810811, 0.13513514, 0.13513514, 0.2972973 ,\n",
       "            0.2972973 , 0.35135135, 0.35135135, 0.75675676, 0.75675676,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.61538462,\n",
       "            0.61538462, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.95278669, 0.92301117, 0.910618  , 0.88750776,\n",
       "            0.88413303, 0.883501  , 0.88160032, 0.86535931, 0.84744254,\n",
       "            0.83497764, 0.83074081, 0.82524225, 0.73259786, 0.71479115,\n",
       "            0.57661473])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.05900000000000016),\n",
       "                                     1: np.float64(0.9409999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.13513514, 0.13513514, 0.2972973 , 0.2972973 , 0.35135135,\n",
       "            0.35135135, 0.78378378, 0.78378378, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.69230769,\n",
       "            0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.95753223, 0.93359722, 0.92197535, 0.90029626,\n",
       "            0.89836405, 0.88443521, 0.8690402 , 0.85727839, 0.85203954,\n",
       "            0.84840635, 0.7536185 , 0.74721682, 0.62913848])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.049000000000000155),\n",
       "                                     1: np.float64(0.9509999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08108108, 0.08108108,\n",
       "            0.13513514, 0.13513514, 0.2972973 , 0.2972973 , 0.37837838,\n",
       "            0.37837838, 0.81081081, 0.81081081, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.69230769,\n",
       "            0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.96234078, 0.94372427, 0.9322518 , 0.91716516,\n",
       "            0.91311628, 0.90369479, 0.88500415, 0.88051304, 0.87329847,\n",
       "            0.87263587, 0.78483349, 0.78318219, 0.68593001])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.039000000000000146),\n",
       "                                     1: np.float64(0.9609999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.27027027,\n",
       "            0.27027027, 0.35135135, 0.35135135, 0.81081081, 0.81081081,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.46153846,\n",
       "            0.46153846, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.96726156, 0.95322292, 0.94575473, 0.94447044,\n",
       "            0.94259984, 0.93391192, 0.92821022, 0.92328471, 0.90908159,\n",
       "            0.90469378, 0.89838354, 0.89775029, 0.83306794, 0.82292813,\n",
       "            0.75075006])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.029000000000000137),\n",
       "                                     1: np.float64(0.9709999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.08108108, 0.08108108, 0.13513514, 0.13513514, 0.27027027,\n",
       "            0.27027027, 0.2972973 , 0.2972973 , 0.83783784, 0.83783784,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.53846154,\n",
       "            0.53846154, 0.69230769, 0.69230769, 0.76923077, 0.76923077,\n",
       "            0.84615385, 0.84615385, 0.92307692, 0.92307692, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.97260012, 0.96290326, 0.95809489, 0.95427553,\n",
       "            0.9538359 , 0.95057934, 0.94400818, 0.94322342, 0.93003516,\n",
       "            0.92955405, 0.92783324, 0.92416103, 0.86819376, 0.86738848,\n",
       "            0.82252493])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.019000000000000128),\n",
       "                                     1: np.float64(0.9809999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.10810811, 0.10810811, 0.24324324, 0.24324324, 0.2972973 ,\n",
       "            0.2972973 , 0.83783784, 0.83783784, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.38461538, 0.38461538, 0.69230769,\n",
       "            0.69230769, 0.76923077, 0.76923077, 0.84615385, 0.84615385,\n",
       "            0.92307692, 0.92307692, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.97901368, 0.9729517 , 0.97104709, 0.96702344,\n",
       "            0.96446893, 0.96296826, 0.95645926, 0.95485822, 0.95273878,\n",
       "            0.95137746, 0.92354804, 0.91570992, 0.89620562])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.009000000000000119),\n",
       "                                     1: np.float64(0.9909999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05405405, 0.05405405,\n",
       "            0.21621622, 0.21621622, 0.27027027, 0.27027027, 0.91891892,\n",
       "            0.91891892, 1.        ]),\n",
       "     'tpr': array([0.        , 0.07692308, 0.30769231, 0.30769231, 0.76923077,\n",
       "            0.76923077, 0.84615385, 0.84615385, 0.92307692, 0.92307692,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.98776908, 0.98657499, 0.98477334, 0.98215282,\n",
       "            0.97989103, 0.97934378, 0.97851508, 0.97798918, 0.96506843,\n",
       "            0.96498765, 0.96161122])}}],\n",
       "  [{'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.1875 , 0.1875 , 0.34375, 0.34375, 0.4375 , 0.4375 ,\n",
       "            0.5625 , 0.5625 , 0.65625, 0.6875 , 0.6875 , 0.84375, 0.84375,\n",
       "            0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.27777778, 0.27777778,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.00045154, 0.00043865, 0.0004349 , 0.00043136,\n",
       "            0.00042857, 0.00042698, 0.00042499, 0.00042436, 0.00042403,\n",
       "            0.00041918, 0.00041699, 0.00041118, 0.00041079, 0.00040568,\n",
       "            0.00040538, 0.00040455, 0.00040443, 0.00040396, 0.00039275,\n",
       "            0.00039173, 0.00038847, 0.00038742, 0.00038551])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.989), 1: np.float64(0.011)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.25   , 0.25   , 0.34375, 0.34375, 0.375  , 0.375  ,\n",
       "            0.46875, 0.46875, 0.53125, 0.53125, 0.6875 , 0.6875 , 0.71875,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.27777778, 0.27777778,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.55555556, 0.55555556, 0.61111111, 0.61111111,\n",
       "            0.66666667, 0.66666667, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.00863764, 0.00708572, 0.00636999, 0.00612188,\n",
       "            0.00602709, 0.005308  , 0.00527998, 0.0052724 , 0.00524681,\n",
       "            0.00503998, 0.00473585, 0.00469278, 0.00453519, 0.00422824,\n",
       "            0.00414011, 0.00396837, 0.00384963, 0.00374553, 0.00374098,\n",
       "            0.00364228, 0.0029217 , 0.00292109, 0.00271068, 0.00263584,\n",
       "            0.00254391])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.979),\n",
       "                                     1: np.float64(0.020999999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.25   , 0.25   , 0.28125,\n",
       "            0.28125, 0.34375, 0.34375, 0.40625, 0.40625, 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.53125, 0.53125, 0.6875 , 0.6875 , 0.71875,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.55555556,\n",
       "            0.55555556, 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.02417232, 0.01852916, 0.01460615, 0.01147507,\n",
       "            0.0112826 , 0.01103386, 0.01052457, 0.01036358, 0.00916839,\n",
       "            0.00880744, 0.00856354, 0.00798086, 0.007596  , 0.00736716,\n",
       "            0.00735787, 0.00721271, 0.00695985, 0.00661134, 0.00656258,\n",
       "            0.00618227, 0.00454611, 0.00449437, 0.00396275, 0.0037286 ,\n",
       "            0.00355035])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.969),\n",
       "                                     1: np.float64(0.030999999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.25   , 0.25   , 0.34375,\n",
       "            0.34375, 0.4375 , 0.4375 , 0.46875, 0.46875, 0.5    , 0.5    ,\n",
       "            0.53125, 0.53125, 0.6875 , 0.6875 , 0.71875, 0.75   , 0.90625,\n",
       "            0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.55555556, 0.55555556, 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.04527533, 0.03389495, 0.02358612, 0.01823737,\n",
       "            0.0177721 , 0.01569427, 0.01304313, 0.01223578, 0.01196228,\n",
       "            0.01149923, 0.01057731, 0.01056913, 0.0105272 , 0.01004358,\n",
       "            0.00981885, 0.00904575, 0.00892532, 0.00827686, 0.0081264 ,\n",
       "            0.00572547, 0.00560129, 0.00474263, 0.00431973, 0.00408716])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.959),\n",
       "                                     1: np.float64(0.040999999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.25   ,\n",
       "            0.25   , 0.34375, 0.34375, 0.375  , 0.375  , 0.4375 , 0.4375 ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.6875 ,\n",
       "            0.6875 , 0.71875, 0.75   , 0.90625, 0.90625, 0.96875, 0.96875,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.22222222, 0.22222222,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.5       ,\n",
       "            0.5       , 0.55555556, 0.55555556, 0.61111111, 0.61111111,\n",
       "            0.66666667, 0.66666667, 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.07036699, 0.05216881, 0.03624775, 0.0347783 ,\n",
       "            0.03294624, 0.02535837, 0.02437897, 0.02090488, 0.01841781,\n",
       "            0.01677527, 0.01641864, 0.01609946, 0.01484413, 0.01477272,\n",
       "            0.01358577, 0.01358165, 0.01304208, 0.01251849, 0.01250159,\n",
       "            0.01112873, 0.01092567, 0.01000363, 0.00964674, 0.0066578 ,\n",
       "            0.00641613, 0.0052642 , 0.00465427, 0.00439412])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9490000000000001),\n",
       "                                     1: np.float64(0.05099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.34375, 0.34375, 0.40625, 0.40625,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.6875 , 0.6875 , 0.71875,\n",
       "            0.75   , 0.90625, 0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.22222222, 0.22222222,\n",
       "            0.27777778, 0.27777778, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.5       , 0.5       , 0.55555556, 0.55555556,\n",
       "            0.66666667, 0.66666667, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.09652258, 0.07068016, 0.04753679, 0.04742344,\n",
       "            0.04343641, 0.042089  , 0.0417925 , 0.03247507, 0.03166319,\n",
       "            0.02597666, 0.02258063, 0.01995523, 0.01961733, 0.01831595,\n",
       "            0.01688788, 0.01658218, 0.0152364 , 0.01329402, 0.01301413,\n",
       "            0.01175261, 0.01125206, 0.00778672, 0.00722055, 0.00589349,\n",
       "            0.00512007, 0.00477722])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9390000000000001),\n",
       "                                     1: np.float64(0.06099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.34375, 0.34375, 0.40625, 0.40625,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.6875 , 0.6875 , 0.71875,\n",
       "            0.75   , 0.90625, 0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.27777778, 0.27777778, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.5       , 0.5       , 0.55555556, 0.55555556,\n",
       "            0.66666667, 0.66666667, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.12362564, 0.09171176, 0.06571925, 0.06043493,\n",
       "            0.05298026, 0.05175701, 0.05012807, 0.04004939, 0.03850142,\n",
       "            0.03087234, 0.02615892, 0.02365808, 0.02227444, 0.02154612,\n",
       "            0.01972776, 0.01933138, 0.01753029, 0.01515842, 0.01473513,\n",
       "            0.01323005, 0.01253425, 0.00855238, 0.00796836, 0.00631779,\n",
       "            0.00536853, 0.00501377])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.929), 1: np.float64(0.071)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.34375, 0.34375, 0.4375 , 0.4375 ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.6875 , 0.6875 , 0.71875,\n",
       "            0.75   , 0.90625, 0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.27777778, 0.27777778, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.5       , 0.5       , 0.55555556, 0.55555556,\n",
       "            0.66666667, 0.66666667, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.14980442, 0.11168479, 0.07931304, 0.07405841,\n",
       "            0.0625856 , 0.06129408, 0.05802505, 0.04708141, 0.04524395,\n",
       "            0.03534704, 0.02902858, 0.02504151, 0.02501981, 0.02479648,\n",
       "            0.02246268, 0.02229834, 0.01942627, 0.01704874, 0.01653658,\n",
       "            0.01472259, 0.01377896, 0.00938733, 0.00862669, 0.00677584,\n",
       "            0.00566609, 0.00526387])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.919),\n",
       "                                     1: np.float64(0.08099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.34375, 0.34375, 0.46875, 0.46875,\n",
       "            0.5    , 0.5    , 0.6875 , 0.6875 , 0.71875, 0.75   , 0.90625,\n",
       "            0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.27777778, 0.27777778, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.5       , 0.5       , 0.61111111, 0.61111111,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.1755976 , 0.13168493, 0.09374251, 0.08866155,\n",
       "            0.07250079, 0.07091012, 0.06510377, 0.05423137, 0.05195311,\n",
       "            0.03992247, 0.03170451, 0.02764182, 0.02615866, 0.02509325,\n",
       "            0.02121665, 0.01886928, 0.01828055, 0.0161168 , 0.01493323,\n",
       "            0.00998598, 0.00927117, 0.007202  , 0.00597727, 0.00550226])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.909),\n",
       "                                     1: np.float64(0.09099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.1875 ,\n",
       "            0.1875 , 0.25   , 0.25   , 0.34375, 0.34375, 0.375  , 0.375  ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.6875 ,\n",
       "            0.6875 , 0.71875, 0.75   , 0.90625, 0.90625, 0.96875, 0.96875,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.27777778, 0.27777778, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.61111111, 0.61111111, 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.2007987 , 0.15255028, 0.1078001 , 0.10313802,\n",
       "            0.08185966, 0.07453327, 0.07219062, 0.06147542, 0.05887547,\n",
       "            0.04423897, 0.0371581 , 0.03486341, 0.03408617, 0.03007593,\n",
       "            0.02935096, 0.02788027, 0.02589293, 0.02315075, 0.02305311,\n",
       "            0.02049101, 0.01992501, 0.01742977, 0.01603397, 0.01046871,\n",
       "            0.00993376, 0.00757868, 0.00622375, 0.00569377])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.899),\n",
       "                                     1: np.float64(0.10099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.25   , 0.25   , 0.34375, 0.34375, 0.375  , 0.375  ,\n",
       "            0.4375 , 0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.5625 ,\n",
       "            0.5625 , 0.6875 , 0.6875 , 0.71875, 0.75   , 0.90625, 0.90625,\n",
       "            0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.27777778, 0.27777778, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.55555556, 0.55555556, 0.61111111, 0.61111111, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.22464336, 0.17185485, 0.12184083, 0.11829175,\n",
       "            0.09159954, 0.08028244, 0.07870157, 0.06827513, 0.06553051,\n",
       "            0.0487444 , 0.04055905, 0.03851737, 0.03653772, 0.03475022,\n",
       "            0.03269535, 0.03246662, 0.03222495, 0.03061877, 0.02850152,\n",
       "            0.02484416, 0.02477318, 0.02225847, 0.02167999, 0.01878931,\n",
       "            0.01715992, 0.01106763, 0.01059072, 0.00800421, 0.00657267,\n",
       "            0.00593264])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.889),\n",
       "                                     1: np.float64(0.11099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.25   , 0.25   , 0.34375, 0.34375, 0.40625, 0.40625,\n",
       "            0.4375 , 0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.5625 ,\n",
       "            0.5625 , 0.6875 , 0.6875 , 0.71875, 0.75   , 0.90625, 0.90625,\n",
       "            0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.27777778, 0.27777778, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.55555556, 0.55555556, 0.61111111, 0.61111111, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.24780834, 0.19138564, 0.13660878, 0.13355234,\n",
       "            0.10144926, 0.08909531, 0.08495712, 0.07559508, 0.0722196 ,\n",
       "            0.05319353, 0.04407175, 0.03925932, 0.03879236, 0.03811114,\n",
       "            0.03601919, 0.03495682, 0.03449632, 0.0334385 , 0.03081605,\n",
       "            0.02677549, 0.02649708, 0.02390852, 0.02334045, 0.02005494,\n",
       "            0.01824443, 0.011608  , 0.01125646, 0.00841665, 0.00688172,\n",
       "            0.00616015])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.879),\n",
       "                                     1: np.float64(0.12099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.25   , 0.25   , 0.34375, 0.34375, 0.4375 , 0.4375 ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.59375, 0.59375, 0.6875 ,\n",
       "            0.6875 , 0.71875, 0.75   , 0.90625, 0.90625, 0.96875, 0.96875,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.27777778, 0.27777778, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.44444444, 0.44444444, 0.55555556, 0.55555556,\n",
       "            0.61111111, 0.61111111, 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.26958166, 0.21028364, 0.15079562, 0.14898971,\n",
       "            0.11114737, 0.09788117, 0.09097264, 0.08271536, 0.07883779,\n",
       "            0.05767695, 0.04742396, 0.04155065, 0.03942149, 0.03732488,\n",
       "            0.03675147, 0.03621683, 0.03291167, 0.02841005, 0.0282561 ,\n",
       "            0.02558418, 0.02504571, 0.02134638, 0.01935013, 0.01217305,\n",
       "            0.01195867, 0.00883983, 0.00722361, 0.00639707])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.869),\n",
       "                                     1: np.float64(0.13099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.25   , 0.25   , 0.34375, 0.34375, 0.4375 , 0.4375 ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.59375, 0.59375, 0.6875 ,\n",
       "            0.6875 , 0.71875, 0.75   , 0.90625, 0.90625, 0.96875, 0.96875,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.27777778, 0.27777778, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.44444444, 0.44444444, 0.55555556, 0.55555556,\n",
       "            0.61111111, 0.61111111, 0.72222222, 0.72222222, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.29018761, 0.22851761, 0.16506048, 0.16464541,\n",
       "            0.12112473, 0.10651961, 0.09676383, 0.08983359, 0.08537808,\n",
       "            0.06231078, 0.05075741, 0.04509534, 0.04286048, 0.03968792,\n",
       "            0.03901177, 0.03898391, 0.03519048, 0.03051522, 0.03008564,\n",
       "            0.02730951, 0.02680332, 0.02266481, 0.02049113, 0.01279257,\n",
       "            0.01270093, 0.00929791, 0.00761154, 0.00666239])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.859), 1: np.float64(0.141)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.25   , 0.25   , 0.34375, 0.34375, 0.4375 , 0.4375 ,\n",
       "            0.5    , 0.5    , 0.59375, 0.59375, 0.6875 , 0.6875 , 0.71875,\n",
       "            0.75   , 0.90625, 0.90625, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.11111111, 0.11111111,\n",
       "            0.27777778, 0.27777778, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.44444444, 0.44444444, 0.55555556, 0.55555556,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.30970274, 0.24484864, 0.22188125, 0.18071302,\n",
       "            0.13115126, 0.11546639, 0.10152352, 0.09629947, 0.09158499,\n",
       "            0.06683715, 0.0542123 , 0.04811314, 0.04531658, 0.04176719,\n",
       "            0.03737413, 0.0323967 , 0.03148837, 0.02896961, 0.0285432 ,\n",
       "            0.02386161, 0.02148407, 0.0134067 , 0.0133293 , 0.0097303 ,\n",
       "            0.00803133, 0.00691196])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.849),\n",
       "                                     1: np.float64(0.15099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.21875,\n",
       "            0.21875, 0.25   , 0.25   , 0.34375, 0.34375, 0.4375 , 0.4375 ,\n",
       "            0.5    , 0.5    , 0.59375, 0.59375, 0.6875 , 0.6875 , 0.71875,\n",
       "            0.75   , 0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.11111111, 0.11111111,\n",
       "            0.27777778, 0.27777778, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.44444444, 0.44444444, 0.55555556, 0.55555556,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.32815779, 0.26164198, 0.24216914, 0.19512904,\n",
       "            0.14005668, 0.12337626, 0.10670629, 0.10407369, 0.09895475,\n",
       "            0.07136055, 0.05742897, 0.05103807, 0.04709075, 0.04459093,\n",
       "            0.03928973, 0.03479603, 0.03346281, 0.0304383 , 0.0301472 ,\n",
       "            0.02506506, 0.0226458 , 0.01589209, 0.01424782, 0.0101779 ,\n",
       "            0.0083857 , 0.00718226])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.839),\n",
       "                                     1: np.float64(0.16099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.09375, 0.09375, 0.125  , 0.125  ,\n",
       "            0.21875, 0.21875, 0.25   , 0.25   , 0.34375, 0.34375, 0.4375 ,\n",
       "            0.4375 , 0.5    , 0.5    , 0.59375, 0.59375, 0.6875 , 0.6875 ,\n",
       "            0.71875, 0.75   , 0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.27777778, 0.27777778, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.55555556,\n",
       "            0.55555556, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.34736919, 0.34655454, 0.27777572, 0.2608615 ,\n",
       "            0.21054806, 0.14972755, 0.13203842, 0.11168735, 0.11076456,\n",
       "            0.10526604, 0.07587484, 0.06078186, 0.0539146 , 0.04896303,\n",
       "            0.04703587, 0.04138551, 0.03672296, 0.03499683, 0.0319815 ,\n",
       "            0.03179186, 0.02619899, 0.02364406, 0.01666653, 0.01492259,\n",
       "            0.01057623, 0.00876096, 0.0074053 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.829),\n",
       "                                     1: np.float64(0.17099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.09375, 0.09375, 0.125  , 0.125  ,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.40625, 0.40625, 0.4375 ,\n",
       "            0.4375 , 0.5    , 0.5    , 0.59375, 0.59375, 0.6875 , 0.6875 ,\n",
       "            0.71875, 0.75   , 0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.36790796, 0.36359066, 0.29368406, 0.27896958,\n",
       "            0.22643571, 0.15932596, 0.11762668, 0.11151839, 0.08056971,\n",
       "            0.06396243, 0.05931229, 0.05760729, 0.05698203, 0.05094107,\n",
       "            0.04931762, 0.0436518 , 0.03868452, 0.03673501, 0.0336005 ,\n",
       "            0.03353698, 0.02740817, 0.02470344, 0.01751372, 0.01568282,\n",
       "            0.01101266, 0.00917871, 0.00765047])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.8190000000000001),\n",
       "                                     1: np.float64(0.18099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.09375, 0.09375, 0.125  , 0.125  ,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.40625, 0.40625, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.59375, 0.59375, 0.65625, 0.65625,\n",
       "            0.71875, 0.75   , 0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.38766888, 0.37998574, 0.30859914, 0.29703129,\n",
       "            0.24200631, 0.16874007, 0.12462189, 0.11802818, 0.08551092,\n",
       "            0.06731052, 0.06308453, 0.06160144, 0.05301297, 0.05291029,\n",
       "            0.05181084, 0.04600454, 0.04083944, 0.03852241, 0.03752455,\n",
       "            0.03536922, 0.02867118, 0.02584202, 0.01843407, 0.01653007,\n",
       "            0.01150524, 0.00966279, 0.0079448 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.809),\n",
       "                                     1: np.float64(0.19099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.09375, 0.09375, 0.125  , 0.125  ,\n",
       "            0.25   , 0.25   , 0.375  , 0.375  , 0.40625, 0.40625, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.59375, 0.59375, 0.65625, 0.65625,\n",
       "            0.71875, 0.75   , 0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.40590154, 0.39527417, 0.32380733, 0.31403951,\n",
       "            0.25731866, 0.17758803, 0.13165764, 0.12391536, 0.07090843,\n",
       "            0.07067323, 0.06685873, 0.0653598 , 0.05606143, 0.05509502,\n",
       "            0.0542455 , 0.04846635, 0.04288312, 0.04051532, 0.03956261,\n",
       "            0.03718979, 0.02996281, 0.02697754, 0.01928005, 0.01731765,\n",
       "            0.01199812, 0.01007194, 0.0082016 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.799),\n",
       "                                     1: np.float64(0.20099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.09375, 0.09375, 0.125  , 0.125  ,\n",
       "            0.25   , 0.25   , 0.375  , 0.375  , 0.40625, 0.40625, 0.5    ,\n",
       "            0.5    , 0.625  , 0.625  , 0.65625, 0.65625, 0.71875, 0.75   ,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.42541325, 0.40974243, 0.33624515, 0.33118782,\n",
       "            0.2713017 , 0.18478293, 0.13856429, 0.13066256, 0.07431124,\n",
       "            0.07424047, 0.07066538, 0.06948829, 0.05707986, 0.0509426 ,\n",
       "            0.042582  , 0.04219872, 0.04152709, 0.038983  , 0.03111415,\n",
       "            0.02816826, 0.02020004, 0.01831189, 0.01253244, 0.01064423,\n",
       "            0.00855802])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.789),\n",
       "                                     1: np.float64(0.21099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.09375, 0.09375, 0.125  , 0.125  ,\n",
       "            0.15625, 0.15625, 0.25   , 0.25   , 0.375  , 0.375  , 0.40625,\n",
       "            0.40625, 0.5    , 0.5    , 0.625  , 0.625  , 0.65625, 0.65625,\n",
       "            0.75   , 0.78125, 0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.22222222, 0.22222222, 0.27777778, 0.27777778,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.44316305, 0.42374737, 0.34972002, 0.34751152,\n",
       "            0.28623371, 0.19818481, 0.19210829, 0.19137644, 0.14559846,\n",
       "            0.1350052 , 0.07796234, 0.07772149, 0.07442023, 0.07354677,\n",
       "            0.05975639, 0.05344712, 0.04464528, 0.04401024, 0.0435511 ,\n",
       "            0.04082301, 0.0296727 , 0.02933055, 0.0211355 , 0.01920624,\n",
       "            0.01303639, 0.01117219, 0.00887118])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.779),\n",
       "                                     1: np.float64(0.22099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.09375, 0.09375, 0.125  , 0.125  ,\n",
       "            0.15625, 0.15625, 0.25   , 0.25   , 0.375  , 0.375  , 0.40625,\n",
       "            0.40625, 0.46875, 0.46875, 0.5    , 0.5    , 0.625  , 0.625  ,\n",
       "            0.65625, 0.65625, 0.75   , 0.78125, 0.875  , 0.875  , 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.22222222, 0.22222222, 0.27777778, 0.27777778,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.55555556, 0.55555556, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.45993241, 0.437591  , 0.36322881, 0.36255952,\n",
       "            0.30055184, 0.20838543, 0.20138922, 0.19851248, 0.15222543,\n",
       "            0.14006984, 0.08161698, 0.08097684, 0.07819769, 0.07745842,\n",
       "            0.06467956, 0.0624958 , 0.06220934, 0.05605325, 0.04672101,\n",
       "            0.04591526, 0.04558883, 0.04269653, 0.0312796 , 0.03047116,\n",
       "            0.02206636, 0.02010552, 0.01352528, 0.01168124, 0.00915551])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.769),\n",
       "                                     1: np.float64(0.23099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  ,\n",
       "            0.15625, 0.15625, 0.25   , 0.25   , 0.375  , 0.375  , 0.40625,\n",
       "            0.40625, 0.46875, 0.46875, 0.5    , 0.5    , 0.625  , 0.625  ,\n",
       "            0.65625, 0.65625, 0.75   , 0.78125, 0.875  , 0.875  , 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.22222222, 0.22222222, 0.27777778, 0.27777778,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.55555556, 0.55555556, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.47653804, 0.45010516, 0.38318401, 0.37851687,\n",
       "            0.31565759, 0.21823201, 0.21108838, 0.20524459, 0.15928643,\n",
       "            0.14401263, 0.08545093, 0.08448557, 0.08240427, 0.08191752,\n",
       "            0.06770445, 0.06569178, 0.06497208, 0.05880893, 0.04895968,\n",
       "            0.04792451, 0.04780729, 0.04469126, 0.03326314, 0.03169311,\n",
       "            0.02308781, 0.02114349, 0.0140927 , 0.01229029, 0.00950607])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.759),\n",
       "                                     1: np.float64(0.24099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  ,\n",
       "            0.15625, 0.15625, 0.25   , 0.25   , 0.375  , 0.375  , 0.40625,\n",
       "            0.40625, 0.46875, 0.46875, 0.5    , 0.5    , 0.625  , 0.625  ,\n",
       "            0.65625, 0.65625, 0.75   , 0.78125, 0.875  , 0.875  , 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.22222222, 0.22222222, 0.27777778, 0.27777778,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.55555556, 0.55555556, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.49281655, 0.46323279, 0.39741462, 0.39474211,\n",
       "            0.33001551, 0.226851  , 0.22100652, 0.21212922, 0.16688249,\n",
       "            0.14813935, 0.08906415, 0.08783946, 0.0865158 , 0.08613374,\n",
       "            0.0706039 , 0.06865625, 0.06777811, 0.06156357, 0.05094124,\n",
       "            0.05003636, 0.04988729, 0.0464603 , 0.0350368 , 0.03288359,\n",
       "            0.02392344, 0.02211483, 0.01463355, 0.01282522, 0.00982464])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7490000000000001),\n",
       "                                     1: np.float64(0.25099999999999995)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  ,\n",
       "            0.1875 , 0.1875 , 0.25   , 0.25   , 0.375  , 0.375  , 0.40625,\n",
       "            0.40625, 0.46875, 0.46875, 0.5    , 0.5    , 0.625  , 0.625  ,\n",
       "            0.65625, 0.65625, 0.75   , 0.78125, 0.875  , 0.875  , 0.96875,\n",
       "            0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.22222222, 0.22222222, 0.27777778, 0.27777778,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.55555556, 0.55555556, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.50745943, 0.4748695 , 0.4104183 , 0.40946427,\n",
       "            0.34507595, 0.23624703, 0.22032932, 0.21850406, 0.17386962,\n",
       "            0.15243829, 0.09312038, 0.09114647, 0.09066688, 0.09051817,\n",
       "            0.07363739, 0.07176067, 0.07043798, 0.06441202, 0.053051  ,\n",
       "            0.0521483 , 0.05212793, 0.04844771, 0.03695089, 0.03407096,\n",
       "            0.02497207, 0.02314197, 0.01520402, 0.01341572, 0.01017165])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7390000000000001),\n",
       "                                     1: np.float64(0.26099999999999995)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.1875 , 0.1875 ,\n",
       "            0.25   , 0.25   , 0.375  , 0.375  , 0.46875, 0.46875, 0.5    ,\n",
       "            0.5    , 0.65625, 0.65625, 0.75   , 0.78125, 0.875  , 0.875  ,\n",
       "            0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.5       , 0.5       , 0.55555556, 0.55555556, 0.72222222,\n",
       "            0.72222222, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.52122686, 0.42393845, 0.35878788, 0.24604589,\n",
       "            0.22905639, 0.22521037, 0.18085351, 0.15735895, 0.09700075,\n",
       "            0.09516077, 0.07703784, 0.07504991, 0.07358082, 0.06738203,\n",
       "            0.05444033, 0.0505821 , 0.0386824 , 0.03532307, 0.02601659,\n",
       "            0.02420025, 0.01579039, 0.01408041, 0.01053151])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7290000000000001),\n",
       "                                     1: np.float64(0.27099999999999996)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.1875 , 0.1875 ,\n",
       "            0.25   , 0.25   , 0.375  , 0.375  , 0.40625, 0.40625, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.65625, 0.65625, 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.72222222, 0.72222222, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.53572338, 0.43731522, 0.37236295, 0.25615789,\n",
       "            0.23713854, 0.2307776 , 0.18779845, 0.16142089, 0.10083507,\n",
       "            0.09980822, 0.09908604, 0.0987144 , 0.07999708, 0.07815379,\n",
       "            0.07653822, 0.07043323, 0.05673573, 0.05263766, 0.03669814,\n",
       "            0.03663593, 0.02712495, 0.02537782, 0.01638959, 0.0147955 ,\n",
       "            0.01091777])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7190000000000001),\n",
       "                                     1: np.float64(0.28099999999999997)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.1875 , 0.1875 ,\n",
       "            0.25   , 0.25   , 0.375  , 0.375  , 0.40625, 0.40625, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.65625, 0.65625, 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.72222222, 0.72222222, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.54919205, 0.45045224, 0.38580986, 0.26626536,\n",
       "            0.24534197, 0.23688057, 0.19477268, 0.16592644, 0.10483757,\n",
       "            0.10437054, 0.10323397, 0.10236706, 0.08315933, 0.08138597,\n",
       "            0.07947855, 0.07348873, 0.05907942, 0.0547579 , 0.03815283,\n",
       "            0.03789477, 0.02824326, 0.02652448, 0.01698936, 0.01548856,\n",
       "            0.01129323])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7090000000000001),\n",
       "                                     1: np.float64(0.291)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.1875 , 0.1875 ,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.40625, 0.40625, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.65625, 0.65625, 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.72222222, 0.72222222, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.5622567 , 0.46355918, 0.39947564, 0.27612182,\n",
       "            0.25343142, 0.24299222, 0.2019809 , 0.17024921, 0.14069852,\n",
       "            0.1090728 , 0.10769857, 0.10593265, 0.08623765, 0.0845944 ,\n",
       "            0.08248215, 0.07600168, 0.06146044, 0.0568538 , 0.03962713,\n",
       "            0.03918503, 0.02933861, 0.02771768, 0.01760522, 0.01620249,\n",
       "            0.0116737 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6990000000000001),\n",
       "                                     1: np.float64(0.30099999999999993)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.1875 , 0.1875 ,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.40625, 0.40625, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.65625, 0.65625, 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.72222222, 0.72222222, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.57488263, 0.47606484, 0.41259865, 0.28512379,\n",
       "            0.2615195 , 0.24967724, 0.2096786 , 0.17461435, 0.14578816,\n",
       "            0.11376773, 0.11235864, 0.10947695, 0.08946562, 0.08804104,\n",
       "            0.08568487, 0.07842523, 0.06407269, 0.05905743, 0.04120476,\n",
       "            0.04064992, 0.030478  , 0.02905562, 0.01832729, 0.01695601,\n",
       "            0.01211012])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6890000000000001),\n",
       "                                     1: np.float64(0.31099999999999994)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.05555555555555555),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.1875 , 0.1875 ,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.40625, 0.40625, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.65625, 0.65625, 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.72222222, 0.72222222, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.58715577, 0.48896115, 0.42576657, 0.29515501,\n",
       "            0.27016133, 0.2551179 , 0.21666755, 0.17914574, 0.14943487,\n",
       "            0.11893514, 0.11673821, 0.11363433, 0.09287265, 0.09138734,\n",
       "            0.0890738 , 0.08070646, 0.06651563, 0.06126461, 0.04278445,\n",
       "            0.04190763, 0.03161472, 0.03027086, 0.01890916, 0.0177066 ,\n",
       "            0.01249662])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.679),\n",
       "                                     1: np.float64(0.32099999999999995)}),\n",
       "    'fpr': np.float64(0.03125),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.40625, 0.40625, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.65625, 0.65625, 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.72222222, 0.72222222, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.59878938, 0.50059367, 0.43890802, 0.30425113,\n",
       "            0.26158661, 0.26141677, 0.22416784, 0.18352958, 0.15401432,\n",
       "            0.12392389, 0.1213754 , 0.11746932, 0.09617845, 0.09494274,\n",
       "            0.09233102, 0.08324182, 0.06931054, 0.06375484, 0.04438677,\n",
       "            0.0433606 , 0.0329234 , 0.0315734 , 0.01961583, 0.01856889,\n",
       "            0.01293274])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.669),\n",
       "                                     1: np.float64(0.33099999999999996)}),\n",
       "    'fpr': np.float64(0.0625),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.40625, 0.40625, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.65625, 0.65625, 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.72222222, 0.72222222, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.60989776, 0.51287719, 0.45160783, 0.31343602,\n",
       "            0.268825  , 0.26715474, 0.2317949 , 0.18779132, 0.15863696,\n",
       "            0.12906252, 0.12581503, 0.12116885, 0.09953172, 0.0983433 ,\n",
       "            0.09578751, 0.08556676, 0.07186206, 0.06585792, 0.0460569 ,\n",
       "            0.04475861, 0.03405712, 0.03302491, 0.02033508, 0.01937503,\n",
       "            0.01338866])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.659),\n",
       "                                     1: np.float64(0.34099999999999997)}),\n",
       "    'fpr': np.float64(0.0625),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.40625, 0.40625, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.65625, 0.65625, 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.72222222, 0.72222222, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.6209142 , 0.52439253, 0.46418878, 0.32273298,\n",
       "            0.27654304, 0.27311227, 0.23950161, 0.19216824, 0.16318148,\n",
       "            0.13420451, 0.13015357, 0.12508647, 0.10289647, 0.10187359,\n",
       "            0.09931785, 0.08809307, 0.0745795 , 0.06817349, 0.04776525,\n",
       "            0.04620277, 0.03528361, 0.03445383, 0.02105429, 0.0202349 ,\n",
       "            0.01384406])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.649),\n",
       "                                     1: np.float64(0.3509999999999999)}),\n",
       "    'fpr': np.float64(0.09375),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.40625, 0.40625, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.65625, 0.65625, 0.78125, 0.8125 ,\n",
       "            0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.72222222, 0.72222222, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.63176762, 0.53574953, 0.4766548 , 0.33201593,\n",
       "            0.28436582, 0.27905499, 0.2472751 , 0.19657646, 0.16770924,\n",
       "            0.1394748 , 0.13451623, 0.12906885, 0.10630691, 0.10546946,\n",
       "            0.10292546, 0.09063938, 0.07726565, 0.07054457, 0.04949383,\n",
       "            0.04767014, 0.03653881, 0.03592128, 0.02177929, 0.021124  ,\n",
       "            0.01430683])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.639),\n",
       "                                     1: np.float64(0.36099999999999993)}),\n",
       "    'fpr': np.float64(0.09375),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.40625, 0.40625, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.65625, 0.65625,\n",
       "            0.78125, 0.8125 , 0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.64202169, 0.54659479, 0.4887408 , 0.34145205,\n",
       "            0.29224742, 0.2848808 , 0.25503046, 0.20117935, 0.17231629,\n",
       "            0.14489496, 0.13906123, 0.13318776, 0.10985151, 0.10916959,\n",
       "            0.10665487, 0.09862872, 0.09349139, 0.09331072, 0.07994197,\n",
       "            0.07302526, 0.05132694, 0.04919728, 0.03788201, 0.03748746,\n",
       "            0.02254731, 0.02207463, 0.01480623])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.629),\n",
       "                                     1: np.float64(0.37099999999999994)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.40625, 0.40625, 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.65625, 0.65625,\n",
       "            0.78125, 0.8125 , 0.875  , 0.875  , 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.65145229, 0.55672463, 0.50052852, 0.35109708,\n",
       "            0.30027343, 0.29053888, 0.26281609, 0.20610312, 0.17711673,\n",
       "            0.15046543, 0.1438436 , 0.13745183, 0.11354154, 0.11297146,\n",
       "            0.1104765 , 0.10212018, 0.09704341, 0.09623127, 0.08274577,\n",
       "            0.07568653, 0.05332236, 0.05082184, 0.03937648, 0.0391903 ,\n",
       "            0.02338517, 0.02312383, 0.01536011])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.619),\n",
       "                                     1: np.float64(0.38099999999999995)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.4375 , 0.4375 , 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.65625, 0.65625,\n",
       "            0.78125, 0.8125 , 0.84375, 0.84375, 0.96875, 0.96875, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.66124738, 0.5671439 , 0.51233789, 0.36030275,\n",
       "            0.30822665, 0.29630307, 0.27068453, 0.21080498, 0.18184012,\n",
       "            0.15611012, 0.14229372, 0.14164222, 0.11714143, 0.11672002,\n",
       "            0.11440931, 0.10557131, 0.10059589, 0.09900863, 0.08547523,\n",
       "            0.07823486, 0.05519758, 0.05238999, 0.05077644, 0.04084351,\n",
       "            0.02416992, 0.02412357, 0.01587215])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.609),\n",
       "                                     1: np.float64(0.39099999999999996)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.4375 , 0.4375 , 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.625  , 0.625  ,\n",
       "            0.65625, 0.65625, 0.78125, 0.8125 , 0.84375, 0.84375, 0.9375 ,\n",
       "            0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.55555556,\n",
       "            0.55555556, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.670371  , 0.57670178, 0.52367286, 0.36988427,\n",
       "            0.3161192 , 0.30202617, 0.27881782, 0.21578192, 0.18683666,\n",
       "            0.1619596 , 0.14796507, 0.14611798, 0.12099176, 0.12078994,\n",
       "            0.11856123, 0.10930232, 0.10429861, 0.10215686, 0.08968562,\n",
       "            0.08880997, 0.08849956, 0.08107524, 0.05739542, 0.05421065,\n",
       "            0.05272515, 0.04277481, 0.02911141, 0.02528507, 0.01649663])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5990000000000001),\n",
       "                                     1: np.float64(0.4009999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.4375 , 0.4375 , 0.5    ,\n",
       "            0.5    , 0.53125, 0.53125, 0.625  , 0.625  , 0.65625, 0.65625,\n",
       "            0.78125, 0.8125 , 0.84375, 0.84375, 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.55555556, 0.55555556, 0.66666667,\n",
       "            0.66666667, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.67955552, 0.58659339, 0.53508632, 0.37832729,\n",
       "            0.3237592 , 0.30854532, 0.28746202, 0.22017103, 0.19200753,\n",
       "            0.16762887, 0.15362083, 0.12504498, 0.12275703, 0.11279185,\n",
       "            0.10795312, 0.10508512, 0.09307375, 0.09217264, 0.0913592 ,\n",
       "            0.0838135 , 0.05915856, 0.05598808, 0.05456649, 0.04459076,\n",
       "            0.03010758, 0.02639293, 0.01708857])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5890000000000001),\n",
       "                                     1: np.float64(0.4109999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.4375 , 0.4375 , 0.5    ,\n",
       "            0.5    , 0.5625 , 0.5625 , 0.625  , 0.625  , 0.65625, 0.65625,\n",
       "            0.78125, 0.8125 , 0.84375, 0.84375, 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.55555556, 0.55555556, 0.66666667,\n",
       "            0.66666667, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.68891486, 0.5963971 , 0.54630611, 0.3873205 ,\n",
       "            0.33132198, 0.31435734, 0.29593738, 0.22471477, 0.19693163,\n",
       "            0.17356214, 0.15937991, 0.12909162, 0.12711617, 0.11639446,\n",
       "            0.1081897 , 0.10803632, 0.0963942 , 0.09564432, 0.09426411,\n",
       "            0.08646843, 0.06081054, 0.05779632, 0.05638593, 0.04654305,\n",
       "            0.03109908, 0.02752965, 0.01768935])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5790000000000001),\n",
       "                                     1: np.float64(0.42099999999999993)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.1111111111111111),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.4375 , 0.4375 , 0.5    ,\n",
       "            0.5    , 0.5625 , 0.5625 , 0.625  , 0.625  , 0.65625, 0.65625,\n",
       "            0.78125, 0.8125 , 0.84375, 0.84375, 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.55555556, 0.55555556, 0.66666667,\n",
       "            0.66666667, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.69781543, 0.60548737, 0.55722703, 0.3969336 ,\n",
       "            0.33929135, 0.32034243, 0.30408472, 0.22974192, 0.20208841,\n",
       "            0.17962538, 0.16523113, 0.13329623, 0.13142198, 0.12023493,\n",
       "            0.11229357, 0.11124432, 0.09989855, 0.09910696, 0.09743773,\n",
       "            0.0894017 , 0.06258258, 0.05961122, 0.05840365, 0.04856267,\n",
       "            0.03213238, 0.02874429, 0.01830486])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5690000000000001),\n",
       "                                     1: np.float64(0.43099999999999994)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.34375, 0.34375, 0.4375 , 0.4375 , 0.5    ,\n",
       "            0.5    , 0.5625 , 0.5625 , 0.625  , 0.625  , 0.65625, 0.65625,\n",
       "            0.78125, 0.8125 , 0.84375, 0.84375, 0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.55555556, 0.55555556, 0.66666667,\n",
       "            0.66666667, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.70542689, 0.61446376, 0.56780214, 0.4061311 ,\n",
       "            0.34736249, 0.32661333, 0.31281784, 0.23537634, 0.20746089,\n",
       "            0.18581228, 0.17167818, 0.1376539 , 0.13621108, 0.12449098,\n",
       "            0.11659294, 0.1148968 , 0.10351586, 0.10293148, 0.10061085,\n",
       "            0.09247351, 0.06444789, 0.06152218, 0.06057679, 0.05068469,\n",
       "            0.03332427, 0.03008498, 0.01901461])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.559),\n",
       "                                     1: np.float64(0.44099999999999995)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.28125, 0.28125, 0.34375, 0.34375, 0.4375 ,\n",
       "            0.4375 , 0.5    , 0.5    , 0.5625 , 0.5625 , 0.625  , 0.625  ,\n",
       "            0.65625, 0.65625, 0.78125, 0.8125 , 0.84375, 0.84375, 0.9375 ,\n",
       "            0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.55555556,\n",
       "            0.55555556, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.71401685, 0.62352302, 0.57863469, 0.41504162,\n",
       "            0.35525267, 0.33264468, 0.32162118, 0.28629696, 0.24268376,\n",
       "            0.24023085, 0.21278456, 0.19208931, 0.17800495, 0.1420723 ,\n",
       "            0.14064849, 0.12843287, 0.1209719 , 0.11818195, 0.10724599,\n",
       "            0.10676323, 0.10377758, 0.09544766, 0.06628318, 0.06348638,\n",
       "            0.06264528, 0.05288005, 0.03442732, 0.03137563, 0.01968036])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.549),\n",
       "                                     1: np.float64(0.45099999999999996)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 ,\n",
       "            0.4375 , 0.5    , 0.5    , 0.5625 , 0.5625 , 0.625  , 0.625  ,\n",
       "            0.65625, 0.65625, 0.78125, 0.8125 , 0.84375, 0.84375, 0.9375 ,\n",
       "            0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.55555556,\n",
       "            0.55555556, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.72147146, 0.63174064, 0.58883164, 0.42430818,\n",
       "            0.36345816, 0.33834557, 0.33001235, 0.29272977, 0.24662585,\n",
       "            0.2455802 , 0.21806427, 0.19837777, 0.18445689, 0.14656216,\n",
       "            0.14490631, 0.13265175, 0.12540721, 0.12171351, 0.11104365,\n",
       "            0.11060275, 0.10708873, 0.09865668, 0.06819156, 0.06538125,\n",
       "            0.06494513, 0.05515469, 0.03562297, 0.03276456, 0.02038321])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5390000000000001),\n",
       "                                     1: np.float64(0.4609999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 ,\n",
       "            0.4375 , 0.5    , 0.5    , 0.5625 , 0.5625 , 0.59375, 0.59375,\n",
       "            0.65625, 0.65625, 0.78125, 0.8125 , 0.84375, 0.84375, 0.9375 ,\n",
       "            0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.55555556,\n",
       "            0.55555556, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.72872503, 0.63974279, 0.59746666, 0.43483869,\n",
       "            0.3714555 , 0.34400913, 0.33835799, 0.29993725, 0.25338063,\n",
       "            0.25197743, 0.22393916, 0.20492552, 0.19014992, 0.15067181,\n",
       "            0.14901188, 0.13719596, 0.13021408, 0.12577096, 0.12207272,\n",
       "            0.11496859, 0.11038401, 0.10186911, 0.07006423, 0.06739487,\n",
       "            0.06723937, 0.05758873, 0.03676747, 0.03424541, 0.02109945])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5290000000000001),\n",
       "                                     1: np.float64(0.4709999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 ,\n",
       "            0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 ,\n",
       "            0.59375, 0.59375, 0.65625, 0.65625, 0.8125 , 0.84375, 0.84375,\n",
       "            0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.55555556,\n",
       "            0.55555556, 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.73602195, 0.6475717 , 0.60503601, 0.44291443,\n",
       "            0.37942208, 0.35086176, 0.34775572, 0.30651196, 0.26001498,\n",
       "            0.25678899, 0.2298175 , 0.21145266, 0.19593288, 0.15594162,\n",
       "            0.15556493, 0.15410799, 0.15355596, 0.14161931, 0.13491383,\n",
       "            0.12957096, 0.12599065, 0.11930178, 0.11391085, 0.10536633,\n",
       "            0.06973692, 0.06966814, 0.06011832, 0.03814685, 0.03582331,\n",
       "            0.02194013])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5190000000000001),\n",
       "                                     1: np.float64(0.4809999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 ,\n",
       "            0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 ,\n",
       "            0.59375, 0.59375, 0.65625, 0.65625, 0.8125 , 0.84375, 0.84375,\n",
       "            0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.74375148, 0.6558298 , 0.61274139, 0.45232746,\n",
       "            0.3873668 , 0.35708123, 0.35664362, 0.31424965, 0.26703271,\n",
       "            0.26274036, 0.23550716, 0.21844474, 0.20173621, 0.18901363,\n",
       "            0.16098464, 0.15939707, 0.15806222, 0.14633915, 0.1401806 ,\n",
       "            0.13355595, 0.12975587, 0.12371367, 0.11763461, 0.10874955,\n",
       "            0.07211228, 0.07196723, 0.0627868 , 0.03946786, 0.03736934,\n",
       "            0.02274521])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5090000000000001),\n",
       "                                     1: np.float64(0.49099999999999994)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.25   , 0.25   ,\n",
       "            0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 , 0.4375 , 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 , 0.59375, 0.59375,\n",
       "            0.65625, 0.65625, 0.8125 , 0.84375, 0.84375, 0.9375 , 0.9375 ,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.75097578, 0.66362412, 0.62042857, 0.46143303,\n",
       "            0.36588789, 0.32160597, 0.27394399, 0.26854901, 0.24146296,\n",
       "            0.22538283, 0.20768272, 0.19433295, 0.16649778, 0.16510045,\n",
       "            0.16264404, 0.15114909, 0.14514538, 0.13772501, 0.13366043,\n",
       "            0.12836155, 0.12137273, 0.11229902, 0.07465081, 0.07433911,\n",
       "            0.06556361, 0.04086334, 0.03903365, 0.0236053 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4990000000000001),\n",
       "                                     1: np.float64(0.5009999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.25   , 0.25   ,\n",
       "            0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 , 0.4375 , 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 , 0.59375, 0.59375,\n",
       "            0.65625, 0.65625, 0.8125 , 0.84375, 0.84375, 0.9375 , 0.9375 ,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.75795886, 0.67124645, 0.62802418, 0.47057547,\n",
       "            0.37522273, 0.32906762, 0.2810103 , 0.27454501, 0.24753398,\n",
       "            0.23245878, 0.21375975, 0.19983269, 0.17220879, 0.17089667,\n",
       "            0.16738388, 0.15612729, 0.14978537, 0.14205548, 0.1377007 ,\n",
       "            0.13316524, 0.12523551, 0.11596454, 0.07729022, 0.07679444,\n",
       "            0.06846989, 0.04233139, 0.04077788, 0.02450996])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4890000000000001),\n",
       "                                     1: np.float64(0.5109999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.25   , 0.25   ,\n",
       "            0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 , 0.4375 , 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 , 0.59375, 0.59375,\n",
       "            0.65625, 0.65625, 0.8125 , 0.84375, 0.84375, 0.9375 , 0.9375 ,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.76478058, 0.67867226, 0.63553773, 0.47963746,\n",
       "            0.38471139, 0.33663247, 0.28817597, 0.28063843, 0.25378448,\n",
       "            0.23970059, 0.21999971, 0.20547302, 0.17813066, 0.17627316,\n",
       "            0.17226605, 0.16127817, 0.15455879, 0.14657081, 0.14188804,\n",
       "            0.13817376, 0.12924576, 0.11978   , 0.08004475, 0.07937684,\n",
       "            0.07152838, 0.04387601, 0.04261485, 0.0254666 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4790000000000001),\n",
       "                                     1: np.float64(0.5209999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.25   , 0.25   ,\n",
       "            0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 , 0.4375 , 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 , 0.59375, 0.59375,\n",
       "            0.65625, 0.65625, 0.8125 , 0.84375, 0.84375, 0.9375 , 0.9375 ,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.77147925, 0.68592889, 0.64299287, 0.48860297,\n",
       "            0.39436845, 0.34431257, 0.29544246, 0.28682442, 0.26020984,\n",
       "            0.2471185 , 0.22639251, 0.21127097, 0.18426918, 0.18189839,\n",
       "            0.17730641, 0.16660757, 0.15947082, 0.15127416, 0.14624077,\n",
       "            0.14337397, 0.13342347, 0.12376152, 0.08291838, 0.0820971 ,\n",
       "            0.07473629, 0.04550146, 0.04454409, 0.02647561])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4690000000000001),\n",
       "                                     1: np.float64(0.5309999999999999)}),\n",
       "    'fpr': np.float64(0.125),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.25   , 0.25   ,\n",
       "            0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 , 0.4375 , 0.46875,\n",
       "            0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 , 0.59375, 0.59375,\n",
       "            0.65625, 0.65625, 0.8125 , 0.84375, 0.84375, 0.9375 , 0.9375 ,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.61111111,\n",
       "            0.61111111, 0.66666667, 0.66666667, 0.72222222, 0.72222222,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.77772317, 0.69288747, 0.65063409, 0.49856553,\n",
       "            0.4036614 , 0.35170922, 0.30294171, 0.29360346, 0.26663528,\n",
       "            0.25448172, 0.23299593, 0.21718932, 0.19035406, 0.18724201,\n",
       "            0.18235676, 0.1720976 , 0.16442174, 0.15610515, 0.15055124,\n",
       "            0.14870326, 0.13753215, 0.12773886, 0.08587361, 0.08466845,\n",
       "            0.07804679, 0.04710621, 0.04653304, 0.02746833])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4590000000000001),\n",
       "                                     1: np.float64(0.5409999999999999)}),\n",
       "    'fpr': np.float64(0.15625),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 ,\n",
       "            0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 ,\n",
       "            0.59375, 0.59375, 0.65625, 0.65625, 0.8125 , 0.84375, 0.84375,\n",
       "            0.9375 , 0.9375 , 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.72222222, 0.72222222, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.78444846, 0.69999227, 0.65799961, 0.59599387,\n",
       "            0.50796574, 0.5071484 , 0.41379855, 0.35984461, 0.31024021,\n",
       "            0.29989717, 0.27335279, 0.26221985, 0.2394983 , 0.22324902,\n",
       "            0.1968904 , 0.19338037, 0.18763925, 0.17772647, 0.16952971,\n",
       "            0.16116588, 0.15519452, 0.15421435, 0.14208383, 0.13201607,\n",
       "            0.08891317, 0.08770461, 0.08152254, 0.04888111, 0.04861324,\n",
       "            0.02857242])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.44900000000000007),\n",
       "                                     1: np.float64(0.5509999999999999)}),\n",
       "    'fpr': np.float64(0.15625),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 ,\n",
       "            0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 ,\n",
       "            0.65625, 0.65625, 0.8125 , 0.84375, 0.84375, 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.79048663, 0.70697286, 0.66555264, 0.60286505,\n",
       "            0.51799815, 0.51614622, 0.4237701 , 0.36739055, 0.31782934,\n",
       "            0.30681101, 0.28030369, 0.27012312, 0.24673627, 0.22941337,\n",
       "            0.20335119, 0.1993543 , 0.19322194, 0.18360726, 0.17485229,\n",
       "            0.16010691, 0.14657001, 0.13645097, 0.09174535, 0.09064793,\n",
       "            0.08524832, 0.06068058, 0.05083095, 0.02970226])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.43900000000000006),\n",
       "                                     1: np.float64(0.5609999999999999)}),\n",
       "    'fpr': np.float64(0.15625),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 ,\n",
       "            0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 ,\n",
       "            0.65625, 0.65625, 0.8125 , 0.84375, 0.84375, 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.79593102, 0.71220719, 0.67285171, 0.61010619,\n",
       "            0.52705328, 0.52599462, 0.43333424, 0.37519057, 0.32570466,\n",
       "            0.31434148, 0.28719613, 0.27796486, 0.25373028, 0.23597239,\n",
       "            0.21013545, 0.20509737, 0.19873258, 0.18987504, 0.18018572,\n",
       "            0.16625323, 0.15119442, 0.14092463, 0.09446698, 0.09364875,\n",
       "            0.08917398, 0.06296023, 0.05320415, 0.0309059 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.42900000000000005),\n",
       "                                     1: np.float64(0.571)}),\n",
       "    'fpr': np.float64(0.15625),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 ,\n",
       "            0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 ,\n",
       "            0.65625, 0.65625, 0.8125 , 0.84375, 0.84375, 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.80272774, 0.71778655, 0.67971488, 0.61838251,\n",
       "            0.53757525, 0.5350205 , 0.44397602, 0.38382874, 0.33333698,\n",
       "            0.32101   , 0.29447826, 0.28606555, 0.26091114, 0.24216828,\n",
       "            0.21772678, 0.21164907, 0.20419279, 0.19586737, 0.18563693,\n",
       "            0.17260433, 0.15599721, 0.14533304, 0.09749625, 0.09731076,\n",
       "            0.09328498, 0.06551602, 0.05558642, 0.03219887])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.41900000000000004),\n",
       "                                     1: np.float64(0.581)}),\n",
       "    'fpr': np.float64(0.1875),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 ,\n",
       "            0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.5625 , 0.5625 ,\n",
       "            0.65625, 0.65625, 0.8125 , 0.84375, 0.84375, 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.8079121 , 0.7230019 , 0.68710242, 0.62465376,\n",
       "            0.54758498, 0.54369595, 0.45426855, 0.39193798, 0.34148662,\n",
       "            0.32881767, 0.30192236, 0.29468472, 0.26867117, 0.24907086,\n",
       "            0.22471179, 0.21818219, 0.21061395, 0.20245362, 0.19144684,\n",
       "            0.17919191, 0.16101163, 0.15032158, 0.10059561, 0.10055353,\n",
       "            0.0976192 , 0.06788709, 0.05816326, 0.03352695])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.40900000000000014),\n",
       "                                     1: np.float64(0.5909999999999999)}),\n",
       "    'fpr': np.float64(0.1875),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375, 0.4375 ,\n",
       "            0.4375 , 0.46875, 0.46875, 0.53125, 0.53125, 0.5625 , 0.5625 ,\n",
       "            0.65625, 0.65625, 0.78125, 0.8125 , 0.84375, 0.84375, 0.90625,\n",
       "            0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.81377782, 0.72849309, 0.69457858, 0.63228478,\n",
       "            0.55726832, 0.55385391, 0.46471203, 0.40042174, 0.34964886,\n",
       "            0.33697086, 0.30973983, 0.30311406, 0.27629472, 0.25603389,\n",
       "            0.23246189, 0.2248056 , 0.20997538, 0.20940284, 0.19728188,\n",
       "            0.18626461, 0.16624015, 0.15536607, 0.1064772 , 0.10435792,\n",
       "            0.10382381, 0.10214784, 0.07060821, 0.06089363, 0.03491055])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.39900000000000013),\n",
       "                                     1: np.float64(0.6009999999999999)}),\n",
       "    'fpr': np.float64(0.1875),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  , 0.375  , 0.4375 ,\n",
       "            0.4375 , 0.46875, 0.46875, 0.53125, 0.53125, 0.5625 , 0.5625 ,\n",
       "            0.65625, 0.65625, 0.78125, 0.8125 , 0.84375, 0.84375, 0.90625,\n",
       "            0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.81887277, 0.73361955, 0.70181847, 0.63868392,\n",
       "            0.56677061, 0.56364363, 0.47519824, 0.40839131, 0.35778927,\n",
       "            0.34556196, 0.31191417, 0.31164464, 0.28447831, 0.26287665,\n",
       "            0.23990738, 0.23131889, 0.21784113, 0.21628322, 0.20316611,\n",
       "            0.19369944, 0.17127437, 0.16044968, 0.11050131, 0.10816132,\n",
       "            0.10700514, 0.10695523, 0.07325743, 0.06374099, 0.03634263])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3890000000000001),\n",
       "                                     1: np.float64(0.6109999999999999)}),\n",
       "    'fpr': np.float64(0.1875),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  , 0.375  , 0.4375 ,\n",
       "            0.4375 , 0.46875, 0.46875, 0.53125, 0.53125, 0.5625 , 0.5625 ,\n",
       "            0.65625, 0.65625, 0.78125, 0.8125 , 0.8125 , 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.82414896, 0.73879151, 0.70935544, 0.6454908 ,\n",
       "            0.57654098, 0.57337612, 0.48556872, 0.4168027 , 0.36639967,\n",
       "            0.35411032, 0.32273018, 0.32059304, 0.29279128, 0.27048155,\n",
       "            0.24792916, 0.23829479, 0.22621714, 0.22393869, 0.2094622 ,\n",
       "            0.20133876, 0.17701637, 0.16606781, 0.11474561, 0.11210483,\n",
       "            0.11209183, 0.07616828, 0.06680842, 0.03788563])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3790000000000001),\n",
       "                                     1: np.float64(0.6209999999999999)}),\n",
       "    'fpr': np.float64(0.21875),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  , 0.375  , 0.4375 ,\n",
       "            0.4375 , 0.46875, 0.46875, 0.53125, 0.53125, 0.5625 , 0.5625 ,\n",
       "            0.65625, 0.65625, 0.78125, 0.78125, 0.8125 , 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.82944441, 0.74399184, 0.716218  , 0.65245914,\n",
       "            0.58700504, 0.58147769, 0.49632972, 0.42584498, 0.37517397,\n",
       "            0.36188812, 0.33328864, 0.32986324, 0.30113995, 0.27813396,\n",
       "            0.25663228, 0.24588283, 0.23481882, 0.23142996, 0.21598522,\n",
       "            0.20887619, 0.182839  , 0.17161675, 0.11905554, 0.11736336,\n",
       "            0.11622288, 0.07922918, 0.06991856, 0.03956774])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3690000000000001),\n",
       "                                     1: np.float64(0.6309999999999999)}),\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  , 0.375  , 0.4375 ,\n",
       "            0.4375 , 0.46875, 0.46875, 0.53125, 0.53125, 0.5625 , 0.5625 ,\n",
       "            0.65625, 0.65625, 0.78125, 0.78125, 0.8125 , 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.8346421 , 0.74912926, 0.72362835, 0.65917314,\n",
       "            0.59700954, 0.59063178, 0.50706668, 0.43457476, 0.38394998,\n",
       "            0.37047905, 0.34245792, 0.33917922, 0.30984833, 0.28609669,\n",
       "            0.26534101, 0.25337792, 0.24308907, 0.23962169, 0.22261588,\n",
       "            0.21711551, 0.18899804, 0.17763552, 0.12363926, 0.12303266,\n",
       "            0.12057872, 0.08247463, 0.07330202, 0.04129908])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3590000000000001),\n",
       "                                     1: np.float64(0.6409999999999999)}),\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.15625, 0.15625,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  , 0.375  , 0.4375 ,\n",
       "            0.4375 , 0.46875, 0.46875, 0.53125, 0.53125, 0.5625 , 0.5625 ,\n",
       "            0.65625, 0.65625, 0.75   , 0.75   , 0.78125, 0.8125 , 0.90625,\n",
       "            0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.11111111, 0.11111111, 0.16666667,\n",
       "            0.16666667, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.38888889, 0.38888889, 0.44444444, 0.44444444, 0.5       ,\n",
       "            0.5       , 0.61111111, 0.61111111, 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.8402476 , 0.75440136, 0.73053103, 0.66689187,\n",
       "            0.60789557, 0.59912323, 0.51855394, 0.44495764, 0.39269897,\n",
       "            0.37825095, 0.35089006, 0.34874151, 0.31788405, 0.29443932,\n",
       "            0.27455844, 0.26191655, 0.25040263, 0.24767283, 0.22959796,\n",
       "            0.22492258, 0.19596108, 0.18390529, 0.1455474 , 0.12900532,\n",
       "            0.12855329, 0.12501022, 0.0860043 , 0.0769501 , 0.04332018])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3490000000000001),\n",
       "                                     1: np.float64(0.6509999999999999)}),\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  ,\n",
       "            0.15625, 0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  ,\n",
       "            0.375  , 0.4375 , 0.4375 , 0.46875, 0.46875, 0.53125, 0.53125,\n",
       "            0.5625 , 0.5625 , 0.65625, 0.65625, 0.75   , 0.75   , 0.78125,\n",
       "            0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.16666667, 0.16666667, 0.22222222, 0.22222222,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.5       , 0.5       , 0.61111111, 0.61111111,\n",
       "            0.66666667, 0.66666667, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.84582041, 0.76911549, 0.76138317, 0.75952114,\n",
       "            0.73733164, 0.67455582, 0.61880477, 0.60769831, 0.52989532,\n",
       "            0.45528441, 0.40160429, 0.38675436, 0.35988756, 0.35882005,\n",
       "            0.32683198, 0.30263885, 0.28438144, 0.27045407, 0.25786677,\n",
       "            0.25605411, 0.23670813, 0.23363617, 0.20295109, 0.19025859,\n",
       "            0.15161929, 0.13552371, 0.13342096, 0.1302963 , 0.08992589,\n",
       "            0.0807301 , 0.04546116])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3390000000000001),\n",
       "                                     1: np.float64(0.6609999999999999)}),\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  ,\n",
       "            0.15625, 0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  ,\n",
       "            0.375  , 0.4375 , 0.4375 , 0.46875, 0.46875, 0.53125, 0.53125,\n",
       "            0.5625 , 0.5625 , 0.65625, 0.65625, 0.75   , 0.75   , 0.78125,\n",
       "            0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.16666667, 0.16666667, 0.22222222, 0.22222222,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.5       , 0.5       , 0.61111111, 0.61111111,\n",
       "            0.66666667, 0.66666667, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.85042683, 0.77461053, 0.76878362, 0.76444113,\n",
       "            0.7448168 , 0.68080041, 0.62825487, 0.61862344, 0.54087709,\n",
       "            0.4643143 , 0.41113826, 0.39778982, 0.36974168, 0.36869193,\n",
       "            0.33705817, 0.31115387, 0.29356091, 0.27812244, 0.2654611 ,\n",
       "            0.26524264, 0.24384366, 0.24303641, 0.20970299, 0.19702022,\n",
       "            0.15807173, 0.14253351, 0.13896584, 0.1356224 , 0.09362628,\n",
       "            0.08479523, 0.04752814])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.32900000000000007),\n",
       "                                     1: np.float64(0.6709999999999999)}),\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.2222222222222222),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  ,\n",
       "            0.15625, 0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  ,\n",
       "            0.375  , 0.4375 , 0.4375 , 0.46875, 0.46875, 0.5    , 0.5    ,\n",
       "            0.53125, 0.53125, 0.65625, 0.65625, 0.75   , 0.75   , 0.78125,\n",
       "            0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.16666667, 0.16666667, 0.22222222, 0.22222222,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.5       , 0.5       , 0.61111111, 0.61111111,\n",
       "            0.66666667, 0.66666667, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.85543704, 0.78036786, 0.77578304, 0.76966847,\n",
       "            0.75190002, 0.687842  , 0.63867585, 0.627919  , 0.55131382,\n",
       "            0.47420105, 0.42081923, 0.40741739, 0.37906094, 0.37891091,\n",
       "            0.34652784, 0.32028235, 0.30379655, 0.2870969 , 0.28368349,\n",
       "            0.27449148, 0.27359076, 0.25198306, 0.21703585, 0.20397369,\n",
       "            0.16475509, 0.14945508, 0.14443451, 0.1411145 , 0.09766763,\n",
       "            0.08896859, 0.04977504])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.31900000000000006),\n",
       "                                     1: np.float64(0.6809999999999999)}),\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.2777777777777778),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  ,\n",
       "            0.15625, 0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375,\n",
       "            0.34375, 0.4375 , 0.4375 , 0.46875, 0.46875, 0.5    , 0.5    ,\n",
       "            0.53125, 0.53125, 0.65625, 0.65625, 0.75   , 0.75   , 0.78125,\n",
       "            0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.16666667, 0.16666667, 0.22222222, 0.22222222,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.5       , 0.5       , 0.61111111, 0.61111111,\n",
       "            0.66666667, 0.66666667, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.86046147, 0.7861982 , 0.78229964, 0.77507969,\n",
       "            0.75867081, 0.69543724, 0.64969315, 0.63631622, 0.56043538,\n",
       "            0.48551224, 0.43072897, 0.41688137, 0.4028297 , 0.38970008,\n",
       "            0.35585758, 0.3300089 , 0.31481547, 0.29690023, 0.29459527,\n",
       "            0.28413453, 0.28241266, 0.26149394, 0.22525089, 0.21137789,\n",
       "            0.17190718, 0.15687464, 0.15027251, 0.14693282, 0.10222201,\n",
       "            0.09347974, 0.05238829])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.30900000000000005),\n",
       "                                     1: np.float64(0.691)}),\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.2777777777777778),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  ,\n",
       "            0.15625, 0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375,\n",
       "            0.34375, 0.4375 , 0.4375 , 0.46875, 0.46875, 0.5    , 0.5    ,\n",
       "            0.53125, 0.53125, 0.65625, 0.65625, 0.75   , 0.75   , 0.78125,\n",
       "            0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.16666667, 0.16666667, 0.22222222, 0.22222222,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.5       , 0.5       , 0.55555556, 0.55555556,\n",
       "            0.66666667, 0.66666667, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.86519241, 0.79163851, 0.78958424, 0.78002181,\n",
       "            0.76606944, 0.70189222, 0.65950583, 0.64674351, 0.57037553,\n",
       "            0.49486585, 0.44048603, 0.42790035, 0.41661692, 0.40022251,\n",
       "            0.36668241, 0.33917767, 0.32522948, 0.32134726, 0.30608199,\n",
       "            0.29419439, 0.29059107, 0.27155675, 0.2327732 , 0.21889306,\n",
       "            0.17934962, 0.16498758, 0.15637956, 0.15334557, 0.1066545 ,\n",
       "            0.09825922, 0.05483559])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.29900000000000015),\n",
       "                                     1: np.float64(0.7009999999999998)}),\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  ,\n",
       "            0.15625, 0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375,\n",
       "            0.34375, 0.4375 , 0.4375 , 0.46875, 0.46875, 0.5    , 0.5    ,\n",
       "            0.53125, 0.53125, 0.65625, 0.65625, 0.75   , 0.75   , 0.78125,\n",
       "            0.8125 , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.16666667, 0.16666667, 0.22222222, 0.22222222,\n",
       "            0.33333333, 0.33333333, 0.38888889, 0.38888889, 0.44444444,\n",
       "            0.44444444, 0.5       , 0.5       , 0.55555556, 0.55555556,\n",
       "            0.66666667, 0.66666667, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.87029207, 0.79720702, 0.79599653, 0.78507643,\n",
       "            0.77272271, 0.7097502 , 0.67059337, 0.65536132, 0.57955037,\n",
       "            0.50648505, 0.45061074, 0.43740519, 0.42863553, 0.4116549 ,\n",
       "            0.37663678, 0.34928773, 0.33703447, 0.33197992, 0.31814695,\n",
       "            0.30455719, 0.29970057, 0.28195925, 0.24169681, 0.22682389,\n",
       "            0.18721284, 0.17351625, 0.16267577, 0.15983411, 0.11183651,\n",
       "            0.10334565, 0.05779879])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.28900000000000015),\n",
       "                                     1: np.float64(0.7109999999999999)}),\n",
       "    'fpr': np.float64(0.25),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.4375 , 0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.53125,\n",
       "            0.53125, 0.65625, 0.65625, 0.75   , 0.75   , 0.78125, 0.8125 ,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.11111111, 0.11111111,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.5       , 0.5       , 0.55555556, 0.55555556, 0.66666667,\n",
       "            0.66666667, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.87473288, 0.80310087, 0.79016722, 0.78021649,\n",
       "            0.71590276, 0.68067669, 0.66538917, 0.59022075, 0.51634274,\n",
       "            0.46108865, 0.44880966, 0.44310399, 0.42281581, 0.38797556,\n",
       "            0.35976404, 0.34813525, 0.34292563, 0.3303362 , 0.3157621 ,\n",
       "            0.3090375 , 0.29278758, 0.25037797, 0.2355011 , 0.19559069,\n",
       "            0.18248237, 0.16993456, 0.16653741, 0.11669239, 0.10885731,\n",
       "            0.06062785])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.27900000000000014),\n",
       "                                     1: np.float64(0.7209999999999999)}),\n",
       "    'fpr': np.float64(0.28125),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.4375 , 0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.53125,\n",
       "            0.53125, 0.65625, 0.65625, 0.75   , 0.75   , 0.78125, 0.8125 ,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.11111111, 0.11111111,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.5       , 0.5       , 0.55555556, 0.55555556, 0.66666667,\n",
       "            0.66666667, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.87943197, 0.80939449, 0.79585693, 0.78726973,\n",
       "            0.72374692, 0.6914366 , 0.67447564, 0.59971322, 0.52883134,\n",
       "            0.47154176, 0.46044627, 0.45571685, 0.43462939, 0.3986031 ,\n",
       "            0.37042402, 0.36057076, 0.35486385, 0.3430658 , 0.32704173,\n",
       "            0.31906151, 0.30510404, 0.26029877, 0.24456322, 0.20463928,\n",
       "            0.19206893, 0.17707538, 0.1745181 , 0.12280449, 0.11479298,\n",
       "            0.06416518])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.26900000000000013),\n",
       "                                     1: np.float64(0.7309999999999999)}),\n",
       "    'fpr': np.float64(0.28125),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.4375 , 0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.53125,\n",
       "            0.53125, 0.65625, 0.65625, 0.75   , 0.75   , 0.78125, 0.8125 ,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.11111111, 0.11111111,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.5       , 0.5       , 0.55555556, 0.55555556, 0.66666667,\n",
       "            0.66666667, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.88379069, 0.81582279, 0.80132015, 0.79457486,\n",
       "            0.73068753, 0.70176707, 0.68483169, 0.61023638, 0.54039793,\n",
       "            0.48308727, 0.47321211, 0.47039115, 0.44680611, 0.41052678,\n",
       "            0.38221156, 0.37336567, 0.36713163, 0.35680545, 0.33976055,\n",
       "            0.32949986, 0.31778503, 0.27054096, 0.25432497, 0.21419832,\n",
       "            0.20234476, 0.18519435, 0.18258051, 0.12889412, 0.12125559,\n",
       "            0.0676957 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2590000000000001),\n",
       "                                     1: np.float64(0.7409999999999999)}),\n",
       "    'fpr': np.float64(0.28125),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.4375 , 0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.53125,\n",
       "            0.53125, 0.65625, 0.65625, 0.75   , 0.75   , 0.78125, 0.8125 ,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.11111111, 0.11111111,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.5       , 0.5       , 0.55555556, 0.55555556, 0.66666667,\n",
       "            0.66666667, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.88814488, 0.8218788 , 0.80624369, 0.80115215,\n",
       "            0.73767513, 0.71206194, 0.69400129, 0.62043064, 0.55163669,\n",
       "            0.49402694, 0.48482816, 0.48461713, 0.45877819, 0.42267568,\n",
       "            0.39369372, 0.38652932, 0.37901149, 0.3712276 , 0.35196926,\n",
       "            0.33997706, 0.33038062, 0.28046574, 0.26354827, 0.22426026,\n",
       "            0.21344297, 0.19317685, 0.19118733, 0.13541469, 0.12790018,\n",
       "            0.07160424])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2490000000000001),\n",
       "                                     1: np.float64(0.7509999999999999)}),\n",
       "    'fpr': np.float64(0.3125),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.34375, 0.34375, 0.4375 , 0.4375 ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.53125, 0.53125, 0.65625,\n",
       "            0.65625, 0.75   , 0.75   , 0.78125, 0.8125 , 0.90625, 0.90625,\n",
       "            1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.11111111, 0.11111111,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.55555556, 0.55555556, 0.66666667, 0.66666667, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.89280163, 0.82864392, 0.81211177, 0.808847  ,\n",
       "            0.74555393, 0.72260202, 0.70450799, 0.63076532, 0.56451212,\n",
       "            0.49905907, 0.47160611, 0.43451956, 0.40574826, 0.39978362,\n",
       "            0.39243052, 0.38530721, 0.36506498, 0.35111677, 0.34454727,\n",
       "            0.29182835, 0.27428245, 0.23492597, 0.22474848, 0.20172183,\n",
       "            0.20041781, 0.14237696, 0.13509028, 0.07566728])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2390000000000001),\n",
       "                                     1: np.float64(0.7609999999999999)}),\n",
       "    'fpr': np.float64(0.34375),\n",
       "    'tpr': np.float64(0.3888888888888889),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.09375, 0.09375, 0.125  ,\n",
       "            0.125  , 0.15625, 0.15625, 0.25   , 0.25   , 0.34375, 0.34375,\n",
       "            0.4375 , 0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.53125,\n",
       "            0.53125, 0.65625, 0.65625, 0.75   , 0.75   , 0.78125, 0.8125 ,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.11111111, 0.11111111, 0.16666667, 0.16666667, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.44444444, 0.44444444,\n",
       "            0.5       , 0.5       , 0.55555556, 0.55555556, 0.66666667,\n",
       "            0.66666667, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.89673206, 0.83455027, 0.82948077, 0.81822109,\n",
       "            0.81753669, 0.81576656, 0.75222792, 0.73260212, 0.71434449,\n",
       "            0.64184217, 0.5761694 , 0.51482981, 0.48448863, 0.44820364,\n",
       "            0.41869829, 0.41432551, 0.40574895, 0.40092826, 0.3794242 ,\n",
       "            0.36292478, 0.35937641, 0.30316579, 0.28535193, 0.24652005,\n",
       "            0.23723237, 0.21140087, 0.21077214, 0.15010813, 0.14307116,\n",
       "            0.08031563])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2290000000000001),\n",
       "                                     1: np.float64(0.7709999999999999)}),\n",
       "    'fpr': np.float64(0.34375),\n",
       "    'tpr': np.float64(0.3888888888888889),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.09375, 0.09375, 0.125  ,\n",
       "            0.125  , 0.15625, 0.15625, 0.25   , 0.25   , 0.34375, 0.34375,\n",
       "            0.4375 , 0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.53125,\n",
       "            0.53125, 0.65625, 0.65625, 0.75   , 0.75   , 0.78125, 0.90625,\n",
       "            0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.11111111, 0.11111111, 0.16666667, 0.16666667, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.44444444, 0.44444444,\n",
       "            0.5       , 0.5       , 0.55555556, 0.55555556, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.90111588, 0.84081511, 0.83491256, 0.82427254,\n",
       "            0.82324003, 0.8229729 , 0.75996262, 0.74316382, 0.72446825,\n",
       "            0.65250606, 0.58935503, 0.52979653, 0.49799537, 0.46105756,\n",
       "            0.43166291, 0.42880924, 0.41979242, 0.41652448, 0.37583563,\n",
       "            0.37496777, 0.37459176, 0.315439  , 0.29680536, 0.25832729,\n",
       "            0.25006375, 0.22111095, 0.15814675, 0.15131621, 0.08512734])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.21900000000000008),\n",
       "                                     1: np.float64(0.7809999999999999)}),\n",
       "    'fpr': np.float64(0.375),\n",
       "    'tpr': np.float64(0.4444444444444444),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.34375, 0.34375, 0.4375 , 0.4375 ,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.65625, 0.65625, 0.75   ,\n",
       "            0.75   , 0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.55555556, 0.55555556, 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.90509295, 0.8466971 , 0.84006036, 0.83004107,\n",
       "            0.76714842, 0.75312775, 0.73447279, 0.6638944 , 0.60195221,\n",
       "            0.54238853, 0.51158359, 0.47541134, 0.44565992, 0.44390631,\n",
       "            0.43426711, 0.43349358, 0.39110872, 0.32843643, 0.30928048,\n",
       "            0.27148962, 0.26453374, 0.23284918, 0.16715938, 0.1606239 ,\n",
       "            0.09069792])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.20900000000000007),\n",
       "                                     1: np.float64(0.7909999999999999)}),\n",
       "    'fpr': np.float64(0.40625),\n",
       "    'tpr': np.float64(0.4444444444444444),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.4375 , 0.4375 , 0.5    , 0.5    , 0.65625, 0.65625, 0.75   ,\n",
       "            0.75   , 0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.5       , 0.5       , 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.9091293 , 0.85256951, 0.84539593, 0.83642594,\n",
       "            0.77508323, 0.76340693, 0.7450187 , 0.67483016, 0.61592873,\n",
       "            0.56146775, 0.55605393, 0.5557392 , 0.52587546, 0.48935594,\n",
       "            0.46024005, 0.45050778, 0.4083196 , 0.34239341, 0.32231756,\n",
       "            0.28527797, 0.27917313, 0.24541803, 0.17694778, 0.17051396,\n",
       "            0.09669057])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.19900000000000018),\n",
       "                                     1: np.float64(0.8009999999999998)}),\n",
       "    'fpr': np.float64(0.4375),\n",
       "    'tpr': np.float64(0.4444444444444444),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.65625, 0.65625, 0.75   ,\n",
       "            0.75   , 0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.5       , 0.5       , 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.91306039, 0.85843458, 0.85081134, 0.84260809,\n",
       "            0.78274965, 0.77355259, 0.75516805, 0.68642717, 0.62953755,\n",
       "            0.57775155, 0.57162334, 0.56910796, 0.54032841, 0.47649814,\n",
       "            0.47553862, 0.46838379, 0.42576855, 0.35699587, 0.33625397,\n",
       "            0.30036779, 0.29523739, 0.25899209, 0.18763095, 0.18144799,\n",
       "            0.10346849])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.18900000000000017),\n",
       "                                     1: np.float64(0.8109999999999998)}),\n",
       "    'fpr': np.float64(0.4375),\n",
       "    'tpr': np.float64(0.4444444444444444),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.65625, 0.65625, 0.75   ,\n",
       "            0.75   , 0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.5       , 0.5       , 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.91685829, 0.86401251, 0.85616624, 0.84885678,\n",
       "            0.79088206, 0.78353058, 0.76509186, 0.69804749, 0.64421251,\n",
       "            0.59418044, 0.58825451, 0.58280207, 0.55547033, 0.49422075,\n",
       "            0.49170762, 0.48716253, 0.44416093, 0.37231872, 0.35084273,\n",
       "            0.31647522, 0.31218924, 0.2739494 , 0.19974143, 0.19322256,\n",
       "            0.11114162])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.17900000000000016),\n",
       "                                     1: np.float64(0.8209999999999998)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.46875, 0.46875, 0.5    , 0.5    , 0.65625, 0.65625, 0.75   ,\n",
       "            0.75   , 0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.5       , 0.5       , 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.94444444, 0.94444444, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.92076069, 0.8697954 , 0.86168525, 0.85500116,\n",
       "            0.79911493, 0.79362449, 0.77570979, 0.70980214, 0.65851632,\n",
       "            0.61093055, 0.60476593, 0.59752119, 0.57112981, 0.5122165 ,\n",
       "            0.50843176, 0.50642656, 0.46278519, 0.38861742, 0.36634971,\n",
       "            0.33338912, 0.33009883, 0.28952492, 0.21224167, 0.20583935,\n",
       "            0.11919347])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.16900000000000015),\n",
       "                                     1: np.float64(0.8309999999999998)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.5555555555555556),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.5    , 0.5    , 0.65625, 0.65625, 0.75   , 0.75   , 0.78125,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.92461533, 0.8754513 , 0.86701053, 0.86124324,\n",
       "            0.80751402, 0.80365867, 0.78622477, 0.72191526, 0.67353272,\n",
       "            0.62784777, 0.62221319, 0.6121371 , 0.58719331, 0.52639109,\n",
       "            0.48272131, 0.40624735, 0.38324795, 0.35179068, 0.34944265,\n",
       "            0.30699763, 0.22667446, 0.22001514, 0.12855117])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.15900000000000014),\n",
       "                                     1: np.float64(0.8409999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.7777777777777778),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.5    , 0.5    , 0.65625, 0.65625, 0.75   , 0.75   , 0.78125,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.92830302, 0.88097586, 0.8724295 , 0.86761129,\n",
       "            0.81603216, 0.81358289, 0.79693685, 0.7343435 , 0.68901326,\n",
       "            0.64524479, 0.64065777, 0.62773675, 0.60378898, 0.5471208 ,\n",
       "            0.50105182, 0.42498843, 0.40129021, 0.37148341, 0.36984599,\n",
       "            0.32585575, 0.24248176, 0.2355597 , 0.13903688])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.14900000000000013),\n",
       "                                     1: np.float64(0.8509999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.7777777777777778),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.34375, 0.34375,\n",
       "            0.5    , 0.5    , 0.65625, 0.65625, 0.75   , 0.75   , 0.78125,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.93193371, 0.87935672, 0.87784688, 0.87404349,\n",
       "            0.8247782 , 0.82331976, 0.8078614 , 0.74716624, 0.70469793,\n",
       "            0.66309844, 0.65987627, 0.64397964, 0.62078605, 0.56858358,\n",
       "            0.5190562 , 0.44512748, 0.42091393, 0.39293688, 0.39175459,\n",
       "            0.34662689, 0.26024867, 0.25296656, 0.1510865 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.13900000000000012),\n",
       "                                     1: np.float64(0.8609999999999999)}),\n",
       "    'fpr': np.float64(0.5625),\n",
       "    'tpr': np.float64(0.7777777777777778),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.3125 , 0.3125 , 0.375  , 0.375  ,\n",
       "            0.5    , 0.5    , 0.65625, 0.65625, 0.75   , 0.75   , 0.78125,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.93558853, 0.88653299, 0.88341708, 0.88062533,\n",
       "            0.83382892, 0.83307332, 0.81899729, 0.7603535 , 0.72054637,\n",
       "            0.68134116, 0.67971312, 0.63938171, 0.63841117, 0.59081669,\n",
       "            0.5378787 , 0.46663622, 0.44197419, 0.41598287, 0.41523992,\n",
       "            0.36923686, 0.27993906, 0.27226599, 0.16472895])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.12900000000000011),\n",
       "                                     1: np.float64(0.8709999999999999)}),\n",
       "    'fpr': np.float64(0.59375),\n",
       "    'tpr': np.float64(0.7777777777777778),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.28125, 0.28125, 0.375  , 0.375  ,\n",
       "            0.5    , 0.5    , 0.65625, 0.65625, 0.71875, 0.71875, 0.75   ,\n",
       "            0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.93928794, 0.89389459, 0.88903513, 0.88724763,\n",
       "            0.84318266, 0.84287822, 0.83033288, 0.77393988, 0.73663783,\n",
       "            0.72916265, 0.7003503 , 0.65951784, 0.65695978, 0.61392768,\n",
       "            0.55788524, 0.48990126, 0.46503712, 0.44096289, 0.44044608,\n",
       "            0.44023982, 0.39406017, 0.30214213, 0.29382782, 0.18031437])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1190000000000001),\n",
       "                                     1: np.float64(0.8809999999999999)}),\n",
       "    'fpr': np.float64(0.65625),\n",
       "    'tpr': np.float64(0.7777777777777778),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.28125, 0.28125, 0.375  , 0.375  ,\n",
       "            0.5    , 0.5    , 0.65625, 0.65625, 0.71875, 0.71875, 0.75   ,\n",
       "            0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.11111111, 0.11111111,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.94275354, 0.90091637, 0.89420709, 0.89408903,\n",
       "            0.85280454, 0.85257068, 0.84165375, 0.7877178 , 0.75304477,\n",
       "            0.74724328, 0.7217258 , 0.68005365, 0.67586551, 0.63789614,\n",
       "            0.57866439, 0.51483292, 0.48941185, 0.46790177, 0.46730952,\n",
       "            0.46227112, 0.42147865, 0.32726975, 0.31799313, 0.19879639])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1090000000000001),\n",
       "                                     1: np.float64(0.8909999999999999)}),\n",
       "    'fpr': np.float64(0.65625),\n",
       "    'tpr': np.float64(0.8333333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.28125, 0.28125, 0.375  , 0.375  ,\n",
       "            0.5    , 0.5    , 0.65625, 0.65625, 0.71875, 0.71875, 0.75   ,\n",
       "            0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.94620521, 0.90791606, 0.90156468, 0.90070129,\n",
       "            0.8627233 , 0.86215207, 0.85320813, 0.8015022 , 0.77042617,\n",
       "            0.76536804, 0.74368304, 0.70137055, 0.69577544, 0.66257484,\n",
       "            0.60142594, 0.54073428, 0.51604818, 0.49741984, 0.49592292,\n",
       "            0.48633326, 0.45155257, 0.35545833, 0.34495848, 0.22019814])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.09900000000000009),\n",
       "                                     1: np.float64(0.9009999999999999)}),\n",
       "    'fpr': np.float64(0.75),\n",
       "    'tpr': np.float64(0.8888888888888888),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.28125, 0.28125, 0.375  , 0.375  ,\n",
       "            0.5    , 0.5    , 0.65625, 0.65625, 0.71875, 0.71875, 0.75   ,\n",
       "            0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.94990818, 0.9143372 , 0.90962986, 0.90792622,\n",
       "            0.87322726, 0.87200155, 0.86464786, 0.81627715, 0.7889106 ,\n",
       "            0.78505881, 0.76613833, 0.72445517, 0.71634577, 0.68783697,\n",
       "            0.62542973, 0.56805074, 0.545253  , 0.52933029, 0.526663  ,\n",
       "            0.51219315, 0.48496523, 0.38856519, 0.37578399, 0.24586119])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.08900000000000019),\n",
       "                                     1: np.float64(0.9109999999999998)}),\n",
       "    'fpr': np.float64(0.78125),\n",
       "    'tpr': np.float64(0.9444444444444444),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.28125, 0.28125, 0.375  , 0.375  ,\n",
       "            0.5    , 0.5    , 0.65625, 0.65625, 0.71875, 0.71875, 0.75   ,\n",
       "            0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.95335899, 0.91979861, 0.91753532, 0.91487688,\n",
       "            0.88396095, 0.88158015, 0.87687371, 0.83099032, 0.80770441,\n",
       "            0.80434256, 0.78973336, 0.74801338, 0.73790067, 0.71411996,\n",
       "            0.6510722 , 0.59803267, 0.57719474, 0.56412916, 0.55991222,\n",
       "            0.54094081, 0.52209589, 0.42566377, 0.41072989, 0.27635604])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.07900000000000018),\n",
       "                                     1: np.float64(0.9209999999999998)}),\n",
       "    'fpr': np.float64(0.84375),\n",
       "    'tpr': np.float64(0.9444444444444444),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.25   , 0.25   , 0.28125, 0.28125, 0.375  , 0.375  ,\n",
       "            0.4375 , 0.4375 , 0.5    , 0.5    , 0.65625, 0.65625, 0.71875,\n",
       "            0.71875, 0.75   , 0.78125, 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.16666667, 0.16666667, 0.22222222, 0.22222222, 0.33333333,\n",
       "            0.33333333, 0.38888889, 0.38888889, 0.44444444, 0.44444444,\n",
       "            0.5       , 0.5       , 0.77777778, 0.77777778, 0.83333333,\n",
       "            0.83333333, 0.88888889, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.95670679, 0.92944631, 0.92568689, 0.92199576,\n",
       "            0.89508276, 0.89106443, 0.8889955 , 0.84602541, 0.82749332,\n",
       "            0.82427924, 0.81366942, 0.77263932, 0.76030623, 0.74536148,\n",
       "            0.74447857, 0.7388746 , 0.67898261, 0.63096747, 0.612274  ,\n",
       "            0.60203782, 0.59535697, 0.5732297 , 0.56326631, 0.46903409,\n",
       "            0.45115508, 0.31416454])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.06900000000000017),\n",
       "                                     1: np.float64(0.9309999999999998)}),\n",
       "    'fpr': np.float64(0.90625),\n",
       "    'tpr': np.float64(0.9444444444444444),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.25   ,\n",
       "            0.25   , 0.28125, 0.28125, 0.375  , 0.375  , 0.40625, 0.40625,\n",
       "            0.4375 , 0.4375 , 0.46875, 0.46875, 0.5    , 0.5    , 0.65625,\n",
       "            0.65625, 0.71875, 0.71875, 0.75   , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.22222222, 0.22222222, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.44444444, 0.44444444, 0.5       , 0.5       ,\n",
       "            0.55555556, 0.55555556, 0.61111111, 0.61111111, 0.77777778,\n",
       "            0.77777778, 0.83333333, 0.83333333, 0.88888889, 0.94444444,\n",
       "            0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.96023791, 0.93669035, 0.93421877, 0.92949643,\n",
       "            0.9013193 , 0.86185337, 0.84823861, 0.84490406, 0.83817074,\n",
       "            0.79864882, 0.78381259, 0.77959936, 0.77910959, 0.77523561,\n",
       "            0.76974094, 0.76962262, 0.76825913, 0.76509884, 0.70908101,\n",
       "            0.6666467 , 0.6507505 , 0.64307552, 0.63345815, 0.60862944,\n",
       "            0.51883905, 0.49727601, 0.36010596])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.05900000000000016),\n",
       "                                     1: np.float64(0.9409999999999998)}),\n",
       "    'fpr': np.float64(0.9375),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.0625 , 0.0625 , 0.125  , 0.125  , 0.25   ,\n",
       "            0.25   , 0.28125, 0.28125, 0.375  , 0.375  , 0.4375 , 0.4375 ,\n",
       "            0.5    , 0.5    , 0.65625, 0.65625, 0.71875, 0.71875, 0.75   ,\n",
       "            0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.05555556, 0.05555556,\n",
       "            0.22222222, 0.22222222, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.5       , 0.5       , 0.66666667, 0.66666667,\n",
       "            0.77777778, 0.77777778, 0.83333333, 0.83333333, 0.88888889,\n",
       "            0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.96381055, 0.94404085, 0.9429388 , 0.9370161 ,\n",
       "            0.91396314, 0.87840334, 0.86870008, 0.86653363, 0.86279767,\n",
       "            0.82623925, 0.80874691, 0.80670079, 0.79883512, 0.79316054,\n",
       "            0.74259449, 0.7064238 , 0.69391724, 0.68860043, 0.67527846,\n",
       "            0.65893079, 0.57621754, 0.55205787, 0.41855642])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.049000000000000155),\n",
       "                                     1: np.float64(0.9509999999999998)}),\n",
       "    'fpr': np.float64(0.96875),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.25   , 0.25   ,\n",
       "            0.28125, 0.28125, 0.375  , 0.375  , 0.40625, 0.40625, 0.4375 ,\n",
       "            0.4375 , 0.5    , 0.5    , 0.65625, 0.65625, 0.71875, 0.71875,\n",
       "            0.75   , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.5       , 0.5       , 0.66666667,\n",
       "            0.66666667, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.96737447, 0.95168066, 0.94324132, 0.92671956,\n",
       "            0.89566149, 0.88904188, 0.88798075, 0.88756161, 0.85409773,\n",
       "            0.84954035, 0.83905558, 0.83670005, 0.83605702, 0.83406163,\n",
       "            0.8230086 , 0.77896757, 0.74992744, 0.74093032, 0.73739121,\n",
       "            0.7205269 , 0.71378888, 0.63474783, 0.61439533, 0.49108223])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.039000000000000146),\n",
       "                                     1: np.float64(0.9609999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.25   , 0.25   , 0.3125 , 0.3125 , 0.40625, 0.40625, 0.4375 ,\n",
       "            0.4375 , 0.5    , 0.5    , 0.53125, 0.53125, 0.65625, 0.65625,\n",
       "            0.71875, 0.75   , 0.75   , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.27777778, 0.27777778, 0.38888889, 0.38888889,\n",
       "            0.44444444, 0.44444444, 0.61111111, 0.61111111, 0.66666667,\n",
       "            0.66666667, 0.72222222, 0.72222222, 0.77777778, 0.77777778,\n",
       "            0.83333333, 0.83333333, 0.88888889, 0.94444444, 0.94444444,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.97118955, 0.96051328, 0.9500903 , 0.93991907,\n",
       "            0.92486994, 0.91429171, 0.91370688, 0.9101772 , 0.88742758,\n",
       "            0.88396206, 0.87250519, 0.86936411, 0.86683838, 0.86388733,\n",
       "            0.85536876, 0.85279899, 0.81971262, 0.81923995, 0.79795331,\n",
       "            0.79247572, 0.79004975, 0.77408355, 0.77112163, 0.70248711,\n",
       "            0.68709943, 0.58293932])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.029000000000000137),\n",
       "                                     1: np.float64(0.9709999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.125  , 0.125  , 0.21875, 0.21875,\n",
       "            0.28125, 0.28125, 0.40625, 0.40625, 0.4375 , 0.4375 , 0.46875,\n",
       "            0.46875, 0.5625 , 0.5625 , 0.6875 , 0.6875 , 0.71875, 0.75   ,\n",
       "            0.75   , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.22222222,\n",
       "            0.22222222, 0.33333333, 0.33333333, 0.44444444, 0.44444444,\n",
       "            0.61111111, 0.61111111, 0.66666667, 0.66666667, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.97532988, 0.96928278, 0.95795477, 0.95323054,\n",
       "            0.94090198, 0.9359112 , 0.93174054, 0.91692183, 0.90624886,\n",
       "            0.90464562, 0.89924787, 0.89489456, 0.89403413, 0.8907798 ,\n",
       "            0.86446071, 0.86436722, 0.84873052, 0.84826941, 0.84619452,\n",
       "            0.8376353 , 0.82645096, 0.78012516, 0.76847635, 0.69415398])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.019000000000000128),\n",
       "                                     1: np.float64(0.9809999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.03125, 0.03125, 0.09375, 0.09375, 0.125  , 0.125  ,\n",
       "            0.1875 , 0.1875 , 0.28125, 0.28125, 0.40625, 0.40625, 0.46875,\n",
       "            0.46875, 0.5625 , 0.5625 , 0.6875 , 0.6875 , 0.71875, 0.75   ,\n",
       "            0.75   , 0.90625, 0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.        , 0.05555556, 0.05555556, 0.11111111,\n",
       "            0.11111111, 0.22222222, 0.22222222, 0.33333333, 0.33333333,\n",
       "            0.44444444, 0.44444444, 0.61111111, 0.61111111, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.83333333,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.98019634, 0.97807287, 0.97239429, 0.96914449,\n",
       "            0.96760778, 0.96710571, 0.95961319, 0.95882145, 0.95368613,\n",
       "            0.94789049, 0.94012821, 0.93961197, 0.92973467, 0.92942826,\n",
       "            0.9137317 , 0.91342809, 0.90718118, 0.90637597, 0.90437509,\n",
       "            0.90192559, 0.887752  , 0.86492865, 0.8573065 , 0.81963162])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.009000000000000119),\n",
       "                                     1: np.float64(0.9909999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.     , 0.     , 0.09375, 0.09375, 0.125  , 0.125  , 0.15625,\n",
       "            0.15625, 0.21875, 0.21875, 0.28125, 0.28125, 0.34375, 0.34375,\n",
       "            0.375  , 0.375  , 0.4375 , 0.4375 , 0.5    , 0.5    , 0.59375,\n",
       "            0.59375, 0.6875 , 0.6875 , 0.71875, 0.8125 , 0.8125 , 0.90625,\n",
       "            0.90625, 1.     ]),\n",
       "     'tpr': array([0.        , 0.05555556, 0.05555556, 0.16666667, 0.16666667,\n",
       "            0.22222222, 0.22222222, 0.33333333, 0.33333333, 0.38888889,\n",
       "            0.38888889, 0.44444444, 0.44444444, 0.55555556, 0.55555556,\n",
       "            0.61111111, 0.61111111, 0.66666667, 0.66666667, 0.72222222,\n",
       "            0.72222222, 0.77777778, 0.77777778, 0.83333333, 0.88888889,\n",
       "            0.88888889, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.98730916, 0.98400671, 0.98229247, 0.98141633,\n",
       "            0.9810151 , 0.98087973, 0.9803684 , 0.97783562, 0.9767269 ,\n",
       "            0.9765104 , 0.97627303, 0.97414304, 0.97311262, 0.97296403,\n",
       "            0.97225702, 0.9694491 , 0.96853296, 0.96757151, 0.9672228 ,\n",
       "            0.96341527, 0.96334839, 0.96206154, 0.96192233, 0.96097085,\n",
       "            0.95561073, 0.95251199, 0.94793759, 0.9446706 , 0.93687987])}}],\n",
       "  [{'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.08823529, 0.08823529,\n",
       "            0.11764706, 0.11764706, 0.17647059, 0.17647059, 0.26470588,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.41176471, 0.41176471,\n",
       "            0.76470588, 0.76470588, 0.79411765, 0.79411765, 0.85294118,\n",
       "            0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.25  , 0.25  , 0.375 , 0.375 , 0.4375, 0.4375,\n",
       "            0.5   , 0.5   , 0.5625, 0.5625, 0.625 , 0.625 , 0.6875, 0.6875,\n",
       "            0.8125, 0.8125, 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.00048374, 0.00047626, 0.00046574, 0.00046171,\n",
       "            0.00046128, 0.00046102, 0.00045804, 0.00045673, 0.00045506,\n",
       "            0.00045324, 0.00045283, 0.00045181, 0.00045086, 0.00045015,\n",
       "            0.00043336, 0.00043331, 0.00043319, 0.00042578, 0.00041859,\n",
       "            0.00041764, 0.00041485, 0.00041352])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.989), 1: np.float64(0.011)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.11764706, 0.11764706,\n",
       "            0.23529412, 0.23529412, 0.26470588, 0.26470588, 0.35294118,\n",
       "            0.35294118, 0.38235294, 0.38235294, 0.79411765, 0.79411765,\n",
       "            0.79411765, 0.79411765, 0.85294118, 0.85294118, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.25  , 0.25  , 0.375 , 0.375 , 0.4375, 0.5   ,\n",
       "            0.5625, 0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.875 ,\n",
       "            0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.00866396, 0.00769912, 0.00666199, 0.006511  ,\n",
       "            0.00606411, 0.00606032, 0.00595801, 0.00589494, 0.00580894,\n",
       "            0.00579983, 0.00576216, 0.00568053, 0.00419932, 0.00418983,\n",
       "            0.00417567, 0.00346184, 0.00330189, 0.00316626, 0.00305331,\n",
       "            0.0029608 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.979),\n",
       "                                     1: np.float64(0.020999999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05882353, 0.05882353,\n",
       "            0.14705882, 0.14705882, 0.23529412, 0.23529412, 0.26470588,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.76470588,\n",
       "            0.76470588, 0.79411765, 0.79411765, 0.82352941, 0.82352941,\n",
       "            0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.375 , 0.375 ,\n",
       "            0.5   , 0.5625, 0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.02201336, 0.01904457, 0.01835762, 0.01825137,\n",
       "            0.01520379, 0.01440224, 0.01355581, 0.01288876, 0.01282464,\n",
       "            0.01244641, 0.01234117, 0.0120934 , 0.01204623, 0.00765893,\n",
       "            0.00758047, 0.00747251, 0.00746651, 0.00578207, 0.00567264,\n",
       "            0.00540366, 0.00495941, 0.0047702 , 0.00444567])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.969),\n",
       "                                     1: np.float64(0.030999999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.05882353, 0.05882353,\n",
       "            0.14705882, 0.14705882, 0.20588235, 0.20588235, 0.26470588,\n",
       "            0.26470588, 0.29411765, 0.35294118, 0.35294118, 0.76470588,\n",
       "            0.76470588, 0.76470588, 0.82352941, 0.82352941, 0.85294118,\n",
       "            0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.1875, 0.1875, 0.25  , 0.25  , 0.3125, 0.3125,\n",
       "            0.375 , 0.375 , 0.5   , 0.5625, 0.5625, 0.6875, 0.6875, 0.75  ,\n",
       "            0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.03862855, 0.03266293, 0.03153878, 0.03027875,\n",
       "            0.0259338 , 0.02489647, 0.02292288, 0.02290952, 0.02092472,\n",
       "            0.02075586, 0.02046499, 0.01976865, 0.01906813, 0.01079016,\n",
       "            0.01075675, 0.01048765, 0.00794052, 0.00749233, 0.00716821,\n",
       "            0.00636672, 0.00612506, 0.00548465])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.959),\n",
       "                                     1: np.float64(0.040999999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02941176, 0.02941176,\n",
       "            0.05882353, 0.05882353, 0.14705882, 0.14705882, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.35294118,\n",
       "            0.35294118, 0.73529412, 0.73529412, 0.76470588, 0.76470588,\n",
       "            0.82352941, 0.82352941, 0.85294118, 0.85294118, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  , 0.25  ,\n",
       "            0.3125, 0.3125, 0.375 , 0.375 , 0.5   , 0.5625, 0.5625, 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.05784873, 0.05674409, 0.04817978, 0.04730999,\n",
       "            0.04549638, 0.0425207 , 0.03814407, 0.03575624, 0.03179686,\n",
       "            0.03140106, 0.02975576, 0.02847031, 0.02839963, 0.02728298,\n",
       "            0.02626418, 0.01447431, 0.01374306, 0.01367772, 0.01327935,\n",
       "            0.01001788, 0.00910542, 0.00875973, 0.0075745 , 0.00729359,\n",
       "            0.00630438])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9490000000000001),\n",
       "                                     1: np.float64(0.05099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02941176, 0.02941176,\n",
       "            0.08823529, 0.08823529, 0.14705882, 0.14705882, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.32352941,\n",
       "            0.32352941, 0.35294118, 0.35294118, 0.73529412, 0.73529412,\n",
       "            0.76470588, 0.76470588, 0.82352941, 0.82352941, 0.85294118,\n",
       "            0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  , 0.25  ,\n",
       "            0.3125, 0.3125, 0.375 , 0.375 , 0.4375, 0.5   , 0.5   , 0.625 ,\n",
       "            0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375,\n",
       "            0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.07987792, 0.07619549, 0.06545532, 0.06263695,\n",
       "            0.05614356, 0.05480359, 0.05152447, 0.0468315 , 0.04152268,\n",
       "            0.04041973, 0.03931227, 0.03879566, 0.03707837, 0.03704208,\n",
       "            0.03570681, 0.03508191, 0.03377322, 0.01772668, 0.01667495,\n",
       "            0.0165646 , 0.01622682, 0.01210623, 0.01062464, 0.01024614,\n",
       "            0.00875248, 0.00836862, 0.00705945])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9390000000000001),\n",
       "                                     1: np.float64(0.06099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02941176, 0.02941176,\n",
       "            0.11764706, 0.11764706, 0.14705882, 0.14705882, 0.26470588,\n",
       "            0.26470588, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.73529412, 0.73529412, 0.76470588, 0.76470588,\n",
       "            0.82352941, 0.82352941, 0.85294118, 0.85294118, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  , 0.25  ,\n",
       "            0.3125, 0.3125, 0.4375, 0.4375, 0.5   , 0.625 , 0.625 , 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.10212292, 0.09445983, 0.08483383, 0.0780315 ,\n",
       "            0.0662407 , 0.06621895, 0.06558243, 0.05901335, 0.04901335,\n",
       "            0.04844516, 0.04595897, 0.04507951, 0.04329168, 0.0426886 ,\n",
       "            0.04088624, 0.02049078, 0.01965486, 0.0191192 , 0.01867337,\n",
       "            0.0141359 , 0.0122267 , 0.01172008, 0.00980725, 0.0093744 ,\n",
       "            0.00772002])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.929), 1: np.float64(0.071)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02941176, 0.02941176,\n",
       "            0.14705882, 0.14705882, 0.26470588, 0.26470588, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.35294118, 0.73529412,\n",
       "            0.73529412, 0.76470588, 0.76470588, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125, 0.3125,\n",
       "            0.4375, 0.4375, 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.12523745, 0.11259563, 0.10398927, 0.09282725,\n",
       "            0.08004905, 0.07068252, 0.05928213, 0.0568227 , 0.05533759,\n",
       "            0.05361695, 0.05071828, 0.05053037, 0.04835837, 0.02348273,\n",
       "            0.0225417 , 0.02172905, 0.02131458, 0.01629052, 0.01367711,\n",
       "            0.01093361, 0.01086481, 0.01032813, 0.00835429])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.919),\n",
       "                                     1: np.float64(0.08099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02941176, 0.02941176,\n",
       "            0.14705882, 0.14705882, 0.20588235, 0.20588235, 0.26470588,\n",
       "            0.26470588, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.35294118, 0.73529412, 0.73529412, 0.76470588, 0.76470588,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125, 0.3125,\n",
       "            0.375 , 0.375 , 0.4375, 0.4375, 0.5   , 0.5625, 0.5625, 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.14937252, 0.13041808, 0.12368448, 0.10751885,\n",
       "            0.09483809, 0.08230485, 0.07347835, 0.0694746 , 0.06890544,\n",
       "            0.06532127, 0.06528145, 0.0624053 , 0.06009472, 0.05822581,\n",
       "            0.05549928, 0.02634291, 0.02545526, 0.02432627, 0.02396842,\n",
       "            0.01837495, 0.01521255, 0.01211456, 0.01187766, 0.01124367,\n",
       "            0.00898755])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.909),\n",
       "                                     1: np.float64(0.09099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.02941176, 0.02941176,\n",
       "            0.14705882, 0.14705882, 0.23529412, 0.23529412, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.35294118,\n",
       "            0.38235294, 0.38235294, 0.73529412, 0.73529412, 0.76470588,\n",
       "            0.76470588, 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125, 0.3125,\n",
       "            0.375 , 0.375 , 0.4375, 0.5   , 0.5625, 0.5625, 0.625 , 0.625 ,\n",
       "            0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375,\n",
       "            1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.17281776, 0.14696541, 0.14335566, 0.12124616,\n",
       "            0.10985934, 0.0938097 , 0.08014467, 0.08010299, 0.07542264,\n",
       "            0.07370309, 0.07139839, 0.06871591, 0.06620828, 0.06422901,\n",
       "            0.06297755, 0.06292757, 0.02931959, 0.0284665 , 0.02699591,\n",
       "            0.02662478, 0.02065344, 0.01671372, 0.01331267, 0.01292312,\n",
       "            0.01218517, 0.00964002])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.899),\n",
       "                                     1: np.float64(0.10099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02941176, 0.02941176, 0.05882353,\n",
       "            0.05882353, 0.17647059, 0.17647059, 0.23529412, 0.23529412,\n",
       "            0.29411765, 0.29411765, 0.32352941, 0.32352941, 0.38235294,\n",
       "            0.38235294, 0.73529412, 0.73529412, 0.76470588, 0.76470588,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.5   , 0.5625, 0.5625, 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.19431159, 0.16386455, 0.16294075, 0.13687172,\n",
       "            0.13445299, 0.10686866, 0.10463939, 0.09145591, 0.0906277 ,\n",
       "            0.08637312, 0.08235729, 0.08049639, 0.07739887, 0.07093496,\n",
       "            0.07008224, 0.03218465, 0.03147108, 0.02954314, 0.02905073,\n",
       "            0.02281121, 0.0180662 , 0.01432696, 0.01393062, 0.01300698,\n",
       "            0.01019403])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.889),\n",
       "                                     1: np.float64(0.11099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02941176, 0.02941176, 0.05882353,\n",
       "            0.05882353, 0.17647059, 0.17647059, 0.23529412, 0.23529412,\n",
       "            0.29411765, 0.29411765, 0.32352941, 0.32352941, 0.38235294,\n",
       "            0.38235294, 0.73529412, 0.73529412, 0.76470588, 0.76470588,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.5   , 0.5625, 0.5625, 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.21678219, 0.18393065, 0.17823498, 0.15353584,\n",
       "            0.14723353, 0.1201937 , 0.11378287, 0.10287502, 0.10165346,\n",
       "            0.09505993, 0.09088179, 0.08967677, 0.08635841, 0.07906338,\n",
       "            0.07624355, 0.03523321, 0.03457366, 0.03220396, 0.03172351,\n",
       "            0.02523562, 0.01959345, 0.01553624, 0.01501992, 0.01395358,\n",
       "            0.01081989])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.879),\n",
       "                                     1: np.float64(0.12099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02941176, 0.02941176, 0.08823529,\n",
       "            0.08823529, 0.17647059, 0.17647059, 0.23529412, 0.23529412,\n",
       "            0.29411765, 0.29411765, 0.32352941, 0.32352941, 0.38235294,\n",
       "            0.38235294, 0.73529412, 0.73529412, 0.76470588, 0.76470588,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.5   , 0.5625, 0.5625, 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.23990602, 0.20360976, 0.19312571, 0.16188666,\n",
       "            0.15976089, 0.13316211, 0.12197542, 0.11414276, 0.11263548,\n",
       "            0.10357471, 0.09941123, 0.0987659 , 0.0953005 , 0.08707475,\n",
       "            0.08234542, 0.0382587 , 0.03760534, 0.03476918, 0.03438914,\n",
       "            0.02766042, 0.02106472, 0.01671809, 0.01604913, 0.01485105,\n",
       "            0.01140257])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.869),\n",
       "                                     1: np.float64(0.13099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02941176, 0.02941176, 0.08823529,\n",
       "            0.08823529, 0.17647059, 0.17647059, 0.23529412, 0.23529412,\n",
       "            0.29411765, 0.29411765, 0.32352941, 0.32352941, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.73529412, 0.73529412,\n",
       "            0.76470588, 0.76470588, 0.82352941, 0.82352941, 0.88235294,\n",
       "            0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.5   , 0.5625, 0.5625, 0.625 ,\n",
       "            0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375,\n",
       "            0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.26234322, 0.2230535 , 0.2082581 , 0.1790442 ,\n",
       "            0.17220306, 0.14622093, 0.13053323, 0.12545134, 0.12420791,\n",
       "            0.11211207, 0.10858276, 0.10850003, 0.10455097, 0.09517138,\n",
       "            0.09333939, 0.0898266 , 0.08857343, 0.0413693 , 0.04078725,\n",
       "            0.03760914, 0.03719416, 0.03005678, 0.02269768, 0.01799474,\n",
       "            0.01711878, 0.0158114 , 0.01206125])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.859), 1: np.float64(0.141)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02941176, 0.02941176, 0.11764706,\n",
       "            0.11764706, 0.17647059, 0.17647059, 0.20588235, 0.20588235,\n",
       "            0.23529412, 0.23529412, 0.29411765, 0.32352941, 0.32352941,\n",
       "            0.38235294, 0.38235294, 0.41176471, 0.41176471, 0.73529412,\n",
       "            0.73529412, 0.76470588, 0.76470588, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.3125, 0.375 , 0.375 , 0.4375, 0.5625, 0.5625,\n",
       "            0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 ,\n",
       "            0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.28419342, 0.24261532, 0.22127314, 0.18504559,\n",
       "            0.18378211, 0.15836864, 0.14891367, 0.13781112, 0.1377488 ,\n",
       "            0.13637726, 0.13541041, 0.1196993 , 0.11772131, 0.11290169,\n",
       "            0.10358096, 0.10023958, 0.09714991, 0.09401057, 0.04417027,\n",
       "            0.0441203 , 0.0402666 , 0.03969057, 0.03246458, 0.02427395,\n",
       "            0.01922042, 0.01815203, 0.01669228, 0.01270203])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.849),\n",
       "                                     1: np.float64(0.15099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02941176, 0.02941176, 0.11764706,\n",
       "            0.11764706, 0.17647059, 0.17647059, 0.23529412, 0.23529412,\n",
       "            0.26470588, 0.26470588, 0.29411765, 0.32352941, 0.32352941,\n",
       "            0.38235294, 0.38235294, 0.41176471, 0.41176471, 0.73529412,\n",
       "            0.73529412, 0.76470588, 0.76470588, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.3125, 0.375 , 0.375 , 0.4375, 0.5625, 0.5625,\n",
       "            0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 ,\n",
       "            0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.30349066, 0.26121037, 0.23446417, 0.20015304,\n",
       "            0.19378185, 0.17292477, 0.15900017, 0.14789532, 0.14681272,\n",
       "            0.14477297, 0.14407184, 0.12799969, 0.12724634, 0.12296345,\n",
       "            0.11124858, 0.10848283, 0.10523806, 0.09962829, 0.04768845,\n",
       "            0.04707447, 0.0429929 , 0.0427094 , 0.03526436, 0.02581323,\n",
       "            0.02048918, 0.01931441, 0.01770461, 0.01327953])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.839),\n",
       "                                     1: np.float64(0.16099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02941176, 0.02941176, 0.11764706,\n",
       "            0.11764706, 0.17647059, 0.17647059, 0.23529412, 0.23529412,\n",
       "            0.26470588, 0.26470588, 0.29411765, 0.32352941, 0.32352941,\n",
       "            0.38235294, 0.38235294, 0.41176471, 0.41176471, 0.73529412,\n",
       "            0.73529412, 0.76470588, 0.76470588, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5625, 0.5625,\n",
       "            0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 ,\n",
       "            0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.32326884, 0.27984454, 0.24697212, 0.21445774,\n",
       "            0.20420937, 0.18609207, 0.1690505 , 0.15820904, 0.15771645,\n",
       "            0.15723798, 0.1505193 , 0.1364842 , 0.13562611, 0.1318713 ,\n",
       "            0.11937923, 0.11590798, 0.11288393, 0.1049258 , 0.05080026,\n",
       "            0.05032591, 0.04569497, 0.04536776, 0.03786572, 0.02730681,\n",
       "            0.02168906, 0.02044072, 0.01865436, 0.01390481])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.829),\n",
       "                                     1: np.float64(0.17099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02941176, 0.02941176, 0.14705882,\n",
       "            0.14705882, 0.17647059, 0.17647059, 0.23529412, 0.23529412,\n",
       "            0.26470588, 0.26470588, 0.29411765, 0.29411765, 0.32352941,\n",
       "            0.32352941, 0.38235294, 0.38235294, 0.41176471, 0.41176471,\n",
       "            0.73529412, 0.73529412, 0.76470588, 0.76470588, 0.82352941,\n",
       "            0.82352941, 0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.5   , 0.5   , 0.5625,\n",
       "            0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.3438173 , 0.29787599, 0.2597143 , 0.21528304,\n",
       "            0.21496017, 0.19893815, 0.17971131, 0.16956761, 0.16910711,\n",
       "            0.16873422, 0.15767202, 0.14591341, 0.14417717, 0.1436919 ,\n",
       "            0.14113566, 0.12757393, 0.12359113, 0.12083222, 0.11067961,\n",
       "            0.05412429, 0.05364768, 0.04846084, 0.04827267, 0.04061779,\n",
       "            0.02895566, 0.02301264, 0.02156327, 0.01964924, 0.01453503])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.8190000000000001),\n",
       "                                     1: np.float64(0.18099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02941176, 0.02941176, 0.14705882,\n",
       "            0.14705882, 0.17647059, 0.17647059, 0.23529412, 0.23529412,\n",
       "            0.26470588, 0.26470588, 0.29411765, 0.29411765, 0.32352941,\n",
       "            0.32352941, 0.38235294, 0.38235294, 0.41176471, 0.41176471,\n",
       "            0.73529412, 0.73529412, 0.73529412, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.5   , 0.5   , 0.5625,\n",
       "            0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.875 , 0.875 ,\n",
       "            0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.36396786, 0.31468862, 0.27158041, 0.22649304,\n",
       "            0.22504623, 0.21095717, 0.18992651, 0.18191604, 0.18018966,\n",
       "            0.17903156, 0.1645138 , 0.15522211, 0.15314831, 0.15147203,\n",
       "            0.15034796, 0.13560258, 0.13099661, 0.12878575, 0.1163055 ,\n",
       "            0.0575197 , 0.0570336 , 0.05132205, 0.0434763 , 0.0306414 ,\n",
       "            0.02441857, 0.02273015, 0.02069274, 0.01520268])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.809),\n",
       "                                     1: np.float64(0.19099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02941176, 0.02941176, 0.14705882,\n",
       "            0.14705882, 0.17647059, 0.17647059, 0.23529412, 0.23529412,\n",
       "            0.26470588, 0.26470588, 0.29411765, 0.29411765, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.73529412, 0.73529412,\n",
       "            0.73529412, 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.5625, 0.5625, 0.625 ,\n",
       "            0.625 , 0.6875, 0.6875, 0.75  , 0.875 , 0.875 , 0.9375, 0.9375,\n",
       "            1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.38038948, 0.33141395, 0.2828033 , 0.23727699,\n",
       "            0.23345041, 0.22483726, 0.19917986, 0.194083  , 0.19155971,\n",
       "            0.18863742, 0.17009793, 0.16507268, 0.16009218, 0.1433272 ,\n",
       "            0.13901985, 0.13701412, 0.12134527, 0.06107249, 0.06022158,\n",
       "            0.05429179, 0.04635783, 0.03226224, 0.02573033, 0.0238584 ,\n",
       "            0.02168448, 0.01580069])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.799),\n",
       "                                     1: np.float64(0.20099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05882353, 0.05882353, 0.14705882,\n",
       "            0.14705882, 0.17647059, 0.17647059, 0.23529412, 0.23529412,\n",
       "            0.26470588, 0.26470588, 0.29411765, 0.29411765, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.73529412, 0.73529412,\n",
       "            0.76470588, 0.76470588, 0.82352941, 0.82352941, 0.88235294,\n",
       "            0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.5625, 0.5625, 0.625 ,\n",
       "            0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375,\n",
       "            0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.39900472, 0.29987159, 0.29449286, 0.24857183,\n",
       "            0.24351638, 0.23677873, 0.20938302, 0.20489002, 0.20217248,\n",
       "            0.19916662, 0.17677155, 0.17411837, 0.16850925, 0.15184904,\n",
       "            0.14622081, 0.14477504, 0.1268666 , 0.06435024, 0.06380241,\n",
       "            0.05705323, 0.05705101, 0.04916456, 0.03387146, 0.02702361,\n",
       "            0.0250771 , 0.02273061, 0.01649426])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.789),\n",
       "                                     1: np.float64(0.21099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05882353, 0.05882353, 0.14705882,\n",
       "            0.14705882, 0.20588235, 0.20588235, 0.23529412, 0.23529412,\n",
       "            0.26470588, 0.29411765, 0.29411765, 0.38235294, 0.38235294,\n",
       "            0.41176471, 0.41176471, 0.73529412, 0.73529412, 0.73529412,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.3125, 0.375 , 0.5625, 0.5625, 0.625 , 0.625 ,\n",
       "            0.6875, 0.6875, 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.4161767 , 0.31672577, 0.30530021, 0.2592859 ,\n",
       "            0.25231853, 0.22095152, 0.21871299, 0.21583295, 0.21364579,\n",
       "            0.2089395 , 0.18399982, 0.17781349, 0.15983857, 0.15359183,\n",
       "            0.15328938, 0.13187857, 0.0678287 , 0.06735333, 0.06013514,\n",
       "            0.05204603, 0.03566   , 0.02845481, 0.02623424, 0.02376843,\n",
       "            0.01717688])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.779),\n",
       "                                     1: np.float64(0.22099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.08823529, 0.08823529, 0.17647059,\n",
       "            0.17647059, 0.20588235, 0.20588235, 0.23529412, 0.23529412,\n",
       "            0.26470588, 0.29411765, 0.29411765, 0.41176471, 0.41176471,\n",
       "            0.73529412, 0.73529412, 0.73529412, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.3125, 0.375 , 0.5625, 0.5625, 0.6875, 0.6875,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.43170004, 0.31852042, 0.31582906, 0.2617014 ,\n",
       "            0.25993879, 0.23291419, 0.22815351, 0.22720016, 0.22541149,\n",
       "            0.21838339, 0.19359112, 0.18816168, 0.16235032, 0.1373688 ,\n",
       "            0.07190054, 0.07049927, 0.06372563, 0.05539541, 0.03759517,\n",
       "            0.03004937, 0.02743709, 0.02490487, 0.01778961])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.769),\n",
       "                                     1: np.float64(0.23099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.08823529, 0.08823529, 0.17647059,\n",
       "            0.17647059, 0.23529412, 0.23529412, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.41176471, 0.41176471, 0.73529412, 0.73529412,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.5625, 0.5625, 0.6875, 0.6875, 0.875 , 0.875 ,\n",
       "            0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.44680887, 0.33188118, 0.32550951, 0.27420465,\n",
       "            0.26774504, 0.23834182, 0.2360443 , 0.22827394, 0.20292097,\n",
       "            0.19396644, 0.17045781, 0.14223751, 0.07524552, 0.06682616,\n",
       "            0.05867019, 0.03933928, 0.03151421, 0.02876066, 0.02607501,\n",
       "            0.01851778])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.759),\n",
       "                                     1: np.float64(0.24099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.08823529, 0.08823529, 0.17647059,\n",
       "            0.17647059, 0.23529412, 0.23529412, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.41176471, 0.41176471, 0.73529412, 0.73529412,\n",
       "            0.73529412, 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.5625, 0.5625, 0.6875, 0.6875, 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.4621785 , 0.34579962, 0.33565057, 0.2864688 ,\n",
       "            0.27639957, 0.24969612, 0.24672581, 0.23855262, 0.2119651 ,\n",
       "            0.19980465, 0.17863914, 0.147632  , 0.07848261, 0.0780128 ,\n",
       "            0.06999012, 0.06207328, 0.04112927, 0.03300569, 0.03012586,\n",
       "            0.02726153, 0.01922994])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7490000000000001),\n",
       "                                     1: np.float64(0.25099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.08823529, 0.08823529, 0.17647059,\n",
       "            0.17647059, 0.23529412, 0.23529412, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.41176471, 0.41176471, 0.73529412, 0.73529412,\n",
       "            0.73529412, 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.5625, 0.5625, 0.6875, 0.6875, 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.47598015, 0.35788812, 0.34591599, 0.2983025 ,\n",
       "            0.2839483 , 0.25989234, 0.25524637, 0.24805975, 0.22159993,\n",
       "            0.20539102, 0.18758417, 0.15260644, 0.08174877, 0.08173664,\n",
       "            0.07324254, 0.06523617, 0.0429093 , 0.03446446, 0.03148151,\n",
       "            0.02844478, 0.01998986])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7390000000000001),\n",
       "                                     1: np.float64(0.26099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.08823529, 0.08823529, 0.17647059,\n",
       "            0.17647059, 0.23529412, 0.23529412, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.35294118, 0.35294118, 0.41176471, 0.41176471,\n",
       "            0.73529412, 0.73529412, 0.73529412, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.5   , 0.5   , 0.5625, 0.5625, 0.6875, 0.6875,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.48913324, 0.37117772, 0.35532139, 0.31008102,\n",
       "            0.29026118, 0.2707344 , 0.26415124, 0.25696684, 0.23145319,\n",
       "            0.2255273 , 0.21123036, 0.21106462, 0.19669785, 0.15761783,\n",
       "            0.08537449, 0.08509375, 0.07712348, 0.06889271, 0.04497057,\n",
       "            0.03616358, 0.03270854, 0.02966785, 0.02062152])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7290000000000001),\n",
       "                                     1: np.float64(0.27099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.08823529, 0.08823529, 0.17647059,\n",
       "            0.17647059, 0.23529412, 0.23529412, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.35294118, 0.35294118, 0.41176471, 0.41176471,\n",
       "            0.70588235, 0.70588235, 0.73529412, 0.73529412, 0.82352941,\n",
       "            0.82352941, 0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.5   , 0.5   , 0.5625, 0.5625, 0.6875, 0.6875,\n",
       "            0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.50211461, 0.38341913, 0.36490936, 0.32023063,\n",
       "            0.2979571 , 0.28111319, 0.27324041, 0.26670082, 0.24087419,\n",
       "            0.23471157, 0.21879026, 0.21711621, 0.20543287, 0.1627871 ,\n",
       "            0.09182234, 0.08907274, 0.08885823, 0.08074405, 0.07240643,\n",
       "            0.04705946, 0.0378783 , 0.03415626, 0.03099698, 0.0214043 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7190000000000001),\n",
       "                                     1: np.float64(0.28099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.08823529, 0.08823529, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.23529412, 0.26470588, 0.26470588,\n",
       "            0.29411765, 0.29411765, 0.35294118, 0.35294118, 0.41176471,\n",
       "            0.41176471, 0.70588235, 0.70588235, 0.73529412, 0.73529412,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.4375, 0.5   , 0.5   , 0.5625, 0.5625, 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.51525864, 0.39532545, 0.37480447, 0.31160665,\n",
       "            0.30562681, 0.29174711, 0.28165096, 0.27643938, 0.25135968,\n",
       "            0.2500549 , 0.24355145, 0.22586886, 0.22226348, 0.214506  ,\n",
       "            0.1679923 , 0.09608464, 0.09313077, 0.09222797, 0.08404321,\n",
       "            0.07599563, 0.04881444, 0.03935386, 0.03573549, 0.03234131,\n",
       "            0.0222573 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7090000000000001),\n",
       "                                     1: np.float64(0.291)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.08823529, 0.08823529, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.23529412, 0.26470588, 0.26470588,\n",
       "            0.29411765, 0.29411765, 0.35294118, 0.35294118, 0.41176471,\n",
       "            0.41176471, 0.70588235, 0.70588235, 0.73529412, 0.73529412,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.4375, 0.5   , 0.5   , 0.5625, 0.5625, 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.52748449, 0.40747441, 0.38406615, 0.32410504,\n",
       "            0.31219052, 0.30188712, 0.29015536, 0.285605  , 0.26164287,\n",
       "            0.25954811, 0.25302271, 0.23326796, 0.22800283, 0.22359437,\n",
       "            0.17296211, 0.10030911, 0.09686481, 0.09579207, 0.08783597,\n",
       "            0.07966648, 0.05083819, 0.04104742, 0.03710562, 0.0336454 ,\n",
       "            0.02296953])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6990000000000001),\n",
       "                                     1: np.float64(0.30099999999999993)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.08823529, 0.08823529, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.23529412, 0.26470588, 0.26470588,\n",
       "            0.29411765, 0.29411765, 0.35294118, 0.35294118, 0.41176471,\n",
       "            0.41176471, 0.70588235, 0.70588235, 0.73529412, 0.73529412,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.4375, 0.5   , 0.5   , 0.5625, 0.5625, 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.53937137, 0.41925448, 0.39331056, 0.33716732,\n",
       "            0.31933652, 0.3121585 , 0.29878007, 0.29520167, 0.27187931,\n",
       "            0.26890083, 0.26203312, 0.24071201, 0.23379978, 0.23190761,\n",
       "            0.17820987, 0.10363563, 0.10106989, 0.09946608, 0.09158223,\n",
       "            0.08350452, 0.05289628, 0.04278449, 0.03868962, 0.03509278,\n",
       "            0.02383811])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6890000000000001),\n",
       "                                     1: np.float64(0.31099999999999994)}),\n",
       "    'fpr': np.float64(0.029411764705882353),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.08823529, 0.08823529, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.23529412, 0.26470588, 0.26470588,\n",
       "            0.29411765, 0.29411765, 0.41176471, 0.41176471, 0.70588235,\n",
       "            0.70588235, 0.73529412, 0.73529412, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.4375, 0.5   , 0.5   , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.54923825, 0.43062947, 0.40168991, 0.34904803,\n",
       "            0.32573442, 0.3218956 , 0.3075254 , 0.30481424, 0.28165943,\n",
       "            0.27801783, 0.27071237, 0.24034382, 0.18325566, 0.10685974,\n",
       "            0.10530882, 0.10329785, 0.0954256 , 0.08743734, 0.05533176,\n",
       "            0.0447367 , 0.04028552, 0.0365956 , 0.02471498])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.679),\n",
       "                                     1: np.float64(0.32099999999999995)}),\n",
       "    'fpr': np.float64(0.029411764705882353),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.20588235,\n",
       "            0.20588235, 0.23529412, 0.23529412, 0.26470588, 0.26470588,\n",
       "            0.29411765, 0.29411765, 0.41176471, 0.41176471, 0.70588235,\n",
       "            0.70588235, 0.73529412, 0.73529412, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.3125,\n",
       "            0.3125, 0.375 , 0.4375, 0.5   , 0.5   , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.5599014 , 0.41223018, 0.4107047 , 0.36185487,\n",
       "            0.33236089, 0.3316772 , 0.31576836, 0.31420201, 0.29203987,\n",
       "            0.28720688, 0.27952569, 0.24859409, 0.18838439, 0.11014358,\n",
       "            0.10953938, 0.10706128, 0.09922921, 0.09137861, 0.05743488,\n",
       "            0.04649354, 0.04192701, 0.03809906, 0.02560437])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.669),\n",
       "                                     1: np.float64(0.33099999999999996)}),\n",
       "    'fpr': np.float64(0.029411764705882353),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.67647059, 0.67647059, 0.73529412,\n",
       "            0.73529412, 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.3125, 0.3125, 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.57199676, 0.42266762, 0.42030462, 0.34186389,\n",
       "            0.32394614, 0.32378726, 0.30252196, 0.29558758, 0.28788624,\n",
       "            0.25663984, 0.19398275, 0.11877715, 0.11381522, 0.11049683,\n",
       "            0.1027106 , 0.0953346 , 0.05912989, 0.04800709, 0.04367233,\n",
       "            0.03960292, 0.02649457])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.659),\n",
       "                                     1: np.float64(0.34099999999999997)}),\n",
       "    'fpr': np.float64(0.029411764705882353),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.67647059, 0.67647059, 0.73529412,\n",
       "            0.73529412, 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.58155626, 0.43311212, 0.42913712, 0.35115154,\n",
       "            0.34621914, 0.33294178, 0.31261704, 0.30486704, 0.2966437 ,\n",
       "            0.26506262, 0.19903467, 0.12357142, 0.11817636, 0.11449324,\n",
       "            0.10674867, 0.09943237, 0.06134299, 0.04986255, 0.04538797,\n",
       "            0.04121878, 0.02742365])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.649),\n",
       "                                     1: np.float64(0.3509999999999999)}),\n",
       "    'fpr': np.float64(0.058823529411764705),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.67647059, 0.67647059, 0.73529412,\n",
       "            0.73529412, 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.59038115, 0.44388336, 0.4375564 , 0.36099507,\n",
       "            0.35250627, 0.34261922, 0.32248914, 0.31411508, 0.30535746,\n",
       "            0.2741326 , 0.20391972, 0.12843615, 0.12290385, 0.11850283,\n",
       "            0.11075007, 0.10380002, 0.06369776, 0.05180386, 0.04727577,\n",
       "            0.04293692, 0.02840072])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.639),\n",
       "                                     1: np.float64(0.36099999999999993)}),\n",
       "    'fpr': np.float64(0.058823529411764705),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.67647059, 0.67647059, 0.73529412,\n",
       "            0.73529412, 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.59998926, 0.45405314, 0.44624009, 0.37065449,\n",
       "            0.3589642 , 0.3521559 , 0.33313014, 0.32295209, 0.31383559,\n",
       "            0.28240839, 0.20920972, 0.13347476, 0.1274359 , 0.12238008,\n",
       "            0.1146747 , 0.10809121, 0.06583029, 0.05361726, 0.04906864,\n",
       "            0.04456854, 0.02934905])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.629),\n",
       "                                     1: np.float64(0.37099999999999994)}),\n",
       "    'fpr': np.float64(0.058823529411764705),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.67647059, 0.67647059, 0.73529412,\n",
       "            0.73529412, 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.60915992, 0.46421064, 0.45537016, 0.37995626,\n",
       "            0.36567939, 0.36160835, 0.34379006, 0.33175532, 0.322351  ,\n",
       "            0.29098744, 0.21475261, 0.13872931, 0.13210415, 0.12657761,\n",
       "            0.1188439 , 0.1125633 , 0.06811466, 0.05553565, 0.05106037,\n",
       "            0.04638634, 0.03039145])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.619),\n",
       "                                     1: np.float64(0.38099999999999995)}),\n",
       "    'fpr': np.float64(0.08823529411764706),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.44117647, 0.44117647, 0.67647059,\n",
       "            0.67647059, 0.73529412, 0.73529412, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  , 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.6176116 , 0.47417507, 0.46389816, 0.38914567,\n",
       "            0.3719227 , 0.3710673 , 0.35445178, 0.34073527, 0.33081434,\n",
       "            0.29916226, 0.27869928, 0.22223918, 0.22012442, 0.14406202,\n",
       "            0.13694125, 0.1308656 , 0.12314671, 0.11712266, 0.07060922,\n",
       "            0.05761658, 0.05304889, 0.04823738, 0.03146422])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.609),\n",
       "                                     1: np.float64(0.39099999999999996)}),\n",
       "    'fpr': np.float64(0.08823529411764706),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.44117647, 0.44117647, 0.67647059,\n",
       "            0.67647059, 0.73529412, 0.73529412, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.6250453 , 0.48417787, 0.47215106, 0.39748714,\n",
       "            0.3960282 , 0.38041616, 0.36441   , 0.34974081, 0.3392139 ,\n",
       "            0.30673388, 0.28526316, 0.22993948, 0.22526609, 0.1493178 ,\n",
       "            0.14177439, 0.13478252, 0.12785083, 0.12174712, 0.07370494,\n",
       "            0.06006495, 0.05511225, 0.05022865, 0.03251288])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5990000000000001),\n",
       "                                     1: np.float64(0.4009999999999999)}),\n",
       "    'fpr': np.float64(0.08823529411764706),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.44117647, 0.44117647, 0.67647059,\n",
       "            0.67647059, 0.73529412, 0.73529412, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.63301345, 0.49400302, 0.48079296, 0.40636866,\n",
       "            0.40514887, 0.39007426, 0.37478167, 0.35841627, 0.34724673,\n",
       "            0.3140504 , 0.29116209, 0.23774568, 0.23083639, 0.15473068,\n",
       "            0.14684872, 0.13857254, 0.13212408, 0.1264576 , 0.07621973,\n",
       "            0.06214569, 0.05726877, 0.0522138 , 0.03367223])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5890000000000001),\n",
       "                                     1: np.float64(0.4109999999999999)}),\n",
       "    'fpr': np.float64(0.11764705882352941),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.44117647, 0.44117647, 0.67647059,\n",
       "            0.67647059, 0.73529412, 0.73529412, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.64108843, 0.50350942, 0.4892939 , 0.4155839 ,\n",
       "            0.41424161, 0.39975533, 0.3853976 , 0.36717843, 0.35536827,\n",
       "            0.32142856, 0.2969115 , 0.24584017, 0.23647999, 0.16031143,\n",
       "            0.15215059, 0.14238198, 0.1364278 , 0.13124176, 0.07863839,\n",
       "            0.0642016 , 0.05946149, 0.05421913, 0.03487573])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5790000000000001),\n",
       "                                     1: np.float64(0.42099999999999993)}),\n",
       "    'fpr': np.float64(0.11764705882352941),\n",
       "    'tpr': np.float64(0.0625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.44117647, 0.44117647, 0.67647059,\n",
       "            0.67647059, 0.73529412, 0.73529412, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.64803449, 0.51327795, 0.49773094, 0.4239004 ,\n",
       "            0.42317183, 0.4088962 , 0.39589151, 0.37578986, 0.36362839,\n",
       "            0.32903121, 0.3029706 , 0.25368487, 0.24173572, 0.16583995,\n",
       "            0.1571814 , 0.14632048, 0.14125757, 0.13575139, 0.08164214,\n",
       "            0.06662564, 0.06185844, 0.05646797, 0.03604293])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5690000000000001),\n",
       "                                     1: np.float64(0.43099999999999994)}),\n",
       "    'fpr': np.float64(0.11764705882352941),\n",
       "    'tpr': np.float64(0.125),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.47058824, 0.47058824, 0.67647059,\n",
       "            0.67647059, 0.73529412, 0.73529412, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.65540561, 0.5225594 , 0.50627407, 0.43267342,\n",
       "            0.43210353, 0.41831137, 0.40291764, 0.38453427, 0.3719003 ,\n",
       "            0.33659017, 0.30908406, 0.24831592, 0.24758718, 0.17091989,\n",
       "            0.16261482, 0.15046527, 0.14609324, 0.14041266, 0.08438679,\n",
       "            0.06894905, 0.06429975, 0.05876175, 0.03736474])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.559),\n",
       "                                     1: np.float64(0.44099999999999995)}),\n",
       "    'fpr': np.float64(0.14705882352941177),\n",
       "    'tpr': np.float64(0.125),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.23529412,\n",
       "            0.23529412, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.47058824, 0.47058824, 0.67647059,\n",
       "            0.67647059, 0.73529412, 0.73529412, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.66239631, 0.53213254, 0.51484626, 0.44116916,\n",
       "            0.44101599, 0.42806724, 0.40933923, 0.39314384, 0.37984833,\n",
       "            0.34413686, 0.31530982, 0.25505778, 0.25323666, 0.17591747,\n",
       "            0.1680884 , 0.15449727, 0.15072691, 0.14488456, 0.08721747,\n",
       "            0.07124776, 0.06673612, 0.06101818, 0.03862363])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.549),\n",
       "                                     1: np.float64(0.45099999999999996)}),\n",
       "    'fpr': np.float64(0.17647058823529413),\n",
       "    'tpr': np.float64(0.125),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.20588235,\n",
       "            0.20588235, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.47058824, 0.47058824, 0.67647059,\n",
       "            0.67647059, 0.76470588, 0.76470588, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.66909136, 0.54127155, 0.52338112, 0.49501718,\n",
       "            0.4496061 , 0.43770744, 0.41597739, 0.40160895, 0.38750007,\n",
       "            0.35171947, 0.32166158, 0.26197095, 0.25922756, 0.18110178,\n",
       "            0.17389778, 0.15600691, 0.1554292 , 0.14973138, 0.09009375,\n",
       "            0.07362641, 0.06938206, 0.06344358, 0.04008022])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5390000000000001),\n",
       "                                     1: np.float64(0.4609999999999999)}),\n",
       "    'fpr': np.float64(0.20588235294117646),\n",
       "    'tpr': np.float64(0.125),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.11764706, 0.11764706, 0.20588235,\n",
       "            0.20588235, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.47058824, 0.47058824, 0.67647059,\n",
       "            0.67647059, 0.76470588, 0.76470588, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.67552989, 0.5503902 , 0.53164601, 0.50442765,\n",
       "            0.45834574, 0.44718339, 0.42212822, 0.41020531, 0.395446  ,\n",
       "            0.3593961 , 0.32793214, 0.268995  , 0.26500747, 0.18644014,\n",
       "            0.17973766, 0.1620611 , 0.16048398, 0.15458388, 0.09322454,\n",
       "            0.07620284, 0.07212261, 0.0657405 , 0.04152866])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5290000000000001),\n",
       "                                     1: np.float64(0.4709999999999999)}),\n",
       "    'fpr': np.float64(0.20588235294117646),\n",
       "    'tpr': np.float64(0.125),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.14705882, 0.14705882, 0.20588235,\n",
       "            0.20588235, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.47058824, 0.47058824, 0.67647059,\n",
       "            0.67647059, 0.76470588, 0.76470588, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.68267202, 0.54306561, 0.54057406, 0.51449783,\n",
       "            0.46707861, 0.45688856, 0.42901648, 0.41869881, 0.40345662,\n",
       "            0.36733717, 0.33429324, 0.27637804, 0.27142714, 0.19175299,\n",
       "            0.18561033, 0.16746858, 0.16531665, 0.15960471, 0.09585492,\n",
       "            0.07843691, 0.0747415 , 0.06809933, 0.04296968])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5190000000000001),\n",
       "                                     1: np.float64(0.4809999999999999)}),\n",
       "    'fpr': np.float64(0.20588235294117646),\n",
       "    'tpr': np.float64(0.125),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.14705882, 0.14705882, 0.20588235,\n",
       "            0.20588235, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.47058824, 0.47058824, 0.67647059,\n",
       "            0.67647059, 0.76470588, 0.76470588, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.68829409, 0.55404188, 0.54853838, 0.52369547,\n",
       "            0.47557135, 0.46642861, 0.4349245 , 0.42733621, 0.41088536,\n",
       "            0.37503836, 0.34083263, 0.28307907, 0.27681914, 0.19701107,\n",
       "            0.19172282, 0.17174972, 0.17033098, 0.16452457, 0.09933077,\n",
       "            0.08119478, 0.07764933, 0.07035882, 0.04448204])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5090000000000001),\n",
       "                                     1: np.float64(0.49099999999999994)}),\n",
       "    'fpr': np.float64(0.20588235294117646),\n",
       "    'tpr': np.float64(0.125),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.14705882, 0.14705882, 0.20588235,\n",
       "            0.20588235, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.41176471, 0.41176471, 0.47058824, 0.47058824, 0.67647059,\n",
       "            0.67647059, 0.76470588, 0.76470588, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875, 0.375 ,\n",
       "            0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.69431697, 0.5649776 , 0.55685002, 0.53338658,\n",
       "            0.48430858, 0.47604934, 0.44124818, 0.43590009, 0.4185489 ,\n",
       "            0.38298585, 0.34748893, 0.2902173 , 0.28289997, 0.20249559,\n",
       "            0.19793735, 0.176332  , 0.17553427, 0.16972709, 0.1026741 ,\n",
       "            0.08392718, 0.08055786, 0.07281793, 0.04607004])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4990000000000001),\n",
       "                                     1: np.float64(0.5009999999999999)}),\n",
       "    'fpr': np.float64(0.20588235294117646),\n",
       "    'tpr': np.float64(0.125),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.26470588, 0.26470588, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.41176471, 0.41176471, 0.47058824,\n",
       "            0.47058824, 0.67647059, 0.67647059, 0.76470588, 0.76470588,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.70165915, 0.7010605 , 0.57627733, 0.56597526,\n",
       "            0.54326611, 0.49283265, 0.48603632, 0.44884874, 0.44422893,\n",
       "            0.42689649, 0.42627346, 0.39048929, 0.35399688, 0.29790797,\n",
       "            0.28993424, 0.20839387, 0.20466028, 0.18092817, 0.18054068,\n",
       "            0.17538668, 0.10540167, 0.08619863, 0.08366985, 0.07548088,\n",
       "            0.04784741])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4890000000000001),\n",
       "                                     1: np.float64(0.5109999999999999)}),\n",
       "    'fpr': np.float64(0.20588235294117646),\n",
       "    'tpr': np.float64(0.1875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.26470588, 0.26470588, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.41176471, 0.41176471, 0.52941176,\n",
       "            0.52941176, 0.67647059, 0.67647059, 0.76470588, 0.76470588,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.70993809, 0.70627466, 0.58673664, 0.57407653,\n",
       "            0.55278703, 0.50138563, 0.49542459, 0.45474666, 0.45304644,\n",
       "            0.43773329, 0.43405684, 0.39850868, 0.36106537, 0.29622808,\n",
       "            0.29596058, 0.21404698, 0.21119155, 0.18648296, 0.18633404,\n",
       "            0.18098732, 0.10926936, 0.08936798, 0.08693484, 0.07808091,\n",
       "            0.04965574])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4790000000000001),\n",
       "                                     1: np.float64(0.5209999999999999)}),\n",
       "    'fpr': np.float64(0.2647058823529412),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.26470588, 0.26470588, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.41176471, 0.41176471, 0.52941176,\n",
       "            0.52941176, 0.67647059, 0.67647059, 0.76470588, 0.76470588,\n",
       "            0.82352941, 0.82352941, 0.88235294, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.71885282, 0.71136694, 0.59698917, 0.58246004,\n",
       "            0.56183505, 0.50934227, 0.5050973 , 0.46122288, 0.46098263,\n",
       "            0.4484142 , 0.44117761, 0.40680824, 0.36812001, 0.30528041,\n",
       "            0.3019961 , 0.21990181, 0.21777721, 0.1929135 , 0.19178902,\n",
       "            0.18617167, 0.11321824, 0.09243303, 0.0905667 , 0.08079059,\n",
       "            0.05143988])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4690000000000001),\n",
       "                                     1: np.float64(0.5309999999999999)}),\n",
       "    'fpr': np.float64(0.2647058823529412),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.26470588, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.41176471, 0.41176471,\n",
       "            0.52941176, 0.52941176, 0.67647059, 0.67647059, 0.76470588,\n",
       "            0.76470588, 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.3125, 0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.625 , 0.625 ,\n",
       "            0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375,\n",
       "            1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.72760886, 0.71706049, 0.60715601, 0.5912427 ,\n",
       "            0.57168114, 0.51801338, 0.51461882, 0.48479848, 0.46935305,\n",
       "            0.46834105, 0.45890723, 0.44867992, 0.41481245, 0.37542992,\n",
       "            0.31452181, 0.30898911, 0.22593924, 0.22475778, 0.19930051,\n",
       "            0.19742302, 0.19201263, 0.11691503, 0.09540602, 0.09406652,\n",
       "            0.0836167 , 0.05338971])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4590000000000001),\n",
       "                                     1: np.float64(0.5409999999999999)}),\n",
       "    'fpr': np.float64(0.2647058823529412),\n",
       "    'tpr': np.float64(0.25),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.26470588,\n",
       "            0.26470588, 0.29411765, 0.29411765, 0.32352941, 0.32352941,\n",
       "            0.41176471, 0.41176471, 0.52941176, 0.52941176, 0.67647059,\n",
       "            0.67647059, 0.76470588, 0.76470588, 0.82352941, 0.82352941,\n",
       "            0.88235294, 0.88235294, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.375 , 0.4375, 0.4375, 0.5   , 0.5   ,\n",
       "            0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 ,\n",
       "            0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.73602129, 0.72237822, 0.61744934, 0.59977401,\n",
       "            0.58120056, 0.52633455, 0.52497814, 0.52282649, 0.52245325,\n",
       "            0.49277594, 0.47769316, 0.47518912, 0.46953699, 0.45609455,\n",
       "            0.4229952 , 0.38265748, 0.32399938, 0.31568009, 0.23209326,\n",
       "            0.23189488, 0.20589047, 0.20316358, 0.19793195, 0.12078556,\n",
       "            0.09849829, 0.09777908, 0.08653851, 0.05541586])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.44900000000000007),\n",
       "                                     1: np.float64(0.5509999999999999)}),\n",
       "    'fpr': np.float64(0.2647058823529412),\n",
       "    'tpr': np.float64(0.3125),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.23529412, 0.23529412, 0.26470588, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.35294118, 0.35294118, 0.41176471, 0.41176471,\n",
       "            0.52941176, 0.52941176, 0.64705882, 0.64705882, 0.76470588,\n",
       "            0.76470588, 0.82352941, 0.82352941, 0.88235294, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  ,\n",
       "            0.3125, 0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.625 , 0.625 ,\n",
       "            0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375,\n",
       "            1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.74429049, 0.72756713, 0.62761402, 0.60832412,\n",
       "            0.53475586, 0.53343174, 0.53022689, 0.5007516 , 0.48605102,\n",
       "            0.48211075, 0.46451529, 0.46348814, 0.43127037, 0.39005117,\n",
       "            0.3336388 , 0.32248508, 0.25317857, 0.23922728, 0.21263027,\n",
       "            0.20903806, 0.20402529, 0.12479678, 0.10169086, 0.10165216,\n",
       "            0.08955638, 0.0575423 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.43900000000000006),\n",
       "                                     1: np.float64(0.5609999999999999)}),\n",
       "    'fpr': np.float64(0.2647058823529412),\n",
       "    'tpr': np.float64(0.3125),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.23529412, 0.23529412, 0.26470588, 0.26470588, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.35294118, 0.41176471,\n",
       "            0.41176471, 0.52941176, 0.52941176, 0.64705882, 0.64705882,\n",
       "            0.76470588, 0.76470588, 0.82352941, 0.82352941, 0.85294118,\n",
       "            0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.25  , 0.25  ,\n",
       "            0.3125, 0.375 , 0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.625 ,\n",
       "            0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375,\n",
       "            0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.75232239, 0.73335831, 0.63855936, 0.61743278,\n",
       "            0.54452587, 0.54235621, 0.53815113, 0.50837837, 0.49390205,\n",
       "            0.49072782, 0.49046453, 0.473973  , 0.46992414, 0.43959648,\n",
       "            0.39791684, 0.34173863, 0.33016515, 0.26096186, 0.24702739,\n",
       "            0.21927195, 0.2143044 , 0.21065452, 0.12839348, 0.11317202,\n",
       "            0.10577213, 0.09302148, 0.06004321])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.42900000000000005),\n",
       "                                     1: np.float64(0.571)}),\n",
       "    'fpr': np.float64(0.3235294117647059),\n",
       "    'tpr': np.float64(0.375),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.26470588,\n",
       "            0.26470588, 0.29411765, 0.32352941, 0.32352941, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.64705882, 0.64705882, 0.76470588, 0.76470588, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.375 , 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.76043241, 0.73821038, 0.64707043, 0.6259594 ,\n",
       "            0.61002936, 0.55471212, 0.55440167, 0.55077889, 0.54571484,\n",
       "            0.51668946, 0.50235177, 0.50172597, 0.49733612, 0.4792038 ,\n",
       "            0.47748168, 0.44814631, 0.40598012, 0.34923815, 0.33713158,\n",
       "            0.26852853, 0.25466411, 0.22633698, 0.22063024, 0.21693907,\n",
       "            0.13300444, 0.11701519, 0.10995922, 0.09613722, 0.062299  ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.41900000000000004),\n",
       "                                     1: np.float64(0.581)}),\n",
       "    'fpr': np.float64(0.3235294117647059),\n",
       "    'tpr': np.float64(0.4375),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.26470588,\n",
       "            0.26470588, 0.29411765, 0.32352941, 0.32352941, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.64705882, 0.64705882, 0.76470588, 0.76470588, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.76860216, 0.74275975, 0.65571924, 0.63420225,\n",
       "            0.61908097, 0.56487032, 0.56446979, 0.55910276, 0.5528011 ,\n",
       "            0.52513923, 0.5129931 , 0.51059097, 0.5039934 , 0.49026696,\n",
       "            0.48467391, 0.45676065, 0.41417974, 0.35654308, 0.34386134,\n",
       "            0.27629328, 0.26250583, 0.23357074, 0.22701858, 0.22318933,\n",
       "            0.13815286, 0.12103418, 0.11450892, 0.0993534 , 0.06466197])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.40900000000000014),\n",
       "                                     1: np.float64(0.5909999999999999)}),\n",
       "    'fpr': np.float64(0.35294117647058826),\n",
       "    'tpr': np.float64(0.4375),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.26470588,\n",
       "            0.26470588, 0.29411765, 0.32352941, 0.32352941, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.64705882, 0.64705882, 0.76470588, 0.76470588, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.77610847, 0.74714293, 0.66383135, 0.64251786,\n",
       "            0.62689471, 0.57598812, 0.57402604, 0.56763879, 0.56005997,\n",
       "            0.53317333, 0.52437934, 0.51965315, 0.51052611, 0.49977903,\n",
       "            0.49254071, 0.46536595, 0.42289868, 0.3639418 , 0.35088638,\n",
       "            0.28451808, 0.27068206, 0.24079247, 0.23401933, 0.22993928,\n",
       "            0.14349899, 0.12516534, 0.11901817, 0.10259482, 0.06723566])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.39900000000000013),\n",
       "                                     1: np.float64(0.6009999999999999)}),\n",
       "    'fpr': np.float64(0.38235294117647056),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.26470588,\n",
       "            0.26470588, 0.29411765, 0.32352941, 0.32352941, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.64705882, 0.64705882, 0.76470588, 0.76470588, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.78367126, 0.75163017, 0.67190448, 0.65090483,\n",
       "            0.63504822, 0.58665825, 0.5838596 , 0.5757772 , 0.56766099,\n",
       "            0.54118001, 0.53522862, 0.5281308 , 0.51775481, 0.50880785,\n",
       "            0.50000204, 0.47385877, 0.43079885, 0.37176309, 0.35820514,\n",
       "            0.29279834, 0.27911426, 0.24841587, 0.24069701, 0.23609488,\n",
       "            0.14833108, 0.12965997, 0.1237833 , 0.10612731, 0.06994902])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3890000000000001),\n",
       "                                     1: np.float64(0.6109999999999999)}),\n",
       "    'fpr': np.float64(0.38235294117647056),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.26470588,\n",
       "            0.26470588, 0.29411765, 0.32352941, 0.32352941, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.64705882, 0.64705882, 0.76470588, 0.76470588, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.79133037, 0.75641616, 0.68013387, 0.65990529,\n",
       "            0.64396449, 0.59688616, 0.593981  , 0.58327543, 0.57589964,\n",
       "            0.54912661, 0.54546699, 0.53579538, 0.52634023, 0.51803882,\n",
       "            0.50705754, 0.48256632, 0.43786027, 0.38021447, 0.36610837,\n",
       "            0.30121965, 0.28772775, 0.2566031 , 0.24696063, 0.24226237,\n",
       "            0.15223954, 0.13472077, 0.12895021, 0.11012203, 0.0728225 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3790000000000001),\n",
       "                                     1: np.float64(0.6209999999999999)}),\n",
       "    'fpr': np.float64(0.38235294117647056),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.26470588,\n",
       "            0.26470588, 0.29411765, 0.32352941, 0.32352941, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.64705882, 0.64705882, 0.76470588, 0.76470588, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.79883746, 0.76112787, 0.68846861, 0.66879502,\n",
       "            0.65216823, 0.60793252, 0.60418096, 0.59190526, 0.58375462,\n",
       "            0.55713549, 0.5565236 , 0.54445774, 0.53474402, 0.52777747,\n",
       "            0.51433894, 0.49100552, 0.44578119, 0.38845945, 0.37442118,\n",
       "            0.3101777 , 0.29693576, 0.26444507, 0.25368149, 0.24867242,\n",
       "            0.15698414, 0.13997819, 0.13401383, 0.1140367 , 0.07602641])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3690000000000001),\n",
       "                                     1: np.float64(0.6309999999999999)}),\n",
       "    'fpr': np.float64(0.4117647058823529),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.64705882, 0.64705882, 0.76470588, 0.76470588, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.375 , 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.80647562, 0.76635278, 0.6972447 , 0.67819079,\n",
       "            0.65951451, 0.61805326, 0.61461165, 0.60098987, 0.56791795,\n",
       "            0.56667449, 0.55319185, 0.54304902, 0.54262329, 0.53614782,\n",
       "            0.52210193, 0.50038149, 0.45599486, 0.39612614, 0.38348265,\n",
       "            0.31849815, 0.3060167 , 0.27261843, 0.26139446, 0.25644206,\n",
       "            0.16303045, 0.14495903, 0.13944385, 0.11795609, 0.07914259])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3590000000000001),\n",
       "                                     1: np.float64(0.6409999999999999)}),\n",
       "    'fpr': np.float64(0.4117647058823529),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.64705882, 0.64705882, 0.76470588, 0.76470588, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.375 , 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.81362491, 0.77090112, 0.70545745, 0.6869824 ,\n",
       "            0.66728308, 0.6286047 , 0.62477435, 0.60944454, 0.57921373,\n",
       "            0.57538785, 0.56156245, 0.55391342, 0.55074813, 0.54529104,\n",
       "            0.52943944, 0.50972663, 0.4654697 , 0.40438628, 0.39209599,\n",
       "            0.32720387, 0.31541104, 0.28110412, 0.26887844, 0.26389915,\n",
       "            0.169071  , 0.15049949, 0.14524523, 0.12222139, 0.08254305])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3490000000000001),\n",
       "                                     1: np.float64(0.6509999999999999)}),\n",
       "    'fpr': np.float64(0.4117647058823529),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.64705882, 0.64705882, 0.76470588, 0.76470588, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.375 , 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.82022619, 0.77593563, 0.71328674, 0.69613064,\n",
       "            0.67534151, 0.63985919, 0.63426621, 0.61791681, 0.59018519,\n",
       "            0.58365641, 0.57038385, 0.56399059, 0.5592218 , 0.55495279,\n",
       "            0.53722715, 0.51922677, 0.47500461, 0.41290021, 0.40092005,\n",
       "            0.33632536, 0.32484719, 0.28947106, 0.27663138, 0.27129895,\n",
       "            0.17465906, 0.15597242, 0.15082782, 0.12663607, 0.08594574])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3390000000000001),\n",
       "                                     1: np.float64(0.6609999999999999)}),\n",
       "    'fpr': np.float64(0.4117647058823529),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.64705882, 0.64705882, 0.79411765, 0.79411765, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.375 , 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.82772152, 0.78018413, 0.72177228, 0.70518111,\n",
       "            0.68328533, 0.6497948 , 0.64506292, 0.62610346, 0.60159953,\n",
       "            0.59259133, 0.57884192, 0.57571231, 0.56811065, 0.56387405,\n",
       "            0.54460892, 0.5284296 , 0.48472239, 0.42118066, 0.41017601,\n",
       "            0.34497103, 0.33525567, 0.28462109, 0.28432767, 0.27921421,\n",
       "            0.18096223, 0.16236583, 0.15757929, 0.1311957 , 0.09001246])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.32900000000000007),\n",
       "                                     1: np.float64(0.6709999999999999)}),\n",
       "    'fpr': np.float64(0.4117647058823529),\n",
       "    'tpr': np.float64(0.5625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.67647059, 0.67647059, 0.79411765, 0.79411765, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.8344312 , 0.78413335, 0.72945511, 0.71366824,\n",
       "            0.69079385, 0.6599721 , 0.65483726, 0.63384381, 0.61276775,\n",
       "            0.60087719, 0.58701355, 0.5867779 , 0.5765266 , 0.57266389,\n",
       "            0.55139035, 0.53785236, 0.49418692, 0.42943879, 0.41855268,\n",
       "            0.3457696 , 0.34545238, 0.29292327, 0.29203187, 0.28712007,\n",
       "            0.18778983, 0.16887844, 0.16459669, 0.13600242, 0.09408339])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.31900000000000006),\n",
       "                                     1: np.float64(0.6809999999999999)}),\n",
       "    'fpr': np.float64(0.4411764705882353),\n",
       "    'tpr': np.float64(0.625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.67647059, 0.67647059, 0.79411765, 0.79411765, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.84126917, 0.78906784, 0.73776145, 0.72282921,\n",
       "            0.69846188, 0.67066485, 0.66553853, 0.64302695, 0.62423038,\n",
       "            0.61018841, 0.59791035, 0.5959364 , 0.58579877, 0.58243367,\n",
       "            0.55944601, 0.54740661, 0.50470354, 0.43828158, 0.42898854,\n",
       "            0.35797931, 0.35632036, 0.30243726, 0.3005926 , 0.29578256,\n",
       "            0.19459759, 0.17548518, 0.17122278, 0.14102958, 0.09846053])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.30900000000000005),\n",
       "                                     1: np.float64(0.691)}),\n",
       "    'fpr': np.float64(0.4411764705882353),\n",
       "    'tpr': np.float64(0.625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.67647059, 0.67647059, 0.79411765, 0.79411765, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.84805542, 0.79336953, 0.74579027, 0.73211953,\n",
       "            0.70640609, 0.68112398, 0.67565437, 0.65112838, 0.63531795,\n",
       "            0.61904483, 0.6097981 , 0.60449866, 0.59507847, 0.59162307,\n",
       "            0.56695416, 0.55755565, 0.51561733, 0.44677581, 0.43839378,\n",
       "            0.369291  , 0.3672611 , 0.31153161, 0.30904912, 0.30480258,\n",
       "            0.20204047, 0.18263293, 0.17885285, 0.14604766, 0.10298568])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.29900000000000015),\n",
       "                                     1: np.float64(0.7009999999999998)}),\n",
       "    'fpr': np.float64(0.47058823529411764),\n",
       "    'tpr': np.float64(0.625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.64705882, 0.64705882, 0.79411765, 0.79411765, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.85456426, 0.79784372, 0.7536481 , 0.74105775,\n",
       "            0.71393738, 0.6913959 , 0.68591954, 0.65944638, 0.64265677,\n",
       "            0.6280714 , 0.62128656, 0.61317769, 0.60452846, 0.60082633,\n",
       "            0.57457543, 0.56744221, 0.52617179, 0.4555511 , 0.44839562,\n",
       "            0.38293985, 0.37862105, 0.32116577, 0.31789577, 0.31401657,\n",
       "            0.20956773, 0.19009592, 0.18680654, 0.15167693, 0.10794987])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.28900000000000015),\n",
       "                                     1: np.float64(0.7109999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.64705882, 0.64705882, 0.79411765, 0.79411765, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.86060921, 0.80252746, 0.7612731 , 0.74983118,\n",
       "            0.72123477, 0.70187418, 0.69596819, 0.66830822, 0.6503115 ,\n",
       "            0.63723128, 0.63199778, 0.62203801, 0.61402935, 0.6104973 ,\n",
       "            0.5823954 , 0.57725326, 0.53713994, 0.46485582, 0.45915885,\n",
       "            0.39336932, 0.39031317, 0.33136191, 0.32718043, 0.3234818 ,\n",
       "            0.21760315, 0.19767524, 0.19464789, 0.15758016, 0.11316054])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.27900000000000014),\n",
       "                                     1: np.float64(0.7209999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.52941176, 0.52941176,\n",
       "            0.64705882, 0.64705882, 0.79411765, 0.79411765, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.86713408, 0.806929  , 0.76956047, 0.75923273,\n",
       "            0.72954069, 0.71255604, 0.70654478, 0.67686455, 0.65821336,\n",
       "            0.64629707, 0.64385139, 0.6312381 , 0.62414447, 0.62060282,\n",
       "            0.59056552, 0.58770236, 0.54851939, 0.47429389, 0.46999596,\n",
       "            0.40391441, 0.40263317, 0.34205386, 0.33665869, 0.33347677,\n",
       "            0.22576231, 0.20637393, 0.20341853, 0.16351919, 0.11888535])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.26900000000000013),\n",
       "                                     1: np.float64(0.7309999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.44117647, 0.44117647,\n",
       "            0.52941176, 0.52941176, 0.61764706, 0.61764706, 0.79411765,\n",
       "            0.79411765, 0.82352941, 0.82352941, 0.85294118, 0.85294118,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5   ,\n",
       "            0.5   , 0.5625, 0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.87330429, 0.81153795, 0.77713386, 0.76823374,\n",
       "            0.7366594 , 0.7226798 , 0.71689258, 0.68544638, 0.66539578,\n",
       "            0.65593811, 0.6557345 , 0.64011577, 0.63456835, 0.62987343,\n",
       "            0.59833804, 0.59818311, 0.56053699, 0.55926049, 0.55737829,\n",
       "            0.4832256 , 0.48116357, 0.42513857, 0.41518603, 0.35272874,\n",
       "            0.34638437, 0.34439943, 0.23498846, 0.21510604, 0.21271829,\n",
       "            0.17001182, 0.12500803])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2590000000000001),\n",
       "                                     1: np.float64(0.7409999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.625),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.23529412, 0.23529412, 0.32352941,\n",
       "            0.32352941, 0.35294118, 0.35294118, 0.41176471, 0.41176471,\n",
       "            0.44117647, 0.44117647, 0.52941176, 0.52941176, 0.61764706,\n",
       "            0.61764706, 0.79411765, 0.79411765, 0.82352941, 0.82352941,\n",
       "            0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.375 , 0.4375, 0.4375, 0.5625, 0.5625,\n",
       "            0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 ,\n",
       "            0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.8795489 , 0.8157667 , 0.7849525 , 0.77730446,\n",
       "            0.74461604, 0.73286508, 0.72718349, 0.69382265, 0.66794359,\n",
       "            0.66519734, 0.64906571, 0.64474013, 0.60866622, 0.57243016,\n",
       "            0.57163651, 0.56643604, 0.49279834, 0.49217914, 0.43732925,\n",
       "            0.42832426, 0.36391042, 0.35648207, 0.35530172, 0.24454176,\n",
       "            0.2247549 , 0.22285349, 0.17661821, 0.13159306])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2490000000000001),\n",
       "                                     1: np.float64(0.7509999999999999)}),\n",
       "    'fpr': np.float64(0.5294117647058824),\n",
       "    'tpr': np.float64(0.6875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.26470588, 0.26470588, 0.32352941,\n",
       "            0.32352941, 0.35294118, 0.35294118, 0.41176471, 0.41176471,\n",
       "            0.44117647, 0.44117647, 0.5       , 0.5       , 0.61764706,\n",
       "            0.61764706, 0.79411765, 0.79411765, 0.82352941, 0.82352941,\n",
       "            0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.375 , 0.4375, 0.4375, 0.5625, 0.5625,\n",
       "            0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.875 ,\n",
       "            0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.88545841, 0.82064051, 0.79286815, 0.7863222 ,\n",
       "            0.75208849, 0.74319778, 0.70437102, 0.70274245, 0.67955477,\n",
       "            0.67506585, 0.65827873, 0.65562681, 0.61977013, 0.58497925,\n",
       "            0.58377108, 0.57608832, 0.56249456, 0.50436783, 0.44967179,\n",
       "            0.44149723, 0.37534151, 0.36707568, 0.36692815, 0.25436186,\n",
       "            0.23435145, 0.23284274, 0.18369379, 0.1384273 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2390000000000001),\n",
       "                                     1: np.float64(0.7609999999999999)}),\n",
       "    'fpr': np.float64(0.5294117647058824),\n",
       "    'tpr': np.float64(0.6875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.26470588, 0.26470588, 0.32352941,\n",
       "            0.32352941, 0.35294118, 0.35294118, 0.41176471, 0.41176471,\n",
       "            0.44117647, 0.44117647, 0.5       , 0.5       , 0.61764706,\n",
       "            0.61764706, 0.82352941, 0.82352941, 0.82352941, 0.85294118,\n",
       "            0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.375 , 0.4375, 0.4375, 0.5625, 0.5625,\n",
       "            0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.9375,\n",
       "            0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.8909361 , 0.825143  , 0.80042671, 0.795369  ,\n",
       "            0.75980352, 0.75369927, 0.71555621, 0.71137775, 0.68880916,\n",
       "            0.68427377, 0.66773266, 0.66651788, 0.63044964, 0.59720691,\n",
       "            0.5960393 , 0.58586152, 0.57607775, 0.51660398, 0.46268896,\n",
       "            0.45512281, 0.37858066, 0.37817531, 0.26436028, 0.24503136,\n",
       "            0.24360657, 0.19142667, 0.14612927])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2290000000000001),\n",
       "                                     1: np.float64(0.7709999999999999)}),\n",
       "    'fpr': np.float64(0.5294117647058824),\n",
       "    'tpr': np.float64(0.6875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.26470588, 0.26470588, 0.32352941,\n",
       "            0.32352941, 0.35294118, 0.41176471, 0.41176471, 0.44117647,\n",
       "            0.44117647, 0.5       , 0.5       , 0.61764706, 0.61764706,\n",
       "            0.82352941, 0.82352941, 0.85294118, 0.85294118, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.375 , 0.4375, 0.4375, 0.5625, 0.5625, 0.625 ,\n",
       "            0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.89664037, 0.82950512, 0.80794453, 0.80446948,\n",
       "            0.76778488, 0.76404349, 0.7268602 , 0.71993548, 0.69688585,\n",
       "            0.67770977, 0.67696501, 0.64171915, 0.61019063, 0.60878961,\n",
       "            0.59577014, 0.5894778 , 0.52882219, 0.4758188 , 0.46944474,\n",
       "            0.39139123, 0.27561182, 0.25669275, 0.2554183 , 0.19939238,\n",
       "            0.15428402])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.21900000000000008),\n",
       "                                     1: np.float64(0.7809999999999999)}),\n",
       "    'fpr': np.float64(0.5588235294117647),\n",
       "    'tpr': np.float64(0.6875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.20588235, 0.20588235, 0.26470588, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.41176471,\n",
       "            0.41176471, 0.47058824, 0.47058824, 0.5       , 0.5       ,\n",
       "            0.61764706, 0.61764706, 0.82352941, 0.82352941, 0.82352941,\n",
       "            0.85294118, 0.85294118, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5625,\n",
       "            0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.9375, 0.9375, 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.90255586, 0.83453354, 0.81586006, 0.81351532,\n",
       "            0.77506559, 0.77391156, 0.73889496, 0.72914074, 0.71587001,\n",
       "            0.70452928, 0.70423709, 0.68917977, 0.68676461, 0.65327492,\n",
       "            0.62439622, 0.60898219, 0.60536155, 0.60366668, 0.54220545,\n",
       "            0.48887385, 0.48457451, 0.40553602, 0.40166487, 0.28829776,\n",
       "            0.26838319, 0.26820481, 0.2077934 , 0.16327182])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.20900000000000007),\n",
       "                                     1: np.float64(0.7909999999999999)}),\n",
       "    'fpr': np.float64(0.6176470588235294),\n",
       "    'tpr': np.float64(0.6875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.11764706, 0.11764706,\n",
       "            0.17647059, 0.17647059, 0.26470588, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.41176471,\n",
       "            0.41176471, 0.5       , 0.5       , 0.61764706, 0.61764706,\n",
       "            0.82352941, 0.82352941, 0.82352941, 0.85294118, 0.85294118,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5625,\n",
       "            0.5625, 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 0.9375, 0.9375,\n",
       "            1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.9074451 , 0.8389218 , 0.8230352 , 0.82245116,\n",
       "            0.81863535, 0.78424439, 0.74973696, 0.7375372 , 0.72711359,\n",
       "            0.71379432, 0.71268059, 0.70076047, 0.69654234, 0.66470623,\n",
       "            0.63780783, 0.61777549, 0.55556503, 0.50335333, 0.49952178,\n",
       "            0.41925609, 0.4143796 , 0.30026156, 0.28167329, 0.28138722,\n",
       "            0.21718332, 0.1732183 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.19900000000000018),\n",
       "                                     1: np.float64(0.8009999999999998)}),\n",
       "    'fpr': np.float64(0.6176470588235294),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.08823529, 0.08823529,\n",
       "            0.17647059, 0.17647059, 0.26470588, 0.26470588, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.32352941, 0.35294118, 0.41176471,\n",
       "            0.41176471, 0.5       , 0.5       , 0.61764706, 0.61764706,\n",
       "            0.82352941, 0.82352941, 0.82352941, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5625,\n",
       "            0.5625, 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.91301722, 0.84434712, 0.84084548, 0.83150087,\n",
       "            0.82752703, 0.79448367, 0.76170048, 0.74725154, 0.73968313,\n",
       "            0.72481567, 0.7208269 , 0.71297333, 0.70672047, 0.67685264,\n",
       "            0.65250156, 0.63219968, 0.56998083, 0.51737246, 0.51542032,\n",
       "            0.43463005, 0.42763418, 0.29522796, 0.2268093 , 0.18345511])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.18900000000000017),\n",
       "                                     1: np.float64(0.8109999999999998)}),\n",
       "    'fpr': np.float64(0.6470588235294118),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.05882353, 0.05882353, 0.08823529,\n",
       "            0.08823529, 0.17647059, 0.17647059, 0.26470588, 0.26470588,\n",
       "            0.29411765, 0.29411765, 0.32352941, 0.32352941, 0.35294118,\n",
       "            0.41176471, 0.41176471, 0.5       , 0.5       , 0.61764706,\n",
       "            0.61764706, 0.82352941, 0.82352941, 0.82352941, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875,\n",
       "            0.1875, 0.25  , 0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375,\n",
       "            0.5625, 0.5625, 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.91815871, 0.85075539, 0.84932429, 0.84820868,\n",
       "            0.84036082, 0.83335658, 0.80454774, 0.77314614, 0.75642713,\n",
       "            0.75204597, 0.73527278, 0.72918806, 0.72523962, 0.71700202,\n",
       "            0.68901886, 0.66728634, 0.64667433, 0.58446106, 0.5320926 ,\n",
       "            0.53198542, 0.45062841, 0.44156353, 0.31037108, 0.23730834,\n",
       "            0.19506473])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.17900000000000016),\n",
       "                                     1: np.float64(0.8209999999999998)}),\n",
       "    'fpr': np.float64(0.7352941176470589),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.08823529, 0.08823529, 0.17647059,\n",
       "            0.17647059, 0.26470588, 0.26470588, 0.29411765, 0.29411765,\n",
       "            0.32352941, 0.32352941, 0.35294118, 0.41176471, 0.41176471,\n",
       "            0.5       , 0.5       , 0.58823529, 0.58823529, 0.82352941,\n",
       "            0.82352941, 0.82352941, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.125 , 0.125 , 0.1875, 0.1875, 0.25  ,\n",
       "            0.25  , 0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5625, 0.5625,\n",
       "            0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.92312946, 0.85549732, 0.8491509 , 0.83930856,\n",
       "            0.81454484, 0.78452333, 0.76565445, 0.76442169, 0.74589705,\n",
       "            0.73773728, 0.73770777, 0.72747184, 0.70150386, 0.679427  ,\n",
       "            0.66136887, 0.59947017, 0.56217949, 0.54910489, 0.46761643,\n",
       "            0.45632428, 0.32662939, 0.24871408, 0.20776407])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.16900000000000015),\n",
       "                                     1: np.float64(0.8309999999999998)}),\n",
       "    'fpr': np.float64(0.7352941176470589),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.08823529, 0.08823529, 0.17647059,\n",
       "            0.17647059, 0.29411765, 0.29411765, 0.32352941, 0.35294118,\n",
       "            0.41176471, 0.41176471, 0.5       , 0.5       , 0.58823529,\n",
       "            0.58823529, 0.82352941, 0.82352941, 0.82352941, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.125 , 0.125 , 0.1875, 0.1875, 0.375 ,\n",
       "            0.375 , 0.4375, 0.4375, 0.5625, 0.5625, 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.92798564, 0.86273119, 0.85783883, 0.84534466,\n",
       "            0.82450527, 0.77688017, 0.7505835 , 0.74653482, 0.73807781,\n",
       "            0.71426786, 0.68983721, 0.67614042, 0.61495259, 0.58062916,\n",
       "            0.56694191, 0.48557291, 0.47173602, 0.34414979, 0.2611685 ,\n",
       "            0.22181082])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.15900000000000014),\n",
       "                                     1: np.float64(0.8409999999999999)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.08823529, 0.08823529, 0.17647059,\n",
       "            0.17647059, 0.29411765, 0.29411765, 0.32352941, 0.35294118,\n",
       "            0.41176471, 0.41176471, 0.44117647, 0.44117647, 0.5       ,\n",
       "            0.5       , 0.58823529, 0.58823529, 0.82352941, 0.82352941,\n",
       "            0.82352941, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.125 , 0.125 , 0.1875, 0.1875, 0.375 ,\n",
       "            0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.5625, 0.5625, 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.93265017, 0.86982717, 0.86495766, 0.85149845,\n",
       "            0.83452066, 0.78902449, 0.76379971, 0.75557765, 0.74911952,\n",
       "            0.72710779, 0.71358493, 0.70230149, 0.70070297, 0.69109342,\n",
       "            0.6310861 , 0.59961371, 0.5850429 , 0.50400924, 0.48787205,\n",
       "            0.36249492, 0.27449794, 0.23723764])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.14900000000000013),\n",
       "                                     1: np.float64(0.8509999999999999)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(0.875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.08823529, 0.08823529, 0.11764706,\n",
       "            0.11764706, 0.17647059, 0.17647059, 0.29411765, 0.29411765,\n",
       "            0.32352941, 0.35294118, 0.41176471, 0.41176471, 0.47058824,\n",
       "            0.47058824, 0.5       , 0.5       , 0.58823529, 0.58823529,\n",
       "            0.82352941, 0.82352941, 0.82352941, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875,\n",
       "            0.1875, 0.375 , 0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.5625,\n",
       "            0.5625, 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.93722929, 0.87691106, 0.87503001, 0.87249508,\n",
       "            0.87050784, 0.85785139, 0.84430784, 0.80165135, 0.7768638 ,\n",
       "            0.76442221, 0.76069406, 0.74033385, 0.73026164, 0.71475733,\n",
       "            0.71231133, 0.70653636, 0.64809107, 0.61530884, 0.60448429,\n",
       "            0.52466069, 0.50567142, 0.38290137, 0.28923692, 0.25489421])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.13900000000000012),\n",
       "                                     1: np.float64(0.8609999999999999)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(0.875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.08823529, 0.08823529, 0.11764706,\n",
       "            0.11764706, 0.17647059, 0.17647059, 0.29411765, 0.29411765,\n",
       "            0.32352941, 0.35294118, 0.41176471, 0.41176471, 0.47058824,\n",
       "            0.47058824, 0.5       , 0.5       , 0.58823529, 0.58823529,\n",
       "            0.82352941, 0.82352941, 0.82352941, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875,\n",
       "            0.1875, 0.375 , 0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.5625,\n",
       "            0.5625, 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.94165033, 0.88393626, 0.88370207, 0.88118463,\n",
       "            0.8763861 , 0.86454842, 0.85431454, 0.81390721, 0.79018181,\n",
       "            0.77441098, 0.77243332, 0.75421788, 0.74689457, 0.73078712,\n",
       "            0.7246209 , 0.72224271, 0.66597619, 0.62940088, 0.62427308,\n",
       "            0.54521469, 0.52430886, 0.4045406 , 0.30574798, 0.27400917])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.12900000000000011),\n",
       "                                     1: np.float64(0.8709999999999999)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(0.875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.11764706, 0.11764706,\n",
       "            0.17647059, 0.17647059, 0.29411765, 0.29411765, 0.32352941,\n",
       "            0.41176471, 0.41176471, 0.5       , 0.5       , 0.55882353,\n",
       "            0.55882353, 0.82352941, 0.82352941, 0.82352941, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.94606065, 0.89208641, 0.88973384, 0.88231014,\n",
       "            0.87129388, 0.86403748, 0.82644911, 0.80185659, 0.78444582,\n",
       "            0.76798129, 0.76374886, 0.73808762, 0.68443593, 0.66230001,\n",
       "            0.64504114, 0.56594108, 0.54397781, 0.42816831, 0.32370401,\n",
       "            0.29575415])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1190000000000001),\n",
       "                                     1: np.float64(0.8809999999999999)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(0.875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.17647059, 0.17647059, 0.29411765, 0.29411765, 0.32352941,\n",
       "            0.41176471, 0.41176471, 0.5       , 0.5       , 0.55882353,\n",
       "            0.55882353, 0.82352941, 0.82352941, 0.82352941, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.95020579, 0.90050288, 0.88934296, 0.88844495,\n",
       "            0.87819156, 0.87373143, 0.83880943, 0.81358165, 0.79672584,\n",
       "            0.78239282, 0.78094601, 0.75442675, 0.70360745, 0.6846487 ,\n",
       "            0.66631411, 0.58793283, 0.56526965, 0.45416357, 0.34412557,\n",
       "            0.32021844])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1090000000000001),\n",
       "                                     1: np.float64(0.8909999999999999)}),\n",
       "    'fpr': np.float64(0.8235294117647058),\n",
       "    'tpr': np.float64(0.875),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.17647059, 0.17647059, 0.29411765, 0.29411765, 0.32352941,\n",
       "            0.38235294, 0.38235294, 0.5       , 0.5       , 0.55882353,\n",
       "            0.55882353, 0.82352941, 0.82352941, 0.82352941, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.95416045, 0.90870497, 0.89654778, 0.89515152,\n",
       "            0.88559647, 0.88346678, 0.85122685, 0.82595379, 0.81010966,\n",
       "            0.80520506, 0.7994709 , 0.7706892 , 0.72393406, 0.70832122,\n",
       "            0.68899948, 0.60946758, 0.58837747, 0.48144017, 0.36646695,\n",
       "            0.34778838])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.09900000000000009),\n",
       "                                     1: np.float64(0.9009999999999999)}),\n",
       "    'fpr': np.float64(0.8529411764705882),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.17647059, 0.17647059, 0.29411765, 0.29411765, 0.32352941,\n",
       "            0.35294118, 0.35294118, 0.5       , 0.5       , 0.55882353,\n",
       "            0.55882353, 0.82352941, 0.82352941, 0.82352941, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.95793544, 0.91684025, 0.90387282, 0.90220846,\n",
       "            0.89337741, 0.89321646, 0.86324553, 0.83873517, 0.82380524,\n",
       "            0.82068468, 0.81780621, 0.78771735, 0.74574381, 0.73294327,\n",
       "            0.71220231, 0.63194258, 0.61354447, 0.51140198, 0.39285848,\n",
       "            0.3791843 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.08900000000000019),\n",
       "                                     1: np.float64(0.9109999999999998)}),\n",
       "    'fpr': np.float64(0.8823529411764706),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.29411765, 0.29411765, 0.32352941, 0.32352941, 0.5       ,\n",
       "            0.5       , 0.55882353, 0.55882353, 0.82352941, 0.82352941,\n",
       "            0.82352941, 0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.375 , 0.4375,\n",
       "            0.5   , 0.5   , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.96163174, 0.92484125, 0.91116506, 0.90281347,\n",
       "            0.87565143, 0.8514632 , 0.83811188, 0.83624816, 0.80478533,\n",
       "            0.767532  , 0.75827825, 0.736589  , 0.65585345, 0.64037122,\n",
       "            0.54454528, 0.4221931 , 0.41530598])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.07900000000000018),\n",
       "                                     1: np.float64(0.9209999999999998)}),\n",
       "    'fpr': np.float64(0.8823529411764706),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.29411765, 0.29411765, 0.32352941, 0.5       , 0.5       ,\n",
       "            0.55882353, 0.55882353, 0.82352941, 0.82352941, 0.82352941,\n",
       "            0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.4375, 0.5   ,\n",
       "            0.5   , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 1.    , 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.96506249, 0.93274942, 0.91852058, 0.91246667,\n",
       "            0.88781599, 0.85512711, 0.853253  , 0.82247935, 0.79057733,\n",
       "            0.78328767, 0.76213097, 0.68155265, 0.66992839, 0.58088642,\n",
       "            0.49006909, 0.45703263, 0.45665501])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.06900000000000017),\n",
       "                                     1: np.float64(0.9309999999999998)}),\n",
       "    'fpr': np.float64(0.9705882352941176),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.14705882, 0.14705882,\n",
       "            0.29411765, 0.29411765, 0.32352941, 0.5       , 0.5       ,\n",
       "            0.55882353, 0.55882353, 0.82352941, 0.82352941, 0.82352941,\n",
       "            0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.4375, 0.5   ,\n",
       "            0.5   , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 , 1.    , 1.    ,\n",
       "            1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.96838984, 0.94051907, 0.92592508, 0.92198531,\n",
       "            0.89994997, 0.87402424, 0.86881182, 0.84065993, 0.81471362,\n",
       "            0.80719708, 0.78848776, 0.70957795, 0.70203524, 0.62070487,\n",
       "            0.53159644, 0.50476536, 0.4969367 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.05900000000000016),\n",
       "                                     1: np.float64(0.9409999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.11764706, 0.11764706,\n",
       "            0.14705882, 0.14705882, 0.29411765, 0.29411765, 0.32352941,\n",
       "            0.5       , 0.5       , 0.55882353, 0.55882353, 0.82352941,\n",
       "            0.82352941, 0.82352941, 0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.4375, 0.5   , 0.5   , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            1.    , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.97146021, 0.94816862, 0.9380864 , 0.93371472,\n",
       "            0.93357263, 0.93159472, 0.91173177, 0.89312461, 0.8856073 ,\n",
       "            0.85908044, 0.84025083, 0.83195498, 0.81534956, 0.74057544,\n",
       "            0.73869083, 0.66431056, 0.58098781, 0.55996994, 0.5463113 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.049000000000000155),\n",
       "                                     1: np.float64(0.9509999999999998)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.11764706, 0.11764706,\n",
       "            0.14705882, 0.14705882, 0.23529412, 0.23529412, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.5       , 0.5       , 0.52941176,\n",
       "            0.52941176, 0.55882353, 0.55882353, 0.79411765, 0.79411765,\n",
       "            0.82352941, 0.82352941, 0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.4375, 0.5   , 0.5   , 0.5625, 0.5625, 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 1.    , 1.    , 1.    ,\n",
       "            1.    ]),\n",
       "     'thresholds': array([       inf, 0.97452   , 0.95584605, 0.94545347, 0.94301147,\n",
       "            0.94165547, 0.94119266, 0.93130931, 0.92444171, 0.92323042,\n",
       "            0.90822384, 0.90291784, 0.87784836, 0.87682197, 0.86748454,\n",
       "            0.86444844, 0.85740146, 0.84413237, 0.79632105, 0.77780045,\n",
       "            0.77492121, 0.71306899, 0.63819433, 0.62453993, 0.60368761])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.039000000000000146),\n",
       "                                     1: np.float64(0.9609999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.11764706, 0.11764706,\n",
       "            0.23529412, 0.23529412, 0.29411765, 0.29411765, 0.32352941,\n",
       "            0.47058824, 0.47058824, 0.52941176, 0.52941176, 0.55882353,\n",
       "            0.55882353, 0.79411765, 0.79411765, 0.82352941, 0.82352941,\n",
       "            0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  ,\n",
       "            0.4375, 0.5   , 0.5   , 0.5625, 0.5625, 0.6875, 0.6875, 0.75  ,\n",
       "            0.75  , 0.875 , 0.875 , 1.    , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.9773945 , 0.96351331, 0.95321878, 0.95089184,\n",
       "            0.94280123, 0.93994227, 0.9355584 , 0.92373065, 0.92103999,\n",
       "            0.90138762, 0.90080873, 0.89566408, 0.89058124, 0.88384835,\n",
       "            0.87381286, 0.83183243, 0.82144998, 0.81371318, 0.7674265 ,\n",
       "            0.70538934, 0.69855798, 0.6741622 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.029000000000000137),\n",
       "                                     1: np.float64(0.9709999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.05882353, 0.05882353,\n",
       "            0.11764706, 0.11764706, 0.20588235, 0.20588235, 0.23529412,\n",
       "            0.23529412, 0.29411765, 0.29411765, 0.32352941, 0.44117647,\n",
       "            0.44117647, 0.5       , 0.5       , 0.52941176, 0.52941176,\n",
       "            0.58823529, 0.58823529, 0.79411765, 0.79411765, 0.82352941,\n",
       "            0.82352941, 0.91176471, 0.97058824, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.125 , 0.125 , 0.1875, 0.1875,\n",
       "            0.25  , 0.25  , 0.3125, 0.3125, 0.4375, 0.5   , 0.5   , 0.5625,\n",
       "            0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 1.    , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.98014629, 0.97118775, 0.96885006, 0.96338441,\n",
       "            0.96123853, 0.96084734, 0.95839526, 0.95526938, 0.954481  ,\n",
       "            0.95000575, 0.94911975, 0.94031448, 0.94022572, 0.92803553,\n",
       "            0.92628461, 0.92359719, 0.92351918, 0.91908777, 0.91869973,\n",
       "            0.90513596, 0.90466545, 0.87254235, 0.86884823, 0.85706532,\n",
       "            0.82676768, 0.78303296, 0.7813288 , 0.75828264])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.019000000000000128),\n",
       "                                     1: np.float64(0.9809999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.05882353, 0.05882353,\n",
       "            0.14705882, 0.14705882, 0.20588235, 0.20588235, 0.29411765,\n",
       "            0.29411765, 0.32352941, 0.35294118, 0.35294118, 0.38235294,\n",
       "            0.38235294, 0.41176471, 0.41176471, 0.5       , 0.5       ,\n",
       "            0.64705882, 0.64705882, 0.76470588, 0.76470588, 0.82352941,\n",
       "            0.82352941, 0.85294118, 0.85294118, 0.88235294, 0.94117647,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.1875, 0.1875, 0.25  , 0.25  ,\n",
       "            0.3125, 0.3125, 0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.5625,\n",
       "            0.5625, 0.625 , 0.625 , 0.6875, 0.6875, 0.75  , 0.75  , 0.875 ,\n",
       "            0.875 , 0.9375, 0.9375, 1.    , 1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.98313757, 0.97904234, 0.97677884, 0.9713661 ,\n",
       "            0.97016871, 0.97016402, 0.96900479, 0.9677158 , 0.96292916,\n",
       "            0.96056236, 0.95990459, 0.95878446, 0.95849947, 0.95699885,\n",
       "            0.95250538, 0.95214236, 0.95170118, 0.94876617, 0.94792013,\n",
       "            0.93700226, 0.93676415, 0.92193733, 0.91880202, 0.90670195,\n",
       "            0.89567317, 0.89141019, 0.8913915 , 0.87765137, 0.86930694,\n",
       "            0.85450911])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.009000000000000119),\n",
       "                                     1: np.float64(0.9909999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02941176, 0.02941176, 0.05882353, 0.05882353,\n",
       "            0.08823529, 0.08823529, 0.26470588, 0.26470588, 0.29411765,\n",
       "            0.35294118, 0.35294118, 0.38235294, 0.38235294, 0.44117647,\n",
       "            0.44117647, 0.64705882, 0.64705882, 0.76470588, 0.76470588,\n",
       "            0.82352941, 0.82352941, 0.85294118, 0.85294118, 0.88235294,\n",
       "            0.94117647, 1.        ]),\n",
       "     'tpr': array([0.    , 0.    , 0.0625, 0.0625, 0.25  , 0.25  , 0.3125, 0.3125,\n",
       "            0.375 , 0.4375, 0.4375, 0.5   , 0.5   , 0.625 , 0.625 , 0.6875,\n",
       "            0.6875, 0.75  , 0.75  , 0.875 , 0.875 , 0.9375, 0.9375, 1.    ,\n",
       "            1.    , 1.    , 1.    ]),\n",
       "     'thresholds': array([       inf, 0.98786562, 0.98773074, 0.98623162, 0.98425461,\n",
       "            0.98386613, 0.98376864, 0.98133459, 0.98053503, 0.9802462 ,\n",
       "            0.97959083, 0.97914304, 0.97895699, 0.97814345, 0.97701389,\n",
       "            0.97664449, 0.97159912, 0.97069843, 0.9670623 , 0.96667356,\n",
       "            0.95978301, 0.95848323, 0.95681433, 0.95613818, 0.95286895,\n",
       "            0.95130752, 0.94742231])}}],\n",
       "  [{'model': LogisticRegression(class_weight={0: np.float64(0.999), 1: np.float64(0.001)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.07894737, 0.07894737, 0.10526316,\n",
       "            0.10526316, 0.15789474, 0.15789474, 0.31578947, 0.31578947,\n",
       "            0.5       , 0.5       , 0.86842105, 0.86842105, 0.89473684,\n",
       "            0.89473684, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.08333333, 0.08333333,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.66666667,\n",
       "            0.66666667, 0.75      , 0.75      , 0.83333333, 0.83333333,\n",
       "            0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.00053436, 0.00053366, 0.00053259, 0.00052784,\n",
       "            0.00052049, 0.00051868, 0.00051216, 0.00049984, 0.00049492,\n",
       "            0.00048651, 0.00048632, 0.0004702 , 0.00047017, 0.00046941,\n",
       "            0.00046859, 0.00046634, 0.00046625])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.989), 1: np.float64(0.011)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.05263158, 0.05263158, 0.10526316,\n",
       "            0.10526316, 0.26315789, 0.26315789, 0.36842105, 0.36842105,\n",
       "            0.47368421, 0.47368421, 0.73684211, 0.73684211, 0.92105263,\n",
       "            0.92105263, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.41666667, 0.41666667, 0.58333333, 0.58333333, 0.66666667,\n",
       "            0.66666667, 0.75      , 0.75      , 0.83333333, 0.83333333,\n",
       "            0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.0082937 , 0.00799381, 0.00786093, 0.00775849,\n",
       "            0.00693774, 0.006018  , 0.00510082, 0.0045969 , 0.00455591,\n",
       "            0.00439782, 0.00438808, 0.00338305, 0.00336303, 0.00323974,\n",
       "            0.00318652, 0.00310182, 0.00302342])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.979),\n",
       "                                     1: np.float64(0.020999999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.05263158, 0.05263158, 0.10526316,\n",
       "            0.10526316, 0.26315789, 0.26315789, 0.36842105, 0.36842105,\n",
       "            0.47368421, 0.47368421, 0.73684211, 0.73684211, 0.94736842,\n",
       "            0.94736842, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.41666667, 0.41666667, 0.58333333, 0.58333333, 0.66666667,\n",
       "            0.66666667, 0.75      , 0.75      , 0.83333333, 0.83333333,\n",
       "            0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.01986472, 0.01939458, 0.01899153, 0.0182793 ,\n",
       "            0.01564358, 0.01215887, 0.00962301, 0.00831256, 0.00820787,\n",
       "            0.00765448, 0.00756149, 0.00514855, 0.00509656, 0.00463274,\n",
       "            0.00459397, 0.00441049, 0.00421442])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.969),\n",
       "                                     1: np.float64(0.030999999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.05263158, 0.05263158, 0.10526316,\n",
       "            0.10526316, 0.26315789, 0.26315789, 0.36842105, 0.36842105,\n",
       "            0.47368421, 0.47368421, 0.76315789, 0.76315789, 0.94736842,\n",
       "            0.94736842, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.41666667, 0.41666667, 0.58333333, 0.58333333, 0.66666667,\n",
       "            0.66666667, 0.75      , 0.75      , 0.83333333, 0.83333333,\n",
       "            0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.03336475, 0.03320084, 0.03272991, 0.03064564,\n",
       "            0.02474494, 0.01824977, 0.01392321, 0.0117618 , 0.01170299,\n",
       "            0.01047822, 0.01023002, 0.00646386, 0.00642612, 0.00560456,\n",
       "            0.00556505, 0.00526407, 0.00494288])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.959),\n",
       "                                     1: np.float64(0.040999999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.10526316, 0.10526316,\n",
       "            0.13157895, 0.13157895, 0.26315789, 0.26315789, 0.36842105,\n",
       "            0.36842105, 0.47368421, 0.47368421, 0.73684211, 0.73684211,\n",
       "            0.92105263, 0.92105263, 1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.04859948, 0.04780867, 0.04411149, 0.03608949,\n",
       "            0.0346074 , 0.03389298, 0.02458261, 0.01799278, 0.01517172,\n",
       "            0.0149969 , 0.01305516, 0.01265503, 0.00767815, 0.00761421,\n",
       "            0.00643492, 0.00639116, 0.00590804, 0.00546363])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9490000000000001),\n",
       "                                     1: np.float64(0.05099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.36842105, 0.36842105, 0.47368421,\n",
       "            0.47368421, 0.73684211, 0.73684211, 0.89473684, 0.89473684,\n",
       "            1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.06548296, 0.06493061, 0.06396135, 0.05744464,\n",
       "            0.04651694, 0.04474914, 0.04214504, 0.03070642, 0.02830016,\n",
       "            0.02254475, 0.02187605, 0.01858182, 0.01838707, 0.01560569,\n",
       "            0.01483628, 0.00901901, 0.0088584 , 0.00764087, 0.00725265,\n",
       "            0.00655813, 0.00596598])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.9390000000000001),\n",
       "                                     1: np.float64(0.06099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.36842105, 0.36842105, 0.47368421,\n",
       "            0.47368421, 0.73684211, 0.73684211, 0.89473684, 0.89473684,\n",
       "            1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.08328412, 0.08092269, 0.08001481, 0.071065  ,\n",
       "            0.05717675, 0.05445059, 0.05044462, 0.0367857 , 0.03357705,\n",
       "            0.02702984, 0.02568993, 0.02195066, 0.02143645, 0.01802073,\n",
       "            0.01688587, 0.01020288, 0.00993662, 0.00845691, 0.00796163,\n",
       "            0.00713263, 0.0064033 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.929), 1: np.float64(0.071)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.28947368, 0.28947368, 0.36842105, 0.36842105, 0.5       ,\n",
       "            0.5       , 0.73684211, 0.73684211, 0.89473684, 0.89473684,\n",
       "            1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.10162128, 0.09702873, 0.0961398 , 0.08441345,\n",
       "            0.06774982, 0.06409829, 0.05825419, 0.04299082, 0.03881818,\n",
       "            0.03151846, 0.02934278, 0.02538429, 0.02442296, 0.01894747,\n",
       "            0.01889912, 0.01138463, 0.0110688 , 0.00919249, 0.00873203,\n",
       "            0.00768828, 0.00683986])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.919),\n",
       "                                     1: np.float64(0.08099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.31578947, 0.31578947, 0.36842105, 0.36842105, 0.5       ,\n",
       "            0.5       , 0.73684211, 0.73684211, 0.89473684, 0.89473684,\n",
       "            1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.12034209, 0.11231322, 0.11183151, 0.09727492,\n",
       "            0.07829638, 0.07331189, 0.0653982 , 0.04898087, 0.04406411,\n",
       "            0.03313971, 0.0329121 , 0.02879035, 0.02737795, 0.02109529,\n",
       "            0.02084212, 0.01260915, 0.01217719, 0.00991327, 0.0094802 ,\n",
       "            0.00813607, 0.00728647])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.909),\n",
       "                                     1: np.float64(0.09099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.26315789, 0.26315789,\n",
       "            0.31578947, 0.31578947, 0.36842105, 0.36842105, 0.5       ,\n",
       "            0.5       , 0.73684211, 0.73684211, 0.92105263, 0.92105263,\n",
       "            1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.13960845, 0.12767276, 0.12740334, 0.10982586,\n",
       "            0.08908727, 0.08222819, 0.0726996 , 0.05524451, 0.04924495,\n",
       "            0.03682258, 0.03648569, 0.03238912, 0.03010392, 0.02325796,\n",
       "            0.02280091, 0.01378028, 0.01330213, 0.01025094, 0.01023964,\n",
       "            0.00853315, 0.00772066])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.899),\n",
       "                                     1: np.float64(0.10099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.15789474, 0.15789474, 0.26315789, 0.26315789,\n",
       "            0.31578947, 0.31578947, 0.36842105, 0.36842105, 0.5       ,\n",
       "            0.5       , 0.73684211, 0.73684211, 0.92105263, 0.92105263,\n",
       "            1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.15956626, 0.14293502, 0.14277931, 0.12202837,\n",
       "            0.1002963 , 0.08086056, 0.07998331, 0.06160958, 0.05428685,\n",
       "            0.04039616, 0.04002274, 0.03596742, 0.03252744, 0.02541489,\n",
       "            0.02458831, 0.01488603, 0.01435293, 0.01105959, 0.01094215,\n",
       "            0.00884887, 0.00811287])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.889),\n",
       "                                     1: np.float64(0.11099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.10526316, 0.10526316,\n",
       "            0.18421053, 0.18421053, 0.26315789, 0.26315789, 0.31578947,\n",
       "            0.31578947, 0.36842105, 0.36842105, 0.52631579, 0.52631579,\n",
       "            0.73684211, 0.73684211, 0.92105263, 0.92105263, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.1796181 , 0.15756228, 0.13416245, 0.11127713,\n",
       "            0.08756834, 0.08626953, 0.06774844, 0.05982788, 0.04438105,\n",
       "            0.04351265, 0.03967283, 0.03544381, 0.02662864, 0.02655839,\n",
       "            0.01622974, 0.01551804, 0.01181405, 0.01173998, 0.00929578,\n",
       "            0.00860179])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.879),\n",
       "                                     1: np.float64(0.12099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.10526316, 0.10526316,\n",
       "            0.21052632, 0.21052632, 0.26315789, 0.26315789, 0.31578947,\n",
       "            0.31578947, 0.36842105, 0.36842105, 0.52631579, 0.52631579,\n",
       "            0.73684211, 0.73684211, 0.89473684, 0.89473684, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.19915805, 0.17185639, 0.14515579, 0.12226982,\n",
       "            0.09272486, 0.09251264, 0.07425083, 0.06521875, 0.04812068,\n",
       "            0.04699826, 0.04336478, 0.03790057, 0.02934277, 0.02844999,\n",
       "            0.01746849, 0.01673883, 0.01295675, 0.01262272, 0.00974903,\n",
       "            0.00910241])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.869),\n",
       "                                     1: np.float64(0.13099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.10526316, 0.10526316,\n",
       "            0.21052632, 0.21052632, 0.26315789, 0.26315789, 0.31578947,\n",
       "            0.31578947, 0.36842105, 0.36842105, 0.52631579, 0.52631579,\n",
       "            0.73684211, 0.73684211, 0.89473684, 0.89473684, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.21908774, 0.18625735, 0.15612749, 0.13312585,\n",
       "            0.10077612, 0.09863006, 0.08052455, 0.07064665, 0.0517546 ,\n",
       "            0.0505111 , 0.0467763 , 0.04039715, 0.03209193, 0.03033486,\n",
       "            0.01869581, 0.0179138 , 0.01389933, 0.01343325, 0.01013849,\n",
       "            0.00958054])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.859), 1: np.float64(0.141)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.10526316, 0.10526316,\n",
       "            0.21052632, 0.21052632, 0.26315789, 0.26315789, 0.31578947,\n",
       "            0.31578947, 0.36842105, 0.36842105, 0.55263158, 0.55263158,\n",
       "            0.73684211, 0.73684211, 0.89473684, 0.89473684, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.23882482, 0.19972484, 0.16614524, 0.14417704,\n",
       "            0.10883826, 0.10443132, 0.08711819, 0.07597187, 0.05543275,\n",
       "            0.05409392, 0.05034581, 0.0426817 , 0.03222261, 0.03221382,\n",
       "            0.01995665, 0.01918541, 0.01486767, 0.01435192, 0.0105559 ,\n",
       "            0.01010207])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.849),\n",
       "                                     1: np.float64(0.15099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.10526316, 0.10526316,\n",
       "            0.21052632, 0.21052632, 0.26315789, 0.26315789, 0.31578947,\n",
       "            0.31578947, 0.36842105, 0.36842105, 0.55263158, 0.55263158,\n",
       "            0.73684211, 0.73684211, 0.89473684, 0.89473684, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.25796906, 0.21277348, 0.17594147, 0.15489351,\n",
       "            0.11662817, 0.10996997, 0.09347344, 0.08149212, 0.05908617,\n",
       "            0.05755483, 0.05381689, 0.04507035, 0.03477662, 0.03410056,\n",
       "            0.02123234, 0.02043539, 0.01570899, 0.01525147, 0.01098302,\n",
       "            0.01062752])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.839),\n",
       "                                     1: np.float64(0.16099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.10526316, 0.10526316,\n",
       "            0.21052632, 0.21052632, 0.26315789, 0.26315789, 0.31578947,\n",
       "            0.31578947, 0.39473684, 0.39473684, 0.55263158, 0.55263158,\n",
       "            0.73684211, 0.73684211, 0.89473684, 0.89473684, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.27691171, 0.22545525, 0.18514507, 0.16577319,\n",
       "            0.12439665, 0.11509801, 0.10002687, 0.08715287, 0.06288224,\n",
       "            0.06097478, 0.04801709, 0.04747068, 0.03740602, 0.03605432,\n",
       "            0.02255735, 0.02174556, 0.01651144, 0.01622006, 0.01144294,\n",
       "            0.01117415])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.829),\n",
       "                                     1: np.float64(0.17099999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.        , 0.10526316, 0.10526316,\n",
       "            0.21052632, 0.21052632, 0.26315789, 0.26315789, 0.31578947,\n",
       "            0.31578947, 0.42105263, 0.42105263, 0.55263158, 0.55263158,\n",
       "            0.73684211, 0.73684211, 0.89473684, 0.89473684, 1.        ,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.29663416, 0.23879875, 0.19563788, 0.17717386,\n",
       "            0.13206961, 0.12072933, 0.10639828, 0.09368258, 0.06680312,\n",
       "            0.06461053, 0.05028596, 0.04990983, 0.03992735, 0.03797159,\n",
       "            0.02388345, 0.02295423, 0.01734947, 0.01711971, 0.01195245,\n",
       "            0.011769  ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.8190000000000001),\n",
       "                                     1: np.float64(0.18099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.21052632, 0.21052632, 0.26315789, 0.26315789,\n",
       "            0.31578947, 0.31578947, 0.42105263, 0.42105263, 0.55263158,\n",
       "            0.55263158, 0.76315789, 0.76315789, 0.89473684, 0.89473684,\n",
       "            1.        , 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        ]),\n",
       "     'thresholds': array([       inf, 0.31470815, 0.25201605, 0.25050038, 0.20452161,\n",
       "            0.18792179, 0.13971757, 0.12586245, 0.11226355, 0.09968414,\n",
       "            0.07062228, 0.06803287, 0.05351927, 0.05240804, 0.04269864,\n",
       "            0.03996002, 0.02448137, 0.02428082, 0.01818654, 0.01810063,\n",
       "            0.01242218, 0.01236327])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.809),\n",
       "                                     1: np.float64(0.19099999999999998)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.10526316, 0.10526316, 0.21052632, 0.21052632,\n",
       "            0.26315789, 0.26315789, 0.34210526, 0.34210526, 0.42105263,\n",
       "            0.42105263, 0.55263158, 0.55263158, 0.76315789, 0.76315789,\n",
       "            0.89473684, 0.89473684, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.33350153, 0.26683603, 0.26257999, 0.22745258,\n",
       "            0.2148193 , 0.21435909, 0.1988439 , 0.14679613, 0.13061285,\n",
       "            0.11709333, 0.10664316, 0.07173126, 0.07149845, 0.05674617,\n",
       "            0.05492122, 0.04537439, 0.04182067, 0.02606132, 0.02548697,\n",
       "            0.01906245, 0.01901255, 0.01624915, 0.01299153, 0.01294929])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.799),\n",
       "                                     1: np.float64(0.20099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.10526316, 0.10526316, 0.21052632, 0.21052632,\n",
       "            0.26315789, 0.26315789, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.44736842, 0.55263158, 0.55263158, 0.76315789, 0.76315789,\n",
       "            0.86842105, 0.86842105, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.35144962, 0.28019001, 0.27335941, 0.23787893,\n",
       "            0.22549269, 0.22311129, 0.21010915, 0.1543875 , 0.13539683,\n",
       "            0.12171157, 0.11318994, 0.07596296, 0.07498041, 0.05729494,\n",
       "            0.05722457, 0.04751935, 0.04377292, 0.02772432, 0.02680692,\n",
       "            0.02023141, 0.02003439, 0.01701842, 0.01362475, 0.01345001])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.789),\n",
       "                                     1: np.float64(0.21099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.10526316, 0.10526316, 0.21052632, 0.21052632,\n",
       "            0.26315789, 0.26315789, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.44736842, 0.55263158, 0.55263158, 0.76315789, 0.76315789,\n",
       "            0.86842105, 0.86842105, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.36847644, 0.2939888 , 0.2848417 , 0.2478511 ,\n",
       "            0.23672528, 0.2308249 , 0.22088831, 0.16185468, 0.14032502,\n",
       "            0.12673954, 0.11955079, 0.08025703, 0.07844289, 0.06043669,\n",
       "            0.0595818 , 0.04956696, 0.04575772, 0.02943833, 0.02824249,\n",
       "            0.02123383, 0.02114693, 0.01786274, 0.0142589 , 0.01396954])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.779),\n",
       "                                     1: np.float64(0.22099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.10526316, 0.10526316, 0.21052632, 0.21052632,\n",
       "            0.26315789, 0.26315789, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.44736842, 0.55263158, 0.55263158, 0.76315789, 0.76315789,\n",
       "            0.86842105, 0.86842105, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.3857182 , 0.30822861, 0.29575832, 0.25805069,\n",
       "            0.24787807, 0.23940098, 0.23197071, 0.16913305, 0.14515317,\n",
       "            0.13149543, 0.12662341, 0.08471816, 0.08214369, 0.06412409,\n",
       "            0.06210368, 0.05178615, 0.047775  , 0.03105736, 0.02961725,\n",
       "            0.02227687, 0.02222117, 0.01853438, 0.01499049, 0.01452893])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.769),\n",
       "                                     1: np.float64(0.23099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.10526316, 0.10526316, 0.21052632, 0.21052632,\n",
       "            0.26315789, 0.26315789, 0.34210526, 0.34210526, 0.44736842,\n",
       "            0.44736842, 0.55263158, 0.55263158, 0.76315789, 0.76315789,\n",
       "            0.84210526, 0.84210526, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.40229208, 0.32139952, 0.30647955, 0.26832699,\n",
       "            0.25861799, 0.24694689, 0.24274862, 0.17627234, 0.14955805,\n",
       "            0.13622861, 0.13349862, 0.08925959, 0.08598565, 0.06752342,\n",
       "            0.06454354, 0.05404485, 0.04994939, 0.03253596, 0.0311214 ,\n",
       "            0.02342746, 0.02341247, 0.01918502, 0.01574427, 0.01509933])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.759),\n",
       "                                     1: np.float64(0.24099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.10526316, 0.10526316, 0.21052632, 0.21052632,\n",
       "            0.26315789, 0.26315789, 0.34210526, 0.34210526, 0.47368421,\n",
       "            0.47368421, 0.55263158, 0.55263158, 0.76315789, 0.76315789,\n",
       "            0.81578947, 0.81578947, 0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.41829406, 0.33579846, 0.31723242, 0.27834726,\n",
       "            0.26977575, 0.25500758, 0.25340972, 0.18324699, 0.15453317,\n",
       "            0.14123405, 0.14096833, 0.09366607, 0.08959933, 0.06743642,\n",
       "            0.06694717, 0.05616201, 0.05196988, 0.03402168, 0.03258781,\n",
       "            0.02679154, 0.02459693, 0.01983441, 0.01650832, 0.01574413])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7490000000000001),\n",
       "                                     1: np.float64(0.25099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.21052632, 0.21052632, 0.23684211, 0.23684211,\n",
       "            0.34210526, 0.34210526, 0.47368421, 0.47368421, 0.55263158,\n",
       "            0.55263158, 0.76315789, 0.76315789, 0.81578947, 0.81578947,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.43403992, 0.3493268 , 0.32712343, 0.28804691,\n",
       "            0.26428264, 0.19039503, 0.15910944, 0.15840431, 0.14866014,\n",
       "            0.0983054 , 0.0931899 , 0.07110457, 0.06946686, 0.05841428,\n",
       "            0.05408565, 0.03558108, 0.03404531, 0.0279468 , 0.02577879,\n",
       "            0.02048074, 0.0172913 , 0.01634317])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7390000000000001),\n",
       "                                     1: np.float64(0.26099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.23684211, 0.23684211, 0.34210526, 0.34210526,\n",
       "            0.47368421, 0.47368421, 0.55263158, 0.55263158, 0.76315789,\n",
       "            0.76315789, 0.81578947, 0.81578947, 0.97368421, 0.97368421,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.44946614, 0.36286264, 0.33696832, 0.2979663 ,\n",
       "            0.27553332, 0.16508618, 0.15645198, 0.1027848 , 0.0969101 ,\n",
       "            0.0748133 , 0.07199261, 0.06060471, 0.05615467, 0.03718615,\n",
       "            0.03550931, 0.02909871, 0.02697696, 0.02113144, 0.01808974,\n",
       "            0.01695491])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7290000000000001),\n",
       "                                     1: np.float64(0.27099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.23684211, 0.23684211, 0.34210526, 0.34210526,\n",
       "            0.47368421, 0.47368421, 0.55263158, 0.55263158, 0.76315789,\n",
       "            0.76315789, 0.81578947, 0.81578947, 0.97368421, 0.97368421,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.46553234, 0.37684254, 0.34721112, 0.30875903,\n",
       "            0.28694504, 0.17180215, 0.16428036, 0.10721181, 0.10112319,\n",
       "            0.07859926, 0.07441027, 0.06293097, 0.05831269, 0.03886622,\n",
       "            0.03702122, 0.03032672, 0.02822422, 0.0218025 , 0.01897841,\n",
       "            0.01760822])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7190000000000001),\n",
       "                                     1: np.float64(0.28099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.23684211, 0.23684211, 0.34210526, 0.34210526,\n",
       "            0.47368421, 0.47368421, 0.55263158, 0.55263158, 0.76315789,\n",
       "            0.76315789, 0.81578947, 0.81578947, 0.97368421, 0.97368421,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.48048501, 0.39069883, 0.35691517, 0.31843606,\n",
       "            0.29759468, 0.17839957, 0.17240485, 0.11128205, 0.10476287,\n",
       "            0.08238122, 0.07688304, 0.06517416, 0.0604411 , 0.04044364,\n",
       "            0.03851726, 0.03153591, 0.02946933, 0.022443  , 0.0198132 ,\n",
       "            0.01823777])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.7090000000000001),\n",
       "                                     1: np.float64(0.291)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.23684211, 0.23684211, 0.34210526, 0.34210526,\n",
       "            0.47368421, 0.47368421, 0.55263158, 0.55263158, 0.76315789,\n",
       "            0.76315789, 0.81578947, 0.81578947, 0.97368421, 0.97368421,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.49510517, 0.40457243, 0.36637706, 0.32794328,\n",
       "            0.30856356, 0.18491503, 0.17775656, 0.11558504, 0.10856103,\n",
       "            0.08629777, 0.07942913, 0.06746608, 0.06257106, 0.04216434,\n",
       "            0.04005907, 0.03284194, 0.03075186, 0.02312197, 0.02073316,\n",
       "            0.0189424 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6990000000000001),\n",
       "                                     1: np.float64(0.30099999999999993)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.23684211, 0.23684211, 0.34210526, 0.34210526,\n",
       "            0.47368421, 0.47368421, 0.55263158, 0.55263158, 0.76315789,\n",
       "            0.76315789, 0.81578947, 0.81578947, 0.97368421, 0.97368421,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.50853666, 0.41848339, 0.37540169, 0.33719852,\n",
       "            0.31935517, 0.19133583, 0.18255329, 0.11996265, 0.11207999,\n",
       "            0.09016247, 0.08207994, 0.06965281, 0.06463927, 0.04389532,\n",
       "            0.04154433, 0.03410897, 0.03203762, 0.023806  , 0.02165834,\n",
       "            0.01968534])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.6890000000000001),\n",
       "                                     1: np.float64(0.31099999999999994)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.21052632, 0.21052632, 0.23684211, 0.23684211,\n",
       "            0.34210526, 0.34210526, 0.5       , 0.5       , 0.55263158,\n",
       "            0.55263158, 0.76315789, 0.76315789, 0.81578947, 0.81578947,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.52304813, 0.43214044, 0.38469444, 0.34757287,\n",
       "            0.33043775, 0.23179174, 0.1985689 , 0.19844681, 0.18674486,\n",
       "            0.12431285, 0.11639657, 0.08478481, 0.08437846, 0.07203977,\n",
       "            0.06693702, 0.04553556, 0.04319312, 0.0354263 , 0.03347129,\n",
       "            0.02446213, 0.02263888, 0.02037296])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.679),\n",
       "                                     1: np.float64(0.32099999999999995)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.21052632, 0.21052632, 0.23684211, 0.23684211,\n",
       "            0.34210526, 0.34210526, 0.5       , 0.5       , 0.55263158,\n",
       "            0.55263158, 0.76315789, 0.76315789, 0.81578947, 0.81578947,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.53575312, 0.44543459, 0.39336363, 0.35680859,\n",
       "            0.34139736, 0.2386542 , 0.20782766, 0.20528425, 0.19181176,\n",
       "            0.12896982, 0.12045131, 0.08852623, 0.08716804, 0.07454147,\n",
       "            0.06926197, 0.04745125, 0.04488894, 0.0369127 , 0.03494225,\n",
       "            0.02525122, 0.02372219, 0.02119881])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.669),\n",
       "                                     1: np.float64(0.33099999999999996)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.21052632, 0.21052632, 0.23684211, 0.23684211,\n",
       "            0.34210526, 0.34210526, 0.5       , 0.5       , 0.55263158,\n",
       "            0.55263158, 0.76315789, 0.76315789, 0.81578947, 0.81578947,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.54867714, 0.45898166, 0.40215177, 0.36637368,\n",
       "            0.35230225, 0.2453539 , 0.21727137, 0.21207784, 0.19662575,\n",
       "            0.13356694, 0.12452422, 0.09225047, 0.08987321, 0.07698338,\n",
       "            0.07155915, 0.04931172, 0.04656419, 0.03837112, 0.03641457,\n",
       "            0.02599727, 0.02480483, 0.02201024])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.659),\n",
       "                                     1: np.float64(0.34099999999999997)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.21052632, 0.21052632, 0.23684211, 0.23684211,\n",
       "            0.34210526, 0.34210526, 0.5       , 0.5       , 0.55263158,\n",
       "            0.55263158, 0.78947368, 0.78947368, 0.81578947, 0.81578947,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.56129525, 0.47266627, 0.41079181, 0.37577366,\n",
       "            0.36294371, 0.25181943, 0.22687444, 0.21876979, 0.20149969,\n",
       "            0.13819659, 0.128509  , 0.09606442, 0.09261689, 0.07943387,\n",
       "            0.07388368, 0.04848162, 0.04829135, 0.03990266, 0.03795222,\n",
       "            0.02679173, 0.02594883, 0.0228858 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.649),\n",
       "                                     1: np.float64(0.3509999999999999)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.21052632, 0.21052632, 0.23684211, 0.23684211,\n",
       "            0.34210526, 0.34210526, 0.5       , 0.5       , 0.55263158,\n",
       "            0.55263158, 0.78947368, 0.78947368, 0.81578947, 0.81578947,\n",
       "            0.97368421, 0.97368421, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.57360374, 0.48653572, 0.41897708, 0.38485098,\n",
       "            0.37366656, 0.25806073, 0.23659107, 0.22525171, 0.20660944,\n",
       "            0.14284686, 0.13230816, 0.09987412, 0.09523995, 0.08175334,\n",
       "            0.07596142, 0.05093052, 0.04984823, 0.04138084, 0.03936249,\n",
       "            0.02750476, 0.02707249, 0.02372627])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.639),\n",
       "                                     1: np.float64(0.36099999999999993)}),\n",
       "    'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.21052632, 0.21052632, 0.23684211, 0.23684211,\n",
       "            0.34210526, 0.34210526, 0.5       , 0.5       , 0.55263158,\n",
       "            0.55263158, 0.78947368, 0.78947368, 0.81578947, 0.81578947,\n",
       "            0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.58577432, 0.49975146, 0.42776915, 0.39483544,\n",
       "            0.38506864, 0.26504351, 0.24694042, 0.23249036, 0.21109922,\n",
       "            0.14778221, 0.13703783, 0.10393738, 0.0981172 , 0.08435973,\n",
       "            0.07842697, 0.05348489, 0.05167741, 0.04294069, 0.04100664,\n",
       "            0.03416081, 0.02827805, 0.02456684])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.629),\n",
       "                                     1: np.float64(0.37099999999999994)}),\n",
       "    'fpr': np.float64(0.02631578947368421),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.05263158,\n",
       "            0.05263158, 0.07894737, 0.07894737, 0.21052632, 0.21052632,\n",
       "            0.23684211, 0.23684211, 0.34210526, 0.34210526, 0.5       ,\n",
       "            0.5       , 0.55263158, 0.55263158, 0.78947368, 0.78947368,\n",
       "            0.84210526, 0.84210526, 0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.5976313 , 0.51363587, 0.43569777, 0.4344852 ,\n",
       "            0.40415035, 0.40407915, 0.3959272 , 0.27124959, 0.25777955,\n",
       "            0.23901876, 0.21636527, 0.15274826, 0.14085709, 0.10807214,\n",
       "            0.10098582, 0.08682726, 0.08064718, 0.05623144, 0.05327128,\n",
       "            0.04251928, 0.0424985 , 0.03555085, 0.02954385, 0.02553232])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.619),\n",
       "                                     1: np.float64(0.38099999999999995)}),\n",
       "    'fpr': np.float64(0.02631578947368421),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.21052632, 0.21052632, 0.23684211, 0.23684211,\n",
       "            0.34210526, 0.34210526, 0.5       , 0.5       , 0.55263158,\n",
       "            0.55263158, 0.78947368, 0.78947368, 0.86842105, 0.86842105,\n",
       "            0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.60915067, 0.52696761, 0.44374338, 0.41376526,\n",
       "            0.40713448, 0.27782537, 0.26855961, 0.24604418, 0.2213007 ,\n",
       "            0.15786288, 0.14532946, 0.11237601, 0.10382209, 0.08942289,\n",
       "            0.08303695, 0.05904562, 0.05502537, 0.04427937, 0.04414693,\n",
       "            0.03703382, 0.03087312, 0.02648686])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.609),\n",
       "                                     1: np.float64(0.39099999999999996)}),\n",
       "    'fpr': np.float64(0.02631578947368421),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.05263158,\n",
       "            0.05263158, 0.07894737, 0.07894737, 0.21052632, 0.21052632,\n",
       "            0.23684211, 0.23684211, 0.34210526, 0.34210526, 0.5       ,\n",
       "            0.5       , 0.57894737, 0.57894737, 0.78947368, 0.78947368,\n",
       "            0.86842105, 0.86842105, 0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.62016062, 0.54012426, 0.45184932, 0.45098447,\n",
       "            0.42380419, 0.42287676, 0.41781816, 0.28435212, 0.2793844 ,\n",
       "            0.25301403, 0.22654194, 0.16290237, 0.14963966, 0.11670708,\n",
       "            0.1068169 , 0.08625902, 0.0855355 , 0.06148117, 0.05691099,\n",
       "            0.04616272, 0.04589334, 0.03863928, 0.03225475, 0.02751543])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5990000000000001),\n",
       "                                     1: np.float64(0.4009999999999999)}),\n",
       "    'fpr': np.float64(0.02631578947368421),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.05263158,\n",
       "            0.05263158, 0.07894737, 0.07894737, 0.21052632, 0.21052632,\n",
       "            0.23684211, 0.23684211, 0.34210526, 0.34210526, 0.5       ,\n",
       "            0.5       , 0.57894737, 0.57894737, 0.78947368, 0.78947368,\n",
       "            0.86842105, 0.86842105, 0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.63068633, 0.5530181 , 0.4603631 , 0.45933329,\n",
       "            0.43327085, 0.43221139, 0.42850312, 0.29116915, 0.28994902,\n",
       "            0.26043378, 0.23157573, 0.16789129, 0.15456222, 0.1210476 ,\n",
       "            0.10976079, 0.08994318, 0.08817989, 0.06362833, 0.05900498,\n",
       "            0.04815157, 0.04782512, 0.04034666, 0.03367028, 0.02853725])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5890000000000001),\n",
       "                                     1: np.float64(0.4109999999999999)}),\n",
       "    'fpr': np.float64(0.02631578947368421),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.05263158,\n",
       "            0.05263158, 0.07894737, 0.07894737, 0.18421053, 0.18421053,\n",
       "            0.23684211, 0.23684211, 0.36842105, 0.36842105, 0.5       ,\n",
       "            0.5       , 0.57894737, 0.57894737, 0.78947368, 0.78947368,\n",
       "            0.86842105, 0.86842105, 0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.64162503, 0.56600626, 0.46777118, 0.46742297,\n",
       "            0.44350379, 0.44142378, 0.43926677, 0.32497859, 0.30134523,\n",
       "            0.26735416, 0.23705024, 0.15871204, 0.158596  , 0.12560819,\n",
       "            0.11259867, 0.09387683, 0.09063494, 0.06589998, 0.06079871,\n",
       "            0.05012201, 0.04956415, 0.04180536, 0.03516065, 0.02964852])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5790000000000001),\n",
       "                                     1: np.float64(0.42099999999999993)}),\n",
       "    'fpr': np.float64(0.02631578947368421),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.05263158,\n",
       "            0.05263158, 0.07894737, 0.07894737, 0.18421053, 0.18421053,\n",
       "            0.23684211, 0.23684211, 0.36842105, 0.36842105, 0.5       ,\n",
       "            0.5       , 0.57894737, 0.57894737, 0.78947368, 0.78947368,\n",
       "            0.86842105, 0.86842105, 0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.33333333, 0.33333333, 0.41666667,\n",
       "            0.41666667, 0.5       , 0.5       , 0.58333333, 0.58333333,\n",
       "            0.66666667, 0.66666667, 0.75      , 0.75      , 0.83333333,\n",
       "            0.83333333, 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.65170557, 0.57898713, 0.47592984, 0.47570029,\n",
       "            0.45322654, 0.45078715, 0.45001786, 0.33361147, 0.31279046,\n",
       "            0.27460739, 0.24251674, 0.16468252, 0.16360586, 0.13037275,\n",
       "            0.11581032, 0.09794259, 0.093357  , 0.06831129, 0.06290432,\n",
       "            0.05232288, 0.05156415, 0.04320241, 0.03678805, 0.03084401])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5690000000000001),\n",
       "                                     1: np.float64(0.43099999999999994)}),\n",
       "    'fpr': np.float64(0.02631578947368421),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.23684211, 0.23684211, 0.36842105, 0.36842105,\n",
       "            0.5       , 0.5       , 0.60526316, 0.60526316, 0.78947368,\n",
       "            0.78947368, 0.86842105, 0.86842105, 0.94736842, 0.94736842,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.33333333, 0.33333333,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.66161463, 0.48402385, 0.46064913, 0.34196746,\n",
       "            0.32441329, 0.2820302 , 0.24823984, 0.17077447, 0.16829842,\n",
       "            0.13503422, 0.11883804, 0.0962171 , 0.09605791, 0.0706124 ,\n",
       "            0.06496259, 0.054467  , 0.05353993, 0.04453348, 0.03839023,\n",
       "            0.03203439])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.559),\n",
       "                                     1: np.float64(0.44099999999999995)}),\n",
       "    'fpr': np.float64(0.02631578947368421),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.23684211, 0.23684211, 0.36842105, 0.36842105,\n",
       "            0.5       , 0.5       , 0.60526316, 0.60526316, 0.78947368,\n",
       "            0.78947368, 0.86842105, 0.86842105, 0.94736842, 0.94736842,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.33333333, 0.33333333,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.67143009, 0.49240009, 0.47107684, 0.35070616,\n",
       "            0.3363058 , 0.28915862, 0.25393315, 0.17696014, 0.17296394,\n",
       "            0.13979752, 0.12200881, 0.09926712, 0.0987885 , 0.07299654,\n",
       "            0.06699458, 0.05669908, 0.05551081, 0.04591845, 0.04005734,\n",
       "            0.03326896])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.549),\n",
       "                                     1: np.float64(0.45099999999999996)}),\n",
       "    'fpr': np.float64(0.05263157894736842),\n",
       "    'tpr': np.float64(0.08333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.23684211, 0.23684211, 0.36842105, 0.36842105,\n",
       "            0.5       , 0.5       , 0.63157895, 0.63157895, 0.78947368,\n",
       "            0.78947368, 0.86842105, 0.86842105, 0.94736842, 0.94736842,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.33333333, 0.33333333,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.68101078, 0.50040302, 0.48183688, 0.35931542,\n",
       "            0.34846872, 0.29647727, 0.2596864 , 0.18329084, 0.17790464,\n",
       "            0.14485725, 0.12527588, 0.10198643, 0.10149365, 0.07554188,\n",
       "            0.06910555, 0.05906496, 0.05758589, 0.04738886, 0.04183791,\n",
       "            0.03456536])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5390000000000001),\n",
       "                                     1: np.float64(0.4609999999999999)}),\n",
       "    'fpr': np.float64(0.05263157894736842),\n",
       "    'tpr': np.float64(0.16666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.23684211, 0.23684211, 0.36842105, 0.36842105,\n",
       "            0.5       , 0.5       , 0.63157895, 0.63157895, 0.78947368,\n",
       "            0.78947368, 0.86842105, 0.86842105, 0.94736842, 0.94736842,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.33333333, 0.33333333,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.690477  , 0.50785145, 0.49209197, 0.3679859 ,\n",
       "            0.36103141, 0.30383778, 0.26534882, 0.18977037, 0.18321984,\n",
       "            0.15020207, 0.12872889, 0.10565839, 0.10423224, 0.07820248,\n",
       "            0.07125707, 0.06156215, 0.05972942, 0.0489404 , 0.04374007,\n",
       "            0.03588568])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5290000000000001),\n",
       "                                     1: np.float64(0.4709999999999999)}),\n",
       "    'fpr': np.float64(0.05263157894736842),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.18421053,\n",
       "            0.18421053, 0.23684211, 0.23684211, 0.36842105, 0.36842105,\n",
       "            0.5       , 0.5       , 0.63157895, 0.63157895, 0.78947368,\n",
       "            0.78947368, 0.86842105, 0.86842105, 0.94736842, 0.94736842,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.33333333, 0.33333333,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.69948783, 0.51611595, 0.50221934, 0.37676877,\n",
       "            0.37352556, 0.31118621, 0.27155059, 0.1964402 , 0.18798863,\n",
       "            0.15553406, 0.13216154, 0.10898949, 0.10705483, 0.08100094,\n",
       "            0.07350621, 0.06416461, 0.06196577, 0.05055135, 0.04570272,\n",
       "            0.03737428])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5190000000000001),\n",
       "                                     1: np.float64(0.4809999999999999)}),\n",
       "    'fpr': np.float64(0.07894736842105263),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.15789474,\n",
       "            0.15789474, 0.23684211, 0.23684211, 0.36842105, 0.36842105,\n",
       "            0.5       , 0.5       , 0.63157895, 0.63157895, 0.78947368,\n",
       "            0.78947368, 0.86842105, 0.86842105, 0.94736842, 0.94736842,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.33333333, 0.33333333,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.70829874, 0.52381983, 0.51165609, 0.39715419,\n",
       "            0.38624199, 0.31864869, 0.27746791, 0.20328956, 0.19343648,\n",
       "            0.16097178, 0.13571039, 0.1123844 , 0.10993529, 0.08345364,\n",
       "            0.07578321, 0.06682485, 0.06426168, 0.05216791, 0.04774322,\n",
       "            0.03881277])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.5090000000000001),\n",
       "                                     1: np.float64(0.49099999999999994)}),\n",
       "    'fpr': np.float64(0.10526315789473684),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.15789474,\n",
       "            0.15789474, 0.23684211, 0.23684211, 0.39473684, 0.39473684,\n",
       "            0.5       , 0.5       , 0.63157895, 0.63157895, 0.78947368,\n",
       "            0.78947368, 0.86842105, 0.86842105, 0.94736842, 0.94736842,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.33333333, 0.33333333,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.71681912, 0.53167429, 0.52136746, 0.40485719,\n",
       "            0.39932587, 0.32611194, 0.28394714, 0.19942213, 0.19862084,\n",
       "            0.16649467, 0.13948732, 0.11584791, 0.11296847, 0.08602486,\n",
       "            0.07817889, 0.06966033, 0.06662666, 0.05385343, 0.04986537,\n",
       "            0.04037606])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4990000000000001),\n",
       "                                     1: np.float64(0.5009999999999999)}),\n",
       "    'fpr': np.float64(0.10526315789473684),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.15789474,\n",
       "            0.15789474, 0.23684211, 0.23684211, 0.39473684, 0.39473684,\n",
       "            0.5       , 0.5       , 0.63157895, 0.63157895, 0.78947368,\n",
       "            0.78947368, 0.86842105, 0.86842105, 0.94736842, 0.94736842,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.33333333, 0.33333333,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.72565866, 0.53937888, 0.53061562, 0.4124902 ,\n",
       "            0.4121671 , 0.33409343, 0.28997549, 0.20737307, 0.20490628,\n",
       "            0.17222118, 0.14298238, 0.11938545, 0.11597652, 0.08810828,\n",
       "            0.08051278, 0.07225908, 0.06906965, 0.05549939, 0.05206173,\n",
       "            0.04158135])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4890000000000001),\n",
       "                                     1: np.float64(0.5109999999999999)}),\n",
       "    'fpr': np.float64(0.10526315789473684),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.05263158, 0.05263158, 0.13157895,\n",
       "            0.13157895, 0.23684211, 0.23684211, 0.39473684, 0.39473684,\n",
       "            0.5       , 0.5       , 0.63157895, 0.63157895, 0.81578947,\n",
       "            0.81578947, 0.86842105, 0.86842105, 0.94736842, 0.94736842,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.33333333, 0.33333333,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.73407106, 0.54747084, 0.54055739, 0.4378161 ,\n",
       "            0.42525809, 0.34174839, 0.29668145, 0.21404608, 0.21010684,\n",
       "            0.17808928, 0.14645645, 0.12278836, 0.11898714, 0.08402301,\n",
       "            0.08285679, 0.07492465, 0.07153381, 0.05727244, 0.05437965,\n",
       "            0.04278428])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4790000000000001),\n",
       "                                     1: np.float64(0.5209999999999999)}),\n",
       "    'fpr': np.float64(0.10526315789473684),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.05263158,\n",
       "            0.05263158, 0.13157895, 0.13157895, 0.23684211, 0.23684211,\n",
       "            0.39473684, 0.39473684, 0.5       , 0.5       , 0.63157895,\n",
       "            0.63157895, 0.81578947, 0.81578947, 0.86842105, 0.86842105,\n",
       "            0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.74215915, 0.70097767, 0.5557266 , 0.55526641,\n",
       "            0.55012418, 0.44426248, 0.43851267, 0.34964289, 0.30341963,\n",
       "            0.22141665, 0.21591225, 0.1841592 , 0.15024251, 0.12649515,\n",
       "            0.12215918, 0.08823994, 0.08540331, 0.07778381, 0.0741716 ,\n",
       "            0.05912901, 0.05682946, 0.0440139 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4690000000000001),\n",
       "                                     1: np.float64(0.5309999999999999)}),\n",
       "    'fpr': np.float64(0.10526315789473684),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.05263158,\n",
       "            0.05263158, 0.10526316, 0.10526316, 0.23684211, 0.23684211,\n",
       "            0.39473684, 0.39473684, 0.5       , 0.5       , 0.63157895,\n",
       "            0.63157895, 0.81578947, 0.81578947, 0.86842105, 0.86842105,\n",
       "            0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.74998603, 0.71212203, 0.56608006, 0.56300495,\n",
       "            0.55952986, 0.54893367, 0.45181973, 0.35771039, 0.3102403 ,\n",
       "            0.22903408, 0.22190265, 0.19038775, 0.15412819, 0.13034129,\n",
       "            0.12542878, 0.09267683, 0.08807973, 0.08077415, 0.07694652,\n",
       "            0.0610385 , 0.05939008, 0.04528915])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.4590000000000001),\n",
       "                                     1: np.float64(0.5409999999999999)}),\n",
       "    'fpr': np.float64(0.10526315789473684),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.05263158,\n",
       "            0.05263158, 0.10526316, 0.10526316, 0.23684211, 0.23684211,\n",
       "            0.39473684, 0.39473684, 0.5       , 0.5       , 0.63157895,\n",
       "            0.63157895, 0.81578947, 0.81578947, 0.86842105, 0.86842105,\n",
       "            0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.75752632, 0.72297432, 0.5763961 , 0.57064821,\n",
       "            0.5676767 , 0.55965987, 0.46518867, 0.36596408, 0.31721169,\n",
       "            0.23691162, 0.22812577, 0.19679794, 0.15817515, 0.13433326,\n",
       "            0.12879868, 0.09734757, 0.09089963, 0.08390536, 0.07986104,\n",
       "            0.06300346, 0.06206455, 0.04661726])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.44900000000000007),\n",
       "                                     1: np.float64(0.5509999999999999)}),\n",
       "    'fpr': np.float64(0.10526315789473684),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.05263158,\n",
       "            0.05263158, 0.10526316, 0.10526316, 0.23684211, 0.23684211,\n",
       "            0.39473684, 0.39473684, 0.52631579, 0.52631579, 0.63157895,\n",
       "            0.63157895, 0.81578947, 0.81578947, 0.86842105, 0.86842105,\n",
       "            0.94736842, 0.94736842, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.76525801, 0.73386878, 0.58661477, 0.57909819,\n",
       "            0.57556365, 0.57026745, 0.47897886, 0.37399308, 0.32467994,\n",
       "            0.24433351, 0.23367185, 0.16354501, 0.16203943, 0.1381523 ,\n",
       "            0.13211766, 0.10150423, 0.09352687, 0.08704973, 0.08270363,\n",
       "            0.06508106, 0.06485864, 0.04798048])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.43900000000000006),\n",
       "                                     1: np.float64(0.5609999999999999)}),\n",
       "    'fpr': np.float64(0.10526315789473684),\n",
       "    'tpr': np.float64(0.3333333333333333),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.05263158,\n",
       "            0.05263158, 0.10526316, 0.10526316, 0.23684211, 0.23684211,\n",
       "            0.39473684, 0.39473684, 0.55263158, 0.55263158, 0.63157895,\n",
       "            0.63157895, 0.81578947, 0.81578947, 0.86842105, 0.86842105,\n",
       "            0.92105263, 0.92105263, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.77244151, 0.74400395, 0.58788622, 0.58633508,\n",
       "            0.58255342, 0.57920283, 0.49228018, 0.38258703, 0.33192025,\n",
       "            0.25285546, 0.24021258, 0.16783085, 0.16628157, 0.14238839,\n",
       "            0.13576879, 0.10442078, 0.0966083 , 0.09045048, 0.08591318,\n",
       "            0.07325517, 0.06778409, 0.04940926])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.42900000000000005),\n",
       "                                     1: np.float64(0.571)}),\n",
       "    'fpr': np.float64(0.10526315789473684),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.10526316, 0.10526316, 0.23684211, 0.23684211,\n",
       "            0.39473684, 0.39473684, 0.55263158, 0.55263158, 0.65789474,\n",
       "            0.65789474, 0.81578947, 0.81578947, 0.86842105, 0.86842105,\n",
       "            0.92105263, 0.92105263, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.77979697, 0.75465912, 0.59758108, 0.59139317,\n",
       "            0.5905855 , 0.58878265, 0.50607993, 0.39107587, 0.33973442,\n",
       "            0.26129009, 0.2468888 , 0.17501081, 0.17050453, 0.14134495,\n",
       "            0.13930681, 0.10718515, 0.09946353, 0.09382429, 0.08898018,\n",
       "            0.07565817, 0.07077742, 0.0507754 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.41900000000000004),\n",
       "                                     1: np.float64(0.581)}),\n",
       "    'fpr': np.float64(0.10526315789473684),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.07894737,\n",
       "            0.07894737, 0.10526316, 0.10526316, 0.23684211, 0.23684211,\n",
       "            0.39473684, 0.39473684, 0.55263158, 0.55263158, 0.65789474,\n",
       "            0.65789474, 0.81578947, 0.81578947, 0.86842105, 0.86842105,\n",
       "            0.92105263, 0.92105263, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.33333333, 0.33333333, 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.78670916, 0.76496414, 0.60694168, 0.60197295,\n",
       "            0.59824295, 0.59764077, 0.5202806 , 0.39946382, 0.34715843,\n",
       "            0.27005082, 0.25351256, 0.1830757 , 0.17527681, 0.14784129,\n",
       "            0.14288323, 0.11031151, 0.10256012, 0.09744456, 0.09232302,\n",
       "            0.07820476, 0.07401298, 0.0522721 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.40900000000000014),\n",
       "                                     1: np.float64(0.5909999999999999)}),\n",
       "    'fpr': np.float64(0.10526315789473684),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.23684211, 0.23684211, 0.39473684, 0.39473684,\n",
       "            0.55263158, 0.55263158, 0.65789474, 0.65789474, 0.81578947,\n",
       "            0.81578947, 0.86842105, 0.86842105, 0.92105263, 0.92105263,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.79365392, 0.77474315, 0.61649711, 0.60703252,\n",
       "            0.53381868, 0.40812701, 0.35529894, 0.27864266, 0.2602205 ,\n",
       "            0.19025235, 0.17962217, 0.15437349, 0.14671459, 0.11352931,\n",
       "            0.10566115, 0.10124471, 0.09571125, 0.08091348, 0.0774329 ,\n",
       "            0.05388549])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.39900000000000013),\n",
       "                                     1: np.float64(0.6009999999999999)}),\n",
       "    'fpr': np.float64(0.13157894736842105),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.26315789, 0.26315789, 0.39473684, 0.39473684,\n",
       "            0.55263158, 0.55263158, 0.68421053, 0.68421053, 0.84210526,\n",
       "            0.84210526, 0.86842105, 0.86842105, 0.92105263, 0.92105263,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.80007784, 0.78414073, 0.62611372, 0.61621138,\n",
       "            0.54811088, 0.36386998, 0.36363537, 0.28668823, 0.26669773,\n",
       "            0.19799826, 0.18472998, 0.15112416, 0.15076961, 0.10965746,\n",
       "            0.1090502 , 0.10535489, 0.09942234, 0.08384666, 0.08114509,\n",
       "            0.05577784])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3890000000000001),\n",
       "                                     1: np.float64(0.6109999999999999)}),\n",
       "    'fpr': np.float64(0.15789473684210525),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.26315789, 0.26315789, 0.39473684, 0.39473684,\n",
       "            0.55263158, 0.55263158, 0.68421053, 0.68421053, 0.84210526,\n",
       "            0.84210526, 0.86842105, 0.86842105, 0.92105263, 0.92105263,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.80676983, 0.79356989, 0.63519389, 0.62520821,\n",
       "            0.56103714, 0.37296373, 0.37211484, 0.29692398, 0.27447095,\n",
       "            0.20499962, 0.18908534, 0.15581113, 0.15475049, 0.11412206,\n",
       "            0.11246437, 0.10929572, 0.10313973, 0.08661813, 0.08471843,\n",
       "            0.05727569])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3790000000000001),\n",
       "                                     1: np.float64(0.6209999999999999)}),\n",
       "    'fpr': np.float64(0.18421052631578946),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.26315789, 0.26315789, 0.39473684, 0.39473684,\n",
       "            0.55263158, 0.55263158, 0.68421053, 0.68421053, 0.84210526,\n",
       "            0.84210526, 0.86842105, 0.86842105, 0.92105263, 0.92105263,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.81328966, 0.80272236, 0.64492001, 0.63476139,\n",
       "            0.57496235, 0.38307565, 0.38098366, 0.30601976, 0.28181146,\n",
       "            0.21287269, 0.19411052, 0.16067205, 0.15906643, 0.11904139,\n",
       "            0.11601234, 0.11372002, 0.10705976, 0.08977011, 0.08877662,\n",
       "            0.05916847])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3690000000000001),\n",
       "                                     1: np.float64(0.6309999999999999)}),\n",
       "    'fpr': np.float64(0.18421052631578946),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.26315789, 0.26315789, 0.39473684, 0.39473684,\n",
       "            0.55263158, 0.55263158, 0.68421053, 0.68421053, 0.84210526,\n",
       "            0.84210526, 0.86842105, 0.86842105, 0.92105263, 0.92105263,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.81889159, 0.81127717, 0.65429799, 0.64332768,\n",
       "            0.58910401, 0.39423219, 0.39019876, 0.31553594, 0.28939384,\n",
       "            0.22085228, 0.20046095, 0.16618661, 0.16357886, 0.12404772,\n",
       "            0.12033094, 0.11834766, 0.1117367 , 0.09310194, 0.09301053,\n",
       "            0.06117219])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3590000000000001),\n",
       "                                     1: np.float64(0.6409999999999999)}),\n",
       "    'fpr': np.float64(0.18421052631578946),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.10526316,\n",
       "            0.10526316, 0.26315789, 0.26315789, 0.39473684, 0.39473684,\n",
       "            0.55263158, 0.55263158, 0.68421053, 0.68421053, 0.84210526,\n",
       "            0.84210526, 0.86842105, 0.86842105, 0.89473684, 0.89473684,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.25      , 0.25      ,\n",
       "            0.41666667, 0.41666667, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.66666667, 0.66666667, 0.75      , 0.75      ,\n",
       "            0.83333333, 0.83333333, 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.82533569, 0.82020005, 0.66381568, 0.65139507,\n",
       "            0.60233127, 0.40423924, 0.3990549 , 0.32637383, 0.29744174,\n",
       "            0.22894275, 0.2056503 , 0.17137931, 0.16801282, 0.12923478,\n",
       "            0.12402465, 0.12299629, 0.11592189, 0.11174606, 0.09732957,\n",
       "            0.06295433])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3490000000000001),\n",
       "                                     1: np.float64(0.6509999999999999)}),\n",
       "    'fpr': np.float64(0.18421052631578946),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.05263158,\n",
       "            0.05263158, 0.10526316, 0.10526316, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.55263158, 0.55263158, 0.68421053,\n",
       "            0.68421053, 0.84210526, 0.84210526, 0.86842105, 0.86842105,\n",
       "            0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.83333333, 0.83333333, 0.91666667,\n",
       "            0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.83145862, 0.82849343, 0.68613888, 0.67327002,\n",
       "            0.67307153, 0.6595676 , 0.61547567, 0.41468849, 0.40876145,\n",
       "            0.33492693, 0.30576096, 0.23748958, 0.21066102, 0.17671576,\n",
       "            0.17279123, 0.13486501, 0.12794028, 0.12789707, 0.1203192 ,\n",
       "            0.11685968, 0.10194336, 0.06503419])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.3390000000000001),\n",
       "                                     1: np.float64(0.6609999999999999)}),\n",
       "    'fpr': np.float64(0.18421052631578946),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.        , 0.02631579, 0.02631579, 0.05263158,\n",
       "            0.05263158, 0.10526316, 0.10526316, 0.26315789, 0.26315789,\n",
       "            0.39473684, 0.39473684, 0.55263158, 0.55263158, 0.68421053,\n",
       "            0.68421053, 0.86842105, 0.86842105, 0.89473684, 0.89473684,\n",
       "            1.        ]),\n",
       "     'tpr': array([0.        , 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "            0.25      , 0.25      , 0.41666667, 0.41666667, 0.5       ,\n",
       "            0.5       , 0.58333333, 0.58333333, 0.66666667, 0.66666667,\n",
       "            0.75      , 0.75      , 0.91666667, 0.91666667, 1.        ,\n",
       "            1.        ]),\n",
       "     'thresholds': array([       inf, 0.83726848, 0.83648746, 0.69579287, 0.68307589,\n",
       "            0.68220373, 0.66775805, 0.62863093, 0.42549989, 0.41847697,\n",
       "            0.34339756, 0.31440403, 0.24636272, 0.2159714 , 0.18246194,\n",
       "            0.17778361, 0.13314818, 0.12501658, 0.12227564, 0.10690962,\n",
       "            0.06726359])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.32900000000000007),\n",
       "                                     1: np.float64(0.6709999999999999)}),\n",
       "    'fpr': np.float64(0.18421052631578946),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.39473684,\n",
       "            0.39473684, 0.55263158, 0.55263158, 0.68421053, 0.68421053,\n",
       "            0.86842105, 0.86842105, 0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.84443835, 0.70525237, 0.69278104, 0.69149977,\n",
       "            0.67638698, 0.6419148 , 0.43698723, 0.42825244, 0.35195539,\n",
       "            0.32310889, 0.25554737, 0.22175557, 0.18848511, 0.18295527,\n",
       "            0.13869695, 0.12987035, 0.12794936, 0.11211114, 0.06959261])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.31900000000000006),\n",
       "                                     1: np.float64(0.6809999999999999)}),\n",
       "    'fpr': np.float64(0.18421052631578946),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.39473684,\n",
       "            0.39473684, 0.57894737, 0.57894737, 0.71052632, 0.71052632,\n",
       "            0.86842105, 0.86842105, 0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.85188767, 0.71498805, 0.70279137, 0.70060425,\n",
       "            0.68444958, 0.65481983, 0.44817689, 0.43864677, 0.36049686,\n",
       "            0.33215312, 0.22804024, 0.22746441, 0.19111652, 0.18838809,\n",
       "            0.14441633, 0.13477087, 0.13387621, 0.11763914, 0.07201345])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.30900000000000005),\n",
       "                                     1: np.float64(0.691)}),\n",
       "    'fpr': np.float64(0.21052631578947367),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.39473684,\n",
       "            0.39473684, 0.57894737, 0.57894737, 0.71052632, 0.71052632,\n",
       "            0.86842105, 0.86842105, 0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.85891219, 0.72427601, 0.71185506, 0.70996984,\n",
       "            0.6930368 , 0.66830851, 0.45960612, 0.44975927, 0.36965158,\n",
       "            0.34095979, 0.23774791, 0.2342711 , 0.20035011, 0.19449648,\n",
       "            0.15090045, 0.14064496, 0.14031643, 0.1236326 , 0.07502526])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.29900000000000015),\n",
       "                                     1: np.float64(0.7009999999999998)}),\n",
       "    'fpr': np.float64(0.23684210526315788),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.39473684,\n",
       "            0.39473684, 0.57894737, 0.57894737, 0.71052632, 0.71052632,\n",
       "            0.86842105, 0.86842105, 0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.86617238, 0.73407349, 0.72187337, 0.71915895,\n",
       "            0.70155438, 0.68118355, 0.47184452, 0.46096439, 0.37869428,\n",
       "            0.3510112 , 0.24813054, 0.24085948, 0.20760587, 0.20033165,\n",
       "            0.1571873 , 0.15125659, 0.14691924, 0.12987787, 0.07779301])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.28900000000000015),\n",
       "                                     1: np.float64(0.7109999999999999)}),\n",
       "    'fpr': np.float64(0.23684210526315788),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.39473684,\n",
       "            0.39473684, 0.57894737, 0.57894737, 0.71052632, 0.71052632,\n",
       "            0.86842105, 0.86842105, 0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.87310091, 0.74301105, 0.73130826, 0.72825837,\n",
       "            0.71009516, 0.69351302, 0.48399761, 0.4719529 , 0.38804685,\n",
       "            0.36152558, 0.25908161, 0.24798086, 0.21499909, 0.20658007,\n",
       "            0.16292846, 0.15684838, 0.15382747, 0.13652464, 0.08070347])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.27900000000000014),\n",
       "                                     1: np.float64(0.7209999999999999)}),\n",
       "    'fpr': np.float64(0.23684210526315788),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.39473684,\n",
       "            0.39473684, 0.57894737, 0.57894737, 0.71052632, 0.71052632,\n",
       "            0.86842105, 0.86842105, 0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.87949855, 0.75247152, 0.74068596, 0.7372626 ,\n",
       "            0.71864121, 0.70644111, 0.49651169, 0.48370159, 0.39782619,\n",
       "            0.37177183, 0.27029088, 0.25515609, 0.2223126 , 0.21319464,\n",
       "            0.16833724, 0.16238765, 0.16114889, 0.14358439, 0.08385318])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.26900000000000013),\n",
       "                                     1: np.float64(0.7309999999999999)}),\n",
       "    'fpr': np.float64(0.2631578947368421),\n",
       "    'tpr': np.float64(0.4166666666666667),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.39473684,\n",
       "            0.39473684, 0.57894737, 0.57894737, 0.71052632, 0.71052632,\n",
       "            0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.88578654, 0.76145645, 0.74964585, 0.746221  ,\n",
       "            0.72745576, 0.71867835, 0.50926411, 0.49597759, 0.40802548,\n",
       "            0.38345984, 0.28215139, 0.26340245, 0.23081454, 0.22056346,\n",
       "            0.16911677, 0.15136245, 0.08742952])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2590000000000001),\n",
       "                                     1: np.float64(0.7409999999999999)}),\n",
       "    'fpr': np.float64(0.2894736842105263),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.39473684,\n",
       "            0.39473684, 0.57894737, 0.57894737, 0.71052632, 0.71052632,\n",
       "            0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.89162481, 0.77060615, 0.75911631, 0.75492635,\n",
       "            0.7362445 , 0.72719784, 0.5222327 , 0.50888729, 0.41862285,\n",
       "            0.39481499, 0.29433606, 0.27163742, 0.23912592, 0.22829419,\n",
       "            0.17760758, 0.15925651, 0.09127286])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2490000000000001),\n",
       "                                     1: np.float64(0.7509999999999999)}),\n",
       "    'fpr': np.float64(0.2894736842105263),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.39473684,\n",
       "            0.39473684, 0.57894737, 0.57894737, 0.71052632, 0.71052632,\n",
       "            0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.89771557, 0.77928333, 0.76821666, 0.76416626,\n",
       "            0.74517838, 0.73603862, 0.53562096, 0.52116885, 0.42933296,\n",
       "            0.40726891, 0.30745673, 0.28008798, 0.2481894 , 0.23605999,\n",
       "            0.18610902, 0.16807846, 0.09501162])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2390000000000001),\n",
       "                                     1: np.float64(0.7609999999999999)}),\n",
       "    'fpr': np.float64(0.2894736842105263),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.39473684,\n",
       "            0.39473684, 0.57894737, 0.57894737, 0.71052632, 0.71052632,\n",
       "            0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.90326709, 0.78812479, 0.77738319, 0.7729959 ,\n",
       "            0.75419058, 0.74486947, 0.54929797, 0.53447253, 0.44046817,\n",
       "            0.41994237, 0.32078553, 0.2891717 , 0.25762724, 0.24457553,\n",
       "            0.19364027, 0.17723071, 0.09927783])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.2290000000000001),\n",
       "                                     1: np.float64(0.7709999999999999)}),\n",
       "    'fpr': np.float64(0.2894736842105263),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.07894737, 0.07894737, 0.10526316, 0.10526316, 0.26315789,\n",
       "            0.26315789, 0.39473684, 0.39473684, 0.57894737, 0.57894737,\n",
       "            0.71052632, 0.71052632, 0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.33333333, 0.33333333, 0.41666667, 0.41666667,\n",
       "            0.5       , 0.5       , 0.58333333, 0.58333333, 0.66666667,\n",
       "            0.66666667, 0.75      , 0.75      , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.90831871, 0.79696948, 0.78630468, 0.78175926,\n",
       "            0.7765709 , 0.7654443 , 0.76325156, 0.75379778, 0.56317708,\n",
       "            0.54868865, 0.45222965, 0.43251783, 0.33472949, 0.29898645,\n",
       "            0.26744433, 0.25412237, 0.20131108, 0.18719898, 0.1041899 ])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.21900000000000008),\n",
       "                                     1: np.float64(0.7809999999999999)}),\n",
       "    'fpr': np.float64(0.3157894736842105),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.07894737, 0.07894737, 0.10526316, 0.10526316, 0.26315789,\n",
       "            0.26315789, 0.39473684, 0.39473684, 0.57894737, 0.57894737,\n",
       "            0.71052632, 0.71052632, 0.86842105, 0.86842105, 0.89473684,\n",
       "            0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.33333333, 0.33333333, 0.41666667, 0.41666667,\n",
       "            0.5       , 0.5       , 0.58333333, 0.58333333, 0.66666667,\n",
       "            0.66666667, 0.75      , 0.75      , 0.83333333, 0.83333333,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.91381985, 0.80572712, 0.79511262, 0.79061601,\n",
       "            0.78666905, 0.77681451, 0.77241658, 0.7631252 , 0.57709522,\n",
       "            0.5623754 , 0.46428921, 0.44717767, 0.34927404, 0.30916461,\n",
       "            0.27838636, 0.26359247, 0.21574124, 0.20999329, 0.20863931,\n",
       "            0.19781561, 0.10892186])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.20900000000000007),\n",
       "                                     1: np.float64(0.7909999999999999)}),\n",
       "    'fpr': np.float64(0.34210526315789475),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.07894737, 0.07894737, 0.10526316, 0.10526316, 0.26315789,\n",
       "            0.26315789, 0.39473684, 0.39473684, 0.60526316, 0.60526316,\n",
       "            0.71052632, 0.71052632, 0.86842105, 0.86842105, 0.89473684,\n",
       "            0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.33333333, 0.33333333, 0.41666667, 0.41666667,\n",
       "            0.5       , 0.5       , 0.58333333, 0.58333333, 0.66666667,\n",
       "            0.66666667, 0.75      , 0.75      , 0.83333333, 0.83333333,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.91866952, 0.81442308, 0.80399519, 0.79934001,\n",
       "            0.79610343, 0.78797935, 0.78166086, 0.77232534, 0.59214199,\n",
       "            0.57696718, 0.47685004, 0.4612842 , 0.32355177, 0.32025345,\n",
       "            0.28966401, 0.27412374, 0.22722316, 0.22079295, 0.21735857,\n",
       "            0.20942055, 0.11458775])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.19900000000000018),\n",
       "                                     1: np.float64(0.8009999999999998)}),\n",
       "    'fpr': np.float64(0.3684210526315789),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.07894737, 0.07894737, 0.10526316, 0.10526316, 0.26315789,\n",
       "            0.26315789, 0.39473684, 0.39473684, 0.60526316, 0.60526316,\n",
       "            0.71052632, 0.71052632, 0.86842105, 0.86842105, 0.89473684,\n",
       "            0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.33333333, 0.33333333, 0.41666667, 0.41666667,\n",
       "            0.5       , 0.5       , 0.58333333, 0.58333333, 0.66666667,\n",
       "            0.66666667, 0.75      , 0.75      , 0.83333333, 0.83333333,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.92302907, 0.82297279, 0.81283859, 0.80798942,\n",
       "            0.80580872, 0.79873793, 0.79060971, 0.78130469, 0.60653067,\n",
       "            0.59244905, 0.49016237, 0.47616966, 0.33939741, 0.33190649,\n",
       "            0.30176926, 0.28607013, 0.23913306, 0.23196719, 0.22671957,\n",
       "            0.22212397, 0.12080741])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.18900000000000017),\n",
       "                                     1: np.float64(0.8109999999999998)}),\n",
       "    'fpr': np.float64(0.39473684210526316),\n",
       "    'tpr': np.float64(0.5),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.07894737, 0.07894737, 0.10526316, 0.10526316, 0.26315789,\n",
       "            0.26315789, 0.39473684, 0.39473684, 0.60526316, 0.60526316,\n",
       "            0.71052632, 0.71052632, 0.86842105, 0.86842105, 0.89473684,\n",
       "            0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.25      ,\n",
       "            0.25      , 0.33333333, 0.33333333, 0.41666667, 0.41666667,\n",
       "            0.5       , 0.5       , 0.58333333, 0.58333333, 0.66666667,\n",
       "            0.66666667, 0.75      , 0.75      , 0.91666667, 0.91666667,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.92775604, 0.83153581, 0.82127351, 0.81636439,\n",
       "            0.8157774 , 0.80923691, 0.80011774, 0.79103694, 0.62166387,\n",
       "            0.60782806, 0.50387154, 0.4932106 , 0.35619954, 0.34493994,\n",
       "            0.31539047, 0.29823166, 0.2511823 , 0.23763349, 0.23624648,\n",
       "            0.23556137, 0.12752642])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.17900000000000016),\n",
       "                                     1: np.float64(0.8209999999999998)}),\n",
       "    'fpr': np.float64(0.39473684210526316),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.39473684,\n",
       "            0.39473684, 0.60526316, 0.60526316, 0.73684211, 0.73684211,\n",
       "            0.86842105, 0.86842105, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.93197128, 0.83992445, 0.82536558, 0.81966964,\n",
       "            0.80968747, 0.80054699, 0.63653095, 0.62378553, 0.51810925,\n",
       "            0.50926132, 0.37349574, 0.3584717 , 0.3123187 , 0.31183773,\n",
       "            0.26310821, 0.24915685, 0.13500733])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.16900000000000015),\n",
       "                                     1: np.float64(0.8309999999999998)}),\n",
       "    'fpr': np.float64(0.42105263157894735),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.39473684,\n",
       "            0.39473684, 0.60526316, 0.60526316, 0.73684211, 0.73684211,\n",
       "            0.86842105, 0.86842105, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.93618022, 0.84844148, 0.83548217, 0.82988328,\n",
       "            0.81900187, 0.81025689, 0.64999281, 0.64030657, 0.53333131,\n",
       "            0.52806406, 0.39245772, 0.37327559, 0.3283059 , 0.32652821,\n",
       "            0.27543899, 0.26248663, 0.14331956])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.15900000000000014),\n",
       "                                     1: np.float64(0.8409999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.39473684,\n",
       "            0.39473684, 0.60526316, 0.60526316, 0.73684211, 0.73684211,\n",
       "            0.84210526, 0.84210526, 0.86842105, 0.86842105, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.9402287 , 0.85687433, 0.84560993, 0.83992481,\n",
       "            0.8284588 , 0.82021634, 0.66416074, 0.65763562, 0.54947832,\n",
       "            0.5480461 , 0.4125051 , 0.38943258, 0.34563189, 0.34273308,\n",
       "            0.29727365, 0.28959893, 0.2890269 , 0.27719208, 0.15273274])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.14900000000000013),\n",
       "                                     1: np.float64(0.8509999999999999)}),\n",
       "    'fpr': np.float64(0.5),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.36842105,\n",
       "            0.36842105, 0.60526316, 0.60526316, 0.73684211, 0.73684211,\n",
       "            0.84210526, 0.84210526, 0.86842105, 0.86842105, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.94399488, 0.8653294 , 0.855107  , 0.84979828,\n",
       "            0.83799578, 0.83010094, 0.67868816, 0.6753954 , 0.59483453,\n",
       "            0.56826971, 0.43328745, 0.40661467, 0.36474648, 0.36044119,\n",
       "            0.31473132, 0.30732406, 0.30403077, 0.29289934, 0.16320543])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.13900000000000012),\n",
       "                                     1: np.float64(0.8609999999999999)}),\n",
       "    'fpr': np.float64(0.5526315789473685),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.26315789, 0.26315789, 0.36842105,\n",
       "            0.36842105, 0.60526316, 0.60526316, 0.73684211, 0.73684211,\n",
       "            0.84210526, 0.84210526, 0.86842105, 0.86842105, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.94752163, 0.87335386, 0.86331869, 0.85863241,\n",
       "            0.84777689, 0.8401512 , 0.6935869 , 0.6934352 , 0.61455606,\n",
       "            0.58943684, 0.45523971, 0.42620235, 0.38612243, 0.3805708 ,\n",
       "            0.33410256, 0.32518975, 0.32168324, 0.3109203 , 0.17572573])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.12900000000000011),\n",
       "                                     1: np.float64(0.8709999999999999)}),\n",
       "    'fpr': np.float64(0.5789473684210527),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.23684211, 0.23684211, 0.36842105,\n",
       "            0.36842105, 0.60526316, 0.60526316, 0.73684211, 0.73684211,\n",
       "            0.84210526, 0.84210526, 0.86842105, 0.86842105, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.95090662, 0.88158599, 0.87159096, 0.86692443,\n",
       "            0.85743706, 0.85025199, 0.71870313, 0.71235184, 0.63523732,\n",
       "            0.61194518, 0.4786035 , 0.44722513, 0.40933439, 0.40259027,\n",
       "            0.35524714, 0.34887291, 0.34098973, 0.33077318, 0.18994084])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1190000000000001),\n",
       "                                     1: np.float64(0.8809999999999999)}),\n",
       "    'fpr': np.float64(0.6052631578947368),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.23684211, 0.23684211, 0.36842105,\n",
       "            0.36842105, 0.60526316, 0.60526316, 0.73684211, 0.73684211,\n",
       "            0.84210526, 0.84210526, 0.86842105, 0.86842105, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.95412916, 0.8899367 , 0.88001716, 0.87520566,\n",
       "            0.86701045, 0.86041411, 0.73626705, 0.73199947, 0.65736858,\n",
       "            0.63576191, 0.5034382 , 0.47036212, 0.43488818, 0.42694838,\n",
       "            0.3781853 , 0.37341464, 0.36283217, 0.35270932, 0.20639041])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.1090000000000001),\n",
       "                                     1: np.float64(0.8909999999999999)}),\n",
       "    'fpr': np.float64(0.6052631578947368),\n",
       "    'tpr': np.float64(0.5833333333333334),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.23684211, 0.23684211, 0.36842105,\n",
       "            0.36842105, 0.60526316, 0.60526316, 0.73684211, 0.73684211,\n",
       "            0.81578947, 0.81578947, 0.84210526, 0.84210526, 0.86842105,\n",
       "            0.86842105, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.95737363, 0.89828099, 0.8880811 , 0.88357986,\n",
       "            0.87707304, 0.87099866, 0.75403727, 0.75194039, 0.68061154,\n",
       "            0.6609832 , 0.53053074, 0.49635693, 0.46398236, 0.45422292,\n",
       "            0.40624323, 0.4046867 , 0.40398235, 0.40034805, 0.38684984,\n",
       "            0.37688856, 0.22540374])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.09900000000000009),\n",
       "                                     1: np.float64(0.9009999999999999)}),\n",
       "    'fpr': np.float64(0.6578947368421053),\n",
       "    'tpr': np.float64(0.6666666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.07894737, 0.07894737,\n",
       "            0.10526316, 0.10526316, 0.21052632, 0.21052632, 0.36842105,\n",
       "            0.36842105, 0.60526316, 0.60526316, 0.73684211, 0.73684211,\n",
       "            0.78947368, 0.78947368, 0.84210526, 0.84210526, 0.86842105,\n",
       "            0.86842105, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.16666667, 0.16666667, 0.33333333,\n",
       "            0.33333333, 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.96015138, 0.90622015, 0.89638611, 0.89199355,\n",
       "            0.88673764, 0.88122987, 0.79368182, 0.77273374, 0.70473995,\n",
       "            0.68703746, 0.55860781, 0.5245529 , 0.49267868, 0.48545412,\n",
       "            0.44695112, 0.43770021, 0.43265706, 0.43091566, 0.41571964,\n",
       "            0.40553399, 0.24919368])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.08900000000000019),\n",
       "                                     1: np.float64(0.9109999999999998)}),\n",
       "    'fpr': np.float64(0.7368421052631579),\n",
       "    'tpr': np.float64(0.75),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.07894737, 0.07894737, 0.10526316, 0.10526316, 0.21052632,\n",
       "            0.21052632, 0.36842105, 0.36842105, 0.60526316, 0.60526316,\n",
       "            0.73684211, 0.73684211, 0.78947368, 0.78947368, 0.86842105,\n",
       "            0.86842105, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.25      ,\n",
       "            0.25      , 0.33333333, 0.33333333, 0.41666667, 0.41666667,\n",
       "            0.5       , 0.5       , 0.58333333, 0.58333333, 0.66666667,\n",
       "            0.66666667, 0.75      , 0.75      , 0.91666667, 0.91666667,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.96297322, 0.9478324 , 0.91470689, 0.90466897,\n",
       "            0.90453935, 0.90030903, 0.89667259, 0.89180879, 0.81213926,\n",
       "            0.79425909, 0.73036416, 0.71536955, 0.58956349, 0.55692643,\n",
       "            0.5240546 , 0.52061813, 0.48087635, 0.46586998, 0.44862539,\n",
       "            0.43861833, 0.27804997])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.07900000000000018),\n",
       "                                     1: np.float64(0.9209999999999998)}),\n",
       "    'fpr': np.float64(0.8421052631578947),\n",
       "    'tpr': np.float64(0.9166666666666666),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.07894737, 0.07894737, 0.10526316, 0.10526316, 0.21052632,\n",
       "            0.21052632, 0.36842105, 0.36842105, 0.60526316, 0.60526316,\n",
       "            0.71052632, 0.71052632, 0.78947368, 0.78947368, 0.86842105,\n",
       "            0.86842105, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.25      ,\n",
       "            0.25      , 0.33333333, 0.33333333, 0.41666667, 0.41666667,\n",
       "            0.5       , 0.5       , 0.58333333, 0.58333333, 0.66666667,\n",
       "            0.66666667, 0.75      , 0.75      , 0.91666667, 0.91666667,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.96567541, 0.95148552, 0.92437293, 0.91346802,\n",
       "            0.9128045 , 0.90876803, 0.90671981, 0.90254395, 0.83106936,\n",
       "            0.81642963, 0.75755201, 0.74461472, 0.62236002, 0.59338449,\n",
       "            0.56285618, 0.56006073, 0.51848175, 0.50452151, 0.48632816,\n",
       "            0.4755993 , 0.31308558])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.06900000000000017),\n",
       "                                     1: np.float64(0.9309999999999998)}),\n",
       "    'fpr': np.float64(0.8947368421052632),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.07894737, 0.07894737, 0.10526316, 0.10526316, 0.21052632,\n",
       "            0.21052632, 0.36842105, 0.36842105, 0.60526316, 0.60526316,\n",
       "            0.68421053, 0.68421053, 0.73684211, 0.73684211, 0.78947368,\n",
       "            0.78947368, 0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.25      ,\n",
       "            0.25      , 0.33333333, 0.33333333, 0.41666667, 0.41666667,\n",
       "            0.5       , 0.5       , 0.58333333, 0.58333333, 0.66666667,\n",
       "            0.66666667, 0.75      , 0.75      , 0.83333333, 0.83333333,\n",
       "            0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.96814784, 0.95529298, 0.9337478 , 0.92194167,\n",
       "            0.92115323, 0.91752596, 0.91676546, 0.91321867, 0.85067399,\n",
       "            0.83929728, 0.78518892, 0.77523138, 0.65836054, 0.63385458,\n",
       "            0.61395443, 0.60560912, 0.59833436, 0.56279254, 0.56185476,\n",
       "            0.54933133, 0.5248172 , 0.51972646, 0.35792209])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.05900000000000016),\n",
       "                                     1: np.float64(0.9409999999999998)}),\n",
       "    'fpr': np.float64(0.9736842105263158),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.10526316, 0.10526316, 0.21052632, 0.21052632, 0.36842105,\n",
       "            0.36842105, 0.60526316, 0.60526316, 0.68421053, 0.68421053,\n",
       "            0.73684211, 0.73684211, 0.78947368, 0.78947368, 0.89473684,\n",
       "            0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.25      ,\n",
       "            0.25      , 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.970714  , 0.95917342, 0.94334999, 0.930853  ,\n",
       "            0.92697852, 0.9242883 , 0.87050614, 0.86255731, 0.81252711,\n",
       "            0.80798165, 0.69818698, 0.68047224, 0.66137524, 0.65664468,\n",
       "            0.6426724 , 0.61556462, 0.60783251, 0.59889179, 0.5821531 ,\n",
       "            0.56914236, 0.41424227])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.049000000000000155),\n",
       "                                     1: np.float64(0.9509999999999998)}),\n",
       "    'fpr': np.float64(0.9736842105263158),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.10526316, 0.10526316, 0.21052632, 0.21052632, 0.34210526,\n",
       "            0.34210526, 0.63157895, 0.63157895, 0.68421053, 0.68421053,\n",
       "            0.73684211, 0.73684211, 0.78947368, 0.78947368, 0.89473684,\n",
       "            0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.25      ,\n",
       "            0.25      , 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.97306217, 0.96328755, 0.95244654, 0.93932682,\n",
       "            0.9372345 , 0.93513042, 0.89147999, 0.88646843, 0.84552282,\n",
       "            0.84134459, 0.73119246, 0.73070412, 0.71359791, 0.71341053,\n",
       "            0.69451222, 0.67529359, 0.66144806, 0.65756429, 0.64416198,\n",
       "            0.62964244, 0.48692509])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.039000000000000146),\n",
       "                                     1: np.float64(0.9609999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.10526316, 0.10526316, 0.21052632, 0.21052632, 0.31578947,\n",
       "            0.31578947, 0.60526316, 0.60526316, 0.65789474, 0.65789474,\n",
       "            0.73684211, 0.73684211, 0.81578947, 0.81578947, 0.89473684,\n",
       "            0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.25      ,\n",
       "            0.25      , 0.41666667, 0.41666667, 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.97541096, 0.96768128, 0.96120116, 0.94807249,\n",
       "            0.94783387, 0.94527771, 0.91293429, 0.91093736, 0.87961418,\n",
       "            0.87515166, 0.78888131, 0.7876548 , 0.78408346, 0.77628695,\n",
       "            0.75296659, 0.74081563, 0.725134  , 0.72424754, 0.71503086,\n",
       "            0.70066535, 0.58245445])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.029000000000000137),\n",
       "                                     1: np.float64(0.9709999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.07894737, 0.07894737, 0.10526316, 0.10526316, 0.13157895,\n",
       "            0.13157895, 0.31578947, 0.31578947, 0.55263158, 0.55263158,\n",
       "            0.60526316, 0.60526316, 0.73684211, 0.73684211, 0.81578947,\n",
       "            0.81578947, 0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.16666667,\n",
       "            0.16666667, 0.25      , 0.25      , 0.41666667, 0.41666667,\n",
       "            0.5       , 0.5       , 0.58333333, 0.58333333, 0.66666667,\n",
       "            0.66666667, 0.75      , 0.75      , 0.83333333, 0.83333333,\n",
       "            0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.97801382, 0.97267529, 0.96974349, 0.96476545,\n",
       "            0.95906004, 0.95821452, 0.95762315, 0.95602999, 0.95448949,\n",
       "            0.93559144, 0.91215587, 0.90963192, 0.85094236, 0.84944962,\n",
       "            0.8454368 , 0.84349303, 0.81867505, 0.81204106, 0.79891142,\n",
       "            0.79881515, 0.79252336, 0.78240308, 0.70081732])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.019000000000000128),\n",
       "                                     1: np.float64(0.9809999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.02631579, 0.05263158, 0.05263158,\n",
       "            0.07894737, 0.07894737, 0.13157895, 0.13157895, 0.31578947,\n",
       "            0.31578947, 0.52631579, 0.52631579, 0.55263158, 0.55263158,\n",
       "            0.76315789, 0.76315789, 0.84210526, 0.84210526, 0.89473684,\n",
       "            0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.08333333, 0.08333333, 0.16666667,\n",
       "            0.16666667, 0.25      , 0.25      , 0.5       , 0.5       ,\n",
       "            0.58333333, 0.58333333, 0.66666667, 0.66666667, 0.75      ,\n",
       "            0.75      , 0.83333333, 0.83333333, 0.91666667, 0.91666667,\n",
       "            1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.98129755, 0.97879626, 0.97805833, 0.97397525,\n",
       "            0.97099877, 0.97056096, 0.96875845, 0.95955001, 0.94369415,\n",
       "            0.94303878, 0.91115579, 0.9107211 , 0.90984418, 0.90977958,\n",
       "            0.88615513, 0.88587729, 0.8792969 , 0.87888649, 0.87604898,\n",
       "            0.87156753, 0.83259109])}},\n",
       "   {'model': LogisticRegression(class_weight={0: np.float64(0.009000000000000119),\n",
       "                                     1: np.float64(0.9909999999999999)}),\n",
       "    'fpr': np.float64(1.0),\n",
       "    'tpr': np.float64(1.0),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': array([0.        , 0.02631579, 0.05263158, 0.05263158, 0.10526316,\n",
       "            0.10526316, 0.13157895, 0.13157895, 0.28947368, 0.28947368,\n",
       "            0.5       , 0.5       , 0.81578947, 0.81578947, 0.86842105,\n",
       "            0.86842105, 0.89473684, 0.89473684, 1.        ]),\n",
       "     'tpr': array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "            0.33333333, 0.33333333, 0.5       , 0.5       , 0.58333333,\n",
       "            0.58333333, 0.75      , 0.75      , 0.83333333, 0.83333333,\n",
       "            0.91666667, 0.91666667, 1.        , 1.        ]),\n",
       "     'thresholds': array([       inf, 0.98720284, 0.98707058, 0.9851617 , 0.98453583,\n",
       "            0.982896  , 0.98265426, 0.98171309, 0.97519587, 0.97502846,\n",
       "            0.96764182, 0.96671257, 0.95697901, 0.95634524, 0.95567626,\n",
       "            0.95545093, 0.95538854, 0.9547961 , 0.94815186])}}]],\n",
       " 'roc_results': {'fpr': array([0.        , 0.        , 0.01666667, 0.01666667, 0.03333333,\n",
       "         0.03333333, 0.05      , 0.05      , 0.08333333, 0.08333333,\n",
       "         0.1       , 0.1       , 0.11666667, 0.11666667, 0.13333333,\n",
       "         0.13333333, 0.25      , 0.25      , 0.26666667, 0.26666667,\n",
       "         0.28333333, 0.28333333, 0.38333333, 0.38333333, 0.46666667,\n",
       "         0.46666667, 0.48333333, 0.48333333, 0.51666667, 0.51666667,\n",
       "         0.6       , 0.6       , 0.66666667, 0.66666667, 0.75      ,\n",
       "         0.75      , 0.85      , 0.85      , 1.        ]),\n",
       "  'tpr': array([0.        , 0.03846154, 0.03846154, 0.07692308, 0.07692308,\n",
       "         0.15384615, 0.15384615, 0.19230769, 0.19230769, 0.26923077,\n",
       "         0.26923077, 0.30769231, 0.30769231, 0.38461538, 0.38461538,\n",
       "         0.42307692, 0.42307692, 0.46153846, 0.46153846, 0.5       ,\n",
       "         0.5       , 0.53846154, 0.53846154, 0.61538462, 0.61538462,\n",
       "         0.69230769, 0.69230769, 0.73076923, 0.73076923, 0.76923077,\n",
       "         0.76923077, 0.80769231, 0.80769231, 0.88461538, 0.88461538,\n",
       "         0.96153846, 0.96153846, 1.        , 1.        ]),\n",
       "  'thresholds': array([       inf, 0.88279248, 0.84809481, 0.8012451 , 0.77175351,\n",
       "         0.72529105, 0.72396799, 0.69750671, 0.67492331, 0.5879227 ,\n",
       "         0.58531341, 0.55461517, 0.55367125, 0.46644325, 0.45209814,\n",
       "         0.44940669, 0.37904469, 0.36130677, 0.33079278, 0.31058761,\n",
       "         0.3077971 , 0.30643804, 0.26886057, 0.26371299, 0.23524845,\n",
       "         0.22967817, 0.22853979, 0.21801881, 0.2027592 , 0.20099719,\n",
       "         0.1727766 , 0.16992574, 0.14360841, 0.12646516, 0.11219609,\n",
       "         0.09904212, 0.08209747, 0.08102902, 0.02138885]),\n",
       "  'name': 'Logistic Regression',\n",
       "  'auc': np.float64(0.6711538461538461),\n",
       "  'model': LogisticRegression()},\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x7b48428171d0>}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Save the data\n",
    "save_to_pickle(list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader, filename='pickle/Logistic_BreastCancer_weighted.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671d9dd3",
   "metadata": {},
   "source": [
    "# Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dd32937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Load the data\n",
    "list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader = load_from_pickle(filename='pickle/Logistic_BreastCancer_weighted.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47987f50",
   "metadata": {},
   "source": [
    "### Ensemble prediction using voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a9ef57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a single ensemble from 66 models across all folds.\n",
      "Extracting full dataset...\n",
      "Getting predictions from all models...\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Loop through all the FPR values to generate the ensemble ROC curve ---\n",
    "\n",
    "\n",
    "\n",
    "results_tuple, prior_proba = predict_ensemble_and_evaluate(list_folds_best_models=list_folds_best_models,\n",
    "    test_loader=test_loader)\n",
    "\n",
    "ensemble_results_soft = results_tuple['soft_voting']\n",
    "ensemble_results_hard = results_tuple['hard_voting']\n",
    "misclassification_risk = results_tuple['misclassification_risk']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd753c5e",
   "metadata": {},
   "source": [
    "## Calculate Neyman Pearson ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efc782bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X after preprocessing: (286, 39)\n",
      "Training data shape: (200, 39), (200,)\n",
      "Test data shape: (86, 39), (86,)\n",
      "Shape of training data: (200, 40)\n",
      "Shape of test data: (86, 40)\n",
      "\n",
      "Data successfully processed and concatenated.\n",
      "Shape of final training data: (200, 40)\n",
      "Generating constrained ROC curve (Neyman-Pearson Simulation)...\n",
      "Phase 1 Complete. Model trained and scores generated.\n",
      "\n",
      "Phase 2: Calculating cutoffs for all alphas without re-training...\n",
      "Sample size is too small for the given alpha. Try a larger alpha.\n",
      "Alpha 0.00 (1/51): No valid cutoff found (sample size may be too small).\n",
      "Sample size is too small for the given alpha. Try a larger alpha.\n",
      "Alpha 0.02 (2/51): No valid cutoff found (sample size may be too small).\n",
      "Sample size is too small for the given alpha. Try a larger alpha.\n",
      "Alpha 0.04 (3/51): No valid cutoff found (sample size may be too small).\n",
      "Alpha 0.06 (4/51): FPR=0.033, TPR=0.077\n",
      "Alpha 0.08 (5/51): FPR=0.050, TPR=0.115\n",
      "Alpha 0.10 (6/51): FPR=0.050, TPR=0.192\n",
      "Alpha 0.12 (7/51): FPR=0.083, TPR=0.231\n",
      "Alpha 0.14 (8/51): FPR=0.117, TPR=0.269\n",
      "Alpha 0.16 (9/51): FPR=0.133, TPR=0.269\n",
      "Alpha 0.18 (10/51): FPR=0.133, TPR=0.269\n",
      "Alpha 0.20 (11/51): FPR=0.150, TPR=0.385\n",
      "Alpha 0.22 (12/51): FPR=0.167, TPR=0.385\n",
      "Alpha 0.24 (13/51): FPR=0.183, TPR=0.462\n",
      "Alpha 0.26 (14/51): FPR=0.183, TPR=0.462\n",
      "Alpha 0.28 (15/51): FPR=0.200, TPR=0.462\n",
      "Alpha 0.30 (16/51): FPR=0.217, TPR=0.500\n",
      "Alpha 0.32 (17/51): FPR=0.217, TPR=0.500\n",
      "Alpha 0.34 (18/51): FPR=0.233, TPR=0.500\n",
      "Alpha 0.36 (19/51): FPR=0.233, TPR=0.538\n",
      "Alpha 0.38 (20/51): FPR=0.233, TPR=0.538\n",
      "Alpha 0.40 (21/51): FPR=0.250, TPR=0.538\n",
      "Alpha 0.42 (22/51): FPR=0.283, TPR=0.577\n",
      "Alpha 0.44 (23/51): FPR=0.317, TPR=0.577\n",
      "Alpha 0.46 (24/51): FPR=0.383, TPR=0.577\n",
      "Alpha 0.48 (25/51): FPR=0.383, TPR=0.577\n",
      "Alpha 0.50 (26/51): FPR=0.400, TPR=0.577\n",
      "Alpha 0.52 (27/51): FPR=0.467, TPR=0.577\n",
      "Alpha 0.54 (28/51): FPR=0.467, TPR=0.615\n",
      "Alpha 0.56 (29/51): FPR=0.467, TPR=0.615\n",
      "Alpha 0.58 (30/51): FPR=0.467, TPR=0.615\n",
      "Alpha 0.60 (31/51): FPR=0.483, TPR=0.615\n",
      "Alpha 0.62 (32/51): FPR=0.483, TPR=0.692\n",
      "Alpha 0.64 (33/51): FPR=0.517, TPR=0.692\n",
      "Alpha 0.66 (34/51): FPR=0.517, TPR=0.692\n",
      "Alpha 0.68 (35/51): FPR=0.533, TPR=0.692\n",
      "Alpha 0.70 (36/51): FPR=0.533, TPR=0.692\n",
      "Alpha 0.72 (37/51): FPR=0.550, TPR=0.692\n",
      "Alpha 0.74 (38/51): FPR=0.567, TPR=0.692\n",
      "Alpha 0.76 (39/51): FPR=0.617, TPR=0.885\n",
      "Alpha 0.78 (40/51): FPR=0.617, TPR=0.885\n",
      "Alpha 0.80 (41/51): FPR=0.667, TPR=0.885\n",
      "Alpha 0.82 (42/51): FPR=0.700, TPR=0.923\n",
      "Alpha 0.84 (43/51): FPR=0.700, TPR=0.923\n",
      "Alpha 0.86 (44/51): FPR=0.783, TPR=0.962\n",
      "Alpha 0.88 (45/51): FPR=0.800, TPR=0.962\n",
      "Alpha 0.90 (46/51): FPR=0.800, TPR=1.000\n",
      "Alpha 0.92 (47/51): FPR=0.800, TPR=1.000\n",
      "Alpha 0.94 (48/51): FPR=0.833, TPR=1.000\n",
      "Alpha 0.96 (49/51): FPR=0.933, TPR=1.000\n",
      "Alpha 0.98 (50/51): FPR=0.967, TPR=1.000\n",
      "Alpha 1.00 (51/51): FPR=1.000, TPR=1.000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, auc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nproc import npc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "train_data, test_data, val_data = generate_data(\"breast_cancer\")  \n",
    "\n",
    "\n",
    "train_data_tensor = data.TensorDataset(torch.tensor(train_data[:, :-1], dtype=torch.float32),\n",
    "                                        torch.tensor(train_data[:, -1], dtype=torch.float32))\n",
    "train_loader = data.DataLoader(train_data_tensor, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) #over-write later for k-fold cross-validation\n",
    "test_data_tensor = data.TensorDataset(torch.tensor(test_data[:, :-1], dtype=torch.float32),\n",
    "                                       torch.tensor(test_data[:, -1], dtype=torch.float32))\n",
    "test_loader = data.DataLoader(test_data_tensor, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]\n",
    "print(\"Generating constrained ROC curve (Neyman-Pearson Simulation)...\")\n",
    "\n",
    "npc_instance = npc()\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "result = npc_instance.npc(\n",
    "    x=X_train, \n",
    "    y=y_train, \n",
    "    method=\"\", # Leave blank to use the provided model\n",
    "    model=model,\n",
    "    rand_seed=42\n",
    ")\n",
    "\n",
    "# Extract the essential, one-time results\n",
    "# The structure is result[fits][split_index][element_index]\n",
    "fit_results = result[0][0]\n",
    "final_model = fit_results[0] # The trained model\n",
    "y_test_calib = fit_results[1]       # The labels from the calibration set\n",
    "y_decision_values = fit_results[2]  # The scores from the single trained model\n",
    "initial_sign = fit_results[4]       # The sign indicating score direction\n",
    "\n",
    "print(\"Phase 1 Complete. Model trained and scores generated.\")\n",
    "\n",
    "# --- 3. Phase 2: Calculate All ROC Points Efficiently ---\n",
    "print(\"\\nPhase 2: Calculating cutoffs for all alphas without re-training...\")\n",
    "\n",
    "# Define the FPR constraints (alphas) we want to target\n",
    "alphas = np.linspace(0, 1, 51)\n",
    "roc_points = []\n",
    "\n",
    "# Get the model's scores on the completely separate test set\n",
    "y_test_scores = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# If the sign is True, it means lower scores are better for class 1.\n",
    "# The npc_core function expects higher scores to be better, so we invert them once.\n",
    "if initial_sign:\n",
    "    y_decision_values = -y_decision_values\n",
    "    y_test_scores = -y_test_scores\n",
    "\n",
    "for i, alpha in enumerate(alphas):\n",
    "    # Call ONLY the fast npc_core function\n",
    "    core_result = npc_instance.npc_core(\n",
    "        y_test=y_test_calib,\n",
    "        y_decision_values=y_decision_values,\n",
    "        alpha=alpha,\n",
    "        delta=0.05,\n",
    "        n_cores=1\n",
    "    )\n",
    "    \n",
    "    if not core_result or core_result[6] == True: # core_result[6] is n_small flag\n",
    "        print(f\"Alpha {alpha:.2f} ({i+1}/{len(alphas)}): No valid cutoff found (sample size may be too small).\")\n",
    "        continue\n",
    "\n",
    "    # Get the optimal cutoff for this specific alpha\n",
    "    cutoff = core_result[0]\n",
    "\n",
    "    # Manually apply the cutoff to the saved scores to get predictions\n",
    "    # Note: We already handled the sign, so higher score is always better here.\n",
    "    y_pred = (y_test_scores >= cutoff).astype(int)\n",
    "\n",
    "    # Calculate TPR and FPR for this point\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    current_fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    current_tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    roc_points.append({'fpr': current_fpr, 'tpr': current_tpr})\n",
    "    print(f\"Alpha {alpha:.2f} ({i+1}/{len(alphas)}): FPR={current_fpr:.3f}, TPR={current_tpr:.3f}\")\n",
    "\n",
    "# --- 4. Process and Plot the Results ---\n",
    "# Remove duplicate points\n",
    "unique_points_dict = {(p['fpr'], p['tpr']): p for p in roc_points}\n",
    "constrained_points = list(unique_points_dict.values())\n",
    "constrained_points = sorted(constrained_points, key=lambda x: x['fpr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "015c16e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constrained ROC curve points saved to pickle/Logistic_Breast_Cancer_NP_roc_curve.pkl\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle_constrained_roc\n",
    "\n",
    "# Save the constrained ROC curve results\n",
    "save_to_pickle_constrained_roc(constrained_points, filename='pickle/Logistic_Breast_Cancer_NP_roc_curve.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233ded62",
   "metadata": {},
   "source": [
    "## Load NP curve pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f98fdfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constrained ROC curve points loaded from pickle/Logistic_Breast_Cancer_NP_roc_curve.pkl\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import load_from_pickle_constrained_roc\n",
    "\n",
    "# Load the constrained ROC curve results\n",
    "constrained_points = load_from_pickle_constrained_roc(filename='pickle/Logistic_Breast_Cancer_NP_roc_curve.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e3a7c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Plotting all ROC curves for comparison ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "results_lists.append(constrained_points)\n",
    "results_lists.append(ensemble_results_hard)\n",
    "results_lists.append(misclassification_risk)\n",
    "\n",
    "# --- Plot the final comparison ---\n",
    "print(\"\\n--- Plotting all ROC curves for comparison ---\")\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"MaxROCFold 1\", \"MaxROCFold 2\", \"MaxROCFold 3\", \"MaxROCFold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\", \"Neyman_Pearson\", \"Ensemble_voting_hard\", \"Misclassification_Risk\"],\n",
    "    results_original_roc=results_original_roc, plot_name=\"logistic_weighted_BreastCanser\", prior_prob=prior_proba\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLlabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
