{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4da4f6",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0556d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d840881",
   "metadata": {},
   "source": [
    "## Display function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c24af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for displaying ROC curves of multiple classifiers\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_connected_points(results_list, results_original_roc, name=\"All Classifiers\"):\n",
    "    \"\"\"\n",
    "    Creates a plot showing the performance of all classifiers as points,\n",
    "    and connects them with a line, sorted by FPR.\n",
    "\n",
    "    Args:\n",
    "        results_list: A list of dictionaries, where each dict contains 'fpr', 'tpr'.\n",
    "    \"\"\"\n",
    "    if not results_list:\n",
    "        print(\"No results to plot.\")\n",
    "        return\n",
    "\n",
    "    # Convert results to a pandas DataFrame for easy sorting\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Sort the models by their False Positive Rate to create a left-to-right line\n",
    "    df_sorted = df.sort_values(by='fpr').reset_index(drop=True)\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot all the individual model points as a scatter plot\n",
    "    # This helps see the actual performance of each model\n",
    "    plt.scatter(df_sorted['fpr'], df_sorted['tpr'], c='black', marker='o', \n",
    "                alpha=0.6, s=100, zorder=3) # zorder=3 puts dots on top\n",
    "\n",
    "    # Plot the line connecting the points\n",
    "    plt.plot(df_sorted['fpr'], df_sorted['tpr'], color='red', lw=1.5,\n",
    "             alpha=0.8, label=f'{name} (AUC = {auc(df_sorted[\"fpr\"], df_sorted[\"tpr\"]):.2f})')\n",
    "    \n",
    "    #plot the original ROC curve\n",
    "    plt.plot(results_original_roc[\"fpr\"], results_original_roc[\"tpr\"], color='blue', \n",
    "             label=f'{results_original_roc[\"name\"]} (AUC = {results_original_roc[\"auc\"]:.2f})')\n",
    "\n",
    "    # Plot the \"no-skill\" line for reference\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title('Performance Path of All Trained Classifiers')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23b1ea",
   "metadata": {},
   "source": [
    "## Best ROC envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e350c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def get_best_roc_envelope(results_list, results_original_roc=None):\n",
    "    \"\"\"\n",
    "    Constructs the upper envelope of multiple ROC curves to find the best\n",
    "    possible operating points from a collection of classifiers.\n",
    "\n",
    "    This function is guaranteed to produce a list of points that starts at\n",
    "    (FPR=0, TPR=0) and ends at (FPR=1, TPR=1), making it suitable for direct\n",
    "    plotting and AUC calculation.\n",
    "\n",
    "    Args:\n",
    "        results_list (list): A list of dictionaries. Each dictionary must\n",
    "                             contain a 'model' name and the full ROC results\n",
    "                             under the 'full_roc' key.\n",
    "        results_original_roc (dict, optional): A dictionary containing the\n",
    "                                               ROC results of a baseline model,\n",
    "                                               which will also be included in\n",
    "                                               the comparison. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A sorted list of dictionaries representing the optimal ROC\n",
    "              envelope. Each dictionary includes 'model', 'fpr', 'tpr',\n",
    "              and 'threshold'.\n",
    "    \"\"\"\n",
    "    all_points = []\n",
    "\n",
    "    # Step 1: Gather all ROC points from all provided models\n",
    "    all_results = results_list[:]\n",
    "    if results_original_roc:\n",
    "        all_results.append({\n",
    "            'model': 'original_baseline',\n",
    "            'full_roc': results_original_roc\n",
    "        })\n",
    "\n",
    "    for result in all_results:\n",
    "        model_name = result.get('model', 'Unknown Model')\n",
    "        roc = result.get('full_roc')\n",
    "        if not roc: continue\n",
    "\n",
    "        fprs = roc.get('fpr', [])\n",
    "        tprs = roc.get('tpr', [])\n",
    "        thresholds = roc.get('thresholds', [])\n",
    "\n",
    "        for i in range(len(fprs)):\n",
    "            threshold = thresholds[i] if i < len(thresholds) else thresholds[-1]\n",
    "            all_points.append({\n",
    "                'model': model_name, 'fpr': fprs[i],\n",
    "                'tpr': tprs[i], 'threshold': threshold\n",
    "            })\n",
    "\n",
    "    # Handle case with no data by returning a default diagonal line\n",
    "    if not all_points:\n",
    "        return [\n",
    "            {'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf},\n",
    "            {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}\n",
    "        ]\n",
    "\n",
    "    # Step 2: Sort all points by FPR (asc), then by TPR (desc)\n",
    "    all_points.sort(key=lambda p: (p['fpr'], -p['tpr']))\n",
    "\n",
    "    # Step 3: Build the core ROC envelope\n",
    "    best_roc_envelope = []\n",
    "    max_tpr_so_far = -1.0\n",
    "    for point in all_points:\n",
    "        # Add a point only if it has a strictly higher TPR\n",
    "        if point['tpr'] > max_tpr_so_far:\n",
    "            # To prevent adding multiple points at the same FPR, check if the last point\n",
    "            # has the same FPR and replace it if so (since this one has a higher TPR)\n",
    "            if best_roc_envelope and best_roc_envelope[-1]['fpr'] == point['fpr']:\n",
    "                best_roc_envelope[-1] = point\n",
    "            else:\n",
    "                best_roc_envelope.append(point)\n",
    "            max_tpr_so_far = point['tpr']\n",
    "    \n",
    "    # Step 4: Manually add extremities if they are missing\n",
    "    \n",
    "    # Ensure the curve starts at (0, 0)\n",
    "    if not best_roc_envelope or best_roc_envelope[0]['fpr'] > 0.0:\n",
    "        best_roc_envelope.insert(0, {\n",
    "            'model': 'start', 'fpr': 0.0, 'tpr': 0.0, 'threshold': np.inf\n",
    "        })\n",
    "\n",
    "    # Ensure the curve ends at (1, 1)\n",
    "    if best_roc_envelope[-1]['fpr'] < 1.0 or best_roc_envelope[-1]['tpr'] < 1.0:\n",
    "        best_roc_envelope.append({\n",
    "            'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0\n",
    "        })\n",
    "\n",
    "    return best_roc_envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b781e9",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8c3deb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_data(dataset):\n",
    "    if dataset == \"data1\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [0, 2], [2, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "    elif dataset == \"data2\":\n",
    "        no_predictors = 2\n",
    "        no_samples = 1600\n",
    "        no_classes = 2\n",
    "        #kerneltype = 'linear'  #comment out for polynomial kernel\n",
    "        #kerneltype = 'poly'  #comment out for linear kernel\n",
    "\n",
    "\n",
    "\n",
    "        n_samples_per_cluster = 400\n",
    "        n_clusters = 4\n",
    "\n",
    "        # Create the clusters deterministically\n",
    "        np.random.seed(0) # for reproducibility\n",
    "\n",
    "        X = np.zeros((n_samples_per_cluster * n_clusters, 2))\n",
    "        y = np.zeros(n_samples_per_cluster * n_clusters)\n",
    "\n",
    "        # Cluster centers in corners of a square\n",
    "        centers = [[0, 0], [2, 0], [1, 2], [1, 2]]\n",
    "\n",
    "        # Assign points to clusters deterministically\n",
    "        for i in range(n_clusters):\n",
    "            cluster_indices = slice(i * n_samples_per_cluster, (i + 1) * n_samples_per_cluster)\n",
    "            X[cluster_indices] = centers[i] + np.random.normal(scale=0.5, size=(n_samples_per_cluster, 2))\n",
    "            if i == 0 or i == 3:\n",
    "                y[cluster_indices] = 0\n",
    "            else:\n",
    "                y[cluster_indices] = 1\n",
    "\n",
    "\n",
    "\n",
    "        #Visualize\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.scatter(X[:,0], X[:,1], c=y, cmap='viridis', s=50)\n",
    "        plt.title('Four Clusters of Equal Size')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "\n",
    "        #add intercept to X\n",
    "        #X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "        # # shuffle data\n",
    "        # permutation = np.random.permutation(no_samples)\n",
    "        # X = X[permutation]\n",
    "        # y = y[permutation]\n",
    "\n",
    "\n",
    "        #Split data into training and testing sets\n",
    "        # Step 1: Split off the 1000 training samples. The rest (600) go into a temporary pool.\n",
    "        # We can use absolute numbers for the size.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            train_size=1000,  # Specify exactly 1000 samples for training\n",
    "            random_state=42,\n",
    "            stratify=y        # Crucial for classification: keeps class proportions the same\n",
    "        )\n",
    "\n",
    "\n",
    "        train_data = np.concatenate((X_train, y_train.reshape(-1, 1)), axis=1)\n",
    "        test_data = np.concatenate((X_test, y_test.reshape(-1, 1)), axis=1)\n",
    "\n",
    "        val_data = test_data\n",
    "\n",
    "        print(f\"Training data shape: {X_train.shape}, {y_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "    elif dataset == \"pneumoniaMNIST\":\n",
    "        import medmnist\n",
    "        print(medmnist.__version__)\n",
    "        # read in the PneumoniaMNIST dataset\n",
    "        from medmnist import PneumoniaMNIST\n",
    "        train_data = PneumoniaMNIST(split='train', download=True, size=224)\n",
    "        test_data = PneumoniaMNIST(split='test', download=True, size=224)\n",
    "        val_data = PneumoniaMNIST(split='val', download=True, size=224)\n",
    "        # print the dataset info\n",
    "        print(f\"Number of training samples: {len(train_data)}\")\n",
    "        print(f\"Number of test samples: {len(test_data)}\")\n",
    "        print(f\"Number of validation samples: {len(val_data)}\")\n",
    "\n",
    "    return train_data, test_data, val_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bfe355",
   "metadata": {},
   "source": [
    "## Calculate Statistics function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af73be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_fpr_tpr(clf_model, X_test, y_test, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculates the False Positive Rate (FPR) and True Positive Rate (TPR) at a given threshold.\n",
    "\n",
    "    Args:\n",
    "        X_test: The test features.\n",
    "        y_test: The true test labels (0 or 1).\n",
    "        threshold: The probability threshold.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the FPR and TPR. Returns None if there's an error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y_prob = clf_model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  #Avoid division by zero\n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0 #Avoid division by zero\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        misclassification_rate = 1 - accuracy\n",
    "\n",
    "        return {\"fpr\": fpr, \"tpr\": tpr, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"accuracy\": accuracy, \"misclassification_rate\": misclassification_rate}\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error calculating FPR and TPR: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59034e",
   "metadata": {},
   "source": [
    "## PneumoniaMNIST: NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74133e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a060ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 1\n",
    "NUM_CHANNELS = 1\n",
    "NUM_EPOCHS = 1\n",
    "NUM_WORKERS = 4\n",
    "K_FOLDS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d23d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes, image_height, image_width):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        #Convoluional layers\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 224x224 -> 112x112\n",
    "        \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 112x112 -> 56x56\n",
    "        \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 56x56 -> 28x28\n",
    "        \n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # 28x28 -> 14x14\n",
    "        )\n",
    "\n",
    "        # --- DYNAMIC FLATTENED SIZE CALCULATION ---\n",
    "        # Create a dummy tensor with the specified input dimensions\n",
    "        dummy_input = torch.randn(1, in_channels, image_height, image_width)\n",
    "        # Pass it through the feature extractor to see the output shape\n",
    "        dummy_output = self.features(dummy_input)\n",
    "        # The number of elements in the output tensor is our flattened size\n",
    "        self.flattened_size = dummy_output.numel()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 512)\n",
    "        self.relu_fc = nn.ReLU()\n",
    "        # Output layer: num_classes=1 for binary classification (outputting logits)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1) # Flatten the tensor\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu_fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.extract_features(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a702675",
   "metadata": {},
   "source": [
    "### Lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac92eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class LitSimpleCNN(pl.LightningModule):\n",
    "    def __init__(self, in_channels, num_classes, learning_rate, image_height, image_width, training_mode='full_network'):\n",
    "        super().__init__()\n",
    "        # Save hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Define the model\n",
    "        self.model = SimpleCNN(\n",
    "            in_channels=self.hparams.in_channels, \n",
    "            num_classes=self.hparams.num_classes,\n",
    "            image_height=self.hparams.image_height,\n",
    "            image_width=self.hparams.image_width\n",
    "        )\n",
    "        \n",
    "        # Define loss function\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Define metrics\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.val_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.val_auc = torchmetrics.AUROC(task=\"binary\")\n",
    "\n",
    "        self.test_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.test_auc = torchmetrics.AUROC(task=\"binary\")\n",
    "        self.test_precision = torchmetrics.Precision(task=\"binary\")\n",
    "        self.test_recall = torchmetrics.Recall(task=\"binary\")\n",
    "        self.test_f1 = torchmetrics.F1Score(task=\"binary\")\n",
    "\n",
    "        # This list will store outputs from each test step\n",
    "        self.last_test_results = {}\n",
    "        self.test_step_outputs = []\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def freeze_feature_extractor(self):\n",
    "        print(\"Freezing feature extractor layers...\")\n",
    "        for param in self.model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.model.fc1.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        # For BCEWithLogitsLoss, labels must be float\n",
    "        labels = labels.float()\n",
    "        \n",
    "        outputs = self(inputs) # Forward pass\n",
    "        loss = self.criterion(outputs, labels)\n",
    "\n",
    "        # We need to handle which part of the network we are training\n",
    "        if self.hparams.training_mode == 'full_network':\n",
    "            self.log('train_loss_full', loss)\n",
    "        elif self.hparams.training_mode == 'classifier_only':\n",
    "            self.log('train_loss_classifier', loss)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.train_accuracy(outputs, labels.int())\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log('train_acc', self.train_accuracy, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        labels = labels.float()\n",
    "        \n",
    "        outputs = self(inputs)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.val_accuracy(outputs, labels.int())\n",
    "        self.val_auc(outputs, labels.int())\n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log('val_acc', self.val_accuracy, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log('val_auc', self.val_auc, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, labels = batch\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, labels.float())\n",
    "        \n",
    "        # Append predictions and labels to our list\n",
    "        self.test_step_outputs.append({\"preds\": outputs.detach(), \"labels\": labels.detach()})\n",
    "        \n",
    "        # Log the loss for this batch\n",
    "        self.log('test_loss', loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # Concatenate all predictions and labels from the list we built\n",
    "        all_preds = torch.cat([x['preds'] for x in self.test_step_outputs])\n",
    "        all_labels = torch.cat([x['labels'] for x in self.test_step_outputs])\n",
    "\n",
    "        # Calculate final metrics over the entire test set\n",
    "        test_acc = self.test_accuracy(all_preds, all_labels.int())\n",
    "        test_auc_val = self.test_auc(all_preds, all_labels.int())\n",
    "        test_prec = self.test_precision(all_preds, all_labels.int())\n",
    "        test_rec = self.test_recall(all_preds, all_labels.int())\n",
    "        test_f1_val = self.test_f1(all_preds, all_labels.int())\n",
    "        test_cm_val = torchmetrics.functional.confusion_matrix(all_preds, all_labels.int(), task=\"binary\")\n",
    "\n",
    "        # Log the final metrics\n",
    "        self.log(\"test_acc_epoch\", test_acc)\n",
    "        self.log(\"test_auc_epoch\", test_auc_val)\n",
    "\n",
    "        print(f\"\\n--- Final Test Metrics ---\")\n",
    "        print(f\"Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"AUC: {test_auc_val:.4f}\")\n",
    "        print(f\"Precision: {test_prec:.4f}\")\n",
    "        print(f\"Recall: {test_rec:.4f}\")\n",
    "        print(f\"F1-Score: {test_f1_val:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{test_cm_val}\")\n",
    "        print(\"--------------------------\\n\")\n",
    "\n",
    "        # Calculate data for the ROC Curve\n",
    "        fpr, tpr, thresholds = torchmetrics.functional.roc(\n",
    "            torch.sigmoid(all_preds),\n",
    "            all_labels.int(),\n",
    "            task=\"binary\"\n",
    "        )\n",
    "\n",
    "        # Store the results to be retrieved later in the main script\n",
    "        self.last_test_results = {\n",
    "            \"fpr\": fpr.cpu(),\n",
    "            \"tpr\": tpr.cpu(),\n",
    "            \"auc\": test_auc_val,\n",
    "            \"f1\": test_f1_val,\n",
    "            \"precision\": test_prec,\n",
    "            \"recall\": test_rec,\n",
    "            \"cm\": test_cm_val,\n",
    "            \"thresholds\": thresholds.cpu(),\n",
    "        }\n",
    "        # Free up memory\n",
    "        self.test_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ea652",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d785e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.2\n",
      "Number of training samples: 4708\n",
      "Number of test samples: 624\n",
      "Number of validation samples: 524\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "train_dataset, test_dataset, val_dataset = generate_data(\"pneumoniaMNIST\")\n",
    "\n",
    "# Ensure you have your train_loader and val_loader defined here\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_dataset.transform = data_transforms\n",
    "test_dataset.transform = data_transforms\n",
    "val_dataset.transform = data_transforms\n",
    "\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "#new_train_loader = data.DataLoader(new_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS) to be done inside the sample_ratio loop\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# initialize fold\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971945fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "best_model_paths = [] # List to store the path of the best model from each stage\n",
    "\n",
    "# 1. Instantiate the LightningModule\n",
    "model = LitSimpleCNN(\n",
    "    in_channels=NUM_CHANNELS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    training_mode='full_network',  # Change to 'classifier_only' if you want to train only the classifier\n",
    "    image_height=IMAGE_SIZE,\n",
    "    image_width=IMAGE_SIZE\n",
    ")\n",
    "\n",
    "# Optional: Print model summary\n",
    "# You need to move the model to a device first for torchsummary to work\n",
    "# summary(model.to('cuda'), (NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE))\n",
    "# model.to('cpu') # Move it back if needed\n",
    "\n",
    "checkpoint_callback_full_model = ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='simple-cnn-full-{epoch:02d}-{val_acc:.2f}',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n",
    "train_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',                 # Use GPUs\n",
    "    devices=1,                         # Number of GPUs to use\n",
    "    #strategy='ddp_notebook',                    # DistributedDataParallel strategy (best for multi-GPU)\n",
    "    max_epochs=NUM_EPOCHS,              # Total number of epochs\n",
    "    callbacks=[checkpoint_callback_full_model, progress_bar],\n",
    "    logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple_cnn-full\")\n",
    ")\n",
    "\n",
    "test_trainer_1 = pl.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=1,  # Use only one GPU\n",
    "    logger = pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=\"simple_cnn_test\"),\n",
    "    # Add the callback here so the Trainer can find the 'best' path\n",
    "    callbacks=[checkpoint_callback_full_model],\n",
    "    precision='16-mixed'  # Use mixed precision for testing\n",
    ")\n",
    "\n",
    "\n",
    "# --- Phase 1 Training ---\n",
    "print(f\"--- Starting Training for {NUM_EPOCHS} epochs on train_loader ---\")\n",
    "train_trainer_1.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "# CRITICAL: Save the path to the best model from this phase\n",
    "path_after_phase1 = checkpoint_callback_full_model.best_model_path\n",
    "print(f\"Best model from Phase 1 saved to: {path_after_phase1}\")\n",
    "\n",
    "# --- Test 1: Evaluate the model from after Phase 1 ---\n",
    "print(f\"\\n--- Testing model from Phase 1 checkpoint: {path_after_phase1} ---\")\n",
    "model.current_test_title = \"ROC Curve after training on DataLoader 1\"\n",
    "model = LitSimpleCNN.load_from_checkpoint(path_after_phase1)  # Load the model from Phase 1\n",
    "model.eval().to('cuda:0')  # Ensure the model is in evaluation mode and on GPU\n",
    "test_trainer_1.test(model, dataloaders=test_loader, ckpt_path=path_after_phase1)\n",
    "results_phase1 = model.last_test_results.copy()\n",
    "results_original_roc = {\"fpr\": results_phase1[\"fpr\"], \"tpr\": results_phase1[\"tpr\"], \"thresholds\": results_phase1[\"thresholds\"], \"name\": \"Original NN PneumoniaMNIST\", \"auc\": results_phase1[\"auc\"], \"model\": model}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c2d0a",
   "metadata": {},
   "source": [
    "### Weighted ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "226e70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSIFIERS = 20\n",
    "w = np.linspace(0.001, 0.999, NUM_CLASSIFIERS, endpoint=True)\n",
    "pos_weights = w/(1-w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d1bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "import numpy as np\n",
    "\n",
    "# --- Place any constants or unchanging objects outside the loop ---\n",
    "pl.seed_everything(42, workers=True)\n",
    "progress_bar = TQDMProgressBar(refresh_rate=10)\n",
    "best_model_paths = [] # List to store the path of the best model from each stage\n",
    "\n",
    "\n",
    "#store the weighted classifiers of all the folds\n",
    "list_folds_weighted_clfs = []  # List to store classifiers from all folds\n",
    "#store the best classfiers of all the folds\n",
    "list_folds_best_models = []  # List to store best models from all folds\n",
    "\n",
    "# Dictionary to store the history of each fold\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "# 3. K-fold cross-validation loop\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_dataset)):\n",
    "    list_weighted_clfs = [] # List to store the models trained at each stage\n",
    "    best_clfs = [] # List to store the best models from each stage\n",
    "    best_model_paths = [] # List to store the path of the best model from each stage\n",
    "\n",
    "    # 1. Instantiate the LightningModule\n",
    "    model = LitSimpleCNN(\n",
    "        in_channels=NUM_CHANNELS,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        training_mode='full_network',  # Change to 'classifier_only' if you want to train only the classifier\n",
    "        image_height=IMAGE_SIZE,\n",
    "        image_width=IMAGE_SIZE\n",
    "    )\n",
    "    print(f\"--- Starting Fold {fold + 1}/{K_FOLDS} ---\")\n",
    "\n",
    "    # 4. Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "    train_loader = data.DataLoader(\n",
    "                      train_dataset,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      sampler=train_subsampler,\n",
    "                      num_workers=NUM_WORKERS)\n",
    "    fold_loader = data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    sampler=val_subsampler,\n",
    "                    num_workers=NUM_WORKERS)\n",
    "\n",
    "    for i, pos_weight in enumerate(pos_weights):\n",
    "        model.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            monitor='val_acc',\n",
    "            dirpath=f'checkpoints/stage_{i+1}/',\n",
    "            filename=f'best-model-{{epoch:02d}}-{{val_acc:.2f}}',\n",
    "            save_top_k=1,\n",
    "            mode='max',\n",
    "        )\n",
    "        \n",
    "        # 3. Instantiate a NEW Trainer for this specific stage\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator='gpu',\n",
    "            devices=1,\n",
    "            #strategy='ddp_notebook',\n",
    "            max_epochs=NUM_EPOCHS, # Number of epochs for THIS stage\n",
    "            callbacks=[checkpoint_callback, progress_bar],\n",
    "            logger=pl.loggers.TensorBoardLogger(\"lightning_logs/\", name=f\"stage_{i+1}_ratio_{pos_weight}\"),\n",
    "            precision='16-mixed'\n",
    "            )\n",
    "        \n",
    "        # 4. Train the model. It will start with weights from the previous stage.\n",
    "        trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "        \n",
    "        # 5. Get the path to the best model from THIS stage and store it\n",
    "        if checkpoint_callback.best_model_path:\n",
    "            best_path_this_stage = checkpoint_callback.best_model_path\n",
    "            print(f\"--- Stage {i+1} complete. Best model path: {best_path_this_stage} ---\")\n",
    "            best_model_paths.append(best_path_this_stage)\n",
    "            \n",
    "            # 6. CRITICAL: Load the best weights back into the model object\n",
    "            # This ensures we carry forward the BEST model to the next stage, not the last.\n",
    "            print(f\"Loading best weights from {best_path_this_stage} to continue...\")\n",
    "            model = LitSimpleCNN.load_from_checkpoint(best_path_this_stage, strict=False)  # Use strict=False to ignore missing keys if any\n",
    "        else:\n",
    "            print(f\"--- Stage {i+1} complete. No checkpoint was saved. ---\")\n",
    "            # If no checkpoint was saved, the model object will just have the weights from the last epoch.\n",
    "\n",
    "    # 7. Test the model after each stage\n",
    "    # Loop through each saved model checkpoint\n",
    "    for i, checkpoint_path in enumerate(best_model_paths):\n",
    "        print(f\"\\n--- Testing model from checkpoint: {checkpoint_path} ---\")\n",
    "\n",
    "        # 1. Load the PyTorch model from the checkpoint\n",
    "        pytorch_model = LitSimpleCNN.load_from_checkpoint(checkpoint_path, strict=False)\n",
    "        pytorch_model.eval()  # Set model to evaluation mode\n",
    "        pytorch_model.to('cuda:0') # Move model to GPU\n",
    "\n",
    "        # --- Generate Predictions for the ENTIRE test set ---\n",
    "        # We will collect the raw model outputs (logits) and true labels\n",
    "        all_logits = []\n",
    "        all_labels = []\n",
    "\n",
    "        # Wrap the loop in torch.no_grad() for efficiency\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(fold_loader, desc=f\"Predicting with model {i+1}\"):\n",
    "                inputs, labels = batch\n",
    "                \n",
    "                # Move data to the GPU\n",
    "                inputs = inputs.to('cuda:0')\n",
    "                \n",
    "                # Get model output (raw logits) for the batch\n",
    "                logits = pytorch_model(inputs)\n",
    "                \n",
    "                # Append batch results to lists (move back to CPU to prevent GPU memory buildup)\n",
    "                all_logits.append(logits.cpu())\n",
    "                all_labels.append(labels.cpu())\n",
    "\n",
    "        # Concatenate all batch results into single tensors\n",
    "        # These now contain the predictions and labels for the full test set\n",
    "        full_dataset_logits = torch.cat(all_logits)\n",
    "        full_dataset_labels = torch.cat(all_labels).int() # Ensure labels are integers\n",
    "\n",
    "        # --- Now, Calculate ALL Metrics using the generated predictions ---\n",
    "\n",
    "        # 2. Calculate the full ROC curve data\n",
    "        # Use the raw logits, torchmetrics will handle applying all thresholds\n",
    "        array_of_all_fprs, array_of_all_tprs, threshold_vals = torchmetrics.functional.roc(\n",
    "            preds=full_dataset_logits,\n",
    "            target=full_dataset_labels,\n",
    "            task=\"binary\"\n",
    "        )\n",
    "\n",
    "        # 3. Calculate confusion matrix based on a hard threshold (e.g., 0.5)\n",
    "        # Note: The model outputs logits, so the threshold 0.5 for probabilities corresponds to 0.0 for logits.\n",
    "        hard_preds = (full_dataset_logits > 0.0).int().numpy()\n",
    "        tn, fp, fn, tp = confusion_matrix(full_dataset_labels.numpy(), hard_preds).ravel()\n",
    "\n",
    "        # 4. Calculate metrics from the confusion matrix\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0  # This is also Recall\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        f1 = 2 * (precision * tpr) / (precision + tpr) if (precision + tpr) > 0 else 0\n",
    "        \n",
    "        print(f\"Results at threshold 0.5: TPR={tpr:.4f}, FPR={fpr:.4f}, F1-Score={f1:.4f}\")\n",
    "        \n",
    "        # 5. Store the comprehensive results for this model\n",
    "        list_weighted_clfs.append({\n",
    "            \"fpr\": fpr,\n",
    "            \"tpr\": tpr,\n",
    "            \"model\": pytorch_model, # Optional: store the model object itself\n",
    "            \"threshold\": 0.5,\n",
    "            \"full_roc\": {\n",
    "                \"fpr\": array_of_all_fprs,\n",
    "                \"tpr\": array_of_all_tprs,\n",
    "                \"thresholds\": threshold_vals\n",
    "            }\n",
    "        })\n",
    "        best_clfs = get_best_roc_envelope(list_weighted_clfs, results_original_roc)\n",
    "    list_folds_weighted_clfs.append(list_weighted_clfs)\n",
    "    list_folds_best_models.append(best_clfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57f49a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to pickle/medMNIST_weighted.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_models': [[{'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.),\n",
       "    'tpr': tensor(0.8959),\n",
       "    'threshold': tensor(0.9962)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0031),\n",
       "    'tpr': tensor(0.9181),\n",
       "    'threshold': tensor(0.9893)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0062),\n",
       "    'tpr': tensor(0.9263),\n",
       "    'threshold': tensor(0.9968)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0093),\n",
       "    'tpr': tensor(0.9474),\n",
       "    'threshold': tensor(0.9653)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0124),\n",
       "    'tpr': tensor(0.9579),\n",
       "    'threshold': tensor(0.9351)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0186),\n",
       "    'tpr': tensor(0.9626),\n",
       "    'threshold': tensor(0.9893)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0248),\n",
       "    'tpr': tensor(0.9684),\n",
       "    'threshold': tensor(0.8447)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0280),\n",
       "    'tpr': tensor(0.9731),\n",
       "    'threshold': tensor(0.8055)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0311),\n",
       "    'tpr': tensor(0.9743),\n",
       "    'threshold': tensor(0.7291)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0373),\n",
       "    'tpr': tensor(0.9766),\n",
       "    'threshold': tensor(0.6680)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0435),\n",
       "    'tpr': tensor(0.9801),\n",
       "    'threshold': tensor(0.6223)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0466),\n",
       "    'tpr': tensor(0.9825),\n",
       "    'threshold': tensor(0.5767)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0497),\n",
       "    'tpr': tensor(0.9836),\n",
       "    'threshold': tensor(0.5509)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0528),\n",
       "    'tpr': tensor(0.9848),\n",
       "    'threshold': tensor(0.5242)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0590),\n",
       "    'tpr': tensor(0.9860),\n",
       "    'threshold': tensor(0.4446)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0621),\n",
       "    'tpr': tensor(0.9871),\n",
       "    'threshold': tensor(0.8282)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0652),\n",
       "    'tpr': tensor(0.9883),\n",
       "    'threshold': tensor(0.7987)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0714),\n",
       "    'tpr': tensor(0.9895),\n",
       "    'threshold': tensor(0.7156)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0776),\n",
       "    'tpr': tensor(0.9906),\n",
       "    'threshold': tensor(0.5714)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0807),\n",
       "    'tpr': tensor(0.9918),\n",
       "    'threshold': tensor(0.5252)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0839),\n",
       "    'tpr': tensor(0.9930),\n",
       "    'threshold': tensor(0.4872)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0932),\n",
       "    'tpr': tensor(0.9942),\n",
       "    'threshold': tensor(0.3953)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1025),\n",
       "    'tpr': tensor(0.9953),\n",
       "    'threshold': tensor(0.3216)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1118),\n",
       "    'tpr': tensor(0.9965),\n",
       "    'threshold': tensor(0.7186)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1522),\n",
       "    'tpr': tensor(0.9977),\n",
       "    'threshold': tensor(3.4976e-05)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1739),\n",
       "    'tpr': tensor(0.9988),\n",
       "    'threshold': tensor(0.0308)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.3168),\n",
       "    'tpr': tensor(1.),\n",
       "    'threshold': tensor(0.0008)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.),\n",
       "    'tpr': tensor(0.8954),\n",
       "    'threshold': tensor(0.7445)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0033),\n",
       "    'tpr': tensor(0.9264),\n",
       "    'threshold': tensor(0.9999)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0065),\n",
       "    'tpr': tensor(0.9322),\n",
       "    'threshold': tensor(0.7920)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0098),\n",
       "    'tpr': tensor(0.9540),\n",
       "    'threshold': tensor(0.9999)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0163),\n",
       "    'tpr': tensor(0.9632),\n",
       "    'threshold': tensor(0.9713)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0195),\n",
       "    'tpr': tensor(0.9667),\n",
       "    'threshold': tensor(0.6785)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0228),\n",
       "    'tpr': tensor(0.9713),\n",
       "    'threshold': tensor(0.1952)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0293),\n",
       "    'tpr': tensor(0.9759),\n",
       "    'threshold': tensor(0.9817)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0326),\n",
       "    'tpr': tensor(0.9816),\n",
       "    'threshold': tensor(0.5871)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0358),\n",
       "    'tpr': tensor(0.9839),\n",
       "    'threshold': tensor(0.5320)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0456),\n",
       "    'tpr': tensor(0.9851),\n",
       "    'threshold': tensor(0.9519)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0489),\n",
       "    'tpr': tensor(0.9874),\n",
       "    'threshold': tensor(0.9445)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0619),\n",
       "    'tpr': tensor(0.9885),\n",
       "    'threshold': tensor(0.9117)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0684),\n",
       "    'tpr': tensor(0.9908),\n",
       "    'threshold': tensor(0.2237)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0717),\n",
       "    'tpr': tensor(0.9920),\n",
       "    'threshold': tensor(0.1898)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0879),\n",
       "    'tpr': tensor(0.9931),\n",
       "    'threshold': tensor(0.1112)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1368),\n",
       "    'tpr': tensor(0.9943),\n",
       "    'threshold': tensor(0.0233)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1564),\n",
       "    'tpr': tensor(0.9954),\n",
       "    'threshold': tensor(0.0002)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1629),\n",
       "    'tpr': tensor(0.9966),\n",
       "    'threshold': tensor(0.0435)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1792),\n",
       "    'tpr': tensor(0.9977),\n",
       "    'threshold': tensor(0.0211)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1922),\n",
       "    'tpr': tensor(0.9989),\n",
       "    'threshold': tensor(9.3917e-06)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1954),\n",
       "    'tpr': tensor(1.),\n",
       "    'threshold': tensor(0.0104)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.),\n",
       "    'tpr': tensor(0.7109),\n",
       "    'threshold': tensor(5.0512e-05)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0036),\n",
       "    'tpr': tensor(0.8973),\n",
       "    'threshold': tensor(0.9677)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0071),\n",
       "    'tpr': tensor(0.9453),\n",
       "    'threshold': tensor(0.8899)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0107),\n",
       "    'tpr': tensor(0.9464),\n",
       "    'threshold': tensor(0.8624)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0142),\n",
       "    'tpr': tensor(0.9509),\n",
       "    'threshold': tensor(0.8457)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0178),\n",
       "    'tpr': tensor(0.9520),\n",
       "    'threshold': tensor(0.8377)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0214),\n",
       "    'tpr': tensor(0.9676),\n",
       "    'threshold': tensor(0.4480)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0249),\n",
       "    'tpr': tensor(0.9721),\n",
       "    'threshold': tensor(0.2419)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0285),\n",
       "    'tpr': tensor(0.9866),\n",
       "    'threshold': tensor(0.1562)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0391),\n",
       "    'tpr': tensor(0.9888),\n",
       "    'threshold': tensor(0.0956)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0463),\n",
       "    'tpr': tensor(0.9900),\n",
       "    'threshold': tensor(0.0772)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0534),\n",
       "    'tpr': tensor(0.9911),\n",
       "    'threshold': tensor(0.7811)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0569),\n",
       "    'tpr': tensor(0.9922),\n",
       "    'threshold': tensor(0.3512)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0676),\n",
       "    'tpr': tensor(0.9933),\n",
       "    'threshold': tensor(0.4385)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0712),\n",
       "    'tpr': tensor(0.9944),\n",
       "    'threshold': tensor(0.4095)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0783),\n",
       "    'tpr': tensor(0.9955),\n",
       "    'threshold': tensor(0.2223)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0890),\n",
       "    'tpr': tensor(0.9967),\n",
       "    'threshold': tensor(0.1113)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1530),\n",
       "    'tpr': tensor(0.9978),\n",
       "    'threshold': tensor(0.0054)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1957),\n",
       "    'tpr': tensor(0.9989),\n",
       "    'threshold': tensor(0.0017)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.2420),\n",
       "    'tpr': tensor(1.),\n",
       "    'threshold': tensor(0.0079)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}],\n",
       "  [{'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.),\n",
       "    'tpr': tensor(0.9084),\n",
       "    'threshold': tensor(0.8700)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0033),\n",
       "    'tpr': tensor(0.9473),\n",
       "    'threshold': tensor(0.4369)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0066),\n",
       "    'tpr': tensor(0.9679),\n",
       "    'threshold': tensor(0.4760)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0099),\n",
       "    'tpr': tensor(0.9702),\n",
       "    'threshold': tensor(0.4565)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0132),\n",
       "    'tpr': tensor(0.9771),\n",
       "    'threshold': tensor(0.3745)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0164),\n",
       "    'tpr': tensor(0.9794),\n",
       "    'threshold': tensor(0.3416)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0230),\n",
       "    'tpr': tensor(0.9817),\n",
       "    'threshold': tensor(0.2385)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0329),\n",
       "    'tpr': tensor(0.9828),\n",
       "    'threshold': tensor(0.2042)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0428),\n",
       "    'tpr': tensor(0.9851),\n",
       "    'threshold': tensor(0.1586)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0493),\n",
       "    'tpr': tensor(0.9885),\n",
       "    'threshold': tensor(0.1194)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0526),\n",
       "    'tpr': tensor(0.9897),\n",
       "    'threshold': tensor(0.1101)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0625),\n",
       "    'tpr': tensor(0.9908),\n",
       "    'threshold': tensor(0.0726)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0658),\n",
       "    'tpr': tensor(0.9920),\n",
       "    'threshold': tensor(0.0719)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0724),\n",
       "    'tpr': tensor(0.9931),\n",
       "    'threshold': tensor(0.0536)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0789),\n",
       "    'tpr': tensor(0.9943),\n",
       "    'threshold': tensor(0.0426)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.0855),\n",
       "    'tpr': tensor(0.9954),\n",
       "    'threshold': tensor(0.0332)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1086),\n",
       "    'tpr': tensor(0.9966),\n",
       "    'threshold': tensor(0.5559)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1184),\n",
       "    'tpr': tensor(0.9977),\n",
       "    'threshold': tensor(0.1695)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.1447),\n",
       "    'tpr': tensor(0.9989),\n",
       "    'threshold': tensor(0.1260)},\n",
       "   {'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'fpr': tensor(0.2336),\n",
       "    'tpr': tensor(1.),\n",
       "    'threshold': tensor(0.0423)},\n",
       "   {'model': 'end', 'fpr': 1.0, 'tpr': 1.0, 'threshold': 0.0}]],\n",
       " 'weighted_clfs': [[{'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.10292397660818714),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0012, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.6811e-01, 9.5809e-01,  ..., 1.6914e-08, 2.4539e-09,\n",
       "             2.1526e-09])}},\n",
       "   {'fpr': np.float64(0.015527950310559006),\n",
       "    'tpr': np.float64(0.8105263157894737),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0012, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9755e-01, 9.9675e-01,  ..., 2.8364e-06, 2.0510e-06,\n",
       "             8.6191e-07])}},\n",
       "   {'fpr': np.float64(0.040372670807453416),\n",
       "    'tpr': np.float64(0.9555555555555556),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0012, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9968e-01, 9.9966e-01,  ..., 6.0520e-06, 3.9669e-06,\n",
       "             7.6337e-07])}},\n",
       "   {'fpr': np.float64(0.06832298136645963),\n",
       "    'tpr': np.float64(0.9730994152046784),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0012, 0.0047,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.7860e-07, 1.0749e-07,\n",
       "             2.1376e-08])}},\n",
       "   {'fpr': np.float64(0.015527950310559006),\n",
       "    'tpr': np.float64(0.9064327485380117),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0012, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9999e-01, 9.9998e-01,  ..., 5.8526e-09, 5.7954e-10,\n",
       "             3.9462e-10])}},\n",
       "   {'fpr': np.float64(0.09627329192546584),\n",
       "    'tpr': np.float64(0.9859649122807017),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0012, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9999e-01, 9.9998e-01,  ..., 8.5523e-06, 6.4789e-06,\n",
       "             5.1900e-06])}},\n",
       "   {'fpr': np.float64(0.09937888198757763),\n",
       "    'tpr': np.float64(0.9894736842105263),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0012, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 9.9999e-01,  ..., 6.7978e-06, 4.9337e-06,\n",
       "             4.0759e-06])}},\n",
       "   {'fpr': np.float64(0.055900621118012424),\n",
       "    'tpr': np.float64(0.9812865497076023),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0012, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9999e-01, 9.9999e-01,  ..., 1.0555e-08, 4.6581e-09,\n",
       "             1.0192e-09])}},\n",
       "   {'fpr': np.float64(0.08385093167701864),\n",
       "    'tpr': np.float64(0.991812865497076),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0124, 0.0124, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155,\n",
       "             0.0155, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155,\n",
       "             0.0155, 0.0155, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186,\n",
       "             0.0186, 0.0186, 0.0186, 0.0217, 0.0248, 0.0280, 0.0280, 0.0280, 0.0280,\n",
       "             0.0311, 0.0311, 0.0311, 0.0311, 0.0342, 0.0342, 0.0373, 0.0373, 0.0373,\n",
       "             0.0404, 0.0435, 0.0466, 0.0466, 0.0497, 0.0528, 0.0528, 0.0528, 0.0528,\n",
       "             0.0528, 0.0559, 0.0559, 0.0559, 0.0559, 0.0590, 0.0590, 0.0590, 0.0621,\n",
       "             0.0621, 0.0621, 0.0652, 0.0652, 0.0683, 0.0714, 0.0714, 0.0745, 0.0776,\n",
       "             0.0776, 0.0807, 0.0807, 0.0839, 0.0839, 0.0870, 0.0932, 0.0932, 0.0963,\n",
       "             0.0994, 0.1025, 0.1025, 0.1056, 0.1087, 0.1118, 0.1149, 0.1180, 0.1211,\n",
       "             0.1242, 0.1242, 0.1273, 0.1304, 0.1335, 0.1366, 0.1398, 0.1429, 0.1460,\n",
       "             0.1491, 0.1522, 0.1553, 0.1584, 0.1584, 0.1615, 0.1646, 0.1677, 0.1708,\n",
       "             0.1739, 0.1739, 0.1770, 0.1801, 0.1832, 0.1863, 0.1894, 0.1925, 0.1957,\n",
       "             0.1988, 0.2019, 0.2050, 0.2081, 0.2112, 0.2143, 0.2174, 0.2205, 0.2236,\n",
       "             0.2267, 0.2298, 0.2329, 0.2360, 0.2391, 0.2422, 0.2453, 0.2484, 0.2516,\n",
       "             0.2547, 0.2578, 0.2609, 0.2640, 0.2671, 0.2702, 0.2733, 0.2764, 0.2795,\n",
       "             0.2826, 0.2857, 0.2888, 0.2919, 0.2950, 0.2981, 0.3012, 0.3043, 0.3075,\n",
       "             0.3106, 0.3137, 0.3168, 0.3199, 0.3230, 0.3261, 0.3292, 0.3323, 0.3354,\n",
       "             0.3385, 0.3416, 0.3447, 0.3478, 0.3509, 0.3540, 0.3571, 0.3602, 0.3634,\n",
       "             0.3665, 0.3696, 0.3727, 0.3758, 0.3789, 0.3820, 0.3851, 0.3882, 0.3913,\n",
       "             0.3944, 0.3975, 0.4006, 0.4037, 0.4068, 0.4099, 0.4130, 0.4161, 0.4193,\n",
       "             0.4224, 0.4255, 0.4286, 0.4317, 0.4348, 0.4379, 0.4410, 0.4441, 0.4472,\n",
       "             0.4503, 0.4534, 0.4565, 0.4596, 0.4627, 0.4658, 0.4689, 0.4720, 0.4752,\n",
       "             0.4783, 0.4814, 0.4845, 0.4876, 0.4907, 0.4938, 0.4969, 0.5000, 0.5031,\n",
       "             0.5062, 0.5093, 0.5124, 0.5155, 0.5186, 0.5217, 0.5248, 0.5280, 0.5311,\n",
       "             0.5342, 0.5373, 0.5404, 0.5435, 0.5466, 0.5497, 0.5528, 0.5559, 0.5590,\n",
       "             0.5621, 0.5652, 0.5683, 0.5714, 0.5745, 0.5776, 0.5807, 0.5839, 0.5870,\n",
       "             0.5901, 0.5932, 0.5963, 0.5994, 0.6025, 0.6056, 0.6087, 0.6118, 0.6118,\n",
       "             0.6149, 0.6180, 0.6211, 0.6242, 0.6273, 0.6304, 0.6335, 0.6366, 0.6398,\n",
       "             0.6429, 0.6460, 0.6491, 0.6522, 0.6553, 0.6584, 0.6615, 0.6646, 0.6677,\n",
       "             0.6708, 0.6739, 0.6770, 0.6801, 0.6832, 0.6863, 0.6894, 0.6925, 0.6957,\n",
       "             0.6988, 0.7019, 0.7050, 0.7081, 0.7112, 0.7143, 0.7174, 0.7205, 0.7236,\n",
       "             0.7267, 0.7298, 0.7329, 0.7360, 0.7391, 0.7422, 0.7453, 0.7484, 0.7516,\n",
       "             0.7547, 0.7578, 0.7609, 0.7640, 0.7671, 0.7702, 0.7733, 0.7764, 0.7795,\n",
       "             0.7826, 0.7857, 0.7888, 0.7919, 0.7950, 0.7981, 0.8012, 0.8043, 0.8075,\n",
       "             0.8106, 0.8137, 0.8168, 0.8199, 0.8230, 0.8261, 0.8292, 0.8323, 0.8354,\n",
       "             0.8385, 0.8416, 0.8447, 0.8478, 0.8509, 0.8540, 0.8571, 0.8602, 0.8634,\n",
       "             0.8665, 0.8696, 0.8727, 0.8758, 0.8789, 0.8820, 0.8851, 0.8882, 0.8913,\n",
       "             0.8944, 0.8975, 0.9006, 0.9037, 0.9068, 0.9099, 0.9130, 0.9161, 0.9193,\n",
       "             0.9224, 0.9255, 0.9286, 0.9317, 0.9348, 0.9379, 0.9410, 0.9441, 0.9472,\n",
       "             0.9503, 0.9534, 0.9565, 0.9596, 0.9627, 0.9658, 0.9689, 0.9720, 0.9752,\n",
       "             0.9783, 0.9814, 0.9845, 0.9876, 0.9907, 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0012, 0.0058, 0.0094, 0.0129, 0.0164, 0.0211, 0.0234, 0.0316,\n",
       "             0.0398, 0.0421, 0.0480, 0.0573, 0.0608, 0.0702, 0.0760, 0.0784, 0.0807,\n",
       "             0.0830, 0.0865, 0.0889, 0.0971, 0.0994, 0.1018, 0.1029, 0.1053, 0.1076,\n",
       "             0.1123, 0.1205, 0.1287, 0.1333, 0.1357, 0.1380, 0.1415, 0.1497, 0.1556,\n",
       "             0.1602, 0.1614, 0.1673, 0.1719, 0.1754, 0.1778, 0.1789, 0.1848, 0.1883,\n",
       "             0.1895, 0.1918, 0.1930, 0.1953, 0.2035, 0.2094, 0.2117, 0.2140, 0.2187,\n",
       "             0.2269, 0.2304, 0.2327, 0.2363, 0.2386, 0.2398, 0.2433, 0.2444, 0.2456,\n",
       "             0.2480, 0.2503, 0.2538, 0.2573, 0.2608, 0.2620, 0.2655, 0.2667, 0.2690,\n",
       "             0.2725, 0.2737, 0.2749, 0.2772, 0.2807, 0.2830, 0.2854, 0.2889, 0.2912,\n",
       "             0.2947, 0.2959, 0.2982, 0.3006, 0.3053, 0.3064, 0.3111, 0.3146, 0.3181,\n",
       "             0.3205, 0.3240, 0.3275, 0.3310, 0.3333, 0.3404, 0.3415, 0.3427, 0.3439,\n",
       "             0.3462, 0.3474, 0.3497, 0.3520, 0.3532, 0.3544, 0.3567, 0.3626, 0.3637,\n",
       "             0.3661, 0.3673, 0.3684, 0.3708, 0.3719, 0.3731, 0.3743, 0.3766, 0.3789,\n",
       "             0.3825, 0.3836, 0.3848, 0.3860, 0.3871, 0.3883, 0.3895, 0.3918, 0.3930,\n",
       "             0.3953, 0.3965, 0.3988, 0.4000, 0.4047, 0.4058, 0.4082, 0.4094, 0.4105,\n",
       "             0.4117, 0.4129, 0.4140, 0.4152, 0.4175, 0.4211, 0.4222, 0.4234, 0.4246,\n",
       "             0.4257, 0.4281, 0.4292, 0.4304, 0.4327, 0.4351, 0.4363, 0.4374, 0.4398,\n",
       "             0.4409, 0.4421, 0.4456, 0.4468, 0.4480, 0.4491, 0.4503, 0.4526, 0.4550,\n",
       "             0.4561, 0.4573, 0.4585, 0.4608, 0.4620, 0.4632, 0.4667, 0.4678, 0.4702,\n",
       "             0.4713, 0.4737, 0.4749, 0.4760, 0.4784, 0.4795, 0.4807, 0.4819, 0.4830,\n",
       "             0.4854, 0.4877, 0.4889, 0.4912, 0.4924, 0.4936, 0.4947, 0.4959, 0.4982,\n",
       "             0.5006, 0.5018, 0.5029, 0.5053, 0.5064, 0.5076, 0.5099, 0.5111, 0.5135,\n",
       "             0.5146, 0.5170, 0.5193, 0.5205, 0.5216, 0.5240, 0.5251, 0.5263, 0.5275,\n",
       "             0.5287, 0.5298, 0.5310, 0.5322, 0.5333, 0.5345, 0.5357, 0.5380, 0.5392,\n",
       "             0.5404, 0.5415, 0.5427, 0.5439, 0.5450, 0.5474, 0.5485, 0.5497, 0.5509,\n",
       "             0.5520, 0.5532, 0.5556, 0.5567, 0.5579, 0.5591, 0.5602, 0.5614, 0.5649,\n",
       "             0.5661, 0.5684, 0.5696, 0.5708, 0.5731, 0.5754, 0.5766, 0.5778, 0.5789,\n",
       "             0.5801, 0.5813, 0.5825, 0.5836, 0.5848, 0.5871, 0.5883, 0.5895, 0.5906,\n",
       "             0.5918, 0.5930, 0.5942, 0.5965, 0.5977, 0.5988, 0.6023, 0.6035, 0.6047,\n",
       "             0.6058, 0.6070, 0.6094, 0.6105, 0.6117, 0.6129, 0.6152, 0.6164, 0.6175,\n",
       "             0.6187, 0.6199, 0.6211, 0.6222, 0.6234, 0.6246, 0.6257, 0.6269, 0.6281,\n",
       "             0.6292, 0.6304, 0.6316, 0.6327, 0.6339, 0.6351, 0.6363, 0.6374, 0.6386,\n",
       "             0.6398, 0.6409, 0.6421, 0.6433, 0.6444, 0.6456, 0.6468, 0.6491, 0.6503,\n",
       "             0.6515, 0.6526, 0.6538, 0.6550, 0.6561, 0.6573, 0.6585, 0.6596, 0.6608,\n",
       "             0.6620, 0.6632, 0.6643, 0.6655, 0.6667, 0.6678, 0.6690, 0.6702, 0.6713,\n",
       "             0.6725, 0.6737, 0.6772, 0.6784, 0.6795, 0.6807, 0.6819, 0.6830, 0.6842,\n",
       "             0.6854, 0.6889, 0.6901, 0.6912, 0.6924, 0.6936, 0.6947, 0.6971, 0.6982,\n",
       "             0.6994, 0.7006, 0.7018, 0.7029, 0.7041, 0.7053, 0.7064, 0.7076, 0.7088,\n",
       "             0.7088, 0.7099, 0.7111, 0.7123, 0.7135, 0.7146, 0.7158, 0.7170, 0.7181,\n",
       "             0.7193, 0.7205, 0.7216, 0.7228, 0.7240, 0.7251, 0.7263, 0.7275, 0.7287,\n",
       "             0.7298, 0.7310, 0.7333, 0.7345, 0.7357, 0.7368, 0.7380, 0.7392, 0.7404,\n",
       "             0.7415, 0.7427, 0.7439, 0.7450, 0.7474, 0.7485, 0.7497, 0.7509, 0.7520,\n",
       "             0.7532, 0.7544, 0.7556, 0.7567, 0.7579, 0.7591, 0.7602, 0.7614, 0.7626,\n",
       "             0.7637, 0.7649, 0.7661, 0.7673, 0.7684, 0.7696, 0.7708, 0.7719, 0.7731,\n",
       "             0.7754, 0.7766, 0.7778, 0.7789, 0.7801, 0.7813, 0.7825, 0.7836, 0.7848,\n",
       "             0.7860, 0.7871, 0.7883, 0.7895, 0.7906, 0.7918, 0.7930, 0.7942, 0.7953,\n",
       "             0.7965, 0.7977, 0.7988, 0.8000, 0.8012, 0.8023, 0.8035, 0.8047, 0.8058,\n",
       "             0.8070, 0.8082, 0.8094, 0.8105, 0.8117, 0.8129, 0.8140, 0.8152, 0.8164,\n",
       "             0.8175, 0.8187, 0.8199, 0.8211, 0.8222, 0.8234, 0.8246, 0.8257, 0.8269,\n",
       "             0.8281, 0.8292, 0.8304, 0.8316, 0.8327, 0.8339, 0.8351, 0.8363, 0.8374,\n",
       "             0.8386, 0.8398, 0.8409, 0.8421, 0.8433, 0.8444, 0.8456, 0.8468, 0.8480,\n",
       "             0.8480, 0.8491, 0.8503, 0.8515, 0.8526, 0.8538, 0.8550, 0.8561, 0.8573,\n",
       "             0.8585, 0.8596, 0.8608, 0.8620, 0.8632, 0.8643, 0.8655, 0.8667, 0.8678,\n",
       "             0.8690, 0.8702, 0.8713, 0.8725, 0.8737, 0.8749, 0.8760, 0.8772, 0.8784,\n",
       "             0.8795, 0.8807, 0.8819, 0.8830, 0.8842, 0.8854, 0.8865, 0.8877, 0.8889,\n",
       "             0.8901, 0.8912, 0.8924, 0.8936, 0.8947, 0.8959, 0.8971, 0.8982, 0.8994,\n",
       "             0.9006, 0.9018, 0.9029, 0.9041, 0.9053, 0.9064, 0.9076, 0.9088, 0.9099,\n",
       "             0.9111, 0.9123, 0.9135, 0.9146, 0.9158, 0.9170, 0.9181, 0.9193, 0.9205,\n",
       "             0.9216, 0.9228, 0.9240, 0.9251, 0.9263, 0.9275, 0.9287, 0.9298, 0.9310,\n",
       "             0.9322, 0.9333, 0.9333, 0.9345, 0.9345, 0.9357, 0.9368, 0.9380, 0.9392,\n",
       "             0.9404, 0.9415, 0.9427, 0.9439, 0.9450, 0.9462, 0.9474, 0.9485, 0.9497,\n",
       "             0.9509, 0.9520, 0.9520, 0.9532, 0.9544, 0.9556, 0.9567, 0.9579, 0.9591,\n",
       "             0.9602, 0.9614, 0.9626, 0.9626, 0.9626, 0.9626, 0.9637, 0.9649, 0.9661,\n",
       "             0.9661, 0.9673, 0.9684, 0.9696, 0.9696, 0.9708, 0.9708, 0.9719, 0.9731,\n",
       "             0.9731, 0.9731, 0.9731, 0.9743, 0.9743, 0.9743, 0.9754, 0.9766, 0.9778,\n",
       "             0.9789, 0.9789, 0.9801, 0.9813, 0.9825, 0.9825, 0.9836, 0.9848, 0.9848,\n",
       "             0.9860, 0.9871, 0.9871, 0.9883, 0.9883, 0.9883, 0.9895, 0.9895, 0.9895,\n",
       "             0.9906, 0.9906, 0.9918, 0.9918, 0.9930, 0.9930, 0.9930, 0.9942, 0.9942,\n",
       "             0.9942, 0.9942, 0.9953, 0.9953, 0.9953, 0.9953, 0.9953, 0.9953, 0.9953,\n",
       "             0.9953, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965,\n",
       "             0.9965, 0.9965, 0.9965, 0.9965, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01,\n",
       "             9.9986e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01,\n",
       "             9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01,\n",
       "             9.9984e-01, 9.9984e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01,\n",
       "             9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9981e-01, 9.9981e-01,\n",
       "             9.9981e-01, 9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9980e-01,\n",
       "             9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9980e-01,\n",
       "             9.9979e-01, 9.9979e-01, 9.9979e-01, 9.9979e-01, 9.9979e-01, 9.9979e-01,\n",
       "             9.9978e-01, 9.9978e-01, 9.9978e-01, 9.9978e-01, 9.9978e-01, 9.9977e-01,\n",
       "             9.9977e-01, 9.9977e-01, 9.9976e-01, 9.9976e-01, 9.9976e-01, 9.9976e-01,\n",
       "             9.9975e-01, 9.9975e-01, 9.9975e-01, 9.9974e-01, 9.9974e-01, 9.9974e-01,\n",
       "             9.9973e-01, 9.9973e-01, 9.9973e-01, 9.9973e-01, 9.9973e-01, 9.9972e-01,\n",
       "             9.9972e-01, 9.9972e-01, 9.9972e-01, 9.9971e-01, 9.9971e-01, 9.9971e-01,\n",
       "             9.9971e-01, 9.9970e-01, 9.9970e-01, 9.9969e-01, 9.9969e-01, 9.9967e-01,\n",
       "             9.9966e-01, 9.9965e-01, 9.9963e-01, 9.9961e-01, 9.9961e-01, 9.9961e-01,\n",
       "             9.9960e-01, 9.9960e-01, 9.9959e-01, 9.9959e-01, 9.9959e-01, 9.9959e-01,\n",
       "             9.9957e-01, 9.9956e-01, 9.9956e-01, 9.9955e-01, 9.9955e-01, 9.9954e-01,\n",
       "             9.9954e-01, 9.9953e-01, 9.9952e-01, 9.9952e-01, 9.9952e-01, 9.9951e-01,\n",
       "             9.9951e-01, 9.9951e-01, 9.9951e-01, 9.9950e-01, 9.9949e-01, 9.9948e-01,\n",
       "             9.9948e-01, 9.9946e-01, 9.9946e-01, 9.9945e-01, 9.9943e-01, 9.9943e-01,\n",
       "             9.9943e-01, 9.9943e-01, 9.9942e-01, 9.9939e-01, 9.9938e-01, 9.9937e-01,\n",
       "             9.9936e-01, 9.9936e-01, 9.9934e-01, 9.9932e-01, 9.9932e-01, 9.9931e-01,\n",
       "             9.9931e-01, 9.9929e-01, 9.9928e-01, 9.9928e-01, 9.9925e-01, 9.9917e-01,\n",
       "             9.9914e-01, 9.9914e-01, 9.9913e-01, 9.9911e-01, 9.9906e-01, 9.9901e-01,\n",
       "             9.9900e-01, 9.9897e-01, 9.9894e-01, 9.9893e-01, 9.9891e-01, 9.9889e-01,\n",
       "             9.9888e-01, 9.9883e-01, 9.9882e-01, 9.9872e-01, 9.9872e-01, 9.9870e-01,\n",
       "             9.9860e-01, 9.9824e-01, 9.9822e-01, 9.9820e-01, 9.9805e-01, 9.9802e-01,\n",
       "             9.9792e-01, 9.9790e-01, 9.9780e-01, 9.9766e-01, 9.9758e-01, 9.9746e-01,\n",
       "             9.9729e-01, 9.9701e-01, 9.9700e-01, 9.9672e-01, 9.9670e-01, 9.9613e-01,\n",
       "             9.9603e-01, 9.9540e-01, 9.9492e-01, 9.9467e-01, 9.9439e-01, 9.9397e-01,\n",
       "             9.9350e-01, 9.9248e-01, 9.9241e-01, 9.9206e-01, 9.9174e-01, 9.9108e-01,\n",
       "             9.9106e-01, 9.9051e-01, 9.8933e-01, 9.8887e-01, 9.8814e-01, 9.8645e-01,\n",
       "             9.8637e-01, 9.8569e-01, 9.8377e-01, 9.8373e-01, 9.8175e-01, 9.8056e-01,\n",
       "             9.7799e-01, 9.7518e-01, 9.7357e-01, 9.7264e-01, 9.7199e-01, 9.7151e-01,\n",
       "             9.7097e-01, 9.7040e-01, 9.5185e-01, 9.5025e-01, 9.4346e-01, 9.3734e-01,\n",
       "             9.2660e-01, 9.1663e-01, 9.1640e-01, 9.1344e-01, 9.1174e-01, 9.0249e-01,\n",
       "             8.8831e-01, 8.8627e-01, 8.6988e-01, 8.4859e-01, 8.3528e-01, 8.3296e-01,\n",
       "             8.2852e-01, 8.2818e-01, 8.0287e-01, 7.9875e-01, 7.5960e-01, 7.3094e-01,\n",
       "             7.1562e-01, 6.3391e-01, 5.8839e-01, 5.7138e-01, 5.3788e-01, 5.2519e-01,\n",
       "             5.2425e-01, 4.8719e-01, 4.3461e-01, 4.0020e-01, 3.9526e-01, 3.9109e-01,\n",
       "             3.8767e-01, 3.2592e-01, 3.2159e-01, 3.2154e-01, 2.6625e-01, 2.5528e-01,\n",
       "             2.2931e-01, 2.0071e-01, 1.9903e-01, 1.7496e-01, 1.5961e-01, 1.5591e-01,\n",
       "             1.4948e-01, 1.3845e-01, 1.3595e-01, 1.2526e-01, 1.0610e-01, 9.8423e-02,\n",
       "             8.1208e-02, 8.1030e-02, 6.5904e-02, 6.0172e-02, 5.8927e-02, 5.5145e-02,\n",
       "             4.5247e-02, 3.7269e-02, 3.5846e-02, 3.1247e-02, 3.0751e-02, 2.7358e-02,\n",
       "             2.5782e-02, 2.4694e-02, 2.4614e-02, 2.3028e-02, 2.2704e-02, 2.1418e-02,\n",
       "             2.0628e-02, 1.8869e-02, 1.8263e-02, 1.8223e-02, 1.6607e-02, 1.6053e-02,\n",
       "             1.5109e-02, 1.4262e-02, 1.3804e-02, 1.2374e-02, 1.1946e-02, 1.1693e-02,\n",
       "             1.0677e-02, 9.5601e-03, 9.2858e-03, 8.7968e-03, 8.4620e-03, 8.1275e-03,\n",
       "             7.7085e-03, 7.3499e-03, 6.9200e-03, 6.5637e-03, 6.3062e-03, 6.2846e-03,\n",
       "             6.2455e-03, 6.0762e-03, 5.6932e-03, 5.4689e-03, 5.2184e-03, 5.2165e-03,\n",
       "             5.1562e-03, 4.9957e-03, 4.9788e-03, 4.9192e-03, 4.6402e-03, 4.5143e-03,\n",
       "             4.4777e-03, 4.3175e-03, 4.1082e-03, 3.6142e-03, 3.1572e-03, 2.9143e-03,\n",
       "             2.7688e-03, 2.7195e-03, 2.6845e-03, 2.4225e-03, 2.3721e-03, 2.3678e-03,\n",
       "             2.3524e-03, 2.3011e-03, 2.2247e-03, 2.1328e-03, 2.0225e-03, 2.0197e-03,\n",
       "             1.9784e-03, 1.9359e-03, 1.4415e-03, 1.4337e-03, 1.4089e-03, 1.3272e-03,\n",
       "             1.3084e-03, 1.2895e-03, 1.2043e-03, 1.1921e-03, 1.1802e-03, 1.1441e-03,\n",
       "             1.0800e-03, 1.0533e-03, 9.8002e-04, 9.6132e-04, 9.5280e-04, 9.3237e-04,\n",
       "             8.3664e-04, 8.1528e-04, 7.9224e-04, 7.8799e-04, 7.5532e-04, 7.2397e-04,\n",
       "             7.1543e-04, 6.1752e-04, 6.0764e-04, 6.0502e-04, 5.8073e-04, 5.3572e-04,\n",
       "             5.3510e-04, 4.7376e-04, 4.6297e-04, 4.2371e-04, 4.2185e-04, 4.1816e-04,\n",
       "             4.0948e-04, 4.0509e-04, 3.8681e-04, 3.4242e-04, 3.3970e-04, 3.3284e-04,\n",
       "             3.1564e-04, 3.0515e-04, 3.0351e-04, 2.6740e-04, 2.6377e-04, 2.5922e-04,\n",
       "             1.9763e-04, 1.8684e-04, 1.8198e-04, 1.5828e-04, 1.5731e-04, 1.5682e-04,\n",
       "             1.5596e-04, 1.5421e-04, 1.5165e-04, 1.4247e-04, 1.3757e-04, 1.3208e-04,\n",
       "             1.2993e-04, 1.2945e-04, 1.2617e-04, 1.2533e-04, 1.1646e-04, 1.1359e-04,\n",
       "             1.1098e-04, 9.9745e-05, 9.3604e-05, 8.8096e-05, 8.4372e-05, 8.3564e-05,\n",
       "             8.1304e-05, 7.8911e-05, 6.9437e-05, 6.9167e-05, 6.5499e-05, 6.2762e-05,\n",
       "             6.1573e-05, 5.8674e-05, 5.5373e-05, 5.2780e-05, 5.2306e-05, 5.2086e-05,\n",
       "             5.1457e-05, 5.1276e-05, 4.8034e-05, 4.7527e-05, 4.4964e-05, 4.4163e-05,\n",
       "             4.2980e-05, 4.0618e-05, 4.0235e-05, 4.0136e-05, 3.7933e-05, 3.6996e-05,\n",
       "             3.6444e-05, 3.5089e-05, 3.5037e-05, 3.3193e-05, 3.2788e-05, 3.2289e-05,\n",
       "             2.9950e-05, 2.8664e-05, 2.7299e-05, 2.7256e-05, 2.4558e-05, 2.4210e-05,\n",
       "             2.0512e-05, 1.9745e-05, 1.9074e-05, 1.6846e-05, 1.6716e-05, 1.5659e-05,\n",
       "             1.5062e-05, 1.4790e-05, 1.4210e-05, 1.3411e-05, 1.3198e-05, 1.3136e-05,\n",
       "             1.1997e-05, 1.1664e-05, 1.1516e-05, 1.1515e-05, 1.0395e-05, 9.9239e-06,\n",
       "             9.5760e-06, 9.0351e-06, 8.9948e-06, 8.8463e-06, 8.7636e-06, 8.6112e-06,\n",
       "             8.5290e-06, 8.3978e-06, 7.9923e-06, 7.4216e-06, 7.4080e-06, 6.0595e-06,\n",
       "             5.6752e-06, 4.9410e-06, 4.7968e-06, 4.6467e-06, 4.6433e-06, 4.5249e-06,\n",
       "             4.4731e-06, 4.4555e-06, 4.4032e-06, 3.3367e-06, 3.3261e-06, 2.9426e-06,\n",
       "             2.8519e-06, 2.7308e-06, 2.6432e-06, 2.1274e-06, 2.0084e-06, 1.6573e-06,\n",
       "             1.6287e-06, 1.4047e-06, 1.3194e-06, 1.3105e-06, 1.2928e-06, 1.2821e-06,\n",
       "             1.2154e-06, 1.1541e-06, 1.1438e-06, 9.7147e-07, 9.5821e-07, 9.3931e-07,\n",
       "             8.8988e-07, 8.3880e-07, 7.9923e-07, 7.8753e-07, 7.3331e-07, 7.1067e-07,\n",
       "             7.0272e-07, 6.7246e-07, 5.0719e-07, 4.5623e-07, 4.3629e-07, 3.4729e-07,\n",
       "             1.9427e-07, 1.7614e-07, 1.7591e-07, 1.6876e-07, 1.6370e-07, 1.3587e-07,\n",
       "             1.1187e-07, 1.0920e-07, 9.9363e-08, 9.8519e-08, 9.5520e-08, 8.7987e-08,\n",
       "             6.5062e-08, 5.7512e-08, 4.0855e-08, 3.9901e-08, 3.8460e-08, 3.1499e-08,\n",
       "             2.1621e-08, 9.5133e-09, 6.1396e-09, 5.1411e-09, 1.6146e-09, 1.4212e-09,\n",
       "             1.3560e-09, 6.4432e-10])}},\n",
       "   {'fpr': np.float64(0.09006211180124224),\n",
       "    'tpr': np.float64(0.9836257309941521),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0012, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.2759e-07, 1.0988e-07,\n",
       "             8.1581e-08])}},\n",
       "   {'fpr': np.float64(0.052795031055900624),\n",
       "    'tpr': np.float64(0.9847953216374269),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0012, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9999e-01, 9.9999e-01,  ..., 5.0046e-08, 4.9964e-08,\n",
       "             4.0131e-08])}},\n",
       "   {'fpr': np.float64(0.13043478260869565),\n",
       "    'tpr': np.float64(0.9964912280701754),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124,\n",
       "             0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124,\n",
       "             0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0155, 0.0155,\n",
       "             0.0155, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155,\n",
       "             0.0155, 0.0155, 0.0155, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186,\n",
       "             0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186,\n",
       "             0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186,\n",
       "             0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186,\n",
       "             0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186,\n",
       "             0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186,\n",
       "             0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186,\n",
       "             0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0217,\n",
       "             0.0248, 0.0248, 0.0248, 0.0248, 0.0248, 0.0248, 0.0248, 0.0248, 0.0280,\n",
       "             0.0280, 0.0280, 0.0280, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
       "             0.0373, 0.0404, 0.0435, 0.0466, 0.0497, 0.0497, 0.0528, 0.0559, 0.0590,\n",
       "             0.0590, 0.0621, 0.0621, 0.0621, 0.0621, 0.0652, 0.0652, 0.0652, 0.0683,\n",
       "             0.0683, 0.0714, 0.0745, 0.0745, 0.0745, 0.0776, 0.0776, 0.0776, 0.0807,\n",
       "             0.0839, 0.0839, 0.0839, 0.0870, 0.0901, 0.0932, 0.0963, 0.0963, 0.0994,\n",
       "             0.0994, 0.1025, 0.1025, 0.1025, 0.1025, 0.1056, 0.1087, 0.1118, 0.1118,\n",
       "             0.1149, 0.1180, 0.1211, 0.1242, 0.1273, 0.1304, 0.1335, 0.1366, 0.1398,\n",
       "             0.1429, 0.1460, 0.1491, 0.1522, 0.1553, 0.1584, 0.1615, 0.1646, 0.1677,\n",
       "             0.1708, 0.1708, 0.1739, 0.1770, 0.1801, 0.1832, 0.1863, 0.1894, 0.1925,\n",
       "             0.1957, 0.1988, 0.2019, 0.2050, 0.2081, 0.2112, 0.2143, 0.2174, 0.2205,\n",
       "             0.2236, 0.2267, 0.2298, 0.2329, 0.2360, 0.2391, 0.2422, 0.2453, 0.2484,\n",
       "             0.2516, 0.2547, 0.2578, 0.2609, 0.2640, 0.2671, 0.2671, 0.2702, 0.2733,\n",
       "             0.2764, 0.2795, 0.2826, 0.2857, 0.2888, 0.2919, 0.2950, 0.2981, 0.3012,\n",
       "             0.3043, 0.3075, 0.3106, 0.3137, 0.3168, 0.3199, 0.3230, 0.3261, 0.3292,\n",
       "             0.3323, 0.3354, 0.3385, 0.3416, 0.3447, 0.3478, 0.3509, 0.3540, 0.3571,\n",
       "             0.3602, 0.3634, 0.3665, 0.3696, 0.3727, 0.3758, 0.3789, 0.3820, 0.3851,\n",
       "             0.3882, 0.3913, 0.3944, 0.3975, 0.4006, 0.4037, 0.4068, 0.4099, 0.4130,\n",
       "             0.4161, 0.4193, 0.4224, 0.4255, 0.4286, 0.4317, 0.4348, 0.4379, 0.4410,\n",
       "             0.4441, 0.4472, 0.4503, 0.4534, 0.4565, 0.4596, 0.4627, 0.4658, 0.4689,\n",
       "             0.4720, 0.4720, 0.4752, 0.4783, 0.4814, 0.4845, 0.4876, 0.4907, 0.4938,\n",
       "             0.4969, 0.5000, 0.5031, 0.5062, 0.5093, 0.5124, 0.5155, 0.5186, 0.5217,\n",
       "             0.5248, 0.5280, 0.5311, 0.5342, 0.5373, 0.5404, 0.5435, 0.5466, 0.5497,\n",
       "             0.5528, 0.5559, 0.5590, 0.5621, 0.5652, 0.5683, 0.5714, 0.5745, 0.5776,\n",
       "             0.5807, 0.5839, 0.5870, 0.5901, 0.5932, 0.5963, 0.5994, 0.6025, 0.6056,\n",
       "             0.6087, 0.6118, 0.6149, 0.6180, 0.6211, 0.6242, 0.6273, 0.6304, 0.6335,\n",
       "             0.6366, 0.6398, 0.6429, 0.6460, 0.6491, 0.6522, 0.6553, 0.6584, 0.6615,\n",
       "             0.6646, 0.6677, 0.6708, 0.6739, 0.6770, 0.6801, 0.6832, 0.6863, 0.6894,\n",
       "             0.6925, 0.6957, 0.6988, 0.7019, 0.7050, 0.7081, 0.7112, 0.7143, 0.7174,\n",
       "             0.7205, 0.7236, 0.7267, 0.7298, 0.7329, 0.7360, 0.7391, 0.7422, 0.7453,\n",
       "             0.7484, 0.7516, 0.7547, 0.7578, 0.7609, 0.7640, 0.7671, 0.7702, 0.7733,\n",
       "             0.7764, 0.7795, 0.7826, 0.7857, 0.7888, 0.7919, 0.7950, 0.7981, 0.8012,\n",
       "             0.8043, 0.8075, 0.8106, 0.8137, 0.8168, 0.8199, 0.8230, 0.8261, 0.8292,\n",
       "             0.8323, 0.8354, 0.8385, 0.8416, 0.8447, 0.8478, 0.8509, 0.8540, 0.8571,\n",
       "             0.8602, 0.8634, 0.8665, 0.8696, 0.8727, 0.8758, 0.8789, 0.8820, 0.8851,\n",
       "             0.8882, 0.8913, 0.8944, 0.8975, 0.9006, 0.9037, 0.9068, 0.9099, 0.9130,\n",
       "             0.9161, 0.9193, 0.9224, 0.9255, 0.9286, 0.9317, 0.9348, 0.9379, 0.9410,\n",
       "             0.9441, 0.9472, 0.9503, 0.9534, 0.9565, 0.9596, 0.9627, 0.9658, 0.9689,\n",
       "             0.9720, 0.9752, 0.9783, 0.9814, 0.9845, 0.9876, 0.9907, 0.9938, 0.9969,\n",
       "             1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0702, 0.1146, 0.1520, 0.1813, 0.2035, 0.2281, 0.2456, 0.2620,\n",
       "             0.2784, 0.2865, 0.2936, 0.3053, 0.3170, 0.3275, 0.3357, 0.3439, 0.3497,\n",
       "             0.3556, 0.3602, 0.3649, 0.3684, 0.3754, 0.3848, 0.3871, 0.3953, 0.4012,\n",
       "             0.4070, 0.4117, 0.4140, 0.4164, 0.4187, 0.4222, 0.4246, 0.4292, 0.4316,\n",
       "             0.4351, 0.4398, 0.4433, 0.4491, 0.4526, 0.4561, 0.4596, 0.4632, 0.4655,\n",
       "             0.4667, 0.4713, 0.4737, 0.4772, 0.4807, 0.4854, 0.4901, 0.4936, 0.4947,\n",
       "             0.4971, 0.4982, 0.5006, 0.5018, 0.5053, 0.5076, 0.5088, 0.5111, 0.5146,\n",
       "             0.5158, 0.5181, 0.5216, 0.5228, 0.5240, 0.5251, 0.5275, 0.5287, 0.5322,\n",
       "             0.5333, 0.5357, 0.5368, 0.5380, 0.5404, 0.5415, 0.5439, 0.5450, 0.5462,\n",
       "             0.5485, 0.5544, 0.5567, 0.5591, 0.5614, 0.5637, 0.5673, 0.5696, 0.5719,\n",
       "             0.5731, 0.5754, 0.5766, 0.5778, 0.5801, 0.5813, 0.5848, 0.5871, 0.5883,\n",
       "             0.5906, 0.5930, 0.5942, 0.5965, 0.5977, 0.5988, 0.6000, 0.6035, 0.6058,\n",
       "             0.6070, 0.6094, 0.6105, 0.6117, 0.6140, 0.6164, 0.6175, 0.6187, 0.6211,\n",
       "             0.6234, 0.6246, 0.6257, 0.6281, 0.6292, 0.6316, 0.6327, 0.6351, 0.6363,\n",
       "             0.6374, 0.6409, 0.6421, 0.6444, 0.6480, 0.6491, 0.6503, 0.6515, 0.6538,\n",
       "             0.6550, 0.6561, 0.6573, 0.6596, 0.6608, 0.6620, 0.6632, 0.6643, 0.6655,\n",
       "             0.6667, 0.6690, 0.6702, 0.6713, 0.6725, 0.6737, 0.6749, 0.6772, 0.6784,\n",
       "             0.6795, 0.6807, 0.6819, 0.6842, 0.6854, 0.6865, 0.6877, 0.6901, 0.6924,\n",
       "             0.6936, 0.6947, 0.6971, 0.6982, 0.7006, 0.7018, 0.7029, 0.7041, 0.7076,\n",
       "             0.7088, 0.7111, 0.7123, 0.7135, 0.7146, 0.7158, 0.7170, 0.7181, 0.7193,\n",
       "             0.7205, 0.7216, 0.7228, 0.7251, 0.7263, 0.7287, 0.7298, 0.7310, 0.7322,\n",
       "             0.7333, 0.7345, 0.7357, 0.7368, 0.7380, 0.7392, 0.7415, 0.7427, 0.7439,\n",
       "             0.7450, 0.7462, 0.7474, 0.7485, 0.7497, 0.7509, 0.7520, 0.7532, 0.7544,\n",
       "             0.7556, 0.7567, 0.7579, 0.7591, 0.7602, 0.7614, 0.7637, 0.7637, 0.7649,\n",
       "             0.7661, 0.7673, 0.7673, 0.7684, 0.7696, 0.7708, 0.7719, 0.7731, 0.7743,\n",
       "             0.7754, 0.7766, 0.7778, 0.7789, 0.7801, 0.7813, 0.7825, 0.7836, 0.7860,\n",
       "             0.7871, 0.7883, 0.7895, 0.7906, 0.7918, 0.7930, 0.7942, 0.7953, 0.7965,\n",
       "             0.7977, 0.7988, 0.8000, 0.8000, 0.8012, 0.8023, 0.8035, 0.8047, 0.8058,\n",
       "             0.8082, 0.8094, 0.8105, 0.8117, 0.8129, 0.8140, 0.8152, 0.8164, 0.8175,\n",
       "             0.8187, 0.8199, 0.8211, 0.8222, 0.8234, 0.8246, 0.8257, 0.8269, 0.8281,\n",
       "             0.8292, 0.8304, 0.8316, 0.8327, 0.8339, 0.8363, 0.8374, 0.8386, 0.8409,\n",
       "             0.8421, 0.8433, 0.8444, 0.8456, 0.8468, 0.8480, 0.8491, 0.8515, 0.8538,\n",
       "             0.8550, 0.8561, 0.8573, 0.8585, 0.8596, 0.8608, 0.8620, 0.8620, 0.8632,\n",
       "             0.8643, 0.8655, 0.8667, 0.8678, 0.8690, 0.8702, 0.8713, 0.8725, 0.8737,\n",
       "             0.8749, 0.8760, 0.8772, 0.8772, 0.8784, 0.8795, 0.8807, 0.8819, 0.8830,\n",
       "             0.8842, 0.8854, 0.8865, 0.8877, 0.8889, 0.8901, 0.8912, 0.8924, 0.8936,\n",
       "             0.8947, 0.8959, 0.8971, 0.8982, 0.8994, 0.9006, 0.9018, 0.9029, 0.9041,\n",
       "             0.9053, 0.9064, 0.9076, 0.9088, 0.9099, 0.9111, 0.9123, 0.9135, 0.9146,\n",
       "             0.9158, 0.9170, 0.9181, 0.9193, 0.9205, 0.9216, 0.9228, 0.9240, 0.9251,\n",
       "             0.9263, 0.9275, 0.9287, 0.9298, 0.9310, 0.9322, 0.9333, 0.9345, 0.9357,\n",
       "             0.9368, 0.9380, 0.9392, 0.9404, 0.9415, 0.9427, 0.9439, 0.9450, 0.9462,\n",
       "             0.9474, 0.9485, 0.9497, 0.9509, 0.9520, 0.9532, 0.9544, 0.9556, 0.9556,\n",
       "             0.9556, 0.9567, 0.9579, 0.9591, 0.9602, 0.9614, 0.9626, 0.9637, 0.9637,\n",
       "             0.9649, 0.9661, 0.9673, 0.9673, 0.9684, 0.9696, 0.9708, 0.9719, 0.9731,\n",
       "             0.9731, 0.9731, 0.9731, 0.9731, 0.9731, 0.9743, 0.9743, 0.9743, 0.9743,\n",
       "             0.9754, 0.9754, 0.9766, 0.9778, 0.9789, 0.9789, 0.9801, 0.9813, 0.9813,\n",
       "             0.9825, 0.9825, 0.9825, 0.9836, 0.9848, 0.9848, 0.9860, 0.9871, 0.9871,\n",
       "             0.9871, 0.9883, 0.9895, 0.9895, 0.9895, 0.9895, 0.9895, 0.9906, 0.9906,\n",
       "             0.9918, 0.9918, 0.9930, 0.9942, 0.9953, 0.9953, 0.9953, 0.9953, 0.9965,\n",
       "             0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965,\n",
       "             0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965,\n",
       "             0.9965, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9986e-01, 9.9986e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01,\n",
       "             9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9984e-01,\n",
       "             9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01,\n",
       "             9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9983e-01, 9.9983e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9981e-01,\n",
       "             9.9981e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01, 9.9980e-01, 9.9979e-01,\n",
       "             9.9979e-01, 9.9979e-01, 9.9978e-01, 9.9978e-01, 9.9977e-01, 9.9976e-01,\n",
       "             9.9976e-01, 9.9976e-01, 9.9976e-01, 9.9975e-01, 9.9975e-01, 9.9974e-01,\n",
       "             9.9974e-01, 9.9974e-01, 9.9974e-01, 9.9974e-01, 9.9973e-01, 9.9972e-01,\n",
       "             9.9971e-01, 9.9971e-01, 9.9970e-01, 9.9967e-01, 9.9967e-01, 9.9966e-01,\n",
       "             9.9966e-01, 9.9964e-01, 9.9962e-01, 9.9962e-01, 9.9961e-01, 9.9960e-01,\n",
       "             9.9958e-01, 9.9957e-01, 9.9956e-01, 9.9953e-01, 9.9953e-01, 9.9953e-01,\n",
       "             9.9953e-01, 9.9952e-01, 9.9950e-01, 9.9948e-01, 9.9948e-01, 9.9946e-01,\n",
       "             9.9944e-01, 9.9941e-01, 9.9940e-01, 9.9939e-01, 9.9937e-01, 9.9933e-01,\n",
       "             9.9933e-01, 9.9931e-01, 9.9930e-01, 9.9928e-01, 9.9925e-01, 9.9912e-01,\n",
       "             9.9911e-01, 9.9909e-01, 9.9905e-01, 9.9902e-01, 9.9901e-01, 9.9898e-01,\n",
       "             9.9897e-01, 9.9894e-01, 9.9889e-01, 9.9863e-01, 9.9851e-01, 9.9840e-01,\n",
       "             9.9808e-01, 9.9792e-01, 9.9771e-01, 9.9742e-01, 9.9734e-01, 9.9733e-01,\n",
       "             9.9722e-01, 9.9675e-01, 9.9667e-01, 9.9648e-01, 9.9648e-01, 9.9619e-01,\n",
       "             9.9521e-01, 9.9485e-01, 9.9398e-01, 9.9348e-01, 9.9331e-01, 9.9176e-01,\n",
       "             9.9127e-01, 9.9086e-01, 9.9064e-01, 9.9055e-01, 9.9045e-01, 9.9033e-01,\n",
       "             9.8991e-01, 9.8990e-01, 9.8970e-01, 9.8969e-01, 9.8872e-01, 9.8745e-01,\n",
       "             9.8418e-01, 9.8400e-01, 9.8076e-01, 9.7691e-01, 9.7610e-01, 9.7309e-01,\n",
       "             9.7008e-01, 9.6915e-01, 9.6643e-01, 9.6264e-01, 9.6111e-01, 9.6104e-01,\n",
       "             9.6030e-01, 9.5655e-01, 9.4843e-01, 9.4010e-01, 9.3323e-01, 9.2804e-01,\n",
       "             9.2103e-01, 9.1534e-01, 9.0595e-01, 9.0586e-01, 8.9822e-01, 8.2039e-01,\n",
       "             8.0339e-01, 7.9290e-01, 7.7936e-01, 7.7585e-01, 7.4083e-01, 7.2917e-01,\n",
       "             7.2477e-01, 7.1995e-01, 7.1863e-01, 7.0122e-01, 6.7885e-01, 6.4721e-01,\n",
       "             6.4587e-01, 6.0774e-01, 5.2762e-01, 4.9415e-01, 4.7062e-01, 4.6448e-01,\n",
       "             3.7526e-01, 3.7366e-01, 3.2093e-01, 2.4752e-01, 2.3327e-01, 1.9566e-01,\n",
       "             1.9548e-01, 1.9357e-01, 1.8723e-01, 1.8512e-01, 1.6990e-01, 1.6064e-01,\n",
       "             1.5320e-01, 1.4431e-01, 1.3224e-01, 1.2423e-01, 1.1806e-01, 1.0216e-01,\n",
       "             9.9304e-02, 9.4088e-02, 9.2573e-02, 9.0637e-02, 8.7438e-02, 8.0440e-02,\n",
       "             7.3338e-02, 7.1258e-02, 6.9927e-02, 6.8470e-02, 6.4102e-02, 6.3445e-02,\n",
       "             6.2413e-02, 6.1455e-02, 6.1008e-02, 5.2117e-02, 4.8495e-02, 4.8455e-02,\n",
       "             4.6697e-02, 4.0245e-02, 3.9506e-02, 3.7011e-02, 3.5734e-02, 3.2748e-02,\n",
       "             3.2424e-02, 3.2129e-02, 3.1507e-02, 3.0637e-02, 2.8133e-02, 2.5197e-02,\n",
       "             2.4834e-02, 2.3590e-02, 2.3214e-02, 2.1111e-02, 2.0012e-02, 1.8084e-02,\n",
       "             1.7801e-02, 1.5759e-02, 1.5528e-02, 1.5513e-02, 1.3313e-02, 1.3307e-02,\n",
       "             1.2056e-02, 1.1787e-02, 1.1679e-02, 1.1628e-02, 1.1269e-02, 1.1041e-02,\n",
       "             1.0838e-02, 1.0516e-02, 9.2187e-03, 8.3959e-03, 8.0289e-03, 7.9882e-03,\n",
       "             7.8948e-03, 7.4960e-03, 6.9939e-03, 6.7101e-03, 6.2653e-03, 5.9041e-03,\n",
       "             5.5621e-03, 5.2729e-03, 5.1650e-03, 4.6244e-03, 4.5796e-03, 4.4222e-03,\n",
       "             4.2776e-03, 4.2535e-03, 4.2098e-03, 4.1089e-03, 3.8131e-03, 3.4957e-03,\n",
       "             3.3570e-03, 3.0788e-03, 3.0523e-03, 2.7258e-03, 2.5992e-03, 2.5346e-03,\n",
       "             2.5240e-03, 2.4655e-03, 2.3805e-03, 2.3296e-03, 2.1767e-03, 2.0197e-03,\n",
       "             1.9827e-03, 1.8749e-03, 1.8494e-03, 1.5683e-03, 1.5622e-03, 1.4809e-03,\n",
       "             1.4247e-03, 1.2551e-03, 1.2005e-03, 1.1621e-03, 1.0572e-03, 1.0502e-03,\n",
       "             1.0436e-03, 9.7898e-04, 9.6862e-04, 9.4402e-04, 9.2912e-04, 9.0861e-04,\n",
       "             7.8332e-04, 7.5445e-04, 7.3559e-04, 6.9711e-04, 6.7643e-04, 6.6384e-04,\n",
       "             6.5225e-04, 6.3411e-04, 6.2184e-04, 5.8800e-04, 5.6021e-04, 5.0001e-04,\n",
       "             4.8860e-04, 4.5942e-04, 4.5760e-04, 4.1313e-04, 4.0806e-04, 3.9620e-04,\n",
       "             3.9514e-04, 3.9281e-04, 3.6979e-04, 3.4874e-04, 3.2872e-04, 3.2726e-04,\n",
       "             3.1227e-04, 3.0896e-04, 3.0404e-04, 2.8220e-04, 2.7405e-04, 2.4840e-04,\n",
       "             2.4734e-04, 2.3485e-04, 2.3255e-04, 2.1873e-04, 2.1552e-04, 2.0717e-04,\n",
       "             1.9784e-04, 1.8448e-04, 1.7236e-04, 1.6037e-04, 1.5910e-04, 1.5679e-04,\n",
       "             1.5334e-04, 1.4623e-04, 1.4359e-04, 1.4306e-04, 1.3501e-04, 1.2408e-04,\n",
       "             1.2212e-04, 1.2060e-04, 1.1393e-04, 1.1258e-04, 8.8704e-05, 8.5756e-05,\n",
       "             8.3212e-05, 7.6273e-05, 7.6158e-05, 7.6158e-05, 7.2116e-05, 6.9937e-05,\n",
       "             6.8471e-05, 6.8124e-05, 6.7853e-05, 6.3841e-05, 6.1188e-05, 5.0184e-05,\n",
       "             4.9545e-05, 4.8682e-05, 4.4902e-05, 4.3442e-05, 4.1302e-05, 4.0886e-05,\n",
       "             4.0363e-05, 4.0359e-05, 3.9248e-05, 3.9228e-05, 3.8600e-05, 3.6987e-05,\n",
       "             3.6651e-05, 3.1628e-05, 3.1582e-05, 2.9110e-05, 2.6033e-05, 2.5320e-05,\n",
       "             2.5135e-05, 2.4627e-05, 2.2220e-05, 2.1501e-05, 1.8835e-05, 1.8551e-05,\n",
       "             1.8473e-05, 1.8434e-05, 1.6160e-05, 1.2801e-05, 1.2449e-05, 1.2412e-05,\n",
       "             1.2310e-05, 1.2226e-05, 1.1033e-05, 1.0836e-05, 1.0087e-05, 9.7774e-06,\n",
       "             8.9031e-06, 8.8440e-06, 8.6992e-06, 8.6008e-06, 8.0304e-06, 6.8588e-06,\n",
       "             6.8440e-06, 6.2252e-06, 5.3562e-06, 4.7625e-06, 4.4356e-06, 3.9464e-06,\n",
       "             3.9299e-06, 3.8445e-06, 3.7558e-06, 3.4928e-06, 3.2070e-06, 3.1365e-06,\n",
       "             3.1219e-06, 3.0256e-06, 2.7174e-06, 2.7046e-06, 2.6634e-06, 2.5008e-06,\n",
       "             2.4971e-06, 2.3053e-06, 2.2337e-06, 2.1830e-06, 2.1561e-06, 1.5681e-06,\n",
       "             9.9449e-07, 9.6866e-07, 9.0567e-07, 8.7263e-07, 7.0394e-07, 6.2281e-07,\n",
       "             4.7540e-07, 4.5872e-07, 4.3515e-07, 3.7700e-07, 3.7243e-07, 3.0021e-07,\n",
       "             2.7268e-07, 2.0363e-07, 1.5338e-07, 1.5234e-07, 1.0633e-07, 1.0049e-07,\n",
       "             6.7709e-08, 5.6624e-08, 5.5146e-08, 4.1702e-08, 3.3875e-08, 2.9401e-08,\n",
       "             1.2102e-08, 1.1202e-08, 5.4592e-09, 4.0980e-09])}},\n",
       "   {'fpr': np.float64(0.049689440993788817),\n",
       "    'tpr': np.float64(0.9812865497076023),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0012, 0.0047,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 5.6908e-10, 1.1577e-10,\n",
       "             1.1370e-10])}},\n",
       "   {'fpr': np.float64(0.024844720496894408),\n",
       "    'tpr': np.float64(0.9625730994152046),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0124, 0.0124,\n",
       "             0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124,\n",
       "             0.0155, 0.0155, 0.0155, 0.0155, 0.0155, 0.0186, 0.0186, 0.0217, 0.0217,\n",
       "             0.0217, 0.0248, 0.0248, 0.0248, 0.0248, 0.0280, 0.0280, 0.0311, 0.0311,\n",
       "             0.0342, 0.0373, 0.0404, 0.0404, 0.0404, 0.0404, 0.0404, 0.0435, 0.0435,\n",
       "             0.0435, 0.0435, 0.0435, 0.0435, 0.0466, 0.0466, 0.0466, 0.0497, 0.0497,\n",
       "             0.0528, 0.0559, 0.0559, 0.0559, 0.0621, 0.0652, 0.0652, 0.0683, 0.0714,\n",
       "             0.0745, 0.0776, 0.0807, 0.0839, 0.0870, 0.0901, 0.0901, 0.0901, 0.0932,\n",
       "             0.0932, 0.0963, 0.0994, 0.1025, 0.1025, 0.1056, 0.1056, 0.1087, 0.1118,\n",
       "             0.1118, 0.1149, 0.1180, 0.1211, 0.1242, 0.1242, 0.1242, 0.1273, 0.1304,\n",
       "             0.1335, 0.1335, 0.1366, 0.1398, 0.1429, 0.1460, 0.1491, 0.1522, 0.1553,\n",
       "             0.1584, 0.1615, 0.1646, 0.1677, 0.1708, 0.1739, 0.1739, 0.1739, 0.1770,\n",
       "             0.1801, 0.1832, 0.1863, 0.1894, 0.1925, 0.1957, 0.1988, 0.2019, 0.2050,\n",
       "             0.2081, 0.2112, 0.2143, 0.2174, 0.2205, 0.2236, 0.2267, 0.2298, 0.2329,\n",
       "             0.2329, 0.2360, 0.2391, 0.2422, 0.2453, 0.2484, 0.2516, 0.2547, 0.2578,\n",
       "             0.2609, 0.2640, 0.2671, 0.2702, 0.2733, 0.2764, 0.2795, 0.2826, 0.2857,\n",
       "             0.2888, 0.2919, 0.2950, 0.2981, 0.3012, 0.3043, 0.3075, 0.3106, 0.3137,\n",
       "             0.3168, 0.3199, 0.3230, 0.3261, 0.3292, 0.3323, 0.3354, 0.3385, 0.3416,\n",
       "             0.3447, 0.3478, 0.3509, 0.3540, 0.3571, 0.3602, 0.3634, 0.3665, 0.3696,\n",
       "             0.3727, 0.3758, 0.3789, 0.3820, 0.3851, 0.3882, 0.3913, 0.3944, 0.3975,\n",
       "             0.4006, 0.4037, 0.4068, 0.4099, 0.4130, 0.4161, 0.4193, 0.4224, 0.4255,\n",
       "             0.4286, 0.4317, 0.4348, 0.4379, 0.4410, 0.4441, 0.4472, 0.4503, 0.4534,\n",
       "             0.4565, 0.4596, 0.4627, 0.4658, 0.4689, 0.4720, 0.4752, 0.4783, 0.4814,\n",
       "             0.4845, 0.4876, 0.4907, 0.4938, 0.4969, 0.5000, 0.5031, 0.5062, 0.5093,\n",
       "             0.5124, 0.5155, 0.5186, 0.5217, 0.5248, 0.5280, 0.5311, 0.5342, 0.5373,\n",
       "             0.5404, 0.5435, 0.5466, 0.5497, 0.5528, 0.5559, 0.5590, 0.5621, 0.5652,\n",
       "             0.5683, 0.5714, 0.5745, 0.5776, 0.5807, 0.5839, 0.5870, 0.5901, 0.5932,\n",
       "             0.5963, 0.5994, 0.6025, 0.6056, 0.6087, 0.6118, 0.6149, 0.6180, 0.6211,\n",
       "             0.6242, 0.6273, 0.6304, 0.6335, 0.6366, 0.6398, 0.6429, 0.6460, 0.6491,\n",
       "             0.6522, 0.6553, 0.6584, 0.6615, 0.6646, 0.6677, 0.6708, 0.6739, 0.6770,\n",
       "             0.6801, 0.6832, 0.6863, 0.6894, 0.6925, 0.6957, 0.6988, 0.7019, 0.7050,\n",
       "             0.7081, 0.7112, 0.7143, 0.7174, 0.7205, 0.7236, 0.7267, 0.7298, 0.7329,\n",
       "             0.7360, 0.7391, 0.7422, 0.7453, 0.7484, 0.7484, 0.7516, 0.7547, 0.7578,\n",
       "             0.7609, 0.7640, 0.7671, 0.7702, 0.7733, 0.7764, 0.7795, 0.7826, 0.7857,\n",
       "             0.7888, 0.7919, 0.7950, 0.7981, 0.8012, 0.8043, 0.8075, 0.8106, 0.8137,\n",
       "             0.8168, 0.8199, 0.8230, 0.8261, 0.8292, 0.8323, 0.8354, 0.8385, 0.8416,\n",
       "             0.8447, 0.8478, 0.8509, 0.8540, 0.8571, 0.8602, 0.8634, 0.8665, 0.8696,\n",
       "             0.8727, 0.8758, 0.8789, 0.8820, 0.8851, 0.8882, 0.8913, 0.8944, 0.8975,\n",
       "             0.9006, 0.9037, 0.9068, 0.9099, 0.9130, 0.9161, 0.9193, 0.9224, 0.9255,\n",
       "             0.9286, 0.9317, 0.9348, 0.9379, 0.9410, 0.9441, 0.9472, 0.9503, 0.9534,\n",
       "             0.9565, 0.9596, 0.9627, 0.9658, 0.9689, 0.9720, 0.9752, 0.9783, 0.9814,\n",
       "             0.9845, 0.9876, 0.9907, 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.2199, 0.2947, 0.3322, 0.3673, 0.3813, 0.3953, 0.4070, 0.4152,\n",
       "             0.4246, 0.4327, 0.4398, 0.4515, 0.4573, 0.4632, 0.4702, 0.4795, 0.4854,\n",
       "             0.4901, 0.4959, 0.5029, 0.5123, 0.5170, 0.5193, 0.5251, 0.5287, 0.5310,\n",
       "             0.5345, 0.5392, 0.5415, 0.5427, 0.5439, 0.5474, 0.5485, 0.5497, 0.5520,\n",
       "             0.5567, 0.5579, 0.5591, 0.5614, 0.5626, 0.5684, 0.5719, 0.5731, 0.5743,\n",
       "             0.5766, 0.5801, 0.5813, 0.5825, 0.5836, 0.5871, 0.5883, 0.5895, 0.5906,\n",
       "             0.5942, 0.5953, 0.5965, 0.5977, 0.5988, 0.6000, 0.6012, 0.6023, 0.6047,\n",
       "             0.6070, 0.6082, 0.6105, 0.6117, 0.6129, 0.6140, 0.6175, 0.6187, 0.6199,\n",
       "             0.6234, 0.6246, 0.6257, 0.6281, 0.6292, 0.6304, 0.6327, 0.6339, 0.6351,\n",
       "             0.6363, 0.6386, 0.6398, 0.6409, 0.6433, 0.6444, 0.6468, 0.6480, 0.6491,\n",
       "             0.6503, 0.6515, 0.6538, 0.6550, 0.6561, 0.6585, 0.6608, 0.6632, 0.6643,\n",
       "             0.6655, 0.6678, 0.6690, 0.6702, 0.6713, 0.6737, 0.6749, 0.6760, 0.6772,\n",
       "             0.6795, 0.6807, 0.6819, 0.6830, 0.6842, 0.6854, 0.6865, 0.6889, 0.6901,\n",
       "             0.6912, 0.6924, 0.6936, 0.6947, 0.6959, 0.6971, 0.6982, 0.6994, 0.7006,\n",
       "             0.7018, 0.7041, 0.7053, 0.7064, 0.7088, 0.7099, 0.7111, 0.7123, 0.7135,\n",
       "             0.7146, 0.7158, 0.7170, 0.7181, 0.7193, 0.7216, 0.7228, 0.7240, 0.7251,\n",
       "             0.7263, 0.7275, 0.7287, 0.7298, 0.7310, 0.7322, 0.7333, 0.7345, 0.7357,\n",
       "             0.7368, 0.7380, 0.7392, 0.7404, 0.7415, 0.7427, 0.7439, 0.7450, 0.7462,\n",
       "             0.7474, 0.7485, 0.7497, 0.7509, 0.7520, 0.7532, 0.7544, 0.7556, 0.7567,\n",
       "             0.7579, 0.7591, 0.7602, 0.7614, 0.7626, 0.7637, 0.7649, 0.7661, 0.7673,\n",
       "             0.7684, 0.7696, 0.7708, 0.7719, 0.7731, 0.7743, 0.7754, 0.7766, 0.7778,\n",
       "             0.7801, 0.7813, 0.7825, 0.7836, 0.7848, 0.7860, 0.7871, 0.7883, 0.7895,\n",
       "             0.7906, 0.7918, 0.7930, 0.7942, 0.7953, 0.7965, 0.7977, 0.7988, 0.8000,\n",
       "             0.8012, 0.8023, 0.8035, 0.8047, 0.8058, 0.8070, 0.8082, 0.8082, 0.8094,\n",
       "             0.8105, 0.8117, 0.8129, 0.8140, 0.8152, 0.8164, 0.8175, 0.8187, 0.8199,\n",
       "             0.8211, 0.8222, 0.8234, 0.8246, 0.8257, 0.8269, 0.8281, 0.8292, 0.8304,\n",
       "             0.8316, 0.8327, 0.8339, 0.8351, 0.8363, 0.8374, 0.8386, 0.8398, 0.8409,\n",
       "             0.8421, 0.8433, 0.8444, 0.8456, 0.8468, 0.8480, 0.8491, 0.8503, 0.8515,\n",
       "             0.8526, 0.8538, 0.8550, 0.8561, 0.8573, 0.8585, 0.8596, 0.8608, 0.8620,\n",
       "             0.8632, 0.8643, 0.8655, 0.8667, 0.8678, 0.8690, 0.8702, 0.8713, 0.8725,\n",
       "             0.8737, 0.8749, 0.8760, 0.8772, 0.8784, 0.8795, 0.8807, 0.8819, 0.8830,\n",
       "             0.8842, 0.8854, 0.8865, 0.8877, 0.8889, 0.8901, 0.8912, 0.8924, 0.8936,\n",
       "             0.8947, 0.8959, 0.8971, 0.8982, 0.8994, 0.9006, 0.9018, 0.9029, 0.9041,\n",
       "             0.9053, 0.9064, 0.9076, 0.9088, 0.9099, 0.9111, 0.9123, 0.9135, 0.9146,\n",
       "             0.9158, 0.9170, 0.9170, 0.9181, 0.9193, 0.9205, 0.9216, 0.9216, 0.9228,\n",
       "             0.9240, 0.9251, 0.9263, 0.9275, 0.9287, 0.9298, 0.9310, 0.9322, 0.9333,\n",
       "             0.9345, 0.9357, 0.9368, 0.9380, 0.9392, 0.9404, 0.9415, 0.9415, 0.9427,\n",
       "             0.9439, 0.9450, 0.9462, 0.9474, 0.9485, 0.9497, 0.9509, 0.9520, 0.9532,\n",
       "             0.9532, 0.9544, 0.9556, 0.9567, 0.9579, 0.9579, 0.9591, 0.9591, 0.9602,\n",
       "             0.9614, 0.9614, 0.9626, 0.9637, 0.9649, 0.9649, 0.9661, 0.9661, 0.9673,\n",
       "             0.9673, 0.9673, 0.9673, 0.9684, 0.9696, 0.9708, 0.9719, 0.9719, 0.9731,\n",
       "             0.9743, 0.9754, 0.9766, 0.9778, 0.9778, 0.9789, 0.9801, 0.9801, 0.9813,\n",
       "             0.9813, 0.9813, 0.9825, 0.9836, 0.9836, 0.9836, 0.9848, 0.9848, 0.9848,\n",
       "             0.9848, 0.9848, 0.9848, 0.9848, 0.9848, 0.9848, 0.9860, 0.9871, 0.9871,\n",
       "             0.9883, 0.9883, 0.9883, 0.9883, 0.9895, 0.9895, 0.9906, 0.9906, 0.9906,\n",
       "             0.9918, 0.9918, 0.9918, 0.9918, 0.9918, 0.9930, 0.9942, 0.9942, 0.9942,\n",
       "             0.9942, 0.9953, 0.9953, 0.9953, 0.9953, 0.9953, 0.9953, 0.9953, 0.9953,\n",
       "             0.9953, 0.9953, 0.9953, 0.9953, 0.9953, 0.9953, 0.9965, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01,\n",
       "             9.9985e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9981e-01, 9.9981e-01, 9.9980e-01,\n",
       "             9.9979e-01, 9.9978e-01, 9.9978e-01, 9.9978e-01, 9.9977e-01, 9.9976e-01,\n",
       "             9.9975e-01, 9.9975e-01, 9.9974e-01, 9.9973e-01, 9.9972e-01, 9.9972e-01,\n",
       "             9.9971e-01, 9.9971e-01, 9.9970e-01, 9.9969e-01, 9.9969e-01, 9.9967e-01,\n",
       "             9.9966e-01, 9.9966e-01, 9.9964e-01, 9.9964e-01, 9.9964e-01, 9.9964e-01,\n",
       "             9.9963e-01, 9.9960e-01, 9.9960e-01, 9.9960e-01, 9.9958e-01, 9.9958e-01,\n",
       "             9.9956e-01, 9.9955e-01, 9.9952e-01, 9.9951e-01, 9.9950e-01, 9.9949e-01,\n",
       "             9.9949e-01, 9.9947e-01, 9.9946e-01, 9.9944e-01, 9.9944e-01, 9.9943e-01,\n",
       "             9.9943e-01, 9.9939e-01, 9.9939e-01, 9.9938e-01, 9.9937e-01, 9.9937e-01,\n",
       "             9.9937e-01, 9.9936e-01, 9.9935e-01, 9.9932e-01, 9.9928e-01, 9.9924e-01,\n",
       "             9.9924e-01, 9.9922e-01, 9.9920e-01, 9.9917e-01, 9.9917e-01, 9.9916e-01,\n",
       "             9.9912e-01, 9.9901e-01, 9.9899e-01, 9.9899e-01, 9.9898e-01, 9.9891e-01,\n",
       "             9.9880e-01, 9.9879e-01, 9.9878e-01, 9.9874e-01, 9.9871e-01, 9.9859e-01,\n",
       "             9.9858e-01, 9.9857e-01, 9.9856e-01, 9.9855e-01, 9.9850e-01, 9.9850e-01,\n",
       "             9.9846e-01, 9.9824e-01, 9.9813e-01, 9.9804e-01, 9.9804e-01, 9.9800e-01,\n",
       "             9.9769e-01, 9.9763e-01, 9.9749e-01, 9.9695e-01, 9.9679e-01, 9.9663e-01,\n",
       "             9.9656e-01, 9.9636e-01, 9.9622e-01, 9.9602e-01, 9.9588e-01, 9.9581e-01,\n",
       "             9.9561e-01, 9.9506e-01, 9.9489e-01, 9.9485e-01, 9.9438e-01, 9.9390e-01,\n",
       "             9.9309e-01, 9.9115e-01, 9.8982e-01, 9.8945e-01, 9.8927e-01, 9.8886e-01,\n",
       "             9.8807e-01, 9.8765e-01, 9.8619e-01, 9.8519e-01, 9.8488e-01, 9.8459e-01,\n",
       "             9.8125e-01, 9.7978e-01, 9.7854e-01, 9.7459e-01, 9.7214e-01, 9.7100e-01,\n",
       "             9.5879e-01, 9.5249e-01, 9.4223e-01, 9.3883e-01, 9.2238e-01, 8.9377e-01,\n",
       "             8.8712e-01, 8.7001e-01, 8.6169e-01, 8.5482e-01, 8.5128e-01, 8.4625e-01,\n",
       "             8.3321e-01, 7.4329e-01, 7.1342e-01, 6.9087e-01, 6.8968e-01, 6.8869e-01,\n",
       "             5.9620e-01, 5.9043e-01, 5.8882e-01, 5.6096e-01, 5.4645e-01, 5.2808e-01,\n",
       "             4.9399e-01, 4.8397e-01, 4.4516e-01, 4.3210e-01, 3.8514e-01, 3.7327e-01,\n",
       "             3.6647e-01, 3.1820e-01, 2.8244e-01, 2.7387e-01, 2.5822e-01, 2.3351e-01,\n",
       "             2.1121e-01, 1.8512e-01, 1.7332e-01, 1.4859e-01, 1.4741e-01, 1.3658e-01,\n",
       "             1.3160e-01, 8.7399e-02, 8.5643e-02, 8.4207e-02, 8.3852e-02, 7.3874e-02,\n",
       "             7.1828e-02, 7.1108e-02, 6.4114e-02, 2.0555e-02, 1.7006e-02, 1.1338e-02,\n",
       "             1.0861e-02, 1.0218e-02, 1.0093e-02, 9.4810e-03, 9.2038e-03, 6.9609e-03,\n",
       "             6.8632e-03, 5.4629e-03, 4.0514e-03, 3.6236e-03, 2.7599e-03, 2.7198e-03,\n",
       "             2.4963e-03, 2.3744e-03, 2.3660e-03, 1.8366e-03, 1.5576e-03, 1.5351e-03,\n",
       "             1.0059e-03, 8.4018e-04, 5.4894e-04, 5.3065e-04, 3.4762e-04, 2.8891e-04,\n",
       "             2.0172e-04, 1.9667e-04, 1.9541e-04, 1.9154e-04, 1.4127e-04, 1.1453e-04,\n",
       "             1.1125e-04, 8.7960e-05, 6.6651e-05, 6.5621e-05, 6.3718e-05, 6.2754e-05,\n",
       "             5.6882e-05, 4.5279e-05, 4.3804e-05, 3.9136e-05, 3.8264e-05, 3.6171e-05,\n",
       "             2.9058e-05, 2.8253e-05, 2.3588e-05, 2.3295e-05, 1.7672e-05, 1.6979e-05,\n",
       "             1.6827e-05, 1.1412e-05, 1.0411e-05, 8.3529e-06, 7.9781e-06, 6.8888e-06,\n",
       "             6.8548e-06, 6.2552e-06, 5.9188e-06, 5.7607e-06, 4.5956e-06, 3.9626e-06,\n",
       "             3.9451e-06, 3.7434e-06, 3.5788e-06, 2.9749e-06, 2.6925e-06, 2.5224e-06,\n",
       "             2.5069e-06, 2.1091e-06, 1.9132e-06, 1.8314e-06, 1.6307e-06, 1.4544e-06,\n",
       "             1.3544e-06, 1.1646e-06, 1.1163e-06, 1.0402e-06, 1.0321e-06, 9.2471e-07,\n",
       "             9.0520e-07, 8.5011e-07, 7.0312e-07, 6.9550e-07, 6.8458e-07, 6.6047e-07,\n",
       "             6.5476e-07, 6.4768e-07, 5.4162e-07, 5.3646e-07, 5.0525e-07, 4.6344e-07,\n",
       "             4.5294e-07, 4.1586e-07, 4.0503e-07, 4.0189e-07, 3.7007e-07, 3.3643e-07,\n",
       "             3.0727e-07, 2.6859e-07, 2.4986e-07, 2.1514e-07, 2.1232e-07, 1.8010e-07,\n",
       "             1.7582e-07, 1.7115e-07, 1.5130e-07, 1.2453e-07, 1.2379e-07, 1.0541e-07,\n",
       "             1.0494e-07, 8.0588e-08, 8.0543e-08, 7.5449e-08, 7.1513e-08, 6.7391e-08,\n",
       "             5.9522e-08, 5.7161e-08, 4.9180e-08, 4.5189e-08, 3.8383e-08, 3.4527e-08,\n",
       "             3.1759e-08, 3.0051e-08, 2.7791e-08, 2.3861e-08, 2.2406e-08, 1.9448e-08,\n",
       "             1.8990e-08, 1.7096e-08, 1.6984e-08, 1.5201e-08, 1.5105e-08, 1.4879e-08,\n",
       "             1.3586e-08, 1.3506e-08, 1.2699e-08, 1.2144e-08, 1.1245e-08, 1.1128e-08,\n",
       "             1.1048e-08, 7.7469e-09, 7.5692e-09, 7.2357e-09, 6.8173e-09, 6.6823e-09,\n",
       "             6.2322e-09, 6.2306e-09, 6.0154e-09, 5.4115e-09, 5.3944e-09, 5.0181e-09,\n",
       "             4.5178e-09, 4.2152e-09, 4.0449e-09, 3.7003e-09, 3.4506e-09, 3.0531e-09,\n",
       "             3.0296e-09, 2.9738e-09, 2.8191e-09, 2.6937e-09, 2.6585e-09, 2.4881e-09,\n",
       "             2.2591e-09, 2.2123e-09, 2.1504e-09, 2.0526e-09, 1.9688e-09, 1.9463e-09,\n",
       "             1.9208e-09, 1.5275e-09, 1.4027e-09, 1.1968e-09, 1.1857e-09, 1.1686e-09,\n",
       "             1.0184e-09, 9.3239e-10, 9.2102e-10, 8.8411e-10, 8.3967e-10, 7.2878e-10,\n",
       "             6.8458e-10, 6.3693e-10, 5.9220e-10, 5.8782e-10, 5.8725e-10, 5.7672e-10,\n",
       "             5.3212e-10, 4.7535e-10, 4.6048e-10, 4.4851e-10, 4.4605e-10, 4.3769e-10,\n",
       "             3.9835e-10, 3.9275e-10, 3.6789e-10, 3.3907e-10, 3.1478e-10, 3.1226e-10,\n",
       "             3.0663e-10, 2.9064e-10, 2.7265e-10, 2.7194e-10, 2.6177e-10, 2.4158e-10,\n",
       "             2.3722e-10, 2.2857e-10, 2.2607e-10, 2.2434e-10, 1.9313e-10, 1.8799e-10,\n",
       "             1.8795e-10, 1.6272e-10, 1.4340e-10, 1.3400e-10, 1.3046e-10, 1.1769e-10,\n",
       "             1.1226e-10, 1.0291e-10, 9.7018e-11, 9.5419e-11, 7.4549e-11, 7.1441e-11,\n",
       "             6.2949e-11, 5.6079e-11, 5.3517e-11, 5.1983e-11, 5.1222e-11, 4.8505e-11,\n",
       "             4.6338e-11, 4.2978e-11, 4.1657e-11, 3.9208e-11, 3.7615e-11, 3.7573e-11,\n",
       "             3.6683e-11, 3.4821e-11, 3.4361e-11, 3.2329e-11, 3.1474e-11, 3.0893e-11,\n",
       "             2.9129e-11, 2.8532e-11, 2.7166e-11, 2.5653e-11, 2.1989e-11, 1.9322e-11,\n",
       "             1.8670e-11, 1.8464e-11, 1.7880e-11, 1.7356e-11, 1.7063e-11, 1.7011e-11,\n",
       "             1.4461e-11, 1.4104e-11, 1.4041e-11, 1.2905e-11, 1.2447e-11, 1.2200e-11,\n",
       "             1.0124e-11, 9.8870e-12, 9.4026e-12, 7.8529e-12, 7.0735e-12, 7.0571e-12,\n",
       "             6.5709e-12, 5.9698e-12, 5.8775e-12, 5.4859e-12, 4.7793e-12, 4.7061e-12,\n",
       "             3.9108e-12, 3.1147e-12, 2.7307e-12, 2.6464e-12, 2.5216e-12, 2.2176e-12,\n",
       "             2.1963e-12, 1.8792e-12, 1.7441e-12, 1.7247e-12, 1.4578e-12, 1.4025e-12,\n",
       "             1.0591e-12, 9.7671e-13, 8.4407e-13, 5.1422e-13, 4.5371e-13, 3.8772e-13,\n",
       "             3.8517e-13, 3.4303e-13, 3.3784e-13, 3.2623e-13, 2.4517e-13, 2.0895e-13,\n",
       "             1.9274e-13, 1.0803e-13, 7.8687e-14, 6.1254e-14, 5.7251e-14, 5.3346e-14,\n",
       "             3.7853e-14, 2.8975e-14, 1.9319e-14, 1.9047e-14, 1.3243e-14, 8.9379e-15,\n",
       "             6.0585e-15, 2.9088e-15, 1.3383e-15, 1.3226e-15, 1.3158e-15, 1.0706e-15,\n",
       "             9.1079e-16, 6.4738e-16, 2.7909e-16])}},\n",
       "   {'fpr': np.float64(0.037267080745341616),\n",
       "    'tpr': np.float64(0.9695906432748538),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0124, 0.0124,\n",
       "             0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0155,\n",
       "             0.0155, 0.0155, 0.0155, 0.0186, 0.0186, 0.0217, 0.0217, 0.0217, 0.0217,\n",
       "             0.0248, 0.0248, 0.0248, 0.0248, 0.0248, 0.0248, 0.0248, 0.0248, 0.0280,\n",
       "             0.0280, 0.0280, 0.0280, 0.0280, 0.0311, 0.0342, 0.0342, 0.0342, 0.0342,\n",
       "             0.0342, 0.0373, 0.0373, 0.0373, 0.0373, 0.0404, 0.0435, 0.0435, 0.0466,\n",
       "             0.0466, 0.0497, 0.0528, 0.0528, 0.0528, 0.0528, 0.0528, 0.0528, 0.0528,\n",
       "             0.0559, 0.0559, 0.0559, 0.0590, 0.0621, 0.0652, 0.0652, 0.0652, 0.0683,\n",
       "             0.0745, 0.0776, 0.0776, 0.0776, 0.0776, 0.0807, 0.0839, 0.0839, 0.0870,\n",
       "             0.0870, 0.0870, 0.0901, 0.0932, 0.0932, 0.0932, 0.0932, 0.0963, 0.0994,\n",
       "             0.1025, 0.1056, 0.1087, 0.1087, 0.1118, 0.1149, 0.1180, 0.1211, 0.1242,\n",
       "             0.1242, 0.1273, 0.1304, 0.1335, 0.1366, 0.1398, 0.1429, 0.1460, 0.1491,\n",
       "             0.1522, 0.1522, 0.1553, 0.1584, 0.1615, 0.1646, 0.1677, 0.1708, 0.1739,\n",
       "             0.1770, 0.1801, 0.1832, 0.1863, 0.1894, 0.1925, 0.1957, 0.1988, 0.2019,\n",
       "             0.2050, 0.2081, 0.2112, 0.2143, 0.2174, 0.2205, 0.2236, 0.2267, 0.2298,\n",
       "             0.2329, 0.2360, 0.2391, 0.2422, 0.2453, 0.2484, 0.2516, 0.2547, 0.2578,\n",
       "             0.2609, 0.2640, 0.2671, 0.2702, 0.2733, 0.2764, 0.2795, 0.2826, 0.2857,\n",
       "             0.2888, 0.2919, 0.2950, 0.2981, 0.3012, 0.3043, 0.3075, 0.3106, 0.3137,\n",
       "             0.3168, 0.3199, 0.3230, 0.3261, 0.3292, 0.3323, 0.3354, 0.3385, 0.3416,\n",
       "             0.3447, 0.3478, 0.3509, 0.3540, 0.3571, 0.3602, 0.3634, 0.3665, 0.3696,\n",
       "             0.3727, 0.3758, 0.3789, 0.3820, 0.3851, 0.3882, 0.3913, 0.3944, 0.3975,\n",
       "             0.4006, 0.4037, 0.4068, 0.4099, 0.4099, 0.4130, 0.4161, 0.4193, 0.4224,\n",
       "             0.4255, 0.4286, 0.4317, 0.4348, 0.4379, 0.4379, 0.4410, 0.4441, 0.4472,\n",
       "             0.4503, 0.4534, 0.4565, 0.4596, 0.4627, 0.4658, 0.4689, 0.4720, 0.4752,\n",
       "             0.4783, 0.4814, 0.4845, 0.4876, 0.4907, 0.4938, 0.4969, 0.5000, 0.5031,\n",
       "             0.5062, 0.5093, 0.5124, 0.5155, 0.5186, 0.5217, 0.5248, 0.5280, 0.5311,\n",
       "             0.5342, 0.5373, 0.5404, 0.5435, 0.5466, 0.5497, 0.5528, 0.5559, 0.5590,\n",
       "             0.5621, 0.5652, 0.5683, 0.5714, 0.5745, 0.5776, 0.5807, 0.5839, 0.5870,\n",
       "             0.5901, 0.5932, 0.5963, 0.5994, 0.6025, 0.6056, 0.6087, 0.6118, 0.6149,\n",
       "             0.6180, 0.6211, 0.6242, 0.6273, 0.6304, 0.6335, 0.6366, 0.6398, 0.6429,\n",
       "             0.6460, 0.6491, 0.6522, 0.6553, 0.6584, 0.6615, 0.6646, 0.6677, 0.6708,\n",
       "             0.6739, 0.6770, 0.6801, 0.6832, 0.6863, 0.6894, 0.6925, 0.6957, 0.6988,\n",
       "             0.7019, 0.7050, 0.7081, 0.7112, 0.7143, 0.7174, 0.7205, 0.7236, 0.7267,\n",
       "             0.7298, 0.7329, 0.7360, 0.7391, 0.7422, 0.7453, 0.7484, 0.7516, 0.7547,\n",
       "             0.7578, 0.7609, 0.7640, 0.7671, 0.7702, 0.7733, 0.7764, 0.7795, 0.7826,\n",
       "             0.7857, 0.7888, 0.7919, 0.7950, 0.7981, 0.8012, 0.8043, 0.8075, 0.8106,\n",
       "             0.8137, 0.8168, 0.8199, 0.8230, 0.8261, 0.8292, 0.8323, 0.8354, 0.8385,\n",
       "             0.8416, 0.8447, 0.8478, 0.8509, 0.8540, 0.8571, 0.8602, 0.8634, 0.8665,\n",
       "             0.8696, 0.8727, 0.8758, 0.8789, 0.8820, 0.8851, 0.8882, 0.8913, 0.8944,\n",
       "             0.8975, 0.9006, 0.9037, 0.9068, 0.9099, 0.9130, 0.9161, 0.9193, 0.9224,\n",
       "             0.9255, 0.9286, 0.9317, 0.9348, 0.9379, 0.9410, 0.9441, 0.9472, 0.9503,\n",
       "             0.9534, 0.9565, 0.9596, 0.9627, 0.9658, 0.9689, 0.9720, 0.9752, 0.9783,\n",
       "             0.9814, 0.9845, 0.9876, 0.9907, 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.1287, 0.1731, 0.2058, 0.2327, 0.2491, 0.2538, 0.2678, 0.2795,\n",
       "             0.2924, 0.3029, 0.3111, 0.3146, 0.3193, 0.3275, 0.3322, 0.3415, 0.3497,\n",
       "             0.3567, 0.3591, 0.3637, 0.3661, 0.3719, 0.3766, 0.3801, 0.3813, 0.3860,\n",
       "             0.3918, 0.3930, 0.3942, 0.3977, 0.4012, 0.4023, 0.4047, 0.4094, 0.4140,\n",
       "             0.4164, 0.4175, 0.4187, 0.4211, 0.4234, 0.4257, 0.4269, 0.4316, 0.4327,\n",
       "             0.4339, 0.4374, 0.4386, 0.4409, 0.4444, 0.4468, 0.4491, 0.4538, 0.4550,\n",
       "             0.4585, 0.4596, 0.4667, 0.4702, 0.4713, 0.4737, 0.4749, 0.4760, 0.4784,\n",
       "             0.4795, 0.4807, 0.4819, 0.4842, 0.4854, 0.4865, 0.4877, 0.4889, 0.4912,\n",
       "             0.4924, 0.4982, 0.4994, 0.5006, 0.5018, 0.5041, 0.5053, 0.5064, 0.5076,\n",
       "             0.5088, 0.5099, 0.5111, 0.5135, 0.5158, 0.5170, 0.5181, 0.5193, 0.5205,\n",
       "             0.5216, 0.5228, 0.5240, 0.5251, 0.5287, 0.5298, 0.5310, 0.5322, 0.5333,\n",
       "             0.5380, 0.5404, 0.5415, 0.5450, 0.5462, 0.5474, 0.5485, 0.5497, 0.5509,\n",
       "             0.5520, 0.5532, 0.5544, 0.5567, 0.5579, 0.5591, 0.5602, 0.5614, 0.5626,\n",
       "             0.5637, 0.5649, 0.5661, 0.5673, 0.5684, 0.5696, 0.5708, 0.5731, 0.5754,\n",
       "             0.5766, 0.5789, 0.5801, 0.5813, 0.5825, 0.5836, 0.5848, 0.5871, 0.5883,\n",
       "             0.5895, 0.5906, 0.5918, 0.5930, 0.5942, 0.5953, 0.5965, 0.5988, 0.6000,\n",
       "             0.6012, 0.6023, 0.6035, 0.6058, 0.6070, 0.6082, 0.6094, 0.6105, 0.6117,\n",
       "             0.6129, 0.6140, 0.6152, 0.6164, 0.6175, 0.6187, 0.6199, 0.6211, 0.6222,\n",
       "             0.6234, 0.6246, 0.6269, 0.6281, 0.6292, 0.6304, 0.6316, 0.6327, 0.6339,\n",
       "             0.6351, 0.6363, 0.6374, 0.6386, 0.6398, 0.6409, 0.6421, 0.6444, 0.6456,\n",
       "             0.6468, 0.6480, 0.6503, 0.6515, 0.6526, 0.6538, 0.6561, 0.6573, 0.6585,\n",
       "             0.6608, 0.6620, 0.6632, 0.6643, 0.6655, 0.6667, 0.6678, 0.6690, 0.6702,\n",
       "             0.6713, 0.6725, 0.6737, 0.6749, 0.6760, 0.6772, 0.6784, 0.6795, 0.6807,\n",
       "             0.6819, 0.6830, 0.6842, 0.6854, 0.6865, 0.6877, 0.6901, 0.6912, 0.6924,\n",
       "             0.6936, 0.6947, 0.6959, 0.6971, 0.6982, 0.6994, 0.7018, 0.7029, 0.7041,\n",
       "             0.7053, 0.7064, 0.7076, 0.7088, 0.7099, 0.7111, 0.7123, 0.7135, 0.7146,\n",
       "             0.7158, 0.7170, 0.7181, 0.7193, 0.7205, 0.7216, 0.7228, 0.7240, 0.7251,\n",
       "             0.7263, 0.7275, 0.7287, 0.7298, 0.7310, 0.7322, 0.7333, 0.7345, 0.7357,\n",
       "             0.7368, 0.7380, 0.7392, 0.7404, 0.7415, 0.7427, 0.7439, 0.7450, 0.7462,\n",
       "             0.7474, 0.7485, 0.7497, 0.7509, 0.7520, 0.7532, 0.7544, 0.7556, 0.7567,\n",
       "             0.7579, 0.7591, 0.7602, 0.7614, 0.7626, 0.7637, 0.7649, 0.7661, 0.7673,\n",
       "             0.7684, 0.7696, 0.7708, 0.7719, 0.7731, 0.7743, 0.7754, 0.7766, 0.7778,\n",
       "             0.7789, 0.7801, 0.7813, 0.7825, 0.7836, 0.7848, 0.7860, 0.7871, 0.7883,\n",
       "             0.7895, 0.7906, 0.7918, 0.7930, 0.7942, 0.7953, 0.7965, 0.7977, 0.7988,\n",
       "             0.8000, 0.8012, 0.8023, 0.8035, 0.8047, 0.8058, 0.8070, 0.8082, 0.8094,\n",
       "             0.8105, 0.8117, 0.8129, 0.8140, 0.8152, 0.8164, 0.8175, 0.8187, 0.8199,\n",
       "             0.8211, 0.8222, 0.8234, 0.8246, 0.8257, 0.8269, 0.8281, 0.8292, 0.8304,\n",
       "             0.8316, 0.8327, 0.8339, 0.8351, 0.8363, 0.8374, 0.8386, 0.8398, 0.8409,\n",
       "             0.8421, 0.8433, 0.8444, 0.8456, 0.8468, 0.8480, 0.8491, 0.8503, 0.8515,\n",
       "             0.8526, 0.8538, 0.8550, 0.8561, 0.8573, 0.8585, 0.8596, 0.8608, 0.8620,\n",
       "             0.8632, 0.8643, 0.8655, 0.8667, 0.8678, 0.8690, 0.8702, 0.8713, 0.8725,\n",
       "             0.8737, 0.8749, 0.8760, 0.8772, 0.8784, 0.8795, 0.8807, 0.8819, 0.8830,\n",
       "             0.8842, 0.8854, 0.8865, 0.8877, 0.8889, 0.8901, 0.8912, 0.8924, 0.8936,\n",
       "             0.8947, 0.8959, 0.8959, 0.8971, 0.8982, 0.8994, 0.9006, 0.9018, 0.9029,\n",
       "             0.9041, 0.9053, 0.9064, 0.9076, 0.9088, 0.9099, 0.9111, 0.9123, 0.9135,\n",
       "             0.9146, 0.9158, 0.9170, 0.9181, 0.9181, 0.9193, 0.9205, 0.9216, 0.9228,\n",
       "             0.9240, 0.9251, 0.9251, 0.9263, 0.9275, 0.9287, 0.9298, 0.9298, 0.9310,\n",
       "             0.9322, 0.9333, 0.9345, 0.9357, 0.9368, 0.9380, 0.9392, 0.9404, 0.9404,\n",
       "             0.9415, 0.9427, 0.9439, 0.9439, 0.9450, 0.9450, 0.9462, 0.9474, 0.9485,\n",
       "             0.9485, 0.9497, 0.9509, 0.9520, 0.9532, 0.9544, 0.9556, 0.9567, 0.9567,\n",
       "             0.9579, 0.9591, 0.9602, 0.9614, 0.9614, 0.9614, 0.9626, 0.9637, 0.9649,\n",
       "             0.9661, 0.9661, 0.9673, 0.9684, 0.9696, 0.9696, 0.9696, 0.9708, 0.9708,\n",
       "             0.9719, 0.9719, 0.9719, 0.9731, 0.9743, 0.9754, 0.9766, 0.9778, 0.9789,\n",
       "             0.9789, 0.9801, 0.9813, 0.9813, 0.9813, 0.9813, 0.9825, 0.9836, 0.9836,\n",
       "             0.9836, 0.9836, 0.9848, 0.9860, 0.9871, 0.9871, 0.9871, 0.9883, 0.9883,\n",
       "             0.9895, 0.9906, 0.9906, 0.9906, 0.9918, 0.9930, 0.9942, 0.9942, 0.9942,\n",
       "             0.9942, 0.9942, 0.9942, 0.9953, 0.9953, 0.9953, 0.9953, 0.9953, 0.9953,\n",
       "             0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965,\n",
       "             0.9965, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9986e-01, 9.9986e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01,\n",
       "             9.9985e-01, 9.9985e-01, 9.9984e-01, 9.9984e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9982e-01, 9.9982e-01, 9.9981e-01, 9.9981e-01, 9.9980e-01, 9.9979e-01,\n",
       "             9.9979e-01, 9.9979e-01, 9.9979e-01, 9.9978e-01, 9.9978e-01, 9.9978e-01,\n",
       "             9.9977e-01, 9.9977e-01, 9.9976e-01, 9.9976e-01, 9.9976e-01, 9.9975e-01,\n",
       "             9.9974e-01, 9.9973e-01, 9.9973e-01, 9.9972e-01, 9.9972e-01, 9.9972e-01,\n",
       "             9.9972e-01, 9.9971e-01, 9.9971e-01, 9.9970e-01, 9.9968e-01, 9.9968e-01,\n",
       "             9.9968e-01, 9.9967e-01, 9.9967e-01, 9.9967e-01, 9.9967e-01, 9.9965e-01,\n",
       "             9.9964e-01, 9.9964e-01, 9.9964e-01, 9.9959e-01, 9.9959e-01, 9.9959e-01,\n",
       "             9.9958e-01, 9.9957e-01, 9.9956e-01, 9.9955e-01, 9.9955e-01, 9.9952e-01,\n",
       "             9.9952e-01, 9.9949e-01, 9.9946e-01, 9.9946e-01, 9.9943e-01, 9.9937e-01,\n",
       "             9.9937e-01, 9.9937e-01, 9.9936e-01, 9.9935e-01, 9.9934e-01, 9.9933e-01,\n",
       "             9.9933e-01, 9.9933e-01, 9.9932e-01, 9.9931e-01, 9.9929e-01, 9.9929e-01,\n",
       "             9.9929e-01, 9.9928e-01, 9.9925e-01, 9.9925e-01, 9.9924e-01, 9.9924e-01,\n",
       "             9.9924e-01, 9.9914e-01, 9.9912e-01, 9.9911e-01, 9.9911e-01, 9.9911e-01,\n",
       "             9.9910e-01, 9.9909e-01, 9.9907e-01, 9.9904e-01, 9.9904e-01, 9.9903e-01,\n",
       "             9.9901e-01, 9.9901e-01, 9.9900e-01, 9.9899e-01, 9.9899e-01, 9.9894e-01,\n",
       "             9.9892e-01, 9.9891e-01, 9.9890e-01, 9.9881e-01, 9.9880e-01, 9.9876e-01,\n",
       "             9.9871e-01, 9.9869e-01, 9.9868e-01, 9.9862e-01, 9.9859e-01, 9.9856e-01,\n",
       "             9.9851e-01, 9.9836e-01, 9.9834e-01, 9.9833e-01, 9.9813e-01, 9.9812e-01,\n",
       "             9.9780e-01, 9.9767e-01, 9.9749e-01, 9.9739e-01, 9.9736e-01, 9.9730e-01,\n",
       "             9.9703e-01, 9.9684e-01, 9.9644e-01, 9.9637e-01, 9.9621e-01, 9.9565e-01,\n",
       "             9.9563e-01, 9.9562e-01, 9.9523e-01, 9.9495e-01, 9.9488e-01, 9.9476e-01,\n",
       "             9.9455e-01, 9.9445e-01, 9.9358e-01, 9.9334e-01, 9.9305e-01, 9.9272e-01,\n",
       "             9.9205e-01, 9.9194e-01, 9.9193e-01, 9.9129e-01, 9.9055e-01, 9.9043e-01,\n",
       "             9.8934e-01, 9.8932e-01, 9.8752e-01, 9.8735e-01, 9.8663e-01, 9.8521e-01,\n",
       "             9.8365e-01, 9.8323e-01, 9.8297e-01, 9.8224e-01, 9.8165e-01, 9.7888e-01,\n",
       "             9.7733e-01, 9.7472e-01, 9.7057e-01, 9.6692e-01, 9.6571e-01, 9.6566e-01,\n",
       "             9.5949e-01, 9.5941e-01, 9.5627e-01, 9.5432e-01, 9.5408e-01, 9.5180e-01,\n",
       "             9.5133e-01, 9.5075e-01, 9.5029e-01, 9.4750e-01, 9.4481e-01, 9.4332e-01,\n",
       "             9.3577e-01, 9.0903e-01, 8.7078e-01, 8.6963e-01, 8.6572e-01, 8.5339e-01,\n",
       "             8.4431e-01, 8.2653e-01, 8.1046e-01, 8.0885e-01, 7.9484e-01, 7.3398e-01,\n",
       "             7.3351e-01, 7.1080e-01, 6.9687e-01, 6.9647e-01, 6.7831e-01, 6.6799e-01,\n",
       "             6.6536e-01, 6.6258e-01, 6.4771e-01, 6.2360e-01, 5.7386e-01, 5.7329e-01,\n",
       "             5.4786e-01, 5.1237e-01, 3.8948e-01, 3.2945e-01, 2.8302e-01, 2.6444e-01,\n",
       "             2.5163e-01, 1.9449e-01, 1.6960e-01, 1.2610e-01, 1.2307e-01, 1.2240e-01,\n",
       "             8.2377e-02, 7.9617e-02, 6.7875e-02, 5.8376e-02, 5.1055e-02, 4.5639e-02,\n",
       "             4.1239e-02, 3.9828e-02, 1.9723e-02, 1.3784e-02, 1.0338e-02, 9.9810e-03,\n",
       "             9.2076e-03, 6.5902e-03, 6.1816e-03, 4.7033e-03, 4.6474e-03, 3.2582e-03,\n",
       "             2.4727e-03, 2.0522e-03, 2.0069e-03, 1.8530e-03, 1.1253e-03, 1.0133e-03,\n",
       "             9.5740e-04, 6.5166e-04, 5.1912e-04, 4.8577e-04, 4.0967e-04, 3.5222e-04,\n",
       "             3.1056e-04, 2.8880e-04, 2.6389e-04, 2.3162e-04, 2.1592e-04, 2.0790e-04,\n",
       "             2.0458e-04, 1.5475e-04, 1.4757e-04, 1.3237e-04, 1.2220e-04, 9.3050e-05,\n",
       "             9.1224e-05, 7.7155e-05, 7.0172e-05, 4.5904e-05, 4.3770e-05, 3.8270e-05,\n",
       "             3.6115e-05, 3.4976e-05, 3.3970e-05, 2.7419e-05, 2.2394e-05, 1.6358e-05,\n",
       "             1.4966e-05, 1.4054e-05, 1.3395e-05, 1.3171e-05, 1.0469e-05, 9.5442e-06,\n",
       "             9.4850e-06, 9.0082e-06, 8.3090e-06, 8.0027e-06, 7.4962e-06, 5.6397e-06,\n",
       "             5.5363e-06, 4.3459e-06, 3.7830e-06, 2.3001e-06, 1.5313e-06, 1.4935e-06,\n",
       "             1.4604e-06, 1.4375e-06, 1.2601e-06, 8.5394e-07, 7.3993e-07, 6.8337e-07,\n",
       "             6.6283e-07, 6.0589e-07, 5.8810e-07, 4.9761e-07, 4.9267e-07, 4.8517e-07,\n",
       "             3.9040e-07, 3.7533e-07, 3.5296e-07, 3.4059e-07, 3.2411e-07, 3.2369e-07,\n",
       "             3.0366e-07, 2.9381e-07, 2.6069e-07, 2.4354e-07, 2.3653e-07, 2.2307e-07,\n",
       "             2.1999e-07, 1.6717e-07, 1.5718e-07, 1.4810e-07, 1.3560e-07, 1.3421e-07,\n",
       "             1.1395e-07, 1.1381e-07, 1.0138e-07, 9.2308e-08, 8.8958e-08, 8.0152e-08,\n",
       "             7.3872e-08, 6.8589e-08, 6.0627e-08, 5.7493e-08, 5.1736e-08, 5.1356e-08,\n",
       "             5.0864e-08, 4.9848e-08, 4.1111e-08, 3.2431e-08, 2.2115e-08, 1.9664e-08,\n",
       "             1.6653e-08, 1.3618e-08, 1.1900e-08, 1.0596e-08, 1.0197e-08, 9.8132e-09,\n",
       "             9.6105e-09, 9.2149e-09, 8.0859e-09, 7.1598e-09, 6.8433e-09, 5.9391e-09,\n",
       "             5.3274e-09, 5.2962e-09, 5.1820e-09, 5.1539e-09, 4.6638e-09, 4.5897e-09,\n",
       "             4.5209e-09, 4.4792e-09, 4.2905e-09, 3.5812e-09, 3.2694e-09, 2.5325e-09,\n",
       "             2.3983e-09, 2.3811e-09, 2.1005e-09, 1.9757e-09, 1.8304e-09, 1.7900e-09,\n",
       "             1.7558e-09, 1.7115e-09, 1.2674e-09, 1.1803e-09, 1.1766e-09, 1.0806e-09,\n",
       "             1.0448e-09, 1.0038e-09, 9.8270e-10, 9.6163e-10, 9.2558e-10, 8.6843e-10,\n",
       "             8.4920e-10, 8.2498e-10, 7.7608e-10, 7.6404e-10, 7.5202e-10, 7.3177e-10,\n",
       "             6.6063e-10, 6.2674e-10, 4.8089e-10, 4.8007e-10, 3.8527e-10, 3.2701e-10,\n",
       "             3.1737e-10, 2.9158e-10, 2.7978e-10, 2.6864e-10, 2.4453e-10, 2.4122e-10,\n",
       "             2.3882e-10, 2.1868e-10, 2.0962e-10, 2.0672e-10, 2.0015e-10, 1.9351e-10,\n",
       "             1.9244e-10, 1.6379e-10, 1.6071e-10, 1.4852e-10, 1.3720e-10, 1.3323e-10,\n",
       "             1.1854e-10, 1.0142e-10, 9.5962e-11, 9.3767e-11, 9.2219e-11, 9.1830e-11,\n",
       "             8.2490e-11, 7.2973e-11, 6.4405e-11, 5.9965e-11, 5.8740e-11, 5.7661e-11,\n",
       "             5.4622e-11, 5.1939e-11, 4.7126e-11, 4.6983e-11, 4.6002e-11, 4.5326e-11,\n",
       "             4.1469e-11, 3.2582e-11, 2.7774e-11, 2.5735e-11, 2.1363e-11, 2.0753e-11,\n",
       "             2.0711e-11, 1.9563e-11, 1.8510e-11, 1.7377e-11, 1.7109e-11, 1.5576e-11,\n",
       "             1.4144e-11, 1.2709e-11, 1.1771e-11, 9.9888e-12, 9.8758e-12, 9.6564e-12,\n",
       "             9.3433e-12, 8.7429e-12, 8.5015e-12, 8.2870e-12, 7.7341e-12, 7.6414e-12,\n",
       "             7.5857e-12, 7.0144e-12, 6.8053e-12, 6.2786e-12, 6.2763e-12, 5.9503e-12,\n",
       "             5.5646e-12, 4.5211e-12, 4.5112e-12, 3.9688e-12, 3.6616e-12, 3.3388e-12,\n",
       "             3.2903e-12, 2.7866e-12, 2.5032e-12, 2.4417e-12, 2.4114e-12, 2.1940e-12,\n",
       "             1.8920e-12, 1.7893e-12, 1.7364e-12, 1.5391e-12, 1.4701e-12, 1.2509e-12,\n",
       "             1.2185e-12, 1.1767e-12, 1.1299e-12, 1.1120e-12, 9.9484e-13, 9.3755e-13,\n",
       "             8.7498e-13, 8.4463e-13, 7.0548e-13, 6.9472e-13, 6.5608e-13, 4.0157e-13,\n",
       "             3.3892e-13, 3.2158e-13, 2.3159e-13, 2.0639e-13, 1.6023e-13, 9.8482e-14,\n",
       "             9.4109e-14, 8.6920e-14, 7.7514e-14, 5.7854e-14, 5.6908e-14, 5.1140e-14,\n",
       "             4.3229e-14, 3.9362e-14, 3.7480e-14, 3.6012e-14, 3.5393e-14, 3.4375e-14,\n",
       "             3.1893e-14, 3.1764e-14, 3.0686e-14, 2.8250e-14, 2.4819e-14, 2.2841e-14,\n",
       "             2.1064e-14, 1.5246e-14, 1.1748e-14, 1.1396e-14, 1.0010e-14, 6.5199e-15,\n",
       "             6.4978e-15, 6.0702e-15, 6.0684e-15, 4.4946e-15, 4.3267e-15, 3.5316e-15,\n",
       "             2.8273e-15, 2.1040e-15, 1.9740e-15, 1.6929e-15, 1.4184e-15, 1.1182e-15,\n",
       "             8.3385e-16, 6.4369e-16, 4.6935e-16, 3.5618e-16, 1.9582e-16, 1.9325e-16,\n",
       "             1.3851e-16, 8.2571e-17, 6.9200e-17, 2.7894e-17, 1.3862e-17, 1.1048e-17,\n",
       "             2.5355e-18])}},\n",
       "   {'fpr': np.float64(0.09006211180124224),\n",
       "    'tpr': np.float64(0.9906432748538012),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0155, 0.0155, 0.0186,\n",
       "             0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0217, 0.0248, 0.0248, 0.0248,\n",
       "             0.0248, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280, 0.0280,\n",
       "             0.0280, 0.0280, 0.0280, 0.0311, 0.0311, 0.0311, 0.0311, 0.0342, 0.0342,\n",
       "             0.0342, 0.0342, 0.0373, 0.0373, 0.0404, 0.0435, 0.0435, 0.0466, 0.0466,\n",
       "             0.0466, 0.0497, 0.0528, 0.0528, 0.0559, 0.0559, 0.0559, 0.0559, 0.0559,\n",
       "             0.0590, 0.0590, 0.0590, 0.0621, 0.0621, 0.0652, 0.0683, 0.0683, 0.0714,\n",
       "             0.0714, 0.0714, 0.0745, 0.0745, 0.0776, 0.0776, 0.0807, 0.0839, 0.0870,\n",
       "             0.0901, 0.0932, 0.0963, 0.0963, 0.0994, 0.1025, 0.1056, 0.1087, 0.1118,\n",
       "             0.1149, 0.1180, 0.1180, 0.1211, 0.1242, 0.1273, 0.1273, 0.1304, 0.1335,\n",
       "             0.1398, 0.1429, 0.1460, 0.1491, 0.1491, 0.1522, 0.1553, 0.1584, 0.1615,\n",
       "             0.1646, 0.1646, 0.1677, 0.1708, 0.1739, 0.1770, 0.1801, 0.1832, 0.1863,\n",
       "             0.1894, 0.1925, 0.1957, 0.1988, 0.2019, 0.2050, 0.2081, 0.2112, 0.2143,\n",
       "             0.2174, 0.2174, 0.2205, 0.2236, 0.2267, 0.2298, 0.2329, 0.2360, 0.2391,\n",
       "             0.2422, 0.2453, 0.2484, 0.2516, 0.2547, 0.2578, 0.2609, 0.2640, 0.2671,\n",
       "             0.2702, 0.2733, 0.2764, 0.2795, 0.2826, 0.2857, 0.2888, 0.2919, 0.2919,\n",
       "             0.2950, 0.2981, 0.3012, 0.3043, 0.3075, 0.3106, 0.3137, 0.3168, 0.3199,\n",
       "             0.3230, 0.3261, 0.3292, 0.3323, 0.3354, 0.3385, 0.3416, 0.3447, 0.3478,\n",
       "             0.3509, 0.3540, 0.3571, 0.3602, 0.3634, 0.3665, 0.3696, 0.3727, 0.3758,\n",
       "             0.3789, 0.3820, 0.3851, 0.3882, 0.3913, 0.3944, 0.3975, 0.4006, 0.4037,\n",
       "             0.4068, 0.4099, 0.4130, 0.4161, 0.4193, 0.4224, 0.4255, 0.4286, 0.4317,\n",
       "             0.4348, 0.4379, 0.4410, 0.4441, 0.4472, 0.4503, 0.4534, 0.4565, 0.4596,\n",
       "             0.4627, 0.4658, 0.4689, 0.4720, 0.4752, 0.4783, 0.4814, 0.4845, 0.4876,\n",
       "             0.4907, 0.4938, 0.4969, 0.5000, 0.5031, 0.5062, 0.5093, 0.5124, 0.5155,\n",
       "             0.5186, 0.5217, 0.5248, 0.5280, 0.5311, 0.5342, 0.5373, 0.5404, 0.5435,\n",
       "             0.5466, 0.5497, 0.5528, 0.5559, 0.5590, 0.5621, 0.5652, 0.5683, 0.5714,\n",
       "             0.5745, 0.5745, 0.5776, 0.5807, 0.5839, 0.5870, 0.5901, 0.5932, 0.5963,\n",
       "             0.5994, 0.6025, 0.6056, 0.6087, 0.6118, 0.6149, 0.6180, 0.6211, 0.6242,\n",
       "             0.6273, 0.6304, 0.6335, 0.6366, 0.6398, 0.6429, 0.6460, 0.6491, 0.6522,\n",
       "             0.6553, 0.6584, 0.6615, 0.6646, 0.6677, 0.6708, 0.6739, 0.6770, 0.6801,\n",
       "             0.6832, 0.6863, 0.6894, 0.6925, 0.6957, 0.6988, 0.7019, 0.7050, 0.7081,\n",
       "             0.7112, 0.7143, 0.7174, 0.7205, 0.7236, 0.7267, 0.7298, 0.7329, 0.7360,\n",
       "             0.7391, 0.7422, 0.7453, 0.7484, 0.7516, 0.7547, 0.7578, 0.7609, 0.7640,\n",
       "             0.7671, 0.7702, 0.7733, 0.7764, 0.7795, 0.7826, 0.7857, 0.7888, 0.7919,\n",
       "             0.7950, 0.7981, 0.8012, 0.8043, 0.8075, 0.8106, 0.8137, 0.8168, 0.8199,\n",
       "             0.8230, 0.8261, 0.8292, 0.8323, 0.8354, 0.8385, 0.8416, 0.8447, 0.8478,\n",
       "             0.8509, 0.8540, 0.8571, 0.8602, 0.8634, 0.8665, 0.8696, 0.8727, 0.8758,\n",
       "             0.8789, 0.8820, 0.8851, 0.8882, 0.8913, 0.8944, 0.8975, 0.9006, 0.9037,\n",
       "             0.9068, 0.9099, 0.9130, 0.9161, 0.9193, 0.9224, 0.9255, 0.9286, 0.9317,\n",
       "             0.9348, 0.9379, 0.9410, 0.9441, 0.9472, 0.9503, 0.9534, 0.9565, 0.9596,\n",
       "             0.9627, 0.9658, 0.9689, 0.9720, 0.9752, 0.9783, 0.9814, 0.9845, 0.9876,\n",
       "             0.9907, 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.5532, 0.6257, 0.6596, 0.6901, 0.7064, 0.7181, 0.7275, 0.7380,\n",
       "             0.7404, 0.7450, 0.7497, 0.7556, 0.7567, 0.7626, 0.7661, 0.7743, 0.7789,\n",
       "             0.7836, 0.7895, 0.7965, 0.7988, 0.8035, 0.8047, 0.8047, 0.8082, 0.8094,\n",
       "             0.8105, 0.8140, 0.8152, 0.8175, 0.8187, 0.8222, 0.8234, 0.8246, 0.8269,\n",
       "             0.8292, 0.8304, 0.8327, 0.8351, 0.8363, 0.8374, 0.8386, 0.8409, 0.8421,\n",
       "             0.8433, 0.8444, 0.8468, 0.8503, 0.8515, 0.8526, 0.8550, 0.8561, 0.8573,\n",
       "             0.8596, 0.8608, 0.8620, 0.8643, 0.8655, 0.8667, 0.8678, 0.8690, 0.8702,\n",
       "             0.8713, 0.8725, 0.8737, 0.8749, 0.8760, 0.8772, 0.8784, 0.8795, 0.8807,\n",
       "             0.8819, 0.8830, 0.8842, 0.8854, 0.8865, 0.8877, 0.8889, 0.8901, 0.8912,\n",
       "             0.8924, 0.8936, 0.8947, 0.8959, 0.8971, 0.8994, 0.9006, 0.9018, 0.9029,\n",
       "             0.9041, 0.9053, 0.9064, 0.9076, 0.9088, 0.9099, 0.9111, 0.9123, 0.9135,\n",
       "             0.9146, 0.9158, 0.9170, 0.9181, 0.9193, 0.9205, 0.9216, 0.9228, 0.9240,\n",
       "             0.9251, 0.9263, 0.9275, 0.9298, 0.9310, 0.9322, 0.9333, 0.9345, 0.9357,\n",
       "             0.9368, 0.9368, 0.9380, 0.9392, 0.9404, 0.9415, 0.9415, 0.9427, 0.9427,\n",
       "             0.9439, 0.9450, 0.9462, 0.9474, 0.9485, 0.9485, 0.9485, 0.9497, 0.9509,\n",
       "             0.9520, 0.9520, 0.9532, 0.9544, 0.9556, 0.9567, 0.9579, 0.9591, 0.9602,\n",
       "             0.9614, 0.9626, 0.9637, 0.9637, 0.9649, 0.9661, 0.9673, 0.9673, 0.9684,\n",
       "             0.9696, 0.9708, 0.9708, 0.9719, 0.9719, 0.9719, 0.9731, 0.9731, 0.9743,\n",
       "             0.9754, 0.9754, 0.9754, 0.9766, 0.9766, 0.9778, 0.9789, 0.9801, 0.9813,\n",
       "             0.9813, 0.9825, 0.9836, 0.9836, 0.9848, 0.9848, 0.9848, 0.9860, 0.9860,\n",
       "             0.9871, 0.9883, 0.9883, 0.9895, 0.9895, 0.9906, 0.9906, 0.9906, 0.9906,\n",
       "             0.9906, 0.9906, 0.9906, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918,\n",
       "             0.9918, 0.9918, 0.9930, 0.9930, 0.9930, 0.9930, 0.9942, 0.9942, 0.9942,\n",
       "             0.9942, 0.9942, 0.9942, 0.9942, 0.9953, 0.9953, 0.9953, 0.9953, 0.9953,\n",
       "             0.9953, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965,\n",
       "             0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965,\n",
       "             0.9965, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9994e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9992e-01, 9.9991e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9986e-01, 9.9986e-01, 9.9985e-01, 9.9985e-01,\n",
       "             9.9984e-01, 9.9983e-01, 9.9983e-01, 9.9982e-01, 9.9981e-01, 9.9979e-01,\n",
       "             9.9976e-01, 9.9974e-01, 9.9973e-01, 9.9970e-01, 9.9969e-01, 9.9929e-01,\n",
       "             9.9927e-01, 9.9925e-01, 9.9921e-01, 9.9920e-01, 9.9908e-01, 9.9896e-01,\n",
       "             9.9893e-01, 9.9886e-01, 9.9875e-01, 9.9851e-01, 9.9813e-01, 9.9808e-01,\n",
       "             9.9789e-01, 9.9657e-01, 9.9629e-01, 9.9380e-01, 9.9316e-01, 9.9167e-01,\n",
       "             9.9163e-01, 9.9136e-01, 9.9049e-01, 9.9004e-01, 9.8975e-01, 9.8927e-01,\n",
       "             9.8879e-01, 9.8851e-01, 9.8815e-01, 9.8040e-01, 9.8014e-01, 9.7928e-01,\n",
       "             9.7909e-01, 9.7524e-01, 9.7475e-01, 9.7357e-01, 9.6962e-01, 9.6770e-01,\n",
       "             9.6570e-01, 9.6373e-01, 9.5682e-01, 9.3728e-01, 9.2733e-01, 9.2274e-01,\n",
       "             9.2192e-01, 9.2058e-01, 8.9217e-01, 8.8001e-01, 8.2719e-01, 8.2641e-01,\n",
       "             8.2349e-01, 8.0750e-01, 8.0006e-01, 7.9848e-01, 7.6287e-01, 7.2380e-01,\n",
       "             7.1645e-01, 7.0158e-01, 6.6471e-01, 5.7198e-01, 4.2366e-01, 3.8505e-01,\n",
       "             3.7568e-01, 3.1181e-01, 3.0851e-01, 2.7914e-01, 2.0760e-01, 1.8551e-01,\n",
       "             1.8378e-01, 1.0344e-01, 1.0122e-01, 9.6229e-02, 7.6813e-02, 7.5443e-02,\n",
       "             7.0978e-02, 6.6701e-02, 5.1244e-02, 5.0178e-02, 4.2760e-02, 3.8457e-02,\n",
       "             3.8068e-02, 3.3891e-02, 3.2148e-02, 3.1429e-02, 2.4254e-02, 1.9640e-02,\n",
       "             9.5321e-03, 8.6675e-03, 8.0861e-03, 7.0225e-03, 6.8615e-03, 6.2967e-03,\n",
       "             5.6492e-03, 4.8242e-03, 2.9979e-03, 2.7864e-03, 2.6160e-03, 2.3569e-03,\n",
       "             2.2324e-03, 2.0693e-03, 1.9756e-03, 1.4392e-03, 1.3612e-03, 1.1801e-03,\n",
       "             1.0323e-03, 9.8521e-04, 9.6125e-04, 7.6637e-04, 7.2549e-04, 7.1389e-04,\n",
       "             4.4926e-04, 3.6241e-04, 3.5738e-04, 3.2735e-04, 2.6902e-04, 2.3885e-04,\n",
       "             2.3332e-04, 2.3321e-04, 1.8972e-04, 1.6383e-04, 1.5052e-04, 1.4053e-04,\n",
       "             1.2720e-04, 1.2542e-04, 1.0886e-04, 1.0580e-04, 1.0293e-04, 1.0227e-04,\n",
       "             9.4871e-05, 8.8618e-05, 8.3294e-05, 7.5842e-05, 7.3299e-05, 6.9430e-05,\n",
       "             6.7963e-05, 6.5154e-05, 6.4734e-05, 6.1497e-05, 5.7116e-05, 5.6674e-05,\n",
       "             5.2548e-05, 4.0558e-05, 3.7893e-05, 3.7865e-05, 3.6541e-05, 3.5985e-05,\n",
       "             3.4754e-05, 3.1816e-05, 3.0476e-05, 2.8148e-05, 2.7137e-05, 2.4859e-05,\n",
       "             2.2549e-05, 2.1503e-05, 2.0350e-05, 1.8450e-05, 1.7532e-05, 1.5830e-05,\n",
       "             1.1816e-05, 1.1620e-05, 1.1327e-05, 1.0030e-05, 9.3735e-06, 8.4569e-06,\n",
       "             7.8722e-06, 6.7338e-06, 6.5977e-06, 6.3683e-06, 3.5486e-06, 3.4315e-06,\n",
       "             3.3007e-06, 3.2881e-06, 2.8759e-06, 2.8421e-06, 2.7807e-06, 2.7073e-06,\n",
       "             2.6965e-06, 2.5796e-06, 2.5151e-06, 2.2375e-06, 2.1484e-06, 2.1463e-06,\n",
       "             2.0599e-06, 1.9367e-06, 1.6327e-06, 1.6249e-06, 1.4644e-06, 1.4613e-06,\n",
       "             1.2550e-06, 1.2107e-06, 1.1353e-06, 1.1297e-06, 1.0889e-06, 1.0738e-06,\n",
       "             1.0098e-06, 1.0020e-06, 9.7890e-07, 9.3705e-07, 7.8094e-07, 7.6406e-07,\n",
       "             7.1105e-07, 6.6427e-07, 6.4926e-07, 6.2019e-07, 5.5546e-07, 5.5151e-07,\n",
       "             4.8874e-07, 4.7762e-07, 4.6936e-07, 4.4859e-07, 4.4743e-07, 4.3212e-07,\n",
       "             3.2674e-07, 3.1205e-07, 2.8726e-07, 2.5418e-07, 2.4886e-07, 2.1760e-07,\n",
       "             2.0127e-07, 1.9121e-07, 1.7606e-07, 1.6297e-07, 1.5925e-07, 1.4238e-07,\n",
       "             1.3712e-07, 1.3617e-07, 1.3110e-07, 1.2347e-07, 1.2123e-07, 1.1232e-07,\n",
       "             1.0851e-07, 1.0793e-07, 1.0227e-07, 9.7076e-08, 9.6169e-08, 9.3649e-08,\n",
       "             7.9102e-08, 7.4486e-08, 6.9820e-08, 6.7831e-08, 5.7823e-08, 5.3810e-08,\n",
       "             5.3772e-08, 5.1485e-08, 4.6102e-08, 4.5806e-08, 4.5220e-08, 4.2884e-08,\n",
       "             3.9634e-08, 3.9370e-08, 3.7421e-08, 3.6869e-08, 3.4242e-08, 3.3720e-08,\n",
       "             3.0766e-08, 2.8069e-08, 2.2664e-08, 2.1095e-08, 2.0524e-08, 1.9951e-08,\n",
       "             1.9509e-08, 1.8773e-08, 1.8481e-08, 1.8404e-08, 1.4890e-08, 1.2406e-08,\n",
       "             1.1866e-08, 1.1318e-08, 1.0400e-08, 9.6622e-09, 9.4428e-09, 8.8255e-09,\n",
       "             8.2776e-09, 7.8900e-09, 7.6243e-09, 7.3107e-09, 7.1522e-09, 6.6423e-09,\n",
       "             6.6157e-09, 6.0270e-09, 5.9445e-09, 5.8779e-09, 3.9993e-09, 3.8831e-09,\n",
       "             3.8403e-09, 3.8103e-09, 3.3099e-09, 2.9585e-09, 2.8175e-09, 2.7972e-09,\n",
       "             2.1258e-09, 2.0586e-09, 2.0108e-09, 1.6930e-09, 1.5586e-09, 1.4203e-09,\n",
       "             1.4077e-09, 1.3145e-09, 1.1066e-09, 1.0551e-09, 9.6316e-10, 9.2644e-10,\n",
       "             9.1525e-10, 9.1000e-10, 7.9007e-10, 6.4545e-10, 6.4460e-10, 3.7273e-10,\n",
       "             3.2577e-10, 2.7113e-10, 2.4478e-10, 2.1416e-10, 1.9619e-10, 1.8936e-10,\n",
       "             1.5442e-10, 1.5097e-10, 1.4089e-10, 1.3681e-10, 1.3454e-10, 1.1683e-10,\n",
       "             1.0565e-10, 7.6365e-11, 3.9805e-11, 1.9182e-11, 1.6170e-11, 1.4803e-11,\n",
       "             1.4470e-11, 1.0974e-11, 7.6006e-12, 7.5502e-12, 4.9702e-12, 4.1519e-12,\n",
       "             3.8748e-12, 3.8690e-12, 3.8316e-12, 3.7488e-12, 3.1854e-12, 2.5145e-12,\n",
       "             1.7968e-12, 1.2822e-12, 1.0936e-12, 9.0786e-13, 8.2926e-13, 6.0966e-13,\n",
       "             5.4975e-13, 5.1912e-13, 4.9868e-13, 2.5181e-13, 2.1941e-13, 8.2916e-14,\n",
       "             5.3200e-14, 5.0077e-14, 4.9232e-14, 4.8896e-14, 5.2021e-15, 4.9387e-15,\n",
       "             3.7060e-15, 1.4136e-15, 1.0967e-15, 7.6160e-17])}},\n",
       "   {'fpr': np.float64(0.062111801242236024),\n",
       "    'tpr': np.float64(0.9801169590643275),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0062, 0.0093, 0.0093, 0.0093, 0.0093, 0.0124,\n",
       "             0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0155,\n",
       "             0.0155, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155,\n",
       "             0.0155, 0.0155, 0.0155, 0.0186, 0.0186, 0.0186, 0.0186, 0.0217, 0.0217,\n",
       "             0.0248, 0.0248, 0.0248, 0.0280, 0.0311, 0.0311, 0.0311, 0.0311, 0.0342,\n",
       "             0.0342, 0.0342, 0.0373, 0.0373, 0.0404, 0.0404, 0.0404, 0.0404, 0.0404,\n",
       "             0.0435, 0.0435, 0.0466, 0.0497, 0.0497, 0.0497, 0.0497, 0.0528, 0.0559,\n",
       "             0.0559, 0.0559, 0.0559, 0.0590, 0.0621, 0.0652, 0.0652, 0.0683, 0.0683,\n",
       "             0.0683, 0.0714, 0.0745, 0.0776, 0.0807, 0.0807, 0.0839, 0.0870, 0.0870,\n",
       "             0.0870, 0.0870, 0.0870, 0.0901, 0.0963, 0.0963, 0.0994, 0.1025, 0.1056,\n",
       "             0.1087, 0.1118, 0.1149, 0.1149, 0.1180, 0.1211, 0.1242, 0.1273, 0.1304,\n",
       "             0.1335, 0.1366, 0.1366, 0.1398, 0.1429, 0.1429, 0.1460, 0.1491, 0.1522,\n",
       "             0.1522, 0.1553, 0.1553, 0.1584, 0.1615, 0.1646, 0.1677, 0.1708, 0.1739,\n",
       "             0.1770, 0.1801, 0.1801, 0.1832, 0.1863, 0.1894, 0.1925, 0.1957, 0.1988,\n",
       "             0.1988, 0.2019, 0.2050, 0.2081, 0.2112, 0.2143, 0.2174, 0.2205, 0.2236,\n",
       "             0.2267, 0.2298, 0.2329, 0.2360, 0.2391, 0.2422, 0.2453, 0.2484, 0.2516,\n",
       "             0.2547, 0.2578, 0.2609, 0.2640, 0.2671, 0.2702, 0.2733, 0.2764, 0.2795,\n",
       "             0.2826, 0.2857, 0.2888, 0.2919, 0.2950, 0.2981, 0.3012, 0.3043, 0.3075,\n",
       "             0.3106, 0.3137, 0.3168, 0.3199, 0.3230, 0.3261, 0.3292, 0.3323, 0.3354,\n",
       "             0.3385, 0.3416, 0.3447, 0.3478, 0.3509, 0.3540, 0.3571, 0.3602, 0.3634,\n",
       "             0.3665, 0.3696, 0.3727, 0.3758, 0.3789, 0.3820, 0.3851, 0.3882, 0.3913,\n",
       "             0.3944, 0.3975, 0.4006, 0.4037, 0.4068, 0.4099, 0.4130, 0.4161, 0.4193,\n",
       "             0.4224, 0.4255, 0.4286, 0.4317, 0.4348, 0.4379, 0.4410, 0.4441, 0.4472,\n",
       "             0.4503, 0.4534, 0.4565, 0.4596, 0.4627, 0.4658, 0.4689, 0.4720, 0.4752,\n",
       "             0.4783, 0.4814, 0.4845, 0.4876, 0.4907, 0.4938, 0.4969, 0.5000, 0.5031,\n",
       "             0.5062, 0.5093, 0.5124, 0.5155, 0.5186, 0.5217, 0.5248, 0.5280, 0.5311,\n",
       "             0.5342, 0.5373, 0.5404, 0.5435, 0.5466, 0.5497, 0.5528, 0.5559, 0.5590,\n",
       "             0.5621, 0.5652, 0.5683, 0.5714, 0.5745, 0.5776, 0.5807, 0.5839, 0.5870,\n",
       "             0.5901, 0.5932, 0.5963, 0.5994, 0.6025, 0.6056, 0.6087, 0.6118, 0.6149,\n",
       "             0.6180, 0.6211, 0.6242, 0.6273, 0.6304, 0.6335, 0.6366, 0.6398, 0.6429,\n",
       "             0.6460, 0.6491, 0.6522, 0.6553, 0.6584, 0.6615, 0.6646, 0.6677, 0.6708,\n",
       "             0.6739, 0.6770, 0.6801, 0.6832, 0.6863, 0.6894, 0.6925, 0.6957, 0.6988,\n",
       "             0.7019, 0.7050, 0.7081, 0.7112, 0.7143, 0.7174, 0.7205, 0.7236, 0.7267,\n",
       "             0.7298, 0.7329, 0.7360, 0.7391, 0.7422, 0.7453, 0.7453, 0.7484, 0.7516,\n",
       "             0.7547, 0.7578, 0.7609, 0.7640, 0.7671, 0.7702, 0.7733, 0.7764, 0.7795,\n",
       "             0.7826, 0.7857, 0.7888, 0.7919, 0.7950, 0.7981, 0.8012, 0.8043, 0.8075,\n",
       "             0.8106, 0.8137, 0.8168, 0.8199, 0.8230, 0.8261, 0.8292, 0.8323, 0.8354,\n",
       "             0.8385, 0.8416, 0.8447, 0.8478, 0.8509, 0.8540, 0.8571, 0.8602, 0.8634,\n",
       "             0.8665, 0.8696, 0.8727, 0.8758, 0.8789, 0.8820, 0.8851, 0.8882, 0.8913,\n",
       "             0.8944, 0.8975, 0.9006, 0.9037, 0.9068, 0.9099, 0.9130, 0.9161, 0.9193,\n",
       "             0.9224, 0.9255, 0.9286, 0.9317, 0.9348, 0.9379, 0.9410, 0.9441, 0.9472,\n",
       "             0.9503, 0.9534, 0.9565, 0.9596, 0.9627, 0.9658, 0.9689, 0.9720, 0.9752,\n",
       "             0.9783, 0.9814, 0.9845, 0.9876, 0.9907, 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0912, 0.1368, 0.1719, 0.2023, 0.2152, 0.2339, 0.2503, 0.2596,\n",
       "             0.2713, 0.2819, 0.2901, 0.2971, 0.3064, 0.3123, 0.3216, 0.3263, 0.3322,\n",
       "             0.3333, 0.3392, 0.3427, 0.3474, 0.3567, 0.3579, 0.3626, 0.3637, 0.3661,\n",
       "             0.3684, 0.3731, 0.3789, 0.3836, 0.3883, 0.3965, 0.4000, 0.4035, 0.4082,\n",
       "             0.4117, 0.4140, 0.4164, 0.4187, 0.4269, 0.4304, 0.4327, 0.4339, 0.4363,\n",
       "             0.4386, 0.4421, 0.4433, 0.4444, 0.4491, 0.4526, 0.4561, 0.4573, 0.4585,\n",
       "             0.4608, 0.4632, 0.4678, 0.4713, 0.4749, 0.4760, 0.4772, 0.4807, 0.4819,\n",
       "             0.4854, 0.4877, 0.4924, 0.4936, 0.4971, 0.4982, 0.5018, 0.5053, 0.5064,\n",
       "             0.5076, 0.5123, 0.5135, 0.5158, 0.5170, 0.5205, 0.5228, 0.5251, 0.5263,\n",
       "             0.5287, 0.5298, 0.5310, 0.5322, 0.5345, 0.5357, 0.5368, 0.5380, 0.5415,\n",
       "             0.5427, 0.5439, 0.5450, 0.5462, 0.5474, 0.5485, 0.5532, 0.5544, 0.5556,\n",
       "             0.5567, 0.5591, 0.5602, 0.5637, 0.5649, 0.5673, 0.5684, 0.5719, 0.5731,\n",
       "             0.5743, 0.5766, 0.5778, 0.5789, 0.5825, 0.5848, 0.5860, 0.5871, 0.5883,\n",
       "             0.5906, 0.5918, 0.5930, 0.5942, 0.5953, 0.5977, 0.5988, 0.6000, 0.6023,\n",
       "             0.6035, 0.6047, 0.6070, 0.6082, 0.6094, 0.6105, 0.6117, 0.6129, 0.6152,\n",
       "             0.6175, 0.6187, 0.6199, 0.6222, 0.6234, 0.6246, 0.6257, 0.6269, 0.6281,\n",
       "             0.6304, 0.6351, 0.6363, 0.6374, 0.6398, 0.6421, 0.6433, 0.6456, 0.6468,\n",
       "             0.6480, 0.6491, 0.6503, 0.6526, 0.6538, 0.6550, 0.6573, 0.6585, 0.6596,\n",
       "             0.6608, 0.6632, 0.6643, 0.6655, 0.6667, 0.6678, 0.6690, 0.6702, 0.6713,\n",
       "             0.6725, 0.6737, 0.6749, 0.6760, 0.6772, 0.6784, 0.6795, 0.6807, 0.6819,\n",
       "             0.6830, 0.6842, 0.6854, 0.6865, 0.6877, 0.6889, 0.6912, 0.6924, 0.6936,\n",
       "             0.6947, 0.6959, 0.6971, 0.6982, 0.7006, 0.7018, 0.7029, 0.7041, 0.7053,\n",
       "             0.7064, 0.7076, 0.7088, 0.7099, 0.7111, 0.7123, 0.7146, 0.7170, 0.7181,\n",
       "             0.7193, 0.7205, 0.7216, 0.7228, 0.7240, 0.7251, 0.7263, 0.7287, 0.7298,\n",
       "             0.7310, 0.7322, 0.7333, 0.7345, 0.7357, 0.7368, 0.7380, 0.7392, 0.7404,\n",
       "             0.7427, 0.7439, 0.7450, 0.7462, 0.7474, 0.7485, 0.7497, 0.7509, 0.7520,\n",
       "             0.7532, 0.7544, 0.7556, 0.7567, 0.7579, 0.7591, 0.7602, 0.7614, 0.7626,\n",
       "             0.7637, 0.7649, 0.7673, 0.7684, 0.7696, 0.7708, 0.7719, 0.7743, 0.7754,\n",
       "             0.7766, 0.7778, 0.7789, 0.7801, 0.7813, 0.7825, 0.7836, 0.7848, 0.7860,\n",
       "             0.7871, 0.7883, 0.7895, 0.7906, 0.7918, 0.7930, 0.7942, 0.7953, 0.7965,\n",
       "             0.7977, 0.7988, 0.8000, 0.8012, 0.8023, 0.8035, 0.8047, 0.8058, 0.8082,\n",
       "             0.8094, 0.8105, 0.8117, 0.8129, 0.8140, 0.8152, 0.8164, 0.8175, 0.8187,\n",
       "             0.8199, 0.8211, 0.8222, 0.8234, 0.8246, 0.8257, 0.8269, 0.8281, 0.8292,\n",
       "             0.8304, 0.8316, 0.8316, 0.8327, 0.8339, 0.8351, 0.8363, 0.8374, 0.8386,\n",
       "             0.8398, 0.8409, 0.8421, 0.8433, 0.8444, 0.8456, 0.8468, 0.8480, 0.8491,\n",
       "             0.8503, 0.8515, 0.8526, 0.8538, 0.8550, 0.8561, 0.8573, 0.8585, 0.8596,\n",
       "             0.8608, 0.8620, 0.8632, 0.8643, 0.8655, 0.8667, 0.8678, 0.8690, 0.8702,\n",
       "             0.8713, 0.8725, 0.8737, 0.8749, 0.8760, 0.8772, 0.8784, 0.8795, 0.8807,\n",
       "             0.8819, 0.8830, 0.8842, 0.8854, 0.8865, 0.8877, 0.8889, 0.8901, 0.8912,\n",
       "             0.8924, 0.8936, 0.8947, 0.8959, 0.8971, 0.8982, 0.8994, 0.9006, 0.9018,\n",
       "             0.9029, 0.9041, 0.9053, 0.9064, 0.9076, 0.9088, 0.9099, 0.9111, 0.9123,\n",
       "             0.9135, 0.9146, 0.9158, 0.9170, 0.9170, 0.9181, 0.9193, 0.9205, 0.9216,\n",
       "             0.9228, 0.9240, 0.9251, 0.9263, 0.9263, 0.9275, 0.9287, 0.9298, 0.9298,\n",
       "             0.9310, 0.9322, 0.9333, 0.9345, 0.9357, 0.9368, 0.9380, 0.9392, 0.9392,\n",
       "             0.9404, 0.9415, 0.9427, 0.9439, 0.9450, 0.9462, 0.9474, 0.9485, 0.9497,\n",
       "             0.9509, 0.9520, 0.9532, 0.9532, 0.9544, 0.9556, 0.9567, 0.9567, 0.9579,\n",
       "             0.9579, 0.9591, 0.9602, 0.9602, 0.9602, 0.9614, 0.9626, 0.9637, 0.9637,\n",
       "             0.9649, 0.9661, 0.9661, 0.9673, 0.9673, 0.9684, 0.9696, 0.9708, 0.9719,\n",
       "             0.9719, 0.9731, 0.9731, 0.9731, 0.9743, 0.9754, 0.9766, 0.9766, 0.9766,\n",
       "             0.9778, 0.9789, 0.9801, 0.9801, 0.9801, 0.9801, 0.9813, 0.9813, 0.9825,\n",
       "             0.9836, 0.9836, 0.9836, 0.9836, 0.9836, 0.9848, 0.9848, 0.9848, 0.9860,\n",
       "             0.9871, 0.9883, 0.9895, 0.9895, 0.9895, 0.9906, 0.9906, 0.9906, 0.9906,\n",
       "             0.9906, 0.9906, 0.9906, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918,\n",
       "             0.9918, 0.9918, 0.9930, 0.9930, 0.9930, 0.9942, 0.9942, 0.9942, 0.9942,\n",
       "             0.9953, 0.9953, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965,\n",
       "             0.9965, 0.9965, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01,\n",
       "             9.9985e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01,\n",
       "             9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01,\n",
       "             9.9981e-01, 9.9981e-01, 9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9979e-01,\n",
       "             9.9978e-01, 9.9978e-01, 9.9977e-01, 9.9977e-01, 9.9977e-01, 9.9976e-01,\n",
       "             9.9976e-01, 9.9976e-01, 9.9976e-01, 9.9975e-01, 9.9975e-01, 9.9974e-01,\n",
       "             9.9974e-01, 9.9973e-01, 9.9973e-01, 9.9973e-01, 9.9973e-01, 9.9971e-01,\n",
       "             9.9971e-01, 9.9970e-01, 9.9968e-01, 9.9968e-01, 9.9967e-01, 9.9966e-01,\n",
       "             9.9965e-01, 9.9965e-01, 9.9963e-01, 9.9963e-01, 9.9962e-01, 9.9962e-01,\n",
       "             9.9961e-01, 9.9960e-01, 9.9959e-01, 9.9958e-01, 9.9958e-01, 9.9958e-01,\n",
       "             9.9958e-01, 9.9957e-01, 9.9957e-01, 9.9956e-01, 9.9956e-01, 9.9951e-01,\n",
       "             9.9951e-01, 9.9949e-01, 9.9947e-01, 9.9946e-01, 9.9946e-01, 9.9946e-01,\n",
       "             9.9945e-01, 9.9942e-01, 9.9938e-01, 9.9936e-01, 9.9935e-01, 9.9935e-01,\n",
       "             9.9933e-01, 9.9929e-01, 9.9927e-01, 9.9926e-01, 9.9926e-01, 9.9925e-01,\n",
       "             9.9922e-01, 9.9916e-01, 9.9913e-01, 9.9913e-01, 9.9912e-01, 9.9911e-01,\n",
       "             9.9904e-01, 9.9903e-01, 9.9896e-01, 9.9895e-01, 9.9892e-01, 9.9882e-01,\n",
       "             9.9870e-01, 9.9867e-01, 9.9865e-01, 9.9863e-01, 9.9854e-01, 9.9848e-01,\n",
       "             9.9827e-01, 9.9767e-01, 9.9765e-01, 9.9758e-01, 9.9755e-01, 9.9743e-01,\n",
       "             9.9715e-01, 9.9684e-01, 9.9682e-01, 9.9681e-01, 9.9657e-01, 9.9653e-01,\n",
       "             9.9629e-01, 9.9555e-01, 9.9515e-01, 9.9460e-01, 9.9404e-01, 9.9332e-01,\n",
       "             9.9319e-01, 9.9169e-01, 9.9053e-01, 9.9018e-01, 9.9011e-01, 9.8918e-01,\n",
       "             9.8915e-01, 9.8904e-01, 9.8828e-01, 9.8754e-01, 9.8562e-01, 9.8426e-01,\n",
       "             9.8323e-01, 9.8316e-01, 9.8268e-01, 9.8104e-01, 9.8061e-01, 9.7881e-01,\n",
       "             9.7871e-01, 9.7648e-01, 9.7478e-01, 9.7269e-01, 9.7117e-01, 9.6875e-01,\n",
       "             9.5974e-01, 9.5775e-01, 9.5650e-01, 9.5525e-01, 9.5046e-01, 9.4791e-01,\n",
       "             9.4681e-01, 9.4679e-01, 9.3961e-01, 9.3188e-01, 9.2754e-01, 9.2580e-01,\n",
       "             9.1374e-01, 8.9594e-01, 8.9390e-01, 8.7414e-01, 8.5576e-01, 8.4683e-01,\n",
       "             8.4038e-01, 7.6522e-01, 7.3357e-01, 6.8654e-01, 6.6460e-01, 6.5654e-01,\n",
       "             5.9787e-01, 5.9110e-01, 5.8694e-01, 5.7571e-01, 5.6230e-01, 5.6139e-01,\n",
       "             5.4059e-01, 5.3975e-01, 4.3494e-01, 4.2379e-01, 4.1642e-01, 3.9378e-01,\n",
       "             3.9240e-01, 3.8397e-01, 3.4263e-01, 3.1778e-01, 3.0925e-01, 2.9305e-01,\n",
       "             2.5360e-01, 2.3998e-01, 2.3511e-01, 2.3166e-01, 2.2873e-01, 2.1781e-01,\n",
       "             1.6513e-01, 1.5591e-01, 1.3420e-01, 1.1281e-01, 1.0749e-01, 1.0260e-01,\n",
       "             1.0089e-01, 8.9059e-02, 8.4140e-02, 7.2579e-02, 5.6859e-02, 5.5044e-02,\n",
       "             5.1218e-02, 5.0626e-02, 4.7996e-02, 3.9026e-02, 3.1123e-02, 2.6023e-02,\n",
       "             2.5023e-02, 2.3283e-02, 2.2218e-02, 1.8872e-02, 1.6317e-02, 1.5813e-02,\n",
       "             1.5764e-02, 1.5745e-02, 1.4086e-02, 1.2520e-02, 1.1574e-02, 9.7933e-03,\n",
       "             9.4929e-03, 9.0557e-03, 6.6811e-03, 4.8944e-03, 4.8650e-03, 4.4537e-03,\n",
       "             3.8652e-03, 3.2489e-03, 2.8807e-03, 2.7353e-03, 2.5237e-03, 1.9850e-03,\n",
       "             1.9719e-03, 1.7987e-03, 1.6047e-03, 1.5936e-03, 1.5782e-03, 1.5606e-03,\n",
       "             1.3601e-03, 1.1404e-03, 9.9522e-04, 9.7936e-04, 9.3635e-04, 8.9686e-04,\n",
       "             6.9698e-04, 6.1655e-04, 4.4839e-04, 3.6302e-04, 3.0874e-04, 2.6727e-04,\n",
       "             2.0457e-04, 1.7484e-04, 1.5338e-04, 1.5258e-04, 1.4446e-04, 1.2564e-04,\n",
       "             9.0419e-05, 9.0044e-05, 8.8842e-05, 7.2270e-05, 6.9659e-05, 6.9315e-05,\n",
       "             6.7682e-05, 6.3464e-05, 6.3336e-05, 6.1306e-05, 5.9376e-05, 5.4764e-05,\n",
       "             4.9775e-05, 4.6604e-05, 3.9276e-05, 3.5562e-05, 3.4214e-05, 2.6691e-05,\n",
       "             2.4375e-05, 2.3943e-05, 2.3221e-05, 2.1677e-05, 2.1603e-05, 1.9819e-05,\n",
       "             1.8631e-05, 1.8408e-05, 1.5440e-05, 1.5098e-05, 1.4534e-05, 1.3794e-05,\n",
       "             1.2688e-05, 1.1600e-05, 1.0440e-05, 1.0011e-05, 9.8639e-06, 9.7714e-06,\n",
       "             8.1048e-06, 8.0513e-06, 7.5136e-06, 6.2176e-06, 6.0435e-06, 5.7502e-06,\n",
       "             5.6422e-06, 5.1519e-06, 5.0908e-06, 4.8295e-06, 4.2379e-06, 4.1290e-06,\n",
       "             3.5986e-06, 3.3542e-06, 3.3532e-06, 3.3526e-06, 3.2850e-06, 3.2155e-06,\n",
       "             2.9997e-06, 2.8038e-06, 2.7274e-06, 2.7265e-06, 2.6802e-06, 1.9901e-06,\n",
       "             1.8825e-06, 1.8282e-06, 1.8281e-06, 1.7869e-06, 1.7860e-06, 1.7742e-06,\n",
       "             1.7047e-06, 1.4645e-06, 1.3873e-06, 1.3810e-06, 1.3792e-06, 1.2444e-06,\n",
       "             1.2128e-06, 1.1780e-06, 1.1508e-06, 1.0353e-06, 7.7131e-07, 7.0021e-07,\n",
       "             6.3695e-07, 6.3510e-07, 6.0253e-07, 5.4878e-07, 5.4510e-07, 5.3300e-07,\n",
       "             5.3037e-07, 5.1898e-07, 4.8088e-07, 4.7701e-07, 4.6926e-07, 4.6654e-07,\n",
       "             4.5392e-07, 4.0313e-07, 3.8961e-07, 3.6986e-07, 3.6085e-07, 3.4583e-07,\n",
       "             3.3207e-07, 3.2348e-07, 2.7127e-07, 2.5781e-07, 2.4541e-07, 2.1174e-07,\n",
       "             1.9530e-07, 1.9090e-07, 1.8872e-07, 1.8820e-07, 1.5225e-07, 1.5052e-07,\n",
       "             1.4198e-07, 1.3928e-07, 1.3119e-07, 1.2141e-07, 1.1703e-07, 1.0713e-07,\n",
       "             1.0282e-07, 8.1098e-08, 7.8796e-08, 7.8205e-08, 7.5841e-08, 7.2074e-08,\n",
       "             7.0426e-08, 6.0368e-08, 5.8911e-08, 5.7925e-08, 5.6503e-08, 4.4927e-08,\n",
       "             4.1097e-08, 4.1084e-08, 4.0797e-08, 4.0070e-08, 3.8378e-08, 3.7102e-08,\n",
       "             3.1372e-08, 2.9787e-08, 2.9735e-08, 2.7959e-08, 2.7734e-08, 2.7386e-08,\n",
       "             2.7059e-08, 2.3895e-08, 2.2708e-08, 2.2144e-08, 1.9909e-08, 1.9069e-08,\n",
       "             1.8852e-08, 1.7549e-08, 1.7304e-08, 1.7018e-08, 1.6068e-08, 1.6063e-08,\n",
       "             1.5723e-08, 1.3419e-08, 1.1642e-08, 1.1133e-08, 1.0979e-08, 1.0454e-08,\n",
       "             1.0355e-08, 1.0176e-08, 1.0088e-08, 9.9727e-09, 9.9063e-09, 9.7593e-09,\n",
       "             9.4924e-09, 8.9815e-09, 8.9112e-09, 8.3503e-09, 7.8922e-09, 6.6900e-09,\n",
       "             6.3569e-09, 5.2363e-09, 4.3507e-09, 4.3313e-09, 4.1666e-09, 3.8315e-09,\n",
       "             3.2605e-09, 3.0608e-09, 2.6899e-09, 2.2469e-09, 2.0303e-09, 1.8684e-09,\n",
       "             1.8158e-09, 1.7971e-09, 1.6817e-09, 1.6068e-09, 1.3495e-09, 1.3391e-09,\n",
       "             1.3177e-09, 1.2932e-09, 1.2738e-09, 1.2274e-09, 6.0086e-10, 4.8605e-10,\n",
       "             4.2667e-10, 4.0971e-10, 3.9959e-10, 3.7145e-10, 3.5057e-10, 3.1851e-10,\n",
       "             3.1669e-10, 3.1209e-10, 2.9082e-10, 2.8049e-10, 1.7508e-10, 1.5819e-10,\n",
       "             1.5520e-10, 1.4708e-10, 1.3032e-10, 1.0714e-10, 9.1004e-11, 8.4280e-11,\n",
       "             6.5978e-11, 5.9665e-11, 5.4206e-11, 5.2972e-11, 5.2329e-11, 4.7457e-11,\n",
       "             4.5788e-11, 4.5277e-11, 3.9103e-11, 3.5957e-11, 2.9274e-11, 2.5356e-11,\n",
       "             1.9775e-11, 1.7755e-11, 1.3895e-11, 1.1464e-11, 1.1277e-11, 1.0338e-11,\n",
       "             4.4409e-12, 3.5993e-12, 1.6673e-12, 1.1832e-12, 2.8369e-13, 2.4564e-13,\n",
       "             5.5330e-14, 3.9045e-15])}},\n",
       "   {'fpr': np.float64(0.09316770186335403),\n",
       "    'tpr': np.float64(0.9847953216374269),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0031, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062, 0.0062,\n",
       "             0.0062, 0.0062, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0124,\n",
       "             0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124,\n",
       "             0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124,\n",
       "             0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0155, 0.0155, 0.0155, 0.0186,\n",
       "             0.0186, 0.0186, 0.0186, 0.0217, 0.0217, 0.0217, 0.0217, 0.0217, 0.0217,\n",
       "             0.0217, 0.0217, 0.0217, 0.0217, 0.0217, 0.0217, 0.0248, 0.0280, 0.0280,\n",
       "             0.0280, 0.0311, 0.0311, 0.0311, 0.0311, 0.0342, 0.0342, 0.0342, 0.0342,\n",
       "             0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
       "             0.0342, 0.0342, 0.0342, 0.0342, 0.0373, 0.0373, 0.0373, 0.0373, 0.0373,\n",
       "             0.0435, 0.0435, 0.0435, 0.0435, 0.0466, 0.0497, 0.0528, 0.0559, 0.0590,\n",
       "             0.0621, 0.0621, 0.0621, 0.0621, 0.0652, 0.0683, 0.0714, 0.0714, 0.0745,\n",
       "             0.0745, 0.0745, 0.0745, 0.0776, 0.0776, 0.0776, 0.0776, 0.0807, 0.0807,\n",
       "             0.0839, 0.0870, 0.0870, 0.0901, 0.0932, 0.0963, 0.0963, 0.0994, 0.1025,\n",
       "             0.1056, 0.1087, 0.1118, 0.1149, 0.1180, 0.1211, 0.1211, 0.1242, 0.1273,\n",
       "             0.1273, 0.1273, 0.1273, 0.1304, 0.1304, 0.1335, 0.1366, 0.1366, 0.1398,\n",
       "             0.1398, 0.1398, 0.1429, 0.1460, 0.1491, 0.1491, 0.1522, 0.1553, 0.1584,\n",
       "             0.1615, 0.1646, 0.1677, 0.1708, 0.1739, 0.1770, 0.1801, 0.1801, 0.1832,\n",
       "             0.1863, 0.1894, 0.1925, 0.1925, 0.1957, 0.1988, 0.2019, 0.2050, 0.2081,\n",
       "             0.2112, 0.2143, 0.2174, 0.2205, 0.2236, 0.2267, 0.2298, 0.2329, 0.2360,\n",
       "             0.2391, 0.2422, 0.2453, 0.2484, 0.2516, 0.2547, 0.2578, 0.2609, 0.2640,\n",
       "             0.2671, 0.2702, 0.2733, 0.2764, 0.2795, 0.2826, 0.2857, 0.2888, 0.2919,\n",
       "             0.2950, 0.2981, 0.3012, 0.3043, 0.3075, 0.3106, 0.3137, 0.3168, 0.3199,\n",
       "             0.3230, 0.3261, 0.3292, 0.3323, 0.3354, 0.3385, 0.3416, 0.3447, 0.3478,\n",
       "             0.3509, 0.3540, 0.3571, 0.3602, 0.3634, 0.3665, 0.3696, 0.3727, 0.3758,\n",
       "             0.3789, 0.3820, 0.3851, 0.3882, 0.3913, 0.3944, 0.3975, 0.4006, 0.4037,\n",
       "             0.4068, 0.4099, 0.4130, 0.4161, 0.4193, 0.4224, 0.4255, 0.4286, 0.4317,\n",
       "             0.4348, 0.4379, 0.4410, 0.4441, 0.4472, 0.4503, 0.4534, 0.4565, 0.4596,\n",
       "             0.4627, 0.4658, 0.4689, 0.4720, 0.4752, 0.4783, 0.4814, 0.4845, 0.4876,\n",
       "             0.4907, 0.4938, 0.4969, 0.5000, 0.5031, 0.5062, 0.5093, 0.5124, 0.5155,\n",
       "             0.5186, 0.5217, 0.5248, 0.5280, 0.5311, 0.5342, 0.5373, 0.5404, 0.5435,\n",
       "             0.5466, 0.5497, 0.5528, 0.5559, 0.5590, 0.5621, 0.5652, 0.5683, 0.5714,\n",
       "             0.5745, 0.5776, 0.5807, 0.5839, 0.5870, 0.5901, 0.5932, 0.5963, 0.5994,\n",
       "             0.6025, 0.6056, 0.6087, 0.6118, 0.6149, 0.6180, 0.6211, 0.6242, 0.6273,\n",
       "             0.6273, 0.6304, 0.6335, 0.6366, 0.6398, 0.6429, 0.6460, 0.6491, 0.6522,\n",
       "             0.6553, 0.6584, 0.6615, 0.6646, 0.6677, 0.6708, 0.6739, 0.6770, 0.6801,\n",
       "             0.6832, 0.6863, 0.6894, 0.6925, 0.6957, 0.6988, 0.7019, 0.7050, 0.7081,\n",
       "             0.7112, 0.7143, 0.7174, 0.7205, 0.7236, 0.7267, 0.7298, 0.7329, 0.7360,\n",
       "             0.7391, 0.7422, 0.7453, 0.7484, 0.7516, 0.7547, 0.7578, 0.7609, 0.7640,\n",
       "             0.7671, 0.7702, 0.7733, 0.7764, 0.7795, 0.7826, 0.7857, 0.7888, 0.7919,\n",
       "             0.7950, 0.7981, 0.8012, 0.8043, 0.8075, 0.8106, 0.8137, 0.8168, 0.8199,\n",
       "             0.8230, 0.8261, 0.8292, 0.8323, 0.8354, 0.8385, 0.8416, 0.8447, 0.8478,\n",
       "             0.8509, 0.8540, 0.8571, 0.8602, 0.8634, 0.8665, 0.8696, 0.8727, 0.8758,\n",
       "             0.8789, 0.8820, 0.8851, 0.8882, 0.8913, 0.8944, 0.8975, 0.9006, 0.9037,\n",
       "             0.9068, 0.9099, 0.9130, 0.9161, 0.9193, 0.9224, 0.9255, 0.9286, 0.9317,\n",
       "             0.9348, 0.9379, 0.9410, 0.9441, 0.9472, 0.9503, 0.9534, 0.9565, 0.9596,\n",
       "             0.9627, 0.9658, 0.9689, 0.9720, 0.9752, 0.9783, 0.9814, 0.9845, 0.9876,\n",
       "             0.9907, 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.7801, 0.8164, 0.8234, 0.8327, 0.8386, 0.8421, 0.8444, 0.8480,\n",
       "             0.8503, 0.8515, 0.8538, 0.8561, 0.8596, 0.8608, 0.8620, 0.8632, 0.8655,\n",
       "             0.8667, 0.8678, 0.8690, 0.8702, 0.8713, 0.8749, 0.8760, 0.8772, 0.8784,\n",
       "             0.8819, 0.8830, 0.8854, 0.8865, 0.8877, 0.8889, 0.8901, 0.8912, 0.8912,\n",
       "             0.8936, 0.8947, 0.8959, 0.8971, 0.8982, 0.8994, 0.9006, 0.9018, 0.9029,\n",
       "             0.9041, 0.9053, 0.9064, 0.9076, 0.9088, 0.9099, 0.9111, 0.9123, 0.9135,\n",
       "             0.9146, 0.9158, 0.9170, 0.9181, 0.9193, 0.9193, 0.9205, 0.9216, 0.9216,\n",
       "             0.9228, 0.9240, 0.9251, 0.9251, 0.9263, 0.9275, 0.9287, 0.9298, 0.9310,\n",
       "             0.9322, 0.9333, 0.9345, 0.9357, 0.9368, 0.9380, 0.9380, 0.9380, 0.9392,\n",
       "             0.9404, 0.9404, 0.9415, 0.9427, 0.9439, 0.9439, 0.9450, 0.9462, 0.9474,\n",
       "             0.9485, 0.9497, 0.9509, 0.9520, 0.9532, 0.9544, 0.9556, 0.9567, 0.9579,\n",
       "             0.9591, 0.9602, 0.9614, 0.9626, 0.9626, 0.9637, 0.9649, 0.9661, 0.9673,\n",
       "             0.9673, 0.9684, 0.9696, 0.9708, 0.9708, 0.9708, 0.9708, 0.9708, 0.9708,\n",
       "             0.9708, 0.9719, 0.9731, 0.9743, 0.9743, 0.9743, 0.9743, 0.9754, 0.9754,\n",
       "             0.9766, 0.9778, 0.9789, 0.9789, 0.9801, 0.9813, 0.9825, 0.9825, 0.9836,\n",
       "             0.9836, 0.9836, 0.9848, 0.9848, 0.9848, 0.9848, 0.9860, 0.9860, 0.9860,\n",
       "             0.9860, 0.9860, 0.9860, 0.9860, 0.9860, 0.9860, 0.9871, 0.9871, 0.9871,\n",
       "             0.9883, 0.9895, 0.9906, 0.9906, 0.9918, 0.9918, 0.9918, 0.9930, 0.9930,\n",
       "             0.9942, 0.9953, 0.9953, 0.9953, 0.9953, 0.9965, 0.9965, 0.9965, 0.9965,\n",
       "             0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9992e-01, 9.9991e-01, 9.9991e-01, 9.9990e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9986e-01, 9.9986e-01, 9.9982e-01, 9.9982e-01,\n",
       "             9.9974e-01, 9.9970e-01, 9.9964e-01, 9.9963e-01, 9.9963e-01, 9.9961e-01,\n",
       "             9.9960e-01, 9.9947e-01, 9.9928e-01, 9.9920e-01, 9.9904e-01, 9.9895e-01,\n",
       "             9.9870e-01, 9.9848e-01, 9.9847e-01, 9.9842e-01, 9.9822e-01, 9.9792e-01,\n",
       "             9.9759e-01, 9.9756e-01, 9.9603e-01, 9.9532e-01, 9.9514e-01, 9.9508e-01,\n",
       "             9.9412e-01, 9.9362e-01, 9.9247e-01, 9.9172e-01, 9.9144e-01, 9.8978e-01,\n",
       "             9.8945e-01, 9.8631e-01, 9.8621e-01, 9.8562e-01, 9.8456e-01, 9.8126e-01,\n",
       "             9.7415e-01, 9.6739e-01, 9.6465e-01, 9.5946e-01, 9.5643e-01, 9.2045e-01,\n",
       "             9.1133e-01, 9.0409e-01, 8.9416e-01, 8.8065e-01, 8.7301e-01, 8.6537e-01,\n",
       "             8.6297e-01, 8.2097e-01, 7.6777e-01, 7.2511e-01, 6.4897e-01, 6.3145e-01,\n",
       "             6.2145e-01, 5.4173e-01, 4.9489e-01, 4.3679e-01, 4.0620e-01, 4.0258e-01,\n",
       "             3.1320e-01, 2.8717e-01, 2.2740e-01, 2.0463e-01, 1.7436e-01, 1.3094e-01,\n",
       "             1.2889e-01, 1.0356e-01, 1.0049e-01, 9.9163e-02, 7.8544e-02, 6.9117e-02,\n",
       "             6.6926e-02, 5.4271e-02, 5.0900e-02, 3.6344e-02, 3.4948e-02, 3.4099e-02,\n",
       "             3.1693e-02, 2.8171e-02, 2.6546e-02, 1.8426e-02, 1.7046e-02, 1.4114e-02,\n",
       "             1.3685e-02, 1.3678e-02, 1.2382e-02, 1.0706e-02, 9.4864e-03, 6.8747e-03,\n",
       "             3.0937e-03, 3.0170e-03, 2.5345e-03, 2.1557e-03, 2.1343e-03, 1.7282e-03,\n",
       "             1.5548e-03, 1.1460e-03, 1.0073e-03, 7.3169e-04, 6.4867e-04, 6.4480e-04,\n",
       "             6.0775e-04, 5.6530e-04, 5.2462e-04, 4.7387e-04, 4.3459e-04, 3.8681e-04,\n",
       "             2.8552e-04, 2.6634e-04, 2.5764e-04, 2.4083e-04, 1.9493e-04, 1.8878e-04,\n",
       "             1.8563e-04, 1.7560e-04, 1.7157e-04, 1.7053e-04, 1.3929e-04, 1.2784e-04,\n",
       "             1.1387e-04, 1.0162e-04, 9.4559e-05, 8.8382e-05, 8.7043e-05, 8.2056e-05,\n",
       "             7.4692e-05, 6.8827e-05, 6.1004e-05, 5.5532e-05, 5.5213e-05, 5.1485e-05,\n",
       "             4.8254e-05, 4.5171e-05, 3.9352e-05, 3.1170e-05, 3.1105e-05, 3.1024e-05,\n",
       "             2.6681e-05, 2.6371e-05, 2.3571e-05, 2.2055e-05, 1.4407e-05, 1.2640e-05,\n",
       "             1.1394e-05, 1.0412e-05, 9.9274e-06, 9.7592e-06, 8.9308e-06, 8.3266e-06,\n",
       "             7.9939e-06, 4.8042e-06, 4.0091e-06, 3.9986e-06, 3.9647e-06, 3.7029e-06,\n",
       "             3.2056e-06, 3.1047e-06, 2.8351e-06, 2.6484e-06, 2.1960e-06, 1.7630e-06,\n",
       "             1.5739e-06, 1.4356e-06, 1.4337e-06, 1.2508e-06, 1.2148e-06, 1.1706e-06,\n",
       "             1.1010e-06, 1.0543e-06, 9.5953e-07, 8.6402e-07, 7.3858e-07, 6.7851e-07,\n",
       "             6.1787e-07, 5.8617e-07, 5.6447e-07, 5.5444e-07, 5.5306e-07, 5.2112e-07,\n",
       "             4.9334e-07, 4.9070e-07, 4.8979e-07, 4.7245e-07, 4.4378e-07, 4.0346e-07,\n",
       "             3.9111e-07, 3.7299e-07, 3.4088e-07, 2.8016e-07, 2.7871e-07, 2.7194e-07,\n",
       "             2.6028e-07, 2.3129e-07, 2.2342e-07, 2.1575e-07, 2.0713e-07, 2.0095e-07,\n",
       "             1.7458e-07, 1.7245e-07, 1.7206e-07, 1.7072e-07, 1.7048e-07, 1.7035e-07,\n",
       "             1.5501e-07, 1.5388e-07, 1.4742e-07, 1.2580e-07, 1.2079e-07, 1.1474e-07,\n",
       "             1.1345e-07, 1.0921e-07, 9.7691e-08, 7.5275e-08, 7.5198e-08, 7.4485e-08,\n",
       "             7.0056e-08, 5.7016e-08, 5.5413e-08, 5.5353e-08, 5.1624e-08, 4.7474e-08,\n",
       "             4.7070e-08, 4.5684e-08, 4.5095e-08, 3.5425e-08, 3.5254e-08, 3.1353e-08,\n",
       "             3.1216e-08, 2.9876e-08, 2.8170e-08, 2.7054e-08, 2.6495e-08, 2.3217e-08,\n",
       "             2.2681e-08, 2.2675e-08, 1.9891e-08, 1.9801e-08, 1.5587e-08, 1.5536e-08,\n",
       "             1.2731e-08, 1.2553e-08, 1.0306e-08, 9.2562e-09, 8.6314e-09, 8.1738e-09,\n",
       "             7.4849e-09, 5.5705e-09, 4.6980e-09, 4.5901e-09, 4.5527e-09, 4.3414e-09,\n",
       "             3.6377e-09, 3.2895e-09, 3.2663e-09, 3.1705e-09, 3.1370e-09, 2.9094e-09,\n",
       "             2.6626e-09, 2.2804e-09, 2.1271e-09, 1.9659e-09, 1.9643e-09, 1.8952e-09,\n",
       "             1.7425e-09, 1.4847e-09, 1.4128e-09, 1.2881e-09, 1.2320e-09, 1.2119e-09,\n",
       "             1.1740e-09, 1.1303e-09, 7.8291e-10, 7.0888e-10, 6.7403e-10, 6.3173e-10,\n",
       "             4.6952e-10, 4.1640e-10, 3.4420e-10, 3.4085e-10, 3.3725e-10, 3.2089e-10,\n",
       "             3.1329e-10, 2.7871e-10, 2.7663e-10, 2.5127e-10, 2.5075e-10, 2.1168e-10,\n",
       "             1.4683e-10, 1.1747e-10, 1.1572e-10, 1.1099e-10, 1.0788e-10, 1.0187e-10,\n",
       "             7.3614e-11, 7.3367e-11, 6.7211e-11, 6.5142e-11, 5.7478e-11, 5.4840e-11,\n",
       "             3.9901e-11, 3.9378e-11, 3.5684e-11, 2.9241e-11, 2.7604e-11, 2.3350e-11,\n",
       "             2.0187e-11, 1.6790e-11, 1.5379e-11, 1.5348e-11, 1.3175e-11, 1.2195e-11,\n",
       "             1.2022e-11, 1.1100e-11, 1.0794e-11, 8.0653e-12, 7.7166e-12, 7.7034e-12,\n",
       "             7.4244e-12, 6.2023e-12, 4.7455e-12, 4.5878e-12, 3.8299e-12, 3.5114e-12,\n",
       "             3.4860e-12, 3.0375e-12, 2.8006e-12, 2.6465e-12, 2.1459e-12, 8.3182e-13,\n",
       "             7.3573e-13, 6.0612e-13, 5.7404e-13, 4.7201e-13, 2.5967e-13, 2.2770e-13,\n",
       "             2.2404e-13, 1.9268e-13, 1.8713e-13, 1.8669e-13, 1.5467e-13, 1.1924e-13,\n",
       "             6.6008e-14, 4.2140e-14, 4.1196e-14, 3.6550e-14, 3.2684e-14, 1.9403e-14,\n",
       "             1.0320e-14, 7.6686e-15, 7.5353e-15, 6.8435e-15, 6.1599e-15, 5.3941e-15,\n",
       "             5.2841e-15, 3.9905e-15, 1.1319e-15, 1.3452e-16, 3.5270e-18, 2.8903e-18,\n",
       "             6.4887e-20])}},\n",
       "   {'fpr': np.float64(0.08385093167701864),\n",
       "    'tpr': np.float64(0.9812865497076023),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031,\n",
       "             0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0031, 0.0062,\n",
       "             0.0062, 0.0062, 0.0062, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093,\n",
       "             0.0093, 0.0093, 0.0093, 0.0093, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124,\n",
       "             0.0124, 0.0124, 0.0124, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155, 0.0155,\n",
       "             0.0155, 0.0155, 0.0186, 0.0186, 0.0186, 0.0186, 0.0186, 0.0217, 0.0248,\n",
       "             0.0248, 0.0248, 0.0280, 0.0280, 0.0280, 0.0311, 0.0311, 0.0311, 0.0311,\n",
       "             0.0311, 0.0311, 0.0311, 0.0311, 0.0342, 0.0342, 0.0342, 0.0342, 0.0373,\n",
       "             0.0404, 0.0435, 0.0435, 0.0466, 0.0466, 0.0466, 0.0466, 0.0466, 0.0466,\n",
       "             0.0466, 0.0466, 0.0466, 0.0466, 0.0497, 0.0528, 0.0559, 0.0590, 0.0590,\n",
       "             0.0621, 0.0621, 0.0621, 0.0621, 0.0621, 0.0621, 0.0652, 0.0683, 0.0714,\n",
       "             0.0745, 0.0745, 0.0745, 0.0745, 0.0745, 0.0776, 0.0776, 0.0776, 0.0807,\n",
       "             0.0839, 0.0839, 0.0870, 0.0901, 0.0901, 0.0901, 0.0932, 0.0932, 0.0994,\n",
       "             0.0994, 0.1025, 0.1025, 0.1056, 0.1087, 0.1118, 0.1149, 0.1180, 0.1180,\n",
       "             0.1211, 0.1242, 0.1273, 0.1304, 0.1335, 0.1366, 0.1366, 0.1398, 0.1429,\n",
       "             0.1460, 0.1491, 0.1522, 0.1553, 0.1584, 0.1615, 0.1615, 0.1646, 0.1677,\n",
       "             0.1708, 0.1708, 0.1739, 0.1739, 0.1770, 0.1801, 0.1832, 0.1832, 0.1863,\n",
       "             0.1894, 0.1925, 0.1925, 0.1957, 0.1988, 0.2019, 0.2050, 0.2081, 0.2112,\n",
       "             0.2143, 0.2143, 0.2174, 0.2205, 0.2205, 0.2236, 0.2267, 0.2298, 0.2329,\n",
       "             0.2360, 0.2391, 0.2422, 0.2453, 0.2484, 0.2516, 0.2547, 0.2578, 0.2609,\n",
       "             0.2640, 0.2671, 0.2702, 0.2733, 0.2764, 0.2795, 0.2826, 0.2857, 0.2888,\n",
       "             0.2919, 0.2950, 0.2981, 0.3012, 0.3043, 0.3075, 0.3106, 0.3137, 0.3168,\n",
       "             0.3199, 0.3230, 0.3261, 0.3292, 0.3323, 0.3354, 0.3385, 0.3416, 0.3447,\n",
       "             0.3478, 0.3509, 0.3540, 0.3571, 0.3602, 0.3634, 0.3665, 0.3696, 0.3727,\n",
       "             0.3758, 0.3789, 0.3820, 0.3851, 0.3882, 0.3913, 0.3944, 0.3975, 0.4006,\n",
       "             0.4037, 0.4068, 0.4099, 0.4130, 0.4161, 0.4193, 0.4224, 0.4255, 0.4286,\n",
       "             0.4317, 0.4348, 0.4379, 0.4410, 0.4441, 0.4472, 0.4503, 0.4534, 0.4565,\n",
       "             0.4596, 0.4627, 0.4658, 0.4689, 0.4720, 0.4752, 0.4783, 0.4814, 0.4845,\n",
       "             0.4876, 0.4907, 0.4938, 0.4969, 0.5000, 0.5031, 0.5062, 0.5093, 0.5124,\n",
       "             0.5155, 0.5186, 0.5217, 0.5248, 0.5280, 0.5311, 0.5342, 0.5373, 0.5404,\n",
       "             0.5435, 0.5466, 0.5497, 0.5528, 0.5559, 0.5590, 0.5621, 0.5652, 0.5683,\n",
       "             0.5714, 0.5745, 0.5776, 0.5807, 0.5839, 0.5870, 0.5901, 0.5932, 0.5963,\n",
       "             0.5994, 0.6025, 0.6056, 0.6087, 0.6118, 0.6149, 0.6180, 0.6180, 0.6211,\n",
       "             0.6242, 0.6273, 0.6304, 0.6335, 0.6366, 0.6398, 0.6429, 0.6460, 0.6491,\n",
       "             0.6522, 0.6553, 0.6584, 0.6615, 0.6646, 0.6677, 0.6708, 0.6739, 0.6770,\n",
       "             0.6801, 0.6832, 0.6863, 0.6894, 0.6925, 0.6957, 0.6988, 0.7019, 0.7050,\n",
       "             0.7081, 0.7112, 0.7143, 0.7174, 0.7205, 0.7236, 0.7267, 0.7298, 0.7329,\n",
       "             0.7360, 0.7391, 0.7422, 0.7453, 0.7484, 0.7516, 0.7547, 0.7578, 0.7609,\n",
       "             0.7640, 0.7671, 0.7702, 0.7733, 0.7764, 0.7795, 0.7826, 0.7857, 0.7888,\n",
       "             0.7919, 0.7950, 0.7981, 0.8012, 0.8043, 0.8075, 0.8106, 0.8137, 0.8168,\n",
       "             0.8199, 0.8230, 0.8261, 0.8292, 0.8323, 0.8354, 0.8385, 0.8416, 0.8447,\n",
       "             0.8478, 0.8509, 0.8540, 0.8571, 0.8602, 0.8634, 0.8665, 0.8696, 0.8727,\n",
       "             0.8758, 0.8789, 0.8820, 0.8851, 0.8882, 0.8913, 0.8944, 0.8975, 0.9006,\n",
       "             0.9037, 0.9068, 0.9099, 0.9130, 0.9161, 0.9193, 0.9224, 0.9255, 0.9286,\n",
       "             0.9317, 0.9348, 0.9379, 0.9410, 0.9441, 0.9472, 0.9503, 0.9534, 0.9565,\n",
       "             0.9596, 0.9627, 0.9658, 0.9689, 0.9720, 0.9752, 0.9783, 0.9814, 0.9845,\n",
       "             0.9876, 0.9907, 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.8058, 0.8468, 0.8550, 0.8620, 0.8667, 0.8713, 0.8737, 0.8749,\n",
       "             0.8760, 0.8784, 0.8807, 0.8830, 0.8842, 0.8865, 0.8877, 0.8889, 0.8912,\n",
       "             0.8924, 0.8936, 0.8971, 0.8982, 0.8994, 0.9006, 0.9018, 0.9029, 0.9029,\n",
       "             0.9041, 0.9053, 0.9064, 0.9064, 0.9076, 0.9088, 0.9099, 0.9111, 0.9135,\n",
       "             0.9146, 0.9158, 0.9170, 0.9181, 0.9181, 0.9193, 0.9205, 0.9216, 0.9228,\n",
       "             0.9240, 0.9251, 0.9263, 0.9263, 0.9275, 0.9287, 0.9298, 0.9310, 0.9322,\n",
       "             0.9333, 0.9345, 0.9345, 0.9357, 0.9368, 0.9380, 0.9392, 0.9392, 0.9392,\n",
       "             0.9404, 0.9415, 0.9415, 0.9427, 0.9439, 0.9439, 0.9450, 0.9462, 0.9474,\n",
       "             0.9485, 0.9497, 0.9509, 0.9520, 0.9520, 0.9532, 0.9544, 0.9556, 0.9556,\n",
       "             0.9556, 0.9556, 0.9567, 0.9567, 0.9579, 0.9591, 0.9602, 0.9614, 0.9626,\n",
       "             0.9637, 0.9649, 0.9661, 0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9684,\n",
       "             0.9684, 0.9696, 0.9708, 0.9719, 0.9731, 0.9743, 0.9743, 0.9743, 0.9743,\n",
       "             0.9743, 0.9754, 0.9766, 0.9778, 0.9789, 0.9789, 0.9801, 0.9813, 0.9813,\n",
       "             0.9813, 0.9825, 0.9825, 0.9825, 0.9836, 0.9848, 0.9848, 0.9860, 0.9860,\n",
       "             0.9871, 0.9871, 0.9883, 0.9883, 0.9883, 0.9883, 0.9883, 0.9883, 0.9895,\n",
       "             0.9895, 0.9895, 0.9895, 0.9895, 0.9895, 0.9895, 0.9906, 0.9906, 0.9906,\n",
       "             0.9906, 0.9906, 0.9906, 0.9906, 0.9906, 0.9906, 0.9918, 0.9918, 0.9918,\n",
       "             0.9918, 0.9930, 0.9930, 0.9942, 0.9942, 0.9942, 0.9942, 0.9953, 0.9953,\n",
       "             0.9953, 0.9953, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965,\n",
       "             0.9965, 0.9977, 0.9977, 0.9977, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9992e-01,\n",
       "             9.9988e-01, 9.9987e-01, 9.9986e-01, 9.9986e-01, 9.9985e-01, 9.9983e-01,\n",
       "             9.9978e-01, 9.9976e-01, 9.9972e-01, 9.9967e-01, 9.9965e-01, 9.9965e-01,\n",
       "             9.9932e-01, 9.9932e-01, 9.9919e-01, 9.9886e-01, 9.9878e-01, 9.9843e-01,\n",
       "             9.9762e-01, 9.9755e-01, 9.9736e-01, 9.9673e-01, 9.9514e-01, 9.9331e-01,\n",
       "             9.9168e-01, 9.9105e-01, 9.9095e-01, 9.9086e-01, 9.8620e-01, 9.8572e-01,\n",
       "             9.8391e-01, 9.8165e-01, 9.7696e-01, 9.7015e-01, 9.6908e-01, 9.6093e-01,\n",
       "             9.5334e-01, 9.5210e-01, 9.4990e-01, 9.4944e-01, 9.4743e-01, 9.3309e-01,\n",
       "             9.2961e-01, 9.2706e-01, 8.9564e-01, 8.8655e-01, 8.6148e-01, 8.5254e-01,\n",
       "             8.3796e-01, 8.3783e-01, 8.3530e-01, 8.0618e-01, 8.0123e-01, 7.8192e-01,\n",
       "             7.5934e-01, 7.0955e-01, 6.6221e-01, 6.1397e-01, 4.8420e-01, 4.2637e-01,\n",
       "             4.0318e-01, 3.1889e-01, 3.1660e-01, 2.8038e-01, 2.3820e-01, 1.9981e-01,\n",
       "             1.0221e-01, 8.1979e-02, 7.3678e-02, 6.4238e-02, 6.1261e-02, 5.8058e-02,\n",
       "             5.1044e-02, 4.7807e-02, 4.7450e-02, 4.1562e-02, 3.4676e-02, 3.0256e-02,\n",
       "             2.7546e-02, 2.6934e-02, 1.9995e-02, 1.9316e-02, 1.8481e-02, 1.3998e-02,\n",
       "             1.2985e-02, 1.2250e-02, 8.7663e-03, 7.7890e-03, 6.7868e-03, 5.3589e-03,\n",
       "             5.2696e-03, 4.4807e-03, 3.6576e-03, 3.5111e-03, 3.2479e-03, 2.9070e-03,\n",
       "             2.8364e-03, 1.4679e-03, 1.3025e-03, 1.2024e-03, 1.1658e-03, 8.3814e-04,\n",
       "             6.4906e-04, 5.3067e-04, 5.1563e-04, 4.2084e-04, 3.6098e-04, 3.5401e-04,\n",
       "             2.8493e-04, 2.7606e-04, 2.7205e-04, 2.5706e-04, 2.3720e-04, 1.7091e-04,\n",
       "             1.4135e-04, 1.3478e-04, 1.1851e-04, 1.1528e-04, 9.7758e-05, 9.4147e-05,\n",
       "             6.4507e-05, 5.3369e-05, 4.9678e-05, 4.4655e-05, 2.3512e-05, 1.8150e-05,\n",
       "             1.7660e-05, 1.6659e-05, 1.5505e-05, 1.2201e-05, 7.2255e-06, 6.9747e-06,\n",
       "             5.6848e-06, 5.6587e-06, 5.5841e-06, 3.6261e-06, 3.2292e-06, 2.4548e-06,\n",
       "             2.4416e-06, 2.1593e-06, 1.9839e-06, 1.8672e-06, 1.6805e-06, 1.3490e-06,\n",
       "             1.3197e-06, 1.2487e-06, 1.1499e-06, 1.1499e-06, 1.0262e-06, 1.0174e-06,\n",
       "             6.4327e-07, 6.1269e-07, 5.9379e-07, 5.5342e-07, 5.3835e-07, 5.2348e-07,\n",
       "             5.0125e-07, 3.8802e-07, 3.8780e-07, 3.1393e-07, 2.2876e-07, 2.0718e-07,\n",
       "             1.8050e-07, 1.5143e-07, 1.4242e-07, 1.4029e-07, 1.2957e-07, 9.7678e-08,\n",
       "             9.6642e-08, 9.2883e-08, 6.7276e-08, 5.7022e-08, 5.5618e-08, 5.0851e-08,\n",
       "             4.7183e-08, 4.5253e-08, 4.1970e-08, 4.0848e-08, 3.9362e-08, 3.8345e-08,\n",
       "             3.0957e-08, 2.7627e-08, 2.7496e-08, 2.6497e-08, 1.9845e-08, 1.7688e-08,\n",
       "             1.7344e-08, 1.6981e-08, 1.6278e-08, 1.6264e-08, 1.2383e-08, 1.2164e-08,\n",
       "             1.2005e-08, 1.1884e-08, 1.1129e-08, 9.5948e-09, 7.9753e-09, 6.3150e-09,\n",
       "             6.2451e-09, 5.3078e-09, 5.0197e-09, 3.3229e-09, 3.0949e-09, 2.8245e-09,\n",
       "             2.5422e-09, 2.1303e-09, 1.6813e-09, 1.6131e-09, 1.5603e-09, 1.3062e-09,\n",
       "             1.2539e-09, 1.1925e-09, 1.1503e-09, 9.7336e-10, 9.3987e-10, 8.3410e-10,\n",
       "             7.4847e-10, 7.0472e-10, 6.8478e-10, 6.6546e-10, 6.4704e-10, 5.9293e-10,\n",
       "             5.1954e-10, 5.1604e-10, 4.9321e-10, 4.7593e-10, 3.8548e-10, 3.4066e-10,\n",
       "             3.2813e-10, 3.0462e-10, 2.8342e-10, 2.6921e-10, 2.4916e-10, 2.4147e-10,\n",
       "             2.2007e-10, 1.7540e-10, 1.5564e-10, 1.1980e-10, 1.1883e-10, 6.2806e-11,\n",
       "             5.4755e-11, 5.2877e-11, 5.1174e-11, 4.7711e-11, 4.1144e-11, 4.1014e-11,\n",
       "             4.0614e-11, 3.1172e-11, 2.9304e-11, 2.8300e-11, 2.4753e-11, 1.9723e-11,\n",
       "             1.9681e-11, 1.9143e-11, 1.6715e-11, 1.5116e-11, 1.2795e-11, 1.0370e-11,\n",
       "             1.0113e-11, 9.8687e-12, 8.6615e-12, 7.6264e-12, 5.4488e-12, 4.6091e-12,\n",
       "             4.4513e-12, 4.0769e-12, 3.5615e-12, 2.9118e-12, 2.8379e-12, 2.6984e-12,\n",
       "             2.6681e-12, 2.5949e-12, 2.4565e-12, 2.4249e-12, 1.9007e-12, 1.6961e-12,\n",
       "             1.6767e-12, 1.5598e-12, 1.0883e-12, 9.7640e-13, 8.3941e-13, 8.0427e-13,\n",
       "             6.8360e-13, 6.3895e-13, 5.8586e-13, 2.8836e-13, 2.8520e-13, 1.5032e-13,\n",
       "             9.7554e-14, 9.2196e-14, 8.7452e-14, 8.4850e-14, 8.4839e-14, 6.8710e-14,\n",
       "             6.5212e-14, 6.2010e-14, 6.1670e-14, 5.1365e-14, 4.9966e-14, 4.8317e-14,\n",
       "             3.8208e-14, 3.6646e-14, 2.6163e-14, 2.5219e-14, 1.8087e-14, 1.7539e-14,\n",
       "             1.2126e-14, 1.2115e-14, 1.1689e-14, 1.0398e-14, 8.6621e-15, 7.6090e-15,\n",
       "             6.0257e-15, 5.5555e-15, 5.2393e-15, 4.9608e-15, 4.4371e-15, 3.9620e-15,\n",
       "             3.2477e-15, 2.1309e-15, 2.0552e-15, 1.6385e-15, 1.5309e-15, 1.4616e-15,\n",
       "             1.2701e-15, 7.6677e-16, 5.8988e-16, 4.9271e-16, 4.8618e-16, 4.6411e-16,\n",
       "             4.4265e-16, 3.1547e-16, 2.7249e-16, 2.1928e-16, 1.9539e-16, 1.7345e-16,\n",
       "             1.7270e-16, 1.7009e-16, 1.6924e-16, 1.2466e-16, 1.2366e-16, 8.8483e-17,\n",
       "             8.3273e-17, 5.8747e-17, 4.6490e-17, 4.1308e-17, 3.3506e-17, 2.7496e-17,\n",
       "             2.3214e-17, 1.7775e-17, 4.2948e-18, 3.6238e-18, 2.7307e-18, 2.1757e-18,\n",
       "             2.0221e-18, 1.3412e-18, 1.7796e-19, 1.5693e-19, 5.3715e-20, 4.1828e-20,\n",
       "             8.5080e-21, 3.3408e-21, 1.8983e-21, 7.2684e-22, 6.8294e-22, 7.5465e-23,\n",
       "             8.7096e-24, 1.8537e-25])}},\n",
       "   {'fpr': np.float64(0.32608695652173914),\n",
       "    'tpr': np.float64(0.9976608187134502),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.1056, 0.1087, 0.1149, 0.1211, 0.1242, 0.1304, 0.1304, 0.1335,\n",
       "             0.1366, 0.1366, 0.1366, 0.1398, 0.1429, 0.1460, 0.1491, 0.1522, 0.1553,\n",
       "             0.1584, 0.1615, 0.1646, 0.1677, 0.1708, 0.1739, 0.1770, 0.1801, 0.1832,\n",
       "             0.1863, 0.1894, 0.1925, 0.1957, 0.1988, 0.2019, 0.2050, 0.2081, 0.2112,\n",
       "             0.2143, 0.2174, 0.2205, 0.2205, 0.2236, 0.2267, 0.2298, 0.2329, 0.2360,\n",
       "             0.2391, 0.2422, 0.2453, 0.2453, 0.2484, 0.2516, 0.2547, 0.2578, 0.2609,\n",
       "             0.2640, 0.2640, 0.2671, 0.2671, 0.2702, 0.2733, 0.2764, 0.2795, 0.2826,\n",
       "             0.2857, 0.2888, 0.2919, 0.2950, 0.2981, 0.3012, 0.3043, 0.3075, 0.3106,\n",
       "             0.3137, 0.3168, 0.3199, 0.3230, 0.3261, 0.3261, 0.3292, 0.3323, 0.3354,\n",
       "             0.3385, 0.3416, 0.3447, 0.3478, 0.3509, 0.3509, 0.3540, 0.3571, 0.3602,\n",
       "             0.3634, 0.3665, 0.3696, 0.3727, 0.3758, 0.3789, 0.3820, 0.3851, 0.3882,\n",
       "             0.3913, 0.3944, 0.3975, 0.4006, 0.4037, 0.4068, 0.4099, 0.4130, 0.4161,\n",
       "             0.4193, 0.4224, 0.4255, 0.4286, 0.4317, 0.4348, 0.4379, 0.4410, 0.4441,\n",
       "             0.4472, 0.4503, 0.4534, 0.4565, 0.4596, 0.4627, 0.4658, 0.4689, 0.4720,\n",
       "             0.4752, 0.4783, 0.4814, 0.4845, 0.4876, 0.4907, 0.4938, 0.4969, 0.5000,\n",
       "             0.5031, 0.5062, 0.5093, 0.5124, 0.5155, 0.5186, 0.5217, 0.5248, 0.5280,\n",
       "             0.5311, 0.5342, 0.5373, 0.5404, 0.5404, 0.5435, 0.5466, 0.5497, 0.5528,\n",
       "             0.5559, 0.5590, 0.5621, 0.5652, 0.5683, 0.5714, 0.5745, 0.5776, 0.5807,\n",
       "             0.5839, 0.5870, 0.5901, 0.5932, 0.5963, 0.5994, 0.6025, 0.6056, 0.6087,\n",
       "             0.6118, 0.6149, 0.6180, 0.6211, 0.6242, 0.6273, 0.6304, 0.6335, 0.6366,\n",
       "             0.6398, 0.6429, 0.6460, 0.6491, 0.6522, 0.6553, 0.6584, 0.6615, 0.6646,\n",
       "             0.6677, 0.6708, 0.6739, 0.6770, 0.6801, 0.6832, 0.6863, 0.6894, 0.6925,\n",
       "             0.6957, 0.6988, 0.7019, 0.7050, 0.7081, 0.7112, 0.7143, 0.7174, 0.7205,\n",
       "             0.7236, 0.7267, 0.7298, 0.7329, 0.7360, 0.7391, 0.7422, 0.7453, 0.7484,\n",
       "             0.7516, 0.7547, 0.7578, 0.7609, 0.7640, 0.7671, 0.7702, 0.7733, 0.7764,\n",
       "             0.7795, 0.7826, 0.7857, 0.7888, 0.7919, 0.7950, 0.7981, 0.8012, 0.8043,\n",
       "             0.8075, 0.8106, 0.8137, 0.8168, 0.8199, 0.8230, 0.8261, 0.8292, 0.8323,\n",
       "             0.8354, 0.8385, 0.8416, 0.8447, 0.8478, 0.8509, 0.8540, 0.8571, 0.8602,\n",
       "             0.8634, 0.8665, 0.8696, 0.8727, 0.8758, 0.8789, 0.8820, 0.8851, 0.8882,\n",
       "             0.8913, 0.8944, 0.8975, 0.9006, 0.9037, 0.9068, 0.9099, 0.9130, 0.9161,\n",
       "             0.9193, 0.9224, 0.9255, 0.9286, 0.9317, 0.9348, 0.9379, 0.9410, 0.9441,\n",
       "             0.9472, 0.9503, 0.9534, 0.9565, 0.9596, 0.9627, 0.9658, 0.9689, 0.9720,\n",
       "             0.9752, 0.9783, 0.9814, 0.9845, 0.9876, 0.9907, 0.9938, 0.9969, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.9848, 0.9871, 0.9883, 0.9883, 0.9883, 0.9883, 0.9895, 0.9895,\n",
       "             0.9895, 0.9906, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918,\n",
       "             0.9918, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918,\n",
       "             0.9918, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918, 0.9918,\n",
       "             0.9918, 0.9918, 0.9918, 0.9930, 0.9930, 0.9930, 0.9930, 0.9930, 0.9930,\n",
       "             0.9930, 0.9930, 0.9930, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942, 0.9942,\n",
       "             0.9942, 0.9953, 0.9953, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965,\n",
       "             0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9965,\n",
       "             0.9965, 0.9965, 0.9965, 0.9965, 0.9965, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988, 0.9988,\n",
       "             0.9988, 0.9988, 0.9988, 0.9988, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9994e-01, 9.9993e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9988e-01, 9.9987e-01, 9.9976e-01, 9.9973e-01, 9.9971e-01,\n",
       "             9.9961e-01, 9.9959e-01, 9.9948e-01, 9.9941e-01, 9.9935e-01, 9.9935e-01,\n",
       "             9.9922e-01, 9.9874e-01, 9.9873e-01, 9.9851e-01, 9.9800e-01, 9.9770e-01,\n",
       "             9.9765e-01, 9.9651e-01, 9.9341e-01, 9.9041e-01, 9.9003e-01, 9.8966e-01,\n",
       "             9.8871e-01, 9.8835e-01, 9.8764e-01, 9.8506e-01, 9.8431e-01, 9.7369e-01,\n",
       "             9.7185e-01, 9.7052e-01, 9.6633e-01, 9.6224e-01, 9.3711e-01, 9.1429e-01,\n",
       "             9.1396e-01, 9.0290e-01, 8.9741e-01, 8.7448e-01, 8.4321e-01, 8.1718e-01,\n",
       "             7.1689e-01, 6.9231e-01, 6.8093e-01, 6.5880e-01, 6.4598e-01, 6.3359e-01,\n",
       "             6.3015e-01, 6.1000e-01, 5.8041e-01, 5.7097e-01, 5.5384e-01, 5.1107e-01,\n",
       "             4.7310e-01, 4.6307e-01, 3.9370e-01, 3.4249e-01, 2.4926e-01, 1.2969e-01,\n",
       "             1.1653e-01, 1.1503e-01, 1.0350e-01, 8.8735e-02, 8.2611e-02, 5.8413e-02,\n",
       "             5.6214e-02, 5.5117e-02, 3.7596e-02, 3.1057e-02, 3.0085e-02, 2.1304e-02,\n",
       "             1.8983e-02, 1.4684e-02, 1.3920e-02, 1.3721e-02, 1.1626e-02, 9.5057e-03,\n",
       "             8.8799e-03, 7.9458e-03, 6.0053e-03, 5.2737e-03, 5.2701e-03, 4.5554e-03,\n",
       "             2.9964e-03, 2.6346e-03, 2.3433e-03, 1.7318e-03, 1.5242e-03, 1.5004e-03,\n",
       "             1.4885e-03, 8.6824e-04, 7.8189e-04, 5.9473e-04, 4.6227e-04, 4.3505e-04,\n",
       "             3.9865e-04, 3.1952e-04, 2.7376e-04, 2.1427e-04, 1.9301e-04, 1.5010e-04,\n",
       "             1.2737e-04, 9.9608e-05, 7.1173e-05, 6.5225e-05, 6.4852e-05, 3.7387e-05,\n",
       "             3.3503e-05, 2.4758e-05, 2.3590e-05, 2.2455e-05, 2.1017e-05, 1.9796e-05,\n",
       "             1.5583e-05, 1.2649e-05, 1.2154e-05, 1.0929e-05, 1.0700e-05, 9.4701e-06,\n",
       "             9.3337e-06, 8.1069e-06, 7.7053e-06, 6.9737e-06, 5.9994e-06, 5.7345e-06,\n",
       "             5.6452e-06, 5.4064e-06, 5.1242e-06, 4.9790e-06, 4.0469e-06, 3.7948e-06,\n",
       "             3.4882e-06, 2.6549e-06, 2.5634e-06, 2.4011e-06, 2.0602e-06, 1.5935e-06,\n",
       "             1.4896e-06, 1.4785e-06, 9.7481e-07, 8.4032e-07, 8.2330e-07, 6.1266e-07,\n",
       "             3.2305e-07, 2.7316e-07, 2.7240e-07, 2.0246e-07, 1.7810e-07, 1.5911e-07,\n",
       "             1.5465e-07, 1.3565e-07, 1.1472e-07, 9.8920e-08, 8.1445e-08, 6.4686e-08,\n",
       "             5.6957e-08, 5.1807e-08, 4.2411e-08, 2.9935e-08, 2.9387e-08, 2.6815e-08,\n",
       "             2.1540e-08, 1.7808e-08, 1.7793e-08, 1.6605e-08, 1.5588e-08, 1.4327e-08,\n",
       "             1.4228e-08, 1.4140e-08, 1.3829e-08, 1.3133e-08, 9.2442e-09, 8.2227e-09,\n",
       "             8.0394e-09, 5.7966e-09, 5.7457e-09, 5.5544e-09, 4.7366e-09, 4.7359e-09,\n",
       "             4.6315e-09, 4.4006e-09, 4.2763e-09, 4.0770e-09, 3.4945e-09, 2.5141e-09,\n",
       "             2.4433e-09, 2.2627e-09, 2.0880e-09, 1.7019e-09, 1.0217e-09, 9.3294e-10,\n",
       "             8.8528e-10, 8.3056e-10, 5.9552e-10, 5.3968e-10, 5.2002e-10, 5.0427e-10,\n",
       "             4.2780e-10, 3.6892e-10, 3.5474e-10, 3.0384e-10, 3.0348e-10, 2.2387e-10,\n",
       "             1.7521e-10, 1.4499e-10, 1.4389e-10, 1.3990e-10, 1.2617e-10, 1.0779e-10,\n",
       "             9.6119e-11, 9.3841e-11, 9.3238e-11, 5.9814e-11, 3.7590e-11, 1.9130e-11,\n",
       "             1.2878e-11, 1.1631e-11, 1.0759e-11, 1.0743e-11, 9.1412e-12, 7.5731e-12,\n",
       "             7.2839e-12, 2.9458e-12, 2.8052e-12, 2.2655e-12, 1.3693e-12, 1.1810e-12,\n",
       "             9.0490e-13, 8.8672e-13, 7.0597e-13, 4.9461e-13, 4.6003e-13, 4.1339e-13,\n",
       "             3.6748e-13, 3.3477e-13, 2.7632e-13, 2.7431e-13, 2.4528e-13, 1.5832e-13,\n",
       "             1.4975e-13, 1.3941e-13, 7.4367e-14, 7.2630e-14, 6.9017e-14, 6.5100e-14,\n",
       "             5.5042e-14, 4.1141e-14, 3.3974e-14, 3.1612e-14, 1.8090e-14, 9.3151e-15,\n",
       "             7.8049e-15, 2.1157e-15, 1.9628e-15, 1.2713e-15, 1.0910e-15, 3.3358e-16,\n",
       "             2.4268e-16, 2.2475e-16, 1.4497e-16, 1.3840e-16, 1.0285e-16, 4.3161e-17,\n",
       "             3.7137e-17, 2.1802e-17, 1.4141e-17, 4.7474e-18, 2.2913e-18, 2.3045e-19,\n",
       "             6.4051e-20, 4.2582e-20, 2.7734e-23])}}],\n",
       "  [{'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.005747126436781609),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 6.6341e-01, 6.4758e-01,  ..., 1.0260e-07, 1.8032e-08,\n",
       "             8.5904e-09])}},\n",
       "   {'fpr': np.float64(0.006514657980456026),\n",
       "    'tpr': np.float64(0.8528735632183908),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9993e-01, 9.9969e-01,  ..., 1.8457e-06, 1.7331e-06,\n",
       "             1.4368e-06])}},\n",
       "   {'fpr': np.float64(0.02280130293159609),\n",
       "    'tpr': np.float64(0.9091954022988505),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 9.9998e-01,  ..., 1.2266e-07, 9.7331e-08,\n",
       "             4.0143e-08])}},\n",
       "   {'fpr': np.float64(0.04234527687296417),\n",
       "    'tpr': np.float64(0.9517241379310345),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9999e-01, 9.9989e-01,  ..., 2.3299e-07, 2.0987e-07,\n",
       "             7.9773e-08])}},\n",
       "   {'fpr': np.float64(0.03257328990228013),\n",
       "    'tpr': np.float64(0.9620689655172414),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9998e-01, 9.9991e-01,  ..., 3.3779e-07, 1.3030e-07,\n",
       "             1.9506e-08])}},\n",
       "   {'fpr': np.float64(0.03908794788273615),\n",
       "    'tpr': np.float64(0.9712643678160919),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.8149e-09, 7.8341e-10,\n",
       "             6.2051e-11])}},\n",
       "   {'fpr': np.float64(0.016286644951140065),\n",
       "    'tpr': np.float64(0.9333333333333333),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9959e-01, 9.9895e-01,  ..., 1.5764e-09, 1.3717e-09,\n",
       "             8.6240e-12])}},\n",
       "   {'fpr': np.float64(0.06188925081433225),\n",
       "    'tpr': np.float64(0.9770114942528736),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9996e-01, 9.9995e-01,  ..., 3.2982e-08, 2.1384e-08,\n",
       "             4.5861e-10])}},\n",
       "   {'fpr': np.float64(0.07166123778501629),\n",
       "    'tpr': np.float64(0.9862068965517241),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9998e-01, 9.9997e-01,  ..., 1.5995e-09, 5.1251e-10,\n",
       "             1.5140e-12])}},\n",
       "   {'fpr': np.float64(0.05863192182410423),\n",
       "    'tpr': np.float64(0.9816091954022989),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9999e-01, 9.9999e-01,  ..., 1.0564e-11, 9.0585e-14,\n",
       "             6.5259e-16])}},\n",
       "   {'fpr': np.float64(0.08794788273615635),\n",
       "    'tpr': np.float64(0.9862068965517241),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,\n",
       "             0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,\n",
       "             0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,\n",
       "             0.0065, 0.0065, 0.0065, 0.0065, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0130, 0.0163, 0.0163, 0.0163, 0.0163, 0.0163, 0.0163, 0.0163, 0.0163,\n",
       "             0.0163, 0.0163, 0.0163, 0.0163, 0.0163, 0.0163, 0.0163, 0.0163, 0.0163,\n",
       "             0.0163, 0.0163, 0.0195, 0.0195, 0.0228, 0.0228, 0.0228, 0.0228, 0.0261,\n",
       "             0.0293, 0.0293, 0.0326, 0.0326, 0.0358, 0.0358, 0.0391, 0.0423, 0.0456,\n",
       "             0.0489, 0.0489, 0.0489, 0.0521, 0.0554, 0.0586, 0.0586, 0.0586, 0.0586,\n",
       "             0.0619, 0.0619, 0.0619, 0.0651, 0.0651, 0.0684, 0.0684, 0.0684, 0.0717,\n",
       "             0.0717, 0.0717, 0.0749, 0.0749, 0.0782, 0.0814, 0.0847, 0.0879, 0.0879,\n",
       "             0.0912, 0.0912, 0.0945, 0.0945, 0.0977, 0.1010, 0.1042, 0.1075, 0.1107,\n",
       "             0.1140, 0.1173, 0.1173, 0.1205, 0.1238, 0.1238, 0.1270, 0.1303, 0.1336,\n",
       "             0.1368, 0.1401, 0.1401, 0.1433, 0.1466, 0.1498, 0.1531, 0.1564, 0.1596,\n",
       "             0.1629, 0.1629, 0.1661, 0.1694, 0.1726, 0.1759, 0.1792, 0.1824, 0.1857,\n",
       "             0.1889, 0.1922, 0.1954, 0.1954, 0.1987, 0.2020, 0.2052, 0.2085, 0.2117,\n",
       "             0.2117, 0.2150, 0.2182, 0.2215, 0.2248, 0.2280, 0.2313, 0.2345, 0.2378,\n",
       "             0.2410, 0.2443, 0.2476, 0.2508, 0.2541, 0.2573, 0.2606, 0.2638, 0.2671,\n",
       "             0.2671, 0.2704, 0.2736, 0.2769, 0.2801, 0.2834, 0.2866, 0.2899, 0.2932,\n",
       "             0.2964, 0.2997, 0.3029, 0.3062, 0.3094, 0.3127, 0.3160, 0.3192, 0.3225,\n",
       "             0.3257, 0.3290, 0.3322, 0.3355, 0.3388, 0.3420, 0.3453, 0.3485, 0.3518,\n",
       "             0.3550, 0.3583, 0.3616, 0.3648, 0.3681, 0.3713, 0.3746, 0.3779, 0.3811,\n",
       "             0.3844, 0.3876, 0.3909, 0.3941, 0.3974, 0.4007, 0.4039, 0.4072, 0.4072,\n",
       "             0.4104, 0.4137, 0.4169, 0.4202, 0.4235, 0.4267, 0.4300, 0.4332, 0.4365,\n",
       "             0.4397, 0.4430, 0.4463, 0.4495, 0.4528, 0.4560, 0.4593, 0.4625, 0.4658,\n",
       "             0.4691, 0.4723, 0.4756, 0.4788, 0.4821, 0.4853, 0.4853, 0.4886, 0.4919,\n",
       "             0.4951, 0.4984, 0.5016, 0.5049, 0.5081, 0.5114, 0.5147, 0.5179, 0.5212,\n",
       "             0.5244, 0.5277, 0.5309, 0.5342, 0.5375, 0.5407, 0.5440, 0.5472, 0.5505,\n",
       "             0.5537, 0.5570, 0.5603, 0.5635, 0.5668, 0.5700, 0.5733, 0.5765, 0.5798,\n",
       "             0.5831, 0.5863, 0.5896, 0.5928, 0.5961, 0.5993, 0.6026, 0.6059, 0.6091,\n",
       "             0.6124, 0.6156, 0.6189, 0.6221, 0.6254, 0.6287, 0.6319, 0.6352, 0.6384,\n",
       "             0.6417, 0.6450, 0.6482, 0.6515, 0.6547, 0.6580, 0.6612, 0.6645, 0.6678,\n",
       "             0.6710, 0.6743, 0.6775, 0.6808, 0.6840, 0.6873, 0.6906, 0.6938, 0.6971,\n",
       "             0.7003, 0.7036, 0.7068, 0.7101, 0.7134, 0.7166, 0.7199, 0.7231, 0.7264,\n",
       "             0.7296, 0.7329, 0.7362, 0.7394, 0.7427, 0.7459, 0.7492, 0.7524, 0.7557,\n",
       "             0.7590, 0.7622, 0.7655, 0.7687, 0.7720, 0.7752, 0.7785, 0.7818, 0.7850,\n",
       "             0.7883, 0.7915, 0.7948, 0.7980, 0.8013, 0.8046, 0.8078, 0.8111, 0.8143,\n",
       "             0.8176, 0.8208, 0.8241, 0.8274, 0.8306, 0.8339, 0.8371, 0.8404, 0.8436,\n",
       "             0.8469, 0.8502, 0.8534, 0.8567, 0.8599, 0.8632, 0.8664, 0.8697, 0.8730,\n",
       "             0.8762, 0.8795, 0.8827, 0.8860, 0.8893, 0.8925, 0.8958, 0.8990, 0.9023,\n",
       "             0.9055, 0.9088, 0.9121, 0.9153, 0.9186, 0.9218, 0.9251, 0.9283, 0.9316,\n",
       "             0.9349, 0.9381, 0.9414, 0.9446, 0.9479, 0.9511, 0.9544, 0.9577, 0.9609,\n",
       "             0.9642, 0.9674, 0.9707, 0.9739, 0.9772, 0.9805, 0.9837, 0.9870, 0.9902,\n",
       "             0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0080, 0.0299, 0.0483, 0.0598, 0.0747, 0.0862, 0.0989, 0.1046,\n",
       "             0.1115, 0.1184, 0.1241, 0.1356, 0.1391, 0.1506, 0.1586, 0.1621, 0.1667,\n",
       "             0.1759, 0.1805, 0.1874, 0.1943, 0.1989, 0.2011, 0.2057, 0.2080, 0.2103,\n",
       "             0.2149, 0.2218, 0.2310, 0.2333, 0.2379, 0.2425, 0.2448, 0.2483, 0.2529,\n",
       "             0.2575, 0.2609, 0.2632, 0.2644, 0.2678, 0.2713, 0.2747, 0.2770, 0.2816,\n",
       "             0.2874, 0.2908, 0.2943, 0.3023, 0.3057, 0.3080, 0.3138, 0.3172, 0.3184,\n",
       "             0.3195, 0.3241, 0.3322, 0.3345, 0.3356, 0.3414, 0.3448, 0.3460, 0.3483,\n",
       "             0.3494, 0.3506, 0.3540, 0.3575, 0.3598, 0.3621, 0.3678, 0.3690, 0.3713,\n",
       "             0.3736, 0.3747, 0.3770, 0.3793, 0.3816, 0.3828, 0.3839, 0.3897, 0.3931,\n",
       "             0.3943, 0.3966, 0.3989, 0.4023, 0.4057, 0.4092, 0.4126, 0.4138, 0.4161,\n",
       "             0.4184, 0.4195, 0.4230, 0.4264, 0.4299, 0.4322, 0.4333, 0.4345, 0.4379,\n",
       "             0.4402, 0.4414, 0.4425, 0.4448, 0.4460, 0.4494, 0.4506, 0.4517, 0.4540,\n",
       "             0.4575, 0.4598, 0.4621, 0.4655, 0.4701, 0.4724, 0.4736, 0.4747, 0.4759,\n",
       "             0.4793, 0.4805, 0.4828, 0.4839, 0.4851, 0.4874, 0.4885, 0.4897, 0.4908,\n",
       "             0.4920, 0.4966, 0.5000, 0.5011, 0.5023, 0.5034, 0.5069, 0.5080, 0.5103,\n",
       "             0.5149, 0.5172, 0.5195, 0.5207, 0.5218, 0.5276, 0.5287, 0.5299, 0.5310,\n",
       "             0.5322, 0.5356, 0.5368, 0.5379, 0.5414, 0.5437, 0.5448, 0.5471, 0.5506,\n",
       "             0.5517, 0.5529, 0.5540, 0.5563, 0.5575, 0.5598, 0.5609, 0.5621, 0.5632,\n",
       "             0.5644, 0.5655, 0.5667, 0.5690, 0.5713, 0.5724, 0.5747, 0.5759, 0.5770,\n",
       "             0.5793, 0.5805, 0.5816, 0.5828, 0.5839, 0.5851, 0.5862, 0.5874, 0.5885,\n",
       "             0.5897, 0.5908, 0.5920, 0.5943, 0.5954, 0.5966, 0.5977, 0.6000, 0.6011,\n",
       "             0.6023, 0.6034, 0.6046, 0.6057, 0.6092, 0.6103, 0.6115, 0.6126, 0.6138,\n",
       "             0.6149, 0.6161, 0.6172, 0.6184, 0.6195, 0.6207, 0.6218, 0.6241, 0.6253,\n",
       "             0.6276, 0.6287, 0.6299, 0.6310, 0.6322, 0.6333, 0.6345, 0.6356, 0.6368,\n",
       "             0.6379, 0.6391, 0.6402, 0.6414, 0.6437, 0.6448, 0.6460, 0.6471, 0.6483,\n",
       "             0.6494, 0.6506, 0.6517, 0.6529, 0.6540, 0.6552, 0.6563, 0.6575, 0.6598,\n",
       "             0.6609, 0.6621, 0.6632, 0.6644, 0.6655, 0.6667, 0.6678, 0.6690, 0.6701,\n",
       "             0.6713, 0.6724, 0.6736, 0.6759, 0.6770, 0.6782, 0.6793, 0.6805, 0.6828,\n",
       "             0.6839, 0.6851, 0.6862, 0.6874, 0.6885, 0.6897, 0.6908, 0.6931, 0.6943,\n",
       "             0.6954, 0.6966, 0.6977, 0.6989, 0.7000, 0.7011, 0.7023, 0.7034, 0.7046,\n",
       "             0.7057, 0.7069, 0.7092, 0.7103, 0.7115, 0.7149, 0.7161, 0.7172, 0.7184,\n",
       "             0.7195, 0.7207, 0.7218, 0.7230, 0.7241, 0.7253, 0.7264, 0.7276, 0.7287,\n",
       "             0.7299, 0.7310, 0.7333, 0.7345, 0.7356, 0.7368, 0.7379, 0.7391, 0.7402,\n",
       "             0.7414, 0.7425, 0.7437, 0.7448, 0.7471, 0.7483, 0.7506, 0.7517, 0.7529,\n",
       "             0.7540, 0.7552, 0.7563, 0.7575, 0.7586, 0.7598, 0.7609, 0.7621, 0.7632,\n",
       "             0.7644, 0.7667, 0.7678, 0.7690, 0.7701, 0.7713, 0.7724, 0.7736, 0.7747,\n",
       "             0.7770, 0.7782, 0.7793, 0.7816, 0.7828, 0.7839, 0.7851, 0.7862, 0.7874,\n",
       "             0.7885, 0.7897, 0.7908, 0.7920, 0.7931, 0.7943, 0.7954, 0.7966, 0.7977,\n",
       "             0.7989, 0.8011, 0.8023, 0.8034, 0.8046, 0.8057, 0.8069, 0.8080, 0.8092,\n",
       "             0.8103, 0.8115, 0.8126, 0.8126, 0.8138, 0.8149, 0.8161, 0.8172, 0.8184,\n",
       "             0.8195, 0.8207, 0.8218, 0.8230, 0.8241, 0.8253, 0.8264, 0.8276, 0.8287,\n",
       "             0.8299, 0.8310, 0.8322, 0.8333, 0.8345, 0.8356, 0.8368, 0.8379, 0.8391,\n",
       "             0.8402, 0.8414, 0.8425, 0.8437, 0.8437, 0.8448, 0.8460, 0.8471, 0.8483,\n",
       "             0.8494, 0.8506, 0.8517, 0.8529, 0.8540, 0.8552, 0.8563, 0.8575, 0.8586,\n",
       "             0.8598, 0.8609, 0.8632, 0.8644, 0.8655, 0.8667, 0.8678, 0.8690, 0.8701,\n",
       "             0.8713, 0.8724, 0.8736, 0.8747, 0.8759, 0.8770, 0.8782, 0.8793, 0.8805,\n",
       "             0.8816, 0.8828, 0.8839, 0.8851, 0.8862, 0.8874, 0.8885, 0.8897, 0.8908,\n",
       "             0.8920, 0.8931, 0.8943, 0.8954, 0.8966, 0.8977, 0.8989, 0.9000, 0.9011,\n",
       "             0.9023, 0.9034, 0.9046, 0.9057, 0.9069, 0.9080, 0.9092, 0.9103, 0.9115,\n",
       "             0.9126, 0.9138, 0.9149, 0.9161, 0.9172, 0.9184, 0.9195, 0.9207, 0.9218,\n",
       "             0.9230, 0.9241, 0.9253, 0.9264, 0.9276, 0.9287, 0.9299, 0.9310, 0.9322,\n",
       "             0.9333, 0.9345, 0.9356, 0.9368, 0.9379, 0.9391, 0.9402, 0.9414, 0.9425,\n",
       "             0.9425, 0.9425, 0.9437, 0.9448, 0.9460, 0.9471, 0.9483, 0.9494, 0.9506,\n",
       "             0.9517, 0.9529, 0.9540, 0.9552, 0.9563, 0.9575, 0.9586, 0.9598, 0.9609,\n",
       "             0.9621, 0.9632, 0.9632, 0.9644, 0.9644, 0.9655, 0.9667, 0.9678, 0.9678,\n",
       "             0.9678, 0.9690, 0.9690, 0.9701, 0.9701, 0.9713, 0.9713, 0.9713, 0.9713,\n",
       "             0.9713, 0.9724, 0.9736, 0.9736, 0.9736, 0.9736, 0.9747, 0.9759, 0.9770,\n",
       "             0.9770, 0.9782, 0.9793, 0.9793, 0.9805, 0.9805, 0.9816, 0.9828, 0.9828,\n",
       "             0.9839, 0.9851, 0.9851, 0.9862, 0.9862, 0.9862, 0.9862, 0.9862, 0.9874,\n",
       "             0.9874, 0.9885, 0.9885, 0.9897, 0.9897, 0.9897, 0.9897, 0.9897, 0.9897,\n",
       "             0.9897, 0.9897, 0.9908, 0.9908, 0.9908, 0.9920, 0.9920, 0.9920, 0.9920,\n",
       "             0.9920, 0.9920, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931,\n",
       "             0.9931, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943,\n",
       "             0.9943, 0.9943, 0.9943, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9987e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9984e-01,\n",
       "             9.9984e-01, 9.9984e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9983e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9981e-01,\n",
       "             9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9979e-01, 9.9979e-01, 9.9978e-01,\n",
       "             9.9978e-01, 9.9977e-01, 9.9977e-01, 9.9977e-01, 9.9977e-01, 9.9976e-01,\n",
       "             9.9976e-01, 9.9976e-01, 9.9976e-01, 9.9975e-01, 9.9975e-01, 9.9975e-01,\n",
       "             9.9975e-01, 9.9974e-01, 9.9974e-01, 9.9974e-01, 9.9973e-01, 9.9973e-01,\n",
       "             9.9972e-01, 9.9972e-01, 9.9972e-01, 9.9971e-01, 9.9970e-01, 9.9969e-01,\n",
       "             9.9969e-01, 9.9969e-01, 9.9969e-01, 9.9969e-01, 9.9968e-01, 9.9965e-01,\n",
       "             9.9965e-01, 9.9965e-01, 9.9965e-01, 9.9963e-01, 9.9962e-01, 9.9962e-01,\n",
       "             9.9962e-01, 9.9960e-01, 9.9957e-01, 9.9955e-01, 9.9952e-01, 9.9950e-01,\n",
       "             9.9950e-01, 9.9949e-01, 9.9944e-01, 9.9943e-01, 9.9943e-01, 9.9941e-01,\n",
       "             9.9935e-01, 9.9935e-01, 9.9933e-01, 9.9933e-01, 9.9932e-01, 9.9929e-01,\n",
       "             9.9923e-01, 9.9920e-01, 9.9919e-01, 9.9917e-01, 9.9915e-01, 9.9904e-01,\n",
       "             9.9903e-01, 9.9902e-01, 9.9898e-01, 9.9898e-01, 9.9892e-01, 9.9891e-01,\n",
       "             9.9884e-01, 9.9883e-01, 9.9880e-01, 9.9870e-01, 9.9857e-01, 9.9843e-01,\n",
       "             9.9843e-01, 9.9819e-01, 9.9818e-01, 9.9816e-01, 9.9812e-01, 9.9811e-01,\n",
       "             9.9773e-01, 9.9770e-01, 9.9765e-01, 9.9763e-01, 9.9750e-01, 9.9730e-01,\n",
       "             9.9665e-01, 9.9621e-01, 9.9583e-01, 9.9568e-01, 9.9556e-01, 9.9553e-01,\n",
       "             9.9539e-01, 9.9498e-01, 9.9419e-01, 9.9394e-01, 9.9387e-01, 9.9363e-01,\n",
       "             9.9358e-01, 9.9282e-01, 9.9269e-01, 9.8922e-01, 9.8901e-01, 9.8709e-01,\n",
       "             9.8570e-01, 9.8372e-01, 9.8227e-01, 9.7905e-01, 9.7399e-01, 9.7332e-01,\n",
       "             9.7199e-01, 9.7134e-01, 9.6883e-01, 9.5658e-01, 9.5282e-01, 9.5203e-01,\n",
       "             9.5033e-01, 9.4726e-01, 9.4609e-01, 9.3831e-01, 9.3820e-01, 9.0950e-01,\n",
       "             9.0740e-01, 9.0683e-01, 9.0468e-01, 9.0239e-01, 9.0064e-01, 8.9594e-01,\n",
       "             8.8067e-01, 8.6048e-01, 8.4932e-01, 8.4895e-01, 8.4470e-01, 8.4183e-01,\n",
       "             8.4090e-01, 8.2322e-01, 8.2298e-01, 8.1869e-01, 7.9267e-01, 7.7822e-01,\n",
       "             7.5022e-01, 7.0970e-01, 6.8094e-01, 6.5522e-01, 6.3982e-01, 6.3887e-01,\n",
       "             5.9598e-01, 5.8128e-01, 5.7190e-01, 5.6596e-01, 5.5240e-01, 5.2526e-01,\n",
       "             5.2326e-01, 5.0350e-01, 4.8105e-01, 4.6043e-01, 4.4914e-01, 4.2718e-01,\n",
       "             4.2353e-01, 3.3186e-01, 3.2890e-01, 2.9456e-01, 2.9293e-01, 2.6535e-01,\n",
       "             2.6519e-01, 2.4431e-01, 2.3305e-01, 2.1277e-01, 2.0407e-01, 1.7358e-01,\n",
       "             1.6478e-01, 1.3434e-01, 1.0434e-01, 9.3784e-02, 9.3211e-02, 6.9953e-02,\n",
       "             6.4321e-02, 5.9418e-02, 5.0855e-02, 3.9550e-02, 3.9306e-02, 3.8529e-02,\n",
       "             2.8798e-02, 2.0844e-02, 2.0039e-02, 1.8982e-02, 1.6152e-02, 1.4864e-02,\n",
       "             1.4815e-02, 1.4468e-02, 1.4203e-02, 1.3499e-02, 1.2925e-02, 1.1250e-02,\n",
       "             1.1212e-02, 8.2794e-03, 7.8332e-03, 6.4686e-03, 5.8510e-03, 5.4187e-03,\n",
       "             5.1389e-03, 4.9220e-03, 4.8021e-03, 4.7165e-03, 4.3060e-03, 3.9611e-03,\n",
       "             3.7490e-03, 3.6051e-03, 3.3285e-03, 3.0394e-03, 2.8644e-03, 2.5307e-03,\n",
       "             2.2977e-03, 1.9712e-03, 1.8854e-03, 1.8735e-03, 1.8061e-03, 1.6939e-03,\n",
       "             1.5841e-03, 1.5164e-03, 1.4572e-03, 1.2735e-03, 1.1581e-03, 1.0796e-03,\n",
       "             9.0568e-04, 8.9472e-04, 8.4538e-04, 8.0034e-04, 7.3117e-04, 7.0359e-04,\n",
       "             6.2964e-04, 5.3917e-04, 4.9778e-04, 4.9354e-04, 4.2015e-04, 4.0565e-04,\n",
       "             3.9730e-04, 3.7460e-04, 3.6964e-04, 3.0380e-04, 2.6928e-04, 2.6096e-04,\n",
       "             2.4296e-04, 2.3559e-04, 2.3396e-04, 2.0434e-04, 2.0253e-04, 1.9602e-04,\n",
       "             1.8266e-04, 1.5106e-04, 1.5068e-04, 1.4721e-04, 1.4487e-04, 1.3582e-04,\n",
       "             1.3010e-04, 1.0812e-04, 1.0210e-04, 9.9881e-05, 9.2780e-05, 9.0828e-05,\n",
       "             5.5168e-05, 5.4297e-05, 5.1277e-05, 4.8369e-05, 3.8687e-05, 3.6103e-05,\n",
       "             3.4989e-05, 3.2002e-05, 2.9512e-05, 2.9228e-05, 2.9197e-05, 2.4989e-05,\n",
       "             2.2114e-05, 2.1645e-05, 2.1273e-05, 1.9667e-05, 1.9601e-05, 1.7037e-05,\n",
       "             1.6835e-05, 1.6195e-05, 1.5827e-05, 1.4139e-05, 1.3979e-05, 1.2451e-05,\n",
       "             1.2068e-05, 1.1532e-05, 1.0920e-05, 1.0163e-05, 9.5923e-06, 8.4884e-06,\n",
       "             8.2577e-06, 8.1191e-06, 7.5312e-06, 6.8969e-06, 5.4802e-06, 5.3313e-06,\n",
       "             4.6125e-06, 4.4836e-06, 4.3343e-06, 4.0860e-06, 3.9145e-06, 3.8564e-06,\n",
       "             3.2821e-06, 3.0162e-06, 2.6952e-06, 2.5683e-06, 2.4746e-06, 2.4252e-06,\n",
       "             2.3089e-06, 2.2232e-06, 2.1977e-06, 2.1027e-06, 2.0070e-06, 1.7779e-06,\n",
       "             1.5348e-06, 1.5162e-06, 1.2301e-06, 1.1961e-06, 1.1494e-06, 1.0960e-06,\n",
       "             9.9898e-07, 7.8528e-07, 7.8287e-07, 7.6818e-07, 7.6231e-07, 7.3440e-07,\n",
       "             7.2557e-07, 6.5241e-07, 5.3437e-07, 5.1865e-07, 5.1723e-07, 4.9314e-07,\n",
       "             4.8839e-07, 4.1197e-07, 3.8418e-07, 3.8016e-07, 3.6283e-07, 2.9303e-07,\n",
       "             2.4306e-07, 1.9523e-07, 1.7260e-07, 1.6365e-07, 1.6365e-07, 1.5656e-07,\n",
       "             1.5430e-07, 1.0911e-07, 1.0609e-07, 1.0337e-07, 7.7484e-08, 6.3685e-08,\n",
       "             6.1099e-08, 5.8518e-08, 5.7172e-08, 5.5387e-08, 5.5380e-08, 5.4188e-08,\n",
       "             5.1931e-08, 2.2741e-08, 2.2692e-08, 2.2675e-08, 2.1699e-08, 1.5399e-08,\n",
       "             1.4894e-08, 1.4719e-08, 1.3455e-08, 1.3261e-08, 1.1600e-08, 1.1580e-08,\n",
       "             9.2946e-09, 7.6039e-09, 7.5820e-09, 6.9398e-09, 6.2841e-09, 6.2553e-09,\n",
       "             6.1933e-09, 5.7231e-09, 5.5901e-09, 5.5242e-09, 5.5213e-09, 4.6268e-09,\n",
       "             4.1640e-09, 3.9599e-09, 3.1197e-09, 3.0882e-09, 2.7754e-09, 2.6787e-09,\n",
       "             2.5860e-09, 2.3616e-09, 1.8200e-09, 1.7108e-09, 1.5087e-09, 1.3598e-09,\n",
       "             1.1359e-09, 9.9370e-10, 3.2699e-10, 3.2549e-10, 2.8960e-10, 2.4566e-10,\n",
       "             2.3952e-10, 2.3266e-10, 2.2448e-10, 2.2055e-10, 2.1543e-10, 2.0714e-10,\n",
       "             1.9374e-10, 1.5197e-10, 1.3791e-10, 9.0903e-11, 8.1619e-11, 7.9870e-11,\n",
       "             6.8205e-11, 4.1550e-11, 3.9774e-11, 3.6577e-11, 2.9590e-11, 2.5180e-11,\n",
       "             1.8480e-11, 1.0701e-11, 6.2669e-12, 6.1410e-12, 5.9147e-12, 5.2881e-12,\n",
       "             4.6165e-12, 4.3445e-12, 2.4902e-12, 2.3470e-12, 1.7215e-12, 1.5485e-12,\n",
       "             8.8624e-13, 5.8804e-13, 4.8832e-13, 4.2099e-13, 3.2063e-13, 2.7400e-13,\n",
       "             2.4604e-13, 1.6772e-13, 1.1842e-13, 9.8197e-14, 7.7500e-14, 2.7754e-14,\n",
       "             1.9097e-14, 1.1242e-14, 4.2806e-15, 9.3274e-17, 1.2610e-17, 9.0356e-23])}},\n",
       "   {'fpr': np.float64(0.11400651465798045),\n",
       "    'tpr': np.float64(0.993103448275862),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0065, 0.0065, 0.0065, 0.0065,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
       "             0.0163, 0.0163, 0.0163, 0.0195, 0.0195, 0.0195, 0.0195, 0.0228, 0.0228,\n",
       "             0.0228, 0.0228, 0.0228, 0.0228, 0.0228, 0.0228, 0.0228, 0.0228, 0.0228,\n",
       "             0.0228, 0.0228, 0.0228, 0.0261, 0.0293, 0.0293, 0.0293, 0.0293, 0.0293,\n",
       "             0.0293, 0.0293, 0.0293, 0.0293, 0.0326, 0.0358, 0.0358, 0.0358, 0.0391,\n",
       "             0.0391, 0.0391, 0.0391, 0.0423, 0.0456, 0.0456, 0.0456, 0.0456, 0.0489,\n",
       "             0.0489, 0.0489, 0.0521, 0.0554, 0.0586, 0.0619, 0.0619, 0.0651, 0.0684,\n",
       "             0.0717, 0.0749, 0.0782, 0.0814, 0.0847, 0.0879, 0.0912, 0.0945, 0.0977,\n",
       "             0.0977, 0.1010, 0.1010, 0.1010, 0.1042, 0.1075, 0.1107, 0.1140, 0.1140,\n",
       "             0.1173, 0.1205, 0.1238, 0.1270, 0.1303, 0.1336, 0.1368, 0.1401, 0.1433,\n",
       "             0.1466, 0.1466, 0.1498, 0.1531, 0.1564, 0.1596, 0.1629, 0.1661, 0.1694,\n",
       "             0.1726, 0.1759, 0.1792, 0.1824, 0.1857, 0.1889, 0.1922, 0.1922, 0.1954,\n",
       "             0.1987, 0.2020, 0.2052, 0.2085, 0.2117, 0.2150, 0.2182, 0.2215, 0.2248,\n",
       "             0.2280, 0.2313, 0.2345, 0.2378, 0.2410, 0.2443, 0.2476, 0.2476, 0.2508,\n",
       "             0.2541, 0.2573, 0.2606, 0.2638, 0.2671, 0.2704, 0.2736, 0.2769, 0.2801,\n",
       "             0.2834, 0.2866, 0.2899, 0.2932, 0.2964, 0.2964, 0.2997, 0.3029, 0.3062,\n",
       "             0.3094, 0.3127, 0.3127, 0.3160, 0.3192, 0.3225, 0.3257, 0.3290, 0.3322,\n",
       "             0.3355, 0.3388, 0.3420, 0.3453, 0.3453, 0.3485, 0.3518, 0.3550, 0.3583,\n",
       "             0.3616, 0.3648, 0.3681, 0.3713, 0.3746, 0.3779, 0.3811, 0.3844, 0.3876,\n",
       "             0.3909, 0.3941, 0.3974, 0.4007, 0.4039, 0.4072, 0.4104, 0.4137, 0.4169,\n",
       "             0.4202, 0.4235, 0.4267, 0.4300, 0.4332, 0.4365, 0.4397, 0.4430, 0.4463,\n",
       "             0.4495, 0.4528, 0.4560, 0.4593, 0.4625, 0.4658, 0.4691, 0.4723, 0.4756,\n",
       "             0.4788, 0.4821, 0.4853, 0.4886, 0.4919, 0.4951, 0.4984, 0.5016, 0.5049,\n",
       "             0.5081, 0.5114, 0.5147, 0.5179, 0.5212, 0.5244, 0.5277, 0.5309, 0.5342,\n",
       "             0.5375, 0.5407, 0.5440, 0.5472, 0.5505, 0.5537, 0.5570, 0.5603, 0.5635,\n",
       "             0.5668, 0.5700, 0.5733, 0.5765, 0.5798, 0.5831, 0.5863, 0.5896, 0.5928,\n",
       "             0.5961, 0.5993, 0.6026, 0.6059, 0.6091, 0.6124, 0.6156, 0.6189, 0.6221,\n",
       "             0.6254, 0.6287, 0.6319, 0.6352, 0.6384, 0.6417, 0.6450, 0.6482, 0.6515,\n",
       "             0.6547, 0.6580, 0.6612, 0.6645, 0.6678, 0.6710, 0.6743, 0.6775, 0.6808,\n",
       "             0.6840, 0.6873, 0.6906, 0.6938, 0.6971, 0.7003, 0.7036, 0.7068, 0.7101,\n",
       "             0.7134, 0.7166, 0.7199, 0.7231, 0.7264, 0.7296, 0.7329, 0.7362, 0.7394,\n",
       "             0.7427, 0.7459, 0.7492, 0.7524, 0.7557, 0.7590, 0.7622, 0.7655, 0.7687,\n",
       "             0.7720, 0.7752, 0.7785, 0.7818, 0.7850, 0.7883, 0.7915, 0.7948, 0.7980,\n",
       "             0.8013, 0.8046, 0.8078, 0.8111, 0.8143, 0.8176, 0.8208, 0.8241, 0.8274,\n",
       "             0.8306, 0.8339, 0.8371, 0.8404, 0.8436, 0.8469, 0.8502, 0.8534, 0.8567,\n",
       "             0.8599, 0.8632, 0.8664, 0.8697, 0.8730, 0.8762, 0.8795, 0.8827, 0.8860,\n",
       "             0.8893, 0.8925, 0.8958, 0.8990, 0.9023, 0.9055, 0.9088, 0.9121, 0.9153,\n",
       "             0.9186, 0.9218, 0.9251, 0.9283, 0.9316, 0.9349, 0.9381, 0.9414, 0.9446,\n",
       "             0.9479, 0.9511, 0.9544, 0.9577, 0.9609, 0.9642, 0.9674, 0.9707, 0.9739,\n",
       "             0.9772, 0.9805, 0.9837, 0.9870, 0.9902, 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0414, 0.1034, 0.1391, 0.1678, 0.2034, 0.2276, 0.2506, 0.2759,\n",
       "             0.2966, 0.3149, 0.3310, 0.3437, 0.3540, 0.3678, 0.3759, 0.3839, 0.3920,\n",
       "             0.4023, 0.4080, 0.4161, 0.4241, 0.4299, 0.4356, 0.4494, 0.4563, 0.4621,\n",
       "             0.4667, 0.4678, 0.4724, 0.4770, 0.4874, 0.4954, 0.4977, 0.5023, 0.5103,\n",
       "             0.5149, 0.5218, 0.5241, 0.5299, 0.5322, 0.5379, 0.5471, 0.5506, 0.5517,\n",
       "             0.5563, 0.5609, 0.5644, 0.5678, 0.5690, 0.5724, 0.5759, 0.5805, 0.5839,\n",
       "             0.5851, 0.5874, 0.5897, 0.5920, 0.5943, 0.5989, 0.6000, 0.6034, 0.6057,\n",
       "             0.6080, 0.6103, 0.6126, 0.6149, 0.6161, 0.6172, 0.6207, 0.6253, 0.6264,\n",
       "             0.6287, 0.6322, 0.6333, 0.6368, 0.6379, 0.6402, 0.6414, 0.6448, 0.6460,\n",
       "             0.6471, 0.6483, 0.6506, 0.6529, 0.6552, 0.6575, 0.6586, 0.6598, 0.6632,\n",
       "             0.6655, 0.6678, 0.6701, 0.6713, 0.6736, 0.6759, 0.6770, 0.6782, 0.6793,\n",
       "             0.6816, 0.6874, 0.6885, 0.6897, 0.6908, 0.6931, 0.6943, 0.6954, 0.6977,\n",
       "             0.6989, 0.7000, 0.7011, 0.7023, 0.7034, 0.7057, 0.7069, 0.7080, 0.7092,\n",
       "             0.7115, 0.7115, 0.7138, 0.7149, 0.7161, 0.7172, 0.7184, 0.7195, 0.7207,\n",
       "             0.7218, 0.7230, 0.7241, 0.7264, 0.7287, 0.7310, 0.7333, 0.7345, 0.7379,\n",
       "             0.7391, 0.7402, 0.7414, 0.7437, 0.7448, 0.7460, 0.7471, 0.7483, 0.7506,\n",
       "             0.7540, 0.7552, 0.7563, 0.7575, 0.7598, 0.7609, 0.7621, 0.7632, 0.7644,\n",
       "             0.7655, 0.7667, 0.7678, 0.7690, 0.7713, 0.7724, 0.7736, 0.7747, 0.7759,\n",
       "             0.7770, 0.7782, 0.7793, 0.7805, 0.7828, 0.7839, 0.7851, 0.7862, 0.7885,\n",
       "             0.7897, 0.7908, 0.7920, 0.7931, 0.7943, 0.7954, 0.7977, 0.7989, 0.8000,\n",
       "             0.8011, 0.8023, 0.8034, 0.8046, 0.8057, 0.8069, 0.8080, 0.8092, 0.8103,\n",
       "             0.8115, 0.8126, 0.8138, 0.8149, 0.8161, 0.8172, 0.8184, 0.8207, 0.8218,\n",
       "             0.8230, 0.8241, 0.8253, 0.8264, 0.8276, 0.8287, 0.8299, 0.8310, 0.8333,\n",
       "             0.8345, 0.8356, 0.8368, 0.8379, 0.8391, 0.8402, 0.8414, 0.8425, 0.8437,\n",
       "             0.8448, 0.8460, 0.8471, 0.8483, 0.8494, 0.8506, 0.8517, 0.8529, 0.8540,\n",
       "             0.8563, 0.8575, 0.8586, 0.8598, 0.8609, 0.8621, 0.8632, 0.8644, 0.8655,\n",
       "             0.8667, 0.8678, 0.8690, 0.8701, 0.8713, 0.8724, 0.8736, 0.8747, 0.8759,\n",
       "             0.8770, 0.8782, 0.8793, 0.8805, 0.8816, 0.8828, 0.8839, 0.8851, 0.8862,\n",
       "             0.8874, 0.8885, 0.8897, 0.8908, 0.8920, 0.8943, 0.8954, 0.8966, 0.8977,\n",
       "             0.8989, 0.9000, 0.9011, 0.9023, 0.9034, 0.9046, 0.9057, 0.9069, 0.9080,\n",
       "             0.9092, 0.9103, 0.9115, 0.9126, 0.9138, 0.9149, 0.9161, 0.9172, 0.9184,\n",
       "             0.9195, 0.9207, 0.9218, 0.9230, 0.9241, 0.9241, 0.9253, 0.9264, 0.9276,\n",
       "             0.9276, 0.9287, 0.9299, 0.9310, 0.9322, 0.9333, 0.9345, 0.9356, 0.9368,\n",
       "             0.9379, 0.9391, 0.9402, 0.9402, 0.9414, 0.9425, 0.9437, 0.9448, 0.9460,\n",
       "             0.9460, 0.9471, 0.9483, 0.9483, 0.9494, 0.9506, 0.9517, 0.9517, 0.9529,\n",
       "             0.9540, 0.9552, 0.9563, 0.9575, 0.9586, 0.9598, 0.9609, 0.9621, 0.9632,\n",
       "             0.9644, 0.9655, 0.9667, 0.9667, 0.9667, 0.9678, 0.9690, 0.9701, 0.9713,\n",
       "             0.9724, 0.9736, 0.9747, 0.9759, 0.9759, 0.9759, 0.9770, 0.9782, 0.9782,\n",
       "             0.9793, 0.9805, 0.9816, 0.9816, 0.9816, 0.9828, 0.9839, 0.9851, 0.9851,\n",
       "             0.9862, 0.9874, 0.9874, 0.9874, 0.9874, 0.9874, 0.9885, 0.9885, 0.9885,\n",
       "             0.9885, 0.9885, 0.9885, 0.9885, 0.9885, 0.9885, 0.9885, 0.9885, 0.9885,\n",
       "             0.9897, 0.9897, 0.9908, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9931,\n",
       "             0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931,\n",
       "             0.9931, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943,\n",
       "             0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9990e-01, 9.9990e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9987e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01,\n",
       "             9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01,\n",
       "             9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9982e-01, 9.9981e-01, 9.9981e-01,\n",
       "             9.9981e-01, 9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9978e-01, 9.9977e-01,\n",
       "             9.9976e-01, 9.9976e-01, 9.9975e-01, 9.9974e-01, 9.9971e-01, 9.9970e-01,\n",
       "             9.9967e-01, 9.9967e-01, 9.9963e-01, 9.9963e-01, 9.9961e-01, 9.9959e-01,\n",
       "             9.9955e-01, 9.9955e-01, 9.9949e-01, 9.9946e-01, 9.9945e-01, 9.9942e-01,\n",
       "             9.9942e-01, 9.9940e-01, 9.9938e-01, 9.9934e-01, 9.9931e-01, 9.9930e-01,\n",
       "             9.9925e-01, 9.9908e-01, 9.9908e-01, 9.9902e-01, 9.9884e-01, 9.9878e-01,\n",
       "             9.9870e-01, 9.9850e-01, 9.9834e-01, 9.9826e-01, 9.9819e-01, 9.9776e-01,\n",
       "             9.9765e-01, 9.9749e-01, 9.9743e-01, 9.9704e-01, 9.9679e-01, 9.9645e-01,\n",
       "             9.9576e-01, 9.9430e-01, 9.9178e-01, 9.9173e-01, 9.9135e-01, 9.9052e-01,\n",
       "             9.9003e-01, 9.8704e-01, 9.8402e-01, 9.8345e-01, 9.8303e-01, 9.8276e-01,\n",
       "             9.8165e-01, 9.7925e-01, 9.7797e-01, 9.7430e-01, 9.7104e-01, 9.7014e-01,\n",
       "             9.6956e-01, 9.6922e-01, 9.6888e-01, 9.6315e-01, 9.6270e-01, 9.5655e-01,\n",
       "             9.5448e-01, 9.5193e-01, 9.4720e-01, 9.4499e-01, 9.4447e-01, 9.4168e-01,\n",
       "             9.3243e-01, 9.2787e-01, 9.2650e-01, 9.1169e-01, 9.0856e-01, 9.0028e-01,\n",
       "             8.9174e-01, 8.8520e-01, 8.6301e-01, 8.3965e-01, 8.0003e-01, 7.8095e-01,\n",
       "             7.4096e-01, 7.2836e-01, 7.2497e-01, 6.8682e-01, 6.8677e-01, 6.4197e-01,\n",
       "             6.1810e-01, 6.0888e-01, 5.9492e-01, 5.5693e-01, 5.4905e-01, 5.1410e-01,\n",
       "             4.9463e-01, 4.1575e-01, 3.9382e-01, 3.8034e-01, 3.6208e-01, 3.0569e-01,\n",
       "             2.9485e-01, 2.6749e-01, 2.3734e-01, 1.7912e-01, 1.7223e-01, 1.4109e-01,\n",
       "             1.3426e-01, 1.2759e-01, 1.1836e-01, 1.1139e-01, 8.1937e-02, 6.5975e-02,\n",
       "             6.0604e-02, 5.5214e-02, 4.2179e-02, 4.2052e-02, 3.7957e-02, 3.6368e-02,\n",
       "             2.7580e-02, 2.0908e-02, 1.8605e-02, 1.8287e-02, 1.8064e-02, 1.7526e-02,\n",
       "             1.7271e-02, 1.6256e-02, 1.3934e-02, 1.1255e-02, 9.0980e-03, 7.9946e-03,\n",
       "             6.7570e-03, 6.5020e-03, 6.4250e-03, 5.9858e-03, 5.9789e-03, 5.7433e-03,\n",
       "             4.2883e-03, 3.9133e-03, 3.2235e-03, 3.0987e-03, 3.0286e-03, 2.9457e-03,\n",
       "             2.8193e-03, 2.5732e-03, 2.1708e-03, 1.9119e-03, 1.7915e-03, 1.7856e-03,\n",
       "             1.7459e-03, 1.6551e-03, 1.5382e-03, 1.3651e-03, 1.3052e-03, 1.1659e-03,\n",
       "             1.1624e-03, 1.1286e-03, 9.9338e-04, 9.0260e-04, 6.3523e-04, 5.4330e-04,\n",
       "             4.7457e-04, 4.6988e-04, 4.5831e-04, 4.3416e-04, 4.0147e-04, 3.6961e-04,\n",
       "             2.9542e-04, 2.8476e-04, 2.5666e-04, 1.9995e-04, 1.9075e-04, 1.8433e-04,\n",
       "             1.6947e-04, 1.2933e-04, 1.1749e-04, 1.1539e-04, 1.0836e-04, 1.0333e-04,\n",
       "             9.6401e-05, 9.3927e-05, 9.3026e-05, 8.9419e-05, 8.0269e-05, 7.2671e-05,\n",
       "             6.8377e-05, 6.8296e-05, 6.5055e-05, 6.4250e-05, 6.2272e-05, 6.1827e-05,\n",
       "             5.9885e-05, 5.7816e-05, 5.2432e-05, 5.1061e-05, 4.3870e-05, 4.2641e-05,\n",
       "             3.9425e-05, 3.4407e-05, 2.7487e-05, 1.9433e-05, 1.8544e-05, 1.8122e-05,\n",
       "             1.7546e-05, 1.6353e-05, 1.6235e-05, 1.6180e-05, 1.4853e-05, 1.4692e-05,\n",
       "             1.3828e-05, 1.3772e-05, 1.3731e-05, 1.2949e-05, 1.2538e-05, 1.1919e-05,\n",
       "             1.0748e-05, 1.0722e-05, 1.0620e-05, 9.6870e-06, 9.5094e-06, 9.4744e-06,\n",
       "             9.0815e-06, 8.7687e-06, 8.5640e-06, 6.3773e-06, 6.1972e-06, 5.6939e-06,\n",
       "             5.5007e-06, 5.0205e-06, 4.8978e-06, 4.3905e-06, 3.5950e-06, 3.5359e-06,\n",
       "             3.2909e-06, 2.5013e-06, 2.3130e-06, 2.3112e-06, 2.1007e-06, 2.0966e-06,\n",
       "             1.8978e-06, 1.5834e-06, 1.1126e-06, 1.0807e-06, 9.3839e-07, 8.7994e-07,\n",
       "             8.4179e-07, 7.7146e-07, 7.3514e-07, 7.2515e-07, 6.8576e-07, 6.5821e-07,\n",
       "             6.5802e-07, 5.8776e-07, 5.5537e-07, 5.4697e-07, 5.2649e-07, 4.8515e-07,\n",
       "             4.4073e-07, 4.3006e-07, 3.7501e-07, 3.5082e-07, 3.2897e-07, 3.1024e-07,\n",
       "             3.0352e-07, 2.8952e-07, 2.8777e-07, 2.6367e-07, 2.5735e-07, 2.4714e-07,\n",
       "             2.4015e-07, 2.1875e-07, 1.8564e-07, 1.7999e-07, 1.5567e-07, 1.5092e-07,\n",
       "             1.2433e-07, 1.1302e-07, 1.1046e-07, 1.0373e-07, 9.4705e-08, 9.3751e-08,\n",
       "             8.8966e-08, 8.5871e-08, 8.5581e-08, 6.3354e-08, 4.2257e-08, 4.0888e-08,\n",
       "             3.0968e-08, 2.5715e-08, 2.3036e-08, 2.2113e-08, 2.1378e-08, 1.9023e-08,\n",
       "             1.8280e-08, 1.6829e-08, 1.6494e-08, 1.5542e-08, 1.2835e-08, 1.2797e-08,\n",
       "             1.2017e-08, 1.1885e-08, 1.1376e-08, 1.1030e-08, 9.0075e-09, 8.8770e-09,\n",
       "             7.8891e-09, 7.2810e-09, 7.0868e-09, 6.6148e-09, 4.8167e-09, 4.2661e-09,\n",
       "             4.1877e-09, 3.7860e-09, 3.6308e-09, 3.4069e-09, 3.2547e-09, 2.5682e-09,\n",
       "             2.5567e-09, 1.9865e-09, 1.6306e-09, 1.4478e-09, 1.2483e-09, 1.1897e-09,\n",
       "             8.6711e-10, 5.9899e-10, 5.8071e-10, 4.9381e-10, 4.8197e-10, 4.5925e-10,\n",
       "             4.2629e-10, 3.8071e-10, 2.8899e-10, 2.6931e-10, 2.4642e-10, 2.1126e-10,\n",
       "             1.7416e-10, 1.6236e-10, 1.6168e-10, 1.0182e-10, 9.7824e-11, 7.1669e-11,\n",
       "             6.1804e-11, 5.7015e-11, 5.0758e-11, 3.1442e-11, 3.0097e-11, 2.0186e-11,\n",
       "             1.8574e-11, 1.4762e-11, 1.3685e-11, 4.3706e-12, 3.9533e-12, 2.9620e-12,\n",
       "             2.7596e-12, 2.6796e-12, 2.4872e-12, 2.2198e-12, 1.4835e-12, 6.0769e-13,\n",
       "             4.7270e-13, 4.2972e-13, 3.7506e-13, 1.2248e-13, 7.9074e-14, 5.0236e-14,\n",
       "             4.2574e-14, 1.6817e-14, 9.2434e-15, 7.8856e-15, 6.0922e-15, 7.7734e-16,\n",
       "             1.4407e-18, 7.6096e-21])}},\n",
       "   {'fpr': np.float64(0.04234527687296417),\n",
       "    'tpr': np.float64(0.9839080459770115),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0023, 0.0034,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 2.7643e-16, 2.7343e-16,\n",
       "             4.8041e-20])}},\n",
       "   {'fpr': np.float64(0.09771986970684039),\n",
       "    'tpr': np.float64(0.9873563218390805),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,\n",
       "             0.0065, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
       "             0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
       "             0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
       "             0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
       "             0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
       "             0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
       "             0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
       "             0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
       "             0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
       "             0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0163,\n",
       "             0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
       "             0.0195, 0.0228, 0.0228, 0.0261, 0.0293, 0.0293, 0.0326, 0.0326, 0.0358,\n",
       "             0.0391, 0.0391, 0.0391, 0.0391, 0.0391, 0.0391, 0.0423, 0.0423, 0.0423,\n",
       "             0.0423, 0.0423, 0.0423, 0.0423, 0.0456, 0.0456, 0.0489, 0.0489, 0.0489,\n",
       "             0.0521, 0.0521, 0.0554, 0.0554, 0.0586, 0.0586, 0.0619, 0.0651, 0.0651,\n",
       "             0.0651, 0.0651, 0.0684, 0.0717, 0.0749, 0.0782, 0.0814, 0.0814, 0.0814,\n",
       "             0.0847, 0.0879, 0.0912, 0.0945, 0.0977, 0.1010, 0.1042, 0.1042, 0.1075,\n",
       "             0.1107, 0.1107, 0.1140, 0.1140, 0.1173, 0.1205, 0.1205, 0.1238, 0.1270,\n",
       "             0.1303, 0.1336, 0.1368, 0.1401, 0.1433, 0.1466, 0.1466, 0.1498, 0.1531,\n",
       "             0.1564, 0.1596, 0.1629, 0.1661, 0.1694, 0.1726, 0.1726, 0.1759, 0.1759,\n",
       "             0.1792, 0.1824, 0.1857, 0.1889, 0.1922, 0.1954, 0.1987, 0.2020, 0.2052,\n",
       "             0.2085, 0.2117, 0.2150, 0.2182, 0.2215, 0.2248, 0.2280, 0.2313, 0.2345,\n",
       "             0.2378, 0.2410, 0.2443, 0.2476, 0.2508, 0.2541, 0.2573, 0.2573, 0.2606,\n",
       "             0.2638, 0.2671, 0.2704, 0.2736, 0.2769, 0.2801, 0.2834, 0.2866, 0.2899,\n",
       "             0.2932, 0.2964, 0.2997, 0.3029, 0.3062, 0.3094, 0.3127, 0.3160, 0.3192,\n",
       "             0.3225, 0.3257, 0.3290, 0.3322, 0.3355, 0.3388, 0.3420, 0.3453, 0.3485,\n",
       "             0.3518, 0.3550, 0.3583, 0.3616, 0.3648, 0.3681, 0.3713, 0.3746, 0.3779,\n",
       "             0.3811, 0.3844, 0.3876, 0.3909, 0.3941, 0.3941, 0.3974, 0.4007, 0.4039,\n",
       "             0.4072, 0.4104, 0.4137, 0.4169, 0.4202, 0.4235, 0.4267, 0.4300, 0.4332,\n",
       "             0.4365, 0.4397, 0.4430, 0.4463, 0.4495, 0.4528, 0.4528, 0.4560, 0.4593,\n",
       "             0.4625, 0.4658, 0.4691, 0.4723, 0.4756, 0.4788, 0.4821, 0.4853, 0.4886,\n",
       "             0.4919, 0.4951, 0.4984, 0.5016, 0.5049, 0.5081, 0.5114, 0.5147, 0.5179,\n",
       "             0.5212, 0.5244, 0.5277, 0.5309, 0.5342, 0.5375, 0.5407, 0.5440, 0.5472,\n",
       "             0.5505, 0.5537, 0.5570, 0.5603, 0.5635, 0.5668, 0.5700, 0.5733, 0.5765,\n",
       "             0.5798, 0.5831, 0.5863, 0.5896, 0.5928, 0.5961, 0.5961, 0.5993, 0.6026,\n",
       "             0.6059, 0.6091, 0.6124, 0.6156, 0.6189, 0.6221, 0.6254, 0.6287, 0.6319,\n",
       "             0.6352, 0.6384, 0.6417, 0.6450, 0.6482, 0.6515, 0.6547, 0.6580, 0.6612,\n",
       "             0.6645, 0.6678, 0.6710, 0.6743, 0.6775, 0.6808, 0.6840, 0.6873, 0.6906,\n",
       "             0.6938, 0.6971, 0.7003, 0.7036, 0.7068, 0.7101, 0.7134, 0.7166, 0.7199,\n",
       "             0.7231, 0.7264, 0.7296, 0.7329, 0.7362, 0.7394, 0.7427, 0.7459, 0.7492,\n",
       "             0.7524, 0.7557, 0.7590, 0.7622, 0.7655, 0.7687, 0.7720, 0.7752, 0.7785,\n",
       "             0.7818, 0.7850, 0.7883, 0.7915, 0.7948, 0.7980, 0.8013, 0.8046, 0.8078,\n",
       "             0.8111, 0.8143, 0.8176, 0.8208, 0.8241, 0.8274, 0.8306, 0.8339, 0.8371,\n",
       "             0.8404, 0.8436, 0.8469, 0.8502, 0.8534, 0.8567, 0.8599, 0.8632, 0.8664,\n",
       "             0.8697, 0.8730, 0.8762, 0.8795, 0.8827, 0.8860, 0.8893, 0.8925, 0.8958,\n",
       "             0.8990, 0.9023, 0.9055, 0.9088, 0.9121, 0.9153, 0.9186, 0.9218, 0.9251,\n",
       "             0.9283, 0.9316, 0.9349, 0.9381, 0.9414, 0.9446, 0.9479, 0.9511, 0.9544,\n",
       "             0.9577, 0.9609, 0.9642, 0.9674, 0.9707, 0.9739, 0.9772, 0.9805, 0.9837,\n",
       "             0.9870, 0.9902, 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.3782, 0.4690, 0.5080, 0.5368, 0.5586, 0.5736, 0.5874, 0.5977,\n",
       "             0.6046, 0.6126, 0.6253, 0.6345, 0.6414, 0.6471, 0.6517, 0.6575, 0.6621,\n",
       "             0.6678, 0.6701, 0.6747, 0.6759, 0.6805, 0.6851, 0.6897, 0.6943, 0.6977,\n",
       "             0.7000, 0.7057, 0.7069, 0.7103, 0.7126, 0.7138, 0.7172, 0.7195, 0.7207,\n",
       "             0.7218, 0.7230, 0.7241, 0.7276, 0.7310, 0.7345, 0.7356, 0.7379, 0.7414,\n",
       "             0.7425, 0.7448, 0.7460, 0.7494, 0.7517, 0.7540, 0.7552, 0.7563, 0.7575,\n",
       "             0.7586, 0.7598, 0.7632, 0.7644, 0.7655, 0.7678, 0.7690, 0.7713, 0.7736,\n",
       "             0.7747, 0.7770, 0.7793, 0.7805, 0.7816, 0.7839, 0.7851, 0.7862, 0.7874,\n",
       "             0.7885, 0.7897, 0.7908, 0.7920, 0.7931, 0.7966, 0.7977, 0.7989, 0.8000,\n",
       "             0.8011, 0.8011, 0.8023, 0.8057, 0.8069, 0.8080, 0.8092, 0.8103, 0.8115,\n",
       "             0.8126, 0.8138, 0.8149, 0.8161, 0.8172, 0.8184, 0.8195, 0.8207, 0.8218,\n",
       "             0.8230, 0.8241, 0.8253, 0.8264, 0.8276, 0.8287, 0.8299, 0.8310, 0.8322,\n",
       "             0.8333, 0.8345, 0.8356, 0.8379, 0.8391, 0.8402, 0.8414, 0.8437, 0.8448,\n",
       "             0.8460, 0.8460, 0.8471, 0.8483, 0.8494, 0.8506, 0.8517, 0.8529, 0.8540,\n",
       "             0.8552, 0.8563, 0.8575, 0.8598, 0.8609, 0.8621, 0.8632, 0.8644, 0.8655,\n",
       "             0.8667, 0.8678, 0.8690, 0.8701, 0.8713, 0.8724, 0.8736, 0.8747, 0.8759,\n",
       "             0.8770, 0.8782, 0.8793, 0.8805, 0.8816, 0.8828, 0.8839, 0.8862, 0.8874,\n",
       "             0.8885, 0.8897, 0.8908, 0.8920, 0.8931, 0.8943, 0.8954, 0.8966, 0.8977,\n",
       "             0.8989, 0.9000, 0.9011, 0.9023, 0.9034, 0.9046, 0.9057, 0.9069, 0.9080,\n",
       "             0.9092, 0.9103, 0.9115, 0.9126, 0.9138, 0.9149, 0.9161, 0.9172, 0.9184,\n",
       "             0.9195, 0.9207, 0.9218, 0.9230, 0.9241, 0.9253, 0.9264, 0.9276, 0.9287,\n",
       "             0.9299, 0.9310, 0.9322, 0.9333, 0.9345, 0.9356, 0.9368, 0.9379, 0.9391,\n",
       "             0.9402, 0.9414, 0.9425, 0.9437, 0.9448, 0.9460, 0.9471, 0.9483, 0.9483,\n",
       "             0.9483, 0.9494, 0.9506, 0.9517, 0.9529, 0.9540, 0.9552, 0.9563, 0.9575,\n",
       "             0.9586, 0.9586, 0.9598, 0.9598, 0.9598, 0.9609, 0.9609, 0.9621, 0.9621,\n",
       "             0.9621, 0.9632, 0.9644, 0.9655, 0.9667, 0.9678, 0.9678, 0.9690, 0.9701,\n",
       "             0.9713, 0.9724, 0.9736, 0.9747, 0.9747, 0.9759, 0.9759, 0.9770, 0.9782,\n",
       "             0.9782, 0.9793, 0.9793, 0.9805, 0.9805, 0.9816, 0.9816, 0.9816, 0.9828,\n",
       "             0.9839, 0.9851, 0.9851, 0.9851, 0.9851, 0.9851, 0.9851, 0.9862, 0.9874,\n",
       "             0.9874, 0.9874, 0.9874, 0.9874, 0.9874, 0.9874, 0.9874, 0.9885, 0.9885,\n",
       "             0.9885, 0.9897, 0.9897, 0.9908, 0.9908, 0.9908, 0.9920, 0.9920, 0.9920,\n",
       "             0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9931, 0.9931, 0.9931,\n",
       "             0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9943, 0.9943, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9987e-01, 9.9987e-01, 9.9986e-01,\n",
       "             9.9985e-01, 9.9983e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01,\n",
       "             9.9982e-01, 9.9982e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01,\n",
       "             9.9980e-01, 9.9980e-01, 9.9977e-01, 9.9976e-01, 9.9975e-01, 9.9974e-01,\n",
       "             9.9974e-01, 9.9974e-01, 9.9973e-01, 9.9972e-01, 9.9972e-01, 9.9970e-01,\n",
       "             9.9970e-01, 9.9968e-01, 9.9967e-01, 9.9966e-01, 9.9965e-01, 9.9965e-01,\n",
       "             9.9964e-01, 9.9961e-01, 9.9959e-01, 9.9958e-01, 9.9952e-01, 9.9944e-01,\n",
       "             9.9939e-01, 9.9939e-01, 9.9936e-01, 9.9936e-01, 9.9926e-01, 9.9922e-01,\n",
       "             9.9920e-01, 9.9899e-01, 9.9893e-01, 9.9884e-01, 9.9884e-01, 9.9881e-01,\n",
       "             9.9872e-01, 9.9847e-01, 9.9847e-01, 9.9844e-01, 9.9813e-01, 9.9813e-01,\n",
       "             9.9800e-01, 9.9790e-01, 9.9696e-01, 9.9625e-01, 9.9613e-01, 9.9600e-01,\n",
       "             9.9559e-01, 9.9346e-01, 9.9304e-01, 9.9199e-01, 9.9167e-01, 9.9084e-01,\n",
       "             9.9022e-01, 9.8951e-01, 9.8804e-01, 9.8243e-01, 9.8223e-01, 9.8222e-01,\n",
       "             9.8056e-01, 9.7723e-01, 9.7150e-01, 9.7058e-01, 9.6984e-01, 9.6625e-01,\n",
       "             9.6345e-01, 9.6291e-01, 9.5242e-01, 9.4761e-01, 9.4452e-01, 9.2851e-01,\n",
       "             9.1617e-01, 9.1141e-01, 9.0435e-01, 9.0412e-01, 9.0029e-01, 8.9675e-01,\n",
       "             8.9502e-01, 8.9188e-01, 8.8051e-01, 8.7633e-01, 8.6376e-01, 8.6185e-01,\n",
       "             8.0444e-01, 7.9866e-01, 7.8598e-01, 6.6012e-01, 5.8413e-01, 5.7297e-01,\n",
       "             5.4604e-01, 5.4162e-01, 4.5494e-01, 4.5164e-01, 3.8360e-01, 3.4572e-01,\n",
       "             3.0826e-01, 2.6988e-01, 2.6882e-01, 2.4493e-01, 2.2866e-01, 2.0006e-01,\n",
       "             1.2812e-01, 1.2120e-01, 1.0324e-01, 7.0203e-02, 6.7474e-02, 4.3949e-02,\n",
       "             4.3364e-02, 3.3114e-02, 2.4396e-02, 2.4393e-02, 1.5633e-02, 1.2673e-02,\n",
       "             1.1630e-02, 9.8748e-03, 9.0113e-03, 4.7637e-03, 4.1516e-03, 3.9449e-03,\n",
       "             3.6723e-03, 3.2913e-03, 2.5499e-03, 1.8347e-03, 1.7068e-03, 1.3341e-03,\n",
       "             1.2995e-03, 1.2421e-03, 1.1279e-03, 9.9742e-04, 8.7402e-04, 8.6474e-04,\n",
       "             8.2781e-04, 7.2728e-04, 6.5964e-04, 6.3613e-04, 6.1952e-04, 5.0152e-04,\n",
       "             5.0070e-04, 4.3525e-04, 3.9762e-04, 3.9752e-04, 3.7626e-04, 3.6085e-04,\n",
       "             2.1716e-04, 1.9346e-04, 1.6025e-04, 1.4757e-04, 1.3378e-04, 1.2942e-04,\n",
       "             1.2564e-04, 8.5708e-05, 6.0053e-05, 5.6658e-05, 5.0631e-05, 4.9361e-05,\n",
       "             4.5395e-05, 4.3919e-05, 4.1840e-05, 4.0268e-05, 3.4960e-05, 3.4187e-05,\n",
       "             2.7266e-05, 2.5679e-05, 2.0943e-05, 2.0387e-05, 2.0243e-05, 1.9505e-05,\n",
       "             1.8159e-05, 1.6932e-05, 1.3129e-05, 1.1180e-05, 1.0407e-05, 1.0010e-05,\n",
       "             9.5320e-06, 8.5665e-06, 6.6798e-06, 5.2199e-06, 3.8980e-06, 3.8857e-06,\n",
       "             2.9071e-06, 2.5078e-06, 2.4102e-06, 1.5709e-06, 1.4707e-06, 1.4239e-06,\n",
       "             1.2684e-06, 1.1389e-06, 1.0304e-06, 1.0012e-06, 8.4316e-07, 8.0709e-07,\n",
       "             7.3860e-07, 5.0078e-07, 4.6623e-07, 4.0567e-07, 4.0426e-07, 2.8575e-07,\n",
       "             2.7209e-07, 2.5882e-07, 2.5422e-07, 2.4575e-07, 2.2051e-07, 1.7803e-07,\n",
       "             1.7609e-07, 1.7167e-07, 1.6840e-07, 1.6544e-07, 1.6130e-07, 1.5380e-07,\n",
       "             1.4783e-07, 1.4187e-07, 1.3679e-07, 1.2008e-07, 9.0872e-08, 8.5406e-08,\n",
       "             6.7498e-08, 6.7251e-08, 6.6230e-08, 6.3096e-08, 5.7148e-08, 5.2042e-08,\n",
       "             4.3851e-08, 4.2255e-08, 3.3636e-08, 3.1706e-08, 2.9307e-08, 2.8543e-08,\n",
       "             2.6966e-08, 2.4296e-08, 1.8526e-08, 1.3419e-08, 1.2795e-08, 1.1372e-08,\n",
       "             1.0730e-08, 1.0549e-08, 1.0250e-08, 6.2524e-09, 5.9015e-09, 5.8225e-09,\n",
       "             5.5102e-09, 5.4801e-09, 5.2137e-09, 5.2023e-09, 4.6065e-09, 3.9554e-09,\n",
       "             3.5804e-09, 3.5621e-09, 3.5331e-09, 3.2667e-09, 3.0359e-09, 2.8941e-09,\n",
       "             2.7788e-09, 2.7685e-09, 2.3736e-09, 2.2246e-09, 2.0986e-09, 1.9920e-09,\n",
       "             1.7729e-09, 1.5649e-09, 1.5582e-09, 1.3348e-09, 1.2802e-09, 9.3261e-10,\n",
       "             8.4614e-10, 7.4867e-10, 7.4040e-10, 6.6483e-10, 6.3694e-10, 5.9691e-10,\n",
       "             4.3975e-10, 4.2840e-10, 3.7391e-10, 3.6270e-10, 2.4987e-10, 2.4387e-10,\n",
       "             2.3170e-10, 2.0532e-10, 2.0060e-10, 1.9692e-10, 1.6991e-10, 1.2221e-10,\n",
       "             1.2013e-10, 1.0222e-10, 1.0163e-10, 9.1884e-11, 8.8632e-11, 6.4194e-11,\n",
       "             5.8958e-11, 5.5513e-11, 5.4055e-11, 4.1409e-11, 3.9722e-11, 3.3512e-11,\n",
       "             2.9758e-11, 2.5905e-11, 2.4786e-11, 2.3457e-11, 2.0936e-11, 1.4142e-11,\n",
       "             9.2129e-12, 8.6717e-12, 8.5043e-12, 7.9353e-12, 7.0145e-12, 5.7313e-12,\n",
       "             5.6063e-12, 4.7422e-12, 3.7463e-12, 2.7882e-12, 2.5217e-12, 2.0905e-12,\n",
       "             2.0764e-12, 1.5886e-12, 1.5250e-12, 1.4539e-12, 9.0989e-13, 8.0342e-13,\n",
       "             7.7908e-13, 7.4713e-13, 7.0434e-13, 6.4507e-13, 6.4426e-13, 5.8715e-13,\n",
       "             5.2868e-13, 3.9695e-13, 3.7366e-13, 3.5262e-13, 3.5014e-13, 3.1289e-13,\n",
       "             2.7373e-13, 2.5930e-13, 1.9469e-13, 1.8037e-13, 1.7459e-13, 1.5266e-13,\n",
       "             1.0141e-13, 7.9443e-14, 6.7057e-14, 6.6785e-14, 5.5097e-14, 4.7392e-14,\n",
       "             4.3886e-14, 4.3481e-14, 4.3187e-14, 3.8722e-14, 3.6286e-14, 1.8950e-14,\n",
       "             1.8386e-14, 1.5228e-14, 1.1074e-14, 5.7466e-15, 4.4986e-15, 2.4932e-15,\n",
       "             1.7114e-15, 9.2564e-16, 8.7869e-16, 5.7563e-16, 4.1172e-16, 3.3619e-16,\n",
       "             3.0930e-16, 2.1111e-16, 1.9483e-16, 6.9953e-17, 2.9938e-17, 2.6411e-17,\n",
       "             1.5826e-17, 1.3799e-17, 8.6584e-18, 6.9443e-18, 3.8188e-18, 3.5587e-18,\n",
       "             1.3885e-18, 5.9354e-19, 1.1461e-19, 1.6392e-20, 4.7275e-21, 1.5034e-21,\n",
       "             1.9517e-23, 3.6825e-27])}},\n",
       "   {'fpr': np.float64(0.10097719869706841),\n",
       "    'tpr': np.float64(0.9919540229885058),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,\n",
       "             0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,\n",
       "             0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,\n",
       "             0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,\n",
       "             0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,\n",
       "             0.0065, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0130, 0.0130, 0.0130, 0.0130, 0.0163, 0.0195,\n",
       "             0.0195, 0.0195, 0.0195, 0.0228, 0.0228, 0.0228, 0.0228, 0.0228, 0.0261,\n",
       "             0.0261, 0.0293, 0.0293, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0358,\n",
       "             0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0391, 0.0391, 0.0391,\n",
       "             0.0423, 0.0423, 0.0423, 0.0423, 0.0423, 0.0456, 0.0489, 0.0489, 0.0489,\n",
       "             0.0521, 0.0521, 0.0554, 0.0554, 0.0586, 0.0619, 0.0651, 0.0684, 0.0684,\n",
       "             0.0717, 0.0717, 0.0717, 0.0749, 0.0782, 0.0782, 0.0814, 0.0847, 0.0847,\n",
       "             0.0879, 0.0912, 0.0945, 0.0977, 0.1010, 0.1042, 0.1075, 0.1107, 0.1107,\n",
       "             0.1140, 0.1173, 0.1205, 0.1238, 0.1270, 0.1303, 0.1336, 0.1368, 0.1401,\n",
       "             0.1433, 0.1466, 0.1498, 0.1498, 0.1531, 0.1564, 0.1596, 0.1629, 0.1629,\n",
       "             0.1629, 0.1661, 0.1694, 0.1726, 0.1759, 0.1792, 0.1792, 0.1824, 0.1857,\n",
       "             0.1889, 0.1922, 0.1954, 0.1954, 0.1954, 0.1987, 0.2020, 0.2052, 0.2085,\n",
       "             0.2117, 0.2150, 0.2182, 0.2215, 0.2248, 0.2280, 0.2313, 0.2345, 0.2378,\n",
       "             0.2410, 0.2443, 0.2476, 0.2508, 0.2541, 0.2573, 0.2606, 0.2638, 0.2671,\n",
       "             0.2704, 0.2736, 0.2769, 0.2801, 0.2834, 0.2866, 0.2899, 0.2932, 0.2964,\n",
       "             0.2997, 0.3029, 0.3062, 0.3094, 0.3127, 0.3160, 0.3192, 0.3225, 0.3257,\n",
       "             0.3290, 0.3322, 0.3355, 0.3388, 0.3420, 0.3453, 0.3485, 0.3518, 0.3550,\n",
       "             0.3583, 0.3616, 0.3648, 0.3681, 0.3713, 0.3746, 0.3779, 0.3811, 0.3844,\n",
       "             0.3876, 0.3909, 0.3941, 0.3974, 0.4007, 0.4039, 0.4072, 0.4104, 0.4137,\n",
       "             0.4169, 0.4202, 0.4235, 0.4267, 0.4300, 0.4332, 0.4365, 0.4397, 0.4430,\n",
       "             0.4463, 0.4495, 0.4528, 0.4560, 0.4593, 0.4625, 0.4658, 0.4691, 0.4723,\n",
       "             0.4756, 0.4788, 0.4821, 0.4853, 0.4886, 0.4919, 0.4951, 0.4984, 0.5016,\n",
       "             0.5049, 0.5081, 0.5114, 0.5147, 0.5179, 0.5212, 0.5244, 0.5277, 0.5309,\n",
       "             0.5342, 0.5375, 0.5407, 0.5440, 0.5472, 0.5505, 0.5537, 0.5570, 0.5603,\n",
       "             0.5635, 0.5668, 0.5700, 0.5733, 0.5765, 0.5798, 0.5831, 0.5863, 0.5896,\n",
       "             0.5928, 0.5961, 0.5993, 0.6026, 0.6059, 0.6091, 0.6124, 0.6156, 0.6189,\n",
       "             0.6221, 0.6254, 0.6287, 0.6319, 0.6352, 0.6384, 0.6417, 0.6450, 0.6482,\n",
       "             0.6515, 0.6547, 0.6580, 0.6612, 0.6645, 0.6678, 0.6710, 0.6743, 0.6775,\n",
       "             0.6808, 0.6840, 0.6873, 0.6906, 0.6938, 0.6971, 0.7003, 0.7036, 0.7068,\n",
       "             0.7101, 0.7134, 0.7166, 0.7199, 0.7231, 0.7264, 0.7296, 0.7329, 0.7362,\n",
       "             0.7394, 0.7427, 0.7459, 0.7492, 0.7524, 0.7557, 0.7590, 0.7622, 0.7655,\n",
       "             0.7687, 0.7720, 0.7752, 0.7785, 0.7818, 0.7850, 0.7883, 0.7915, 0.7948,\n",
       "             0.7980, 0.8013, 0.8046, 0.8078, 0.8111, 0.8143, 0.8176, 0.8208, 0.8241,\n",
       "             0.8274, 0.8306, 0.8339, 0.8371, 0.8404, 0.8436, 0.8469, 0.8502, 0.8534,\n",
       "             0.8567, 0.8599, 0.8632, 0.8664, 0.8697, 0.8730, 0.8762, 0.8795, 0.8827,\n",
       "             0.8860, 0.8893, 0.8925, 0.8958, 0.8990, 0.9023, 0.9055, 0.9088, 0.9121,\n",
       "             0.9153, 0.9186, 0.9218, 0.9251, 0.9283, 0.9316, 0.9349, 0.9381, 0.9414,\n",
       "             0.9446, 0.9479, 0.9511, 0.9544, 0.9577, 0.9609, 0.9642, 0.9674, 0.9707,\n",
       "             0.9739, 0.9772, 0.9805, 0.9837, 0.9870, 0.9902, 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0678, 0.1149, 0.1471, 0.1759, 0.1943, 0.2069, 0.2264, 0.2368,\n",
       "             0.2529, 0.2644, 0.2747, 0.2885, 0.3023, 0.3115, 0.3195, 0.3218, 0.3276,\n",
       "             0.3356, 0.3402, 0.3460, 0.3552, 0.3632, 0.3736, 0.3759, 0.3793, 0.3897,\n",
       "             0.3966, 0.4057, 0.4092, 0.4149, 0.4195, 0.4230, 0.4310, 0.4368, 0.4391,\n",
       "             0.4460, 0.4506, 0.4529, 0.4563, 0.4609, 0.4644, 0.4713, 0.4724, 0.4736,\n",
       "             0.4770, 0.4816, 0.4862, 0.4874, 0.4908, 0.4954, 0.4966, 0.5023, 0.5034,\n",
       "             0.5057, 0.5080, 0.5092, 0.5103, 0.5149, 0.5195, 0.5230, 0.5264, 0.5287,\n",
       "             0.5299, 0.5322, 0.5333, 0.5356, 0.5402, 0.5425, 0.5437, 0.5448, 0.5471,\n",
       "             0.5506, 0.5529, 0.5540, 0.5552, 0.5563, 0.5586, 0.5598, 0.5609, 0.5621,\n",
       "             0.5655, 0.5667, 0.5701, 0.5736, 0.5782, 0.5793, 0.5805, 0.5816, 0.5828,\n",
       "             0.5851, 0.5885, 0.5897, 0.5920, 0.5931, 0.5943, 0.5954, 0.5989, 0.6011,\n",
       "             0.6046, 0.6092, 0.6115, 0.6126, 0.6138, 0.6149, 0.6161, 0.6172, 0.6184,\n",
       "             0.6207, 0.6230, 0.6241, 0.6264, 0.6276, 0.6287, 0.6310, 0.6322, 0.6356,\n",
       "             0.6368, 0.6379, 0.6391, 0.6402, 0.6414, 0.6425, 0.6437, 0.6448, 0.6460,\n",
       "             0.6471, 0.6483, 0.6494, 0.6517, 0.6552, 0.6563, 0.6598, 0.6609, 0.6621,\n",
       "             0.6644, 0.6655, 0.6678, 0.6690, 0.6713, 0.6724, 0.6736, 0.6747, 0.6759,\n",
       "             0.6770, 0.6782, 0.6793, 0.6816, 0.6828, 0.6839, 0.6851, 0.6874, 0.6908,\n",
       "             0.6920, 0.6931, 0.6943, 0.6954, 0.6966, 0.6977, 0.7000, 0.7011, 0.7023,\n",
       "             0.7034, 0.7046, 0.7069, 0.7092, 0.7103, 0.7115, 0.7126, 0.7138, 0.7161,\n",
       "             0.7184, 0.7195, 0.7207, 0.7218, 0.7230, 0.7241, 0.7253, 0.7264, 0.7276,\n",
       "             0.7287, 0.7299, 0.7310, 0.7322, 0.7333, 0.7345, 0.7368, 0.7379, 0.7391,\n",
       "             0.7402, 0.7414, 0.7425, 0.7437, 0.7460, 0.7471, 0.7483, 0.7494, 0.7506,\n",
       "             0.7517, 0.7529, 0.7540, 0.7552, 0.7563, 0.7586, 0.7609, 0.7621, 0.7632,\n",
       "             0.7644, 0.7655, 0.7667, 0.7678, 0.7690, 0.7701, 0.7713, 0.7724, 0.7736,\n",
       "             0.7747, 0.7759, 0.7770, 0.7793, 0.7805, 0.7816, 0.7828, 0.7839, 0.7851,\n",
       "             0.7862, 0.7874, 0.7885, 0.7897, 0.7908, 0.7920, 0.7943, 0.7954, 0.7966,\n",
       "             0.7977, 0.7989, 0.8000, 0.8011, 0.8023, 0.8034, 0.8057, 0.8069, 0.8080,\n",
       "             0.8092, 0.8103, 0.8115, 0.8126, 0.8138, 0.8149, 0.8161, 0.8172, 0.8184,\n",
       "             0.8195, 0.8207, 0.8218, 0.8230, 0.8241, 0.8253, 0.8264, 0.8287, 0.8299,\n",
       "             0.8310, 0.8322, 0.8333, 0.8345, 0.8356, 0.8368, 0.8391, 0.8402, 0.8414,\n",
       "             0.8425, 0.8437, 0.8448, 0.8460, 0.8471, 0.8483, 0.8494, 0.8506, 0.8517,\n",
       "             0.8529, 0.8540, 0.8552, 0.8563, 0.8575, 0.8586, 0.8598, 0.8609, 0.8621,\n",
       "             0.8632, 0.8644, 0.8667, 0.8678, 0.8690, 0.8701, 0.8713, 0.8724, 0.8736,\n",
       "             0.8747, 0.8759, 0.8770, 0.8782, 0.8793, 0.8805, 0.8816, 0.8828, 0.8839,\n",
       "             0.8851, 0.8851, 0.8862, 0.8874, 0.8885, 0.8897, 0.8908, 0.8920, 0.8931,\n",
       "             0.8943, 0.8954, 0.8966, 0.8977, 0.8989, 0.9000, 0.9011, 0.9023, 0.9034,\n",
       "             0.9046, 0.9057, 0.9069, 0.9080, 0.9092, 0.9103, 0.9115, 0.9126, 0.9138,\n",
       "             0.9149, 0.9161, 0.9172, 0.9184, 0.9195, 0.9207, 0.9218, 0.9230, 0.9241,\n",
       "             0.9253, 0.9264, 0.9276, 0.9299, 0.9310, 0.9322, 0.9333, 0.9345, 0.9356,\n",
       "             0.9368, 0.9379, 0.9391, 0.9402, 0.9414, 0.9425, 0.9437, 0.9448, 0.9460,\n",
       "             0.9471, 0.9483, 0.9494, 0.9494, 0.9506, 0.9517, 0.9529, 0.9529, 0.9529,\n",
       "             0.9540, 0.9552, 0.9563, 0.9563, 0.9575, 0.9586, 0.9598, 0.9609, 0.9609,\n",
       "             0.9621, 0.9621, 0.9632, 0.9632, 0.9644, 0.9655, 0.9667, 0.9678, 0.9678,\n",
       "             0.9690, 0.9701, 0.9713, 0.9724, 0.9736, 0.9747, 0.9747, 0.9759, 0.9770,\n",
       "             0.9770, 0.9782, 0.9793, 0.9805, 0.9816, 0.9816, 0.9816, 0.9828, 0.9839,\n",
       "             0.9839, 0.9851, 0.9851, 0.9862, 0.9862, 0.9862, 0.9862, 0.9862, 0.9874,\n",
       "             0.9874, 0.9885, 0.9897, 0.9897, 0.9897, 0.9908, 0.9908, 0.9908, 0.9920,\n",
       "             0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9931,\n",
       "             0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931,\n",
       "             0.9931, 0.9931, 0.9931, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9954,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9986e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9985e-01, 9.9985e-01,\n",
       "             9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01,\n",
       "             9.9983e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01,\n",
       "             9.9982e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01, 9.9979e-01,\n",
       "             9.9979e-01, 9.9978e-01, 9.9978e-01, 9.9977e-01, 9.9977e-01, 9.9976e-01,\n",
       "             9.9976e-01, 9.9975e-01, 9.9975e-01, 9.9974e-01, 9.9974e-01, 9.9973e-01,\n",
       "             9.9973e-01, 9.9973e-01, 9.9972e-01, 9.9972e-01, 9.9972e-01, 9.9971e-01,\n",
       "             9.9971e-01, 9.9971e-01, 9.9970e-01, 9.9967e-01, 9.9967e-01, 9.9965e-01,\n",
       "             9.9964e-01, 9.9964e-01, 9.9962e-01, 9.9961e-01, 9.9960e-01, 9.9959e-01,\n",
       "             9.9956e-01, 9.9950e-01, 9.9945e-01, 9.9945e-01, 9.9940e-01, 9.9940e-01,\n",
       "             9.9937e-01, 9.9937e-01, 9.9936e-01, 9.9935e-01, 9.9932e-01, 9.9932e-01,\n",
       "             9.9925e-01, 9.9918e-01, 9.9917e-01, 9.9915e-01, 9.9907e-01, 9.9904e-01,\n",
       "             9.9891e-01, 9.9889e-01, 9.9875e-01, 9.9871e-01, 9.9870e-01, 9.9856e-01,\n",
       "             9.9814e-01, 9.9805e-01, 9.9804e-01, 9.9789e-01, 9.9784e-01, 9.9758e-01,\n",
       "             9.9741e-01, 9.9732e-01, 9.9706e-01, 9.9696e-01, 9.9593e-01, 9.9590e-01,\n",
       "             9.9586e-01, 9.9547e-01, 9.9416e-01, 9.9297e-01, 9.9219e-01, 9.9105e-01,\n",
       "             9.9070e-01, 9.9054e-01, 9.9016e-01, 9.8956e-01, 9.8940e-01, 9.8777e-01,\n",
       "             9.8438e-01, 9.8241e-01, 9.8156e-01, 9.8029e-01, 9.7996e-01, 9.7422e-01,\n",
       "             9.7166e-01, 9.6590e-01, 9.6134e-01, 9.6075e-01, 9.5926e-01, 9.5035e-01,\n",
       "             9.4447e-01, 9.3930e-01, 9.2147e-01, 9.1811e-01, 8.9488e-01, 8.9041e-01,\n",
       "             8.8100e-01, 8.7280e-01, 8.6244e-01, 8.0915e-01, 8.0055e-01, 7.9973e-01,\n",
       "             6.5120e-01, 5.8015e-01, 4.8745e-01, 4.6553e-01, 4.5896e-01, 4.4619e-01,\n",
       "             4.3885e-01, 3.9628e-01, 3.6930e-01, 3.5925e-01, 3.5414e-01, 3.3104e-01,\n",
       "             2.1664e-01, 1.9269e-01, 1.9219e-01, 1.6442e-01, 1.5866e-01, 1.4438e-01,\n",
       "             1.3321e-01, 1.2527e-01, 1.1452e-01, 1.1264e-01, 8.5215e-02, 6.8434e-02,\n",
       "             4.3517e-02, 3.7875e-02, 3.5798e-02, 3.2913e-02, 2.6401e-02, 2.6258e-02,\n",
       "             2.1116e-02, 1.4696e-02, 1.4442e-02, 1.3120e-02, 1.2718e-02, 1.2386e-02,\n",
       "             1.2121e-02, 1.0369e-02, 8.4407e-03, 7.1779e-03, 6.3945e-03, 6.1934e-03,\n",
       "             6.0073e-03, 5.7138e-03, 5.2611e-03, 5.1392e-03, 2.8693e-03, 2.8394e-03,\n",
       "             2.2969e-03, 1.9845e-03, 1.9263e-03, 1.8695e-03, 1.8611e-03, 1.7550e-03,\n",
       "             1.7333e-03, 1.7121e-03, 1.3448e-03, 1.3214e-03, 1.1134e-03, 9.6958e-04,\n",
       "             5.7092e-04, 4.7745e-04, 4.7075e-04, 4.5386e-04, 4.3645e-04, 4.2557e-04,\n",
       "             4.2455e-04, 3.6097e-04, 3.5109e-04, 3.3412e-04, 3.3260e-04, 3.1376e-04,\n",
       "             3.0379e-04, 3.0129e-04, 2.8897e-04, 2.6410e-04, 1.5190e-04, 1.1697e-04,\n",
       "             1.1144e-04, 9.7797e-05, 9.0482e-05, 8.4457e-05, 8.3666e-05, 6.4592e-05,\n",
       "             6.4115e-05, 6.3919e-05, 6.3387e-05, 6.1487e-05, 5.4799e-05, 4.9111e-05,\n",
       "             4.6658e-05, 3.9171e-05, 3.1601e-05, 3.1303e-05, 3.0248e-05, 2.9544e-05,\n",
       "             2.7041e-05, 2.6639e-05, 2.5154e-05, 2.5073e-05, 2.2353e-05, 2.0154e-05,\n",
       "             1.7645e-05, 1.7559e-05, 1.7369e-05, 1.6191e-05, 1.5536e-05, 1.4340e-05,\n",
       "             1.3882e-05, 1.3344e-05, 1.1909e-05, 1.0818e-05, 9.5869e-06, 9.5774e-06,\n",
       "             9.0463e-06, 8.8431e-06, 6.6371e-06, 5.0889e-06, 4.6608e-06, 4.5413e-06,\n",
       "             4.3050e-06, 3.6752e-06, 3.6336e-06, 2.8554e-06, 2.6596e-06, 2.6384e-06,\n",
       "             2.5252e-06, 2.4992e-06, 2.4393e-06, 2.2802e-06, 2.2481e-06, 2.1881e-06,\n",
       "             1.8388e-06, 1.6673e-06, 1.4584e-06, 1.3513e-06, 1.1960e-06, 1.1882e-06,\n",
       "             9.7368e-07, 9.1552e-07, 8.6922e-07, 7.5976e-07, 6.6324e-07, 6.4426e-07,\n",
       "             5.7016e-07, 5.2572e-07, 4.8927e-07, 4.7348e-07, 4.6771e-07, 4.6328e-07,\n",
       "             4.5226e-07, 4.4374e-07, 4.4363e-07, 3.5775e-07, 3.3208e-07, 2.9304e-07,\n",
       "             2.8233e-07, 2.5940e-07, 2.2791e-07, 2.1451e-07, 1.9918e-07, 1.9752e-07,\n",
       "             1.7329e-07, 1.6964e-07, 1.4778e-07, 1.3140e-07, 9.8608e-08, 9.6355e-08,\n",
       "             9.3034e-08, 7.3228e-08, 6.6734e-08, 5.9012e-08, 5.6352e-08, 5.4704e-08,\n",
       "             5.0422e-08, 4.9995e-08, 4.6170e-08, 3.5381e-08, 3.3738e-08, 3.1314e-08,\n",
       "             3.0089e-08, 2.8853e-08, 2.7305e-08, 2.6898e-08, 2.4658e-08, 2.1200e-08,\n",
       "             1.9117e-08, 1.8527e-08, 1.7402e-08, 1.3941e-08, 1.1524e-08, 1.1042e-08,\n",
       "             9.7984e-09, 9.6867e-09, 9.3474e-09, 9.1447e-09, 8.8996e-09, 8.4158e-09,\n",
       "             8.3996e-09, 5.3876e-09, 4.9513e-09, 4.2444e-09, 4.1772e-09, 3.7363e-09,\n",
       "             3.4097e-09, 3.2546e-09, 2.9561e-09, 2.2005e-09, 1.8214e-09, 1.5845e-09,\n",
       "             1.5010e-09, 1.1694e-09, 1.1173e-09, 8.9433e-10, 8.8256e-10, 8.5948e-10,\n",
       "             8.5218e-10, 7.8654e-10, 7.1001e-10, 6.5226e-10, 5.9843e-10, 4.9850e-10,\n",
       "             4.5118e-10, 4.1799e-10, 3.9940e-10, 3.4257e-10, 3.1786e-10, 2.9726e-10,\n",
       "             2.8368e-10, 2.2069e-10, 2.1015e-10, 2.0713e-10, 2.0443e-10, 2.0400e-10,\n",
       "             1.8765e-10, 1.3487e-10, 1.2096e-10, 8.8842e-11, 8.2925e-11, 8.2289e-11,\n",
       "             7.1906e-11, 7.1142e-11, 5.4525e-11, 5.0830e-11, 2.9036e-11, 2.7332e-11,\n",
       "             2.1944e-11, 2.0110e-11, 1.6916e-11, 1.5131e-11, 1.3974e-11, 8.6244e-12,\n",
       "             8.4482e-12, 7.6893e-12, 4.5732e-12, 3.1500e-12, 2.6301e-12, 1.1981e-12,\n",
       "             1.1711e-12, 1.0194e-12, 6.3526e-13, 4.9402e-13, 4.3088e-13, 3.7284e-13,\n",
       "             2.6769e-13, 2.2911e-13, 2.2336e-13, 2.2317e-13, 8.1962e-14, 1.9042e-14,\n",
       "             1.0246e-14, 7.5566e-15, 1.4230e-15, 1.3032e-15, 8.3465e-16, 7.0545e-16,\n",
       "             4.6836e-16, 4.3261e-16, 3.3479e-16, 6.8222e-17, 5.6809e-17, 6.6368e-18,\n",
       "             4.0896e-19, 8.8062e-21, 3.9739e-24])}},\n",
       "   {'fpr': np.float64(0.20846905537459284),\n",
       "    'tpr': np.float64(0.9942528735632183),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0033, 0.0098, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0130,\n",
       "             0.0130, 0.0130, 0.0130, 0.0130, 0.0163, 0.0163, 0.0163, 0.0163, 0.0163,\n",
       "             0.0163, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
       "             0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
       "             0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
       "             0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
       "             0.0195, 0.0228, 0.0228, 0.0228, 0.0228, 0.0228, 0.0228, 0.0228, 0.0228,\n",
       "             0.0228, 0.0228, 0.0228, 0.0228, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261,\n",
       "             0.0261, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261,\n",
       "             0.0261, 0.0293, 0.0293, 0.0293, 0.0293, 0.0293, 0.0293, 0.0293, 0.0293,\n",
       "             0.0293, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326,\n",
       "             0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0358, 0.0358,\n",
       "             0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0391, 0.0391,\n",
       "             0.0391, 0.0391, 0.0391, 0.0391, 0.0391, 0.0391, 0.0423, 0.0423, 0.0456,\n",
       "             0.0456, 0.0456, 0.0456, 0.0456, 0.0489, 0.0489, 0.0489, 0.0489, 0.0489,\n",
       "             0.0489, 0.0489, 0.0489, 0.0489, 0.0489, 0.0489, 0.0489, 0.0489, 0.0521,\n",
       "             0.0521, 0.0521, 0.0521, 0.0554, 0.0586, 0.0619, 0.0619, 0.0651, 0.0651,\n",
       "             0.0651, 0.0651, 0.0651, 0.0684, 0.0717, 0.0749, 0.0749, 0.0749, 0.0749,\n",
       "             0.0749, 0.0749, 0.0749, 0.0749, 0.0749, 0.0749, 0.0749, 0.0782, 0.0782,\n",
       "             0.0814, 0.0814, 0.0847, 0.0847, 0.0879, 0.0879, 0.0912, 0.0945, 0.0945,\n",
       "             0.0945, 0.0945, 0.0945, 0.0945, 0.0977, 0.1010, 0.1042, 0.1075, 0.1107,\n",
       "             0.1140, 0.1173, 0.1173, 0.1205, 0.1205, 0.1205, 0.1205, 0.1205, 0.1238,\n",
       "             0.1270, 0.1303, 0.1303, 0.1303, 0.1336, 0.1336, 0.1336, 0.1368, 0.1401,\n",
       "             0.1433, 0.1466, 0.1498, 0.1531, 0.1531, 0.1564, 0.1564, 0.1596, 0.1629,\n",
       "             0.1629, 0.1661, 0.1694, 0.1726, 0.1759, 0.1792, 0.1824, 0.1857, 0.1889,\n",
       "             0.1922, 0.1954, 0.1987, 0.2020, 0.2052, 0.2085, 0.2117, 0.2150, 0.2182,\n",
       "             0.2215, 0.2215, 0.2248, 0.2280, 0.2313, 0.2345, 0.2378, 0.2410, 0.2443,\n",
       "             0.2476, 0.2508, 0.2541, 0.2573, 0.2606, 0.2638, 0.2671, 0.2704, 0.2736,\n",
       "             0.2769, 0.2801, 0.2834, 0.2866, 0.2899, 0.2932, 0.2964, 0.2997, 0.3029,\n",
       "             0.3062, 0.3094, 0.3127, 0.3160, 0.3192, 0.3225, 0.3257, 0.3290, 0.3290,\n",
       "             0.3290, 0.3322, 0.3355, 0.3388, 0.3420, 0.3453, 0.3485, 0.3518, 0.3550,\n",
       "             0.3583, 0.3616, 0.3648, 0.3681, 0.3713, 0.3746, 0.3779, 0.3811, 0.3844,\n",
       "             0.3876, 0.3909, 0.3941, 0.3974, 0.4007, 0.4039, 0.4072, 0.4104, 0.4137,\n",
       "             0.4169, 0.4202, 0.4235, 0.4267, 0.4300, 0.4332, 0.4365, 0.4397, 0.4430,\n",
       "             0.4463, 0.4495, 0.4528, 0.4560, 0.4593, 0.4593, 0.4625, 0.4658, 0.4691,\n",
       "             0.4723, 0.4756, 0.4788, 0.4821, 0.4853, 0.4886, 0.4919, 0.4951, 0.4984,\n",
       "             0.5016, 0.5049, 0.5081, 0.5114, 0.5147, 0.5179, 0.5212, 0.5244, 0.5277,\n",
       "             0.5309, 0.5342, 0.5375, 0.5407, 0.5440, 0.5472, 0.5505, 0.5537, 0.5570,\n",
       "             0.5603, 0.5635, 0.5668, 0.5700, 0.5733, 0.5765, 0.5798, 0.5831, 0.5831,\n",
       "             0.5863, 0.5896, 0.5928, 0.5961, 0.5993, 0.6026, 0.6059, 0.6091, 0.6124,\n",
       "             0.6156, 0.6189, 0.6221, 0.6254, 0.6287, 0.6319, 0.6352, 0.6384, 0.6417,\n",
       "             0.6450, 0.6482, 0.6515, 0.6547, 0.6580, 0.6612, 0.6645, 0.6678, 0.6710,\n",
       "             0.6743, 0.6775, 0.6808, 0.6840, 0.6873, 0.6906, 0.6938, 0.6971, 0.7003,\n",
       "             0.7036, 0.7068, 0.7101, 0.7134, 0.7166, 0.7199, 0.7231, 0.7264, 0.7296,\n",
       "             0.7329, 0.7362, 0.7394, 0.7427, 0.7459, 0.7492, 0.7524, 0.7557, 0.7590,\n",
       "             0.7622, 0.7655, 0.7687, 0.7720, 0.7752, 0.7785, 0.7818, 0.7850, 0.7883,\n",
       "             0.7915, 0.7948, 0.7980, 0.8013, 0.8046, 0.8078, 0.8111, 0.8143, 0.8176,\n",
       "             0.8208, 0.8241, 0.8274, 0.8306, 0.8339, 0.8371, 0.8404, 0.8436, 0.8469,\n",
       "             0.8502, 0.8534, 0.8567, 0.8599, 0.8632, 0.8664, 0.8697, 0.8730, 0.8762,\n",
       "             0.8795, 0.8827, 0.8860, 0.8893, 0.8925, 0.8958, 0.8990, 0.9023, 0.9055,\n",
       "             0.9088, 0.9121, 0.9153, 0.9186, 0.9218, 0.9251, 0.9283, 0.9316, 0.9349,\n",
       "             0.9381, 0.9414, 0.9446, 0.9479, 0.9511, 0.9544, 0.9577, 0.9609, 0.9642,\n",
       "             0.9674, 0.9707, 0.9739, 0.9772, 0.9805, 0.9837, 0.9870, 0.9902, 0.9935,\n",
       "             0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.5621, 0.6356, 0.6736, 0.7000, 0.7115, 0.7253, 0.7345, 0.7379,\n",
       "             0.7460, 0.7552, 0.7563, 0.7598, 0.7655, 0.7678, 0.7690, 0.7713, 0.7724,\n",
       "             0.7736, 0.7782, 0.7816, 0.7851, 0.7874, 0.7897, 0.7920, 0.7966, 0.7977,\n",
       "             0.8000, 0.8023, 0.8069, 0.8080, 0.8103, 0.8126, 0.8138, 0.8149, 0.8161,\n",
       "             0.8207, 0.8218, 0.8230, 0.8264, 0.8287, 0.8299, 0.8310, 0.8322, 0.8345,\n",
       "             0.8356, 0.8379, 0.8391, 0.8402, 0.8414, 0.8425, 0.8460, 0.8483, 0.8494,\n",
       "             0.8506, 0.8506, 0.8517, 0.8540, 0.8552, 0.8563, 0.8575, 0.8586, 0.8598,\n",
       "             0.8609, 0.8621, 0.8632, 0.8655, 0.8655, 0.8678, 0.8690, 0.8701, 0.8724,\n",
       "             0.8736, 0.8759, 0.8770, 0.8782, 0.8805, 0.8816, 0.8828, 0.8839, 0.8851,\n",
       "             0.8862, 0.8862, 0.8874, 0.8885, 0.8897, 0.8908, 0.8920, 0.8931, 0.8943,\n",
       "             0.8954, 0.8954, 0.8966, 0.8977, 0.8989, 0.9000, 0.9011, 0.9023, 0.9034,\n",
       "             0.9046, 0.9057, 0.9069, 0.9080, 0.9092, 0.9103, 0.9126, 0.9126, 0.9138,\n",
       "             0.9149, 0.9161, 0.9172, 0.9184, 0.9195, 0.9207, 0.9218, 0.9218, 0.9230,\n",
       "             0.9241, 0.9253, 0.9264, 0.9276, 0.9287, 0.9299, 0.9299, 0.9310, 0.9310,\n",
       "             0.9322, 0.9333, 0.9345, 0.9356, 0.9356, 0.9368, 0.9379, 0.9391, 0.9402,\n",
       "             0.9414, 0.9425, 0.9437, 0.9448, 0.9460, 0.9471, 0.9483, 0.9494, 0.9494,\n",
       "             0.9506, 0.9517, 0.9529, 0.9529, 0.9529, 0.9529, 0.9540, 0.9540, 0.9552,\n",
       "             0.9563, 0.9575, 0.9586, 0.9586, 0.9586, 0.9586, 0.9598, 0.9609, 0.9621,\n",
       "             0.9632, 0.9644, 0.9655, 0.9667, 0.9678, 0.9690, 0.9701, 0.9701, 0.9713,\n",
       "             0.9713, 0.9724, 0.9724, 0.9736, 0.9736, 0.9747, 0.9747, 0.9747, 0.9759,\n",
       "             0.9770, 0.9782, 0.9793, 0.9805, 0.9805, 0.9805, 0.9805, 0.9805, 0.9805,\n",
       "             0.9805, 0.9805, 0.9816, 0.9816, 0.9828, 0.9839, 0.9851, 0.9862, 0.9862,\n",
       "             0.9862, 0.9862, 0.9874, 0.9885, 0.9885, 0.9897, 0.9908, 0.9908, 0.9908,\n",
       "             0.9908, 0.9908, 0.9908, 0.9908, 0.9920, 0.9920, 0.9931, 0.9931, 0.9931,\n",
       "             0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943,\n",
       "             0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943,\n",
       "             0.9943, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9966,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9986e-01, 9.9984e-01, 9.9984e-01,\n",
       "             9.9983e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01, 9.9980e-01, 9.9980e-01,\n",
       "             9.9979e-01, 9.9979e-01, 9.9979e-01, 9.9978e-01, 9.9978e-01, 9.9978e-01,\n",
       "             9.9978e-01, 9.9976e-01, 9.9976e-01, 9.9974e-01, 9.9972e-01, 9.9971e-01,\n",
       "             9.9970e-01, 9.9969e-01, 9.9966e-01, 9.9966e-01, 9.9964e-01, 9.9961e-01,\n",
       "             9.9961e-01, 9.9960e-01, 9.9959e-01, 9.9958e-01, 9.9956e-01, 9.9953e-01,\n",
       "             9.9952e-01, 9.9949e-01, 9.9946e-01, 9.9945e-01, 9.9943e-01, 9.9942e-01,\n",
       "             9.9933e-01, 9.9927e-01, 9.9917e-01, 9.9908e-01, 9.9907e-01, 9.9906e-01,\n",
       "             9.9903e-01, 9.9900e-01, 9.9896e-01, 9.9885e-01, 9.9884e-01, 9.9871e-01,\n",
       "             9.9833e-01, 9.9832e-01, 9.9814e-01, 9.9784e-01, 9.9775e-01, 9.9735e-01,\n",
       "             9.9699e-01, 9.9696e-01, 9.9688e-01, 9.9653e-01, 9.9647e-01, 9.9623e-01,\n",
       "             9.9593e-01, 9.9509e-01, 9.9495e-01, 9.9255e-01, 9.9150e-01, 9.9083e-01,\n",
       "             9.9082e-01, 9.8938e-01, 9.8925e-01, 9.8468e-01, 9.7918e-01, 9.7377e-01,\n",
       "             9.5849e-01, 9.5236e-01, 9.5005e-01, 9.4491e-01, 9.4386e-01, 9.3059e-01,\n",
       "             9.0952e-01, 8.8872e-01, 8.7954e-01, 8.7885e-01, 7.9442e-01, 7.8353e-01,\n",
       "             7.2923e-01, 6.8456e-01, 6.5707e-01, 6.3851e-01, 6.3454e-01, 6.3096e-01,\n",
       "             6.1735e-01, 5.9830e-01, 5.0963e-01, 4.5604e-01, 4.4624e-01, 3.7371e-01,\n",
       "             3.4022e-01, 3.4013e-01, 2.7035e-01, 2.6710e-01, 2.5744e-01, 2.2983e-01,\n",
       "             1.6923e-01, 1.5086e-01, 1.4258e-01, 1.3807e-01, 1.3772e-01, 1.3254e-01,\n",
       "             1.2611e-01, 9.6876e-02, 8.3695e-02, 7.4410e-02, 7.0988e-02, 7.0585e-02,\n",
       "             6.5298e-02, 6.4465e-02, 5.8346e-02, 5.7960e-02, 4.2553e-02, 3.7947e-02,\n",
       "             3.1184e-02, 3.0900e-02, 3.0783e-02, 2.8084e-02, 2.4839e-02, 2.2210e-02,\n",
       "             2.1511e-02, 1.6491e-02, 1.4746e-02, 1.2787e-02, 1.0912e-02, 6.9557e-03,\n",
       "             6.9308e-03, 6.0647e-03, 5.8777e-03, 5.4257e-03, 5.3070e-03, 5.1680e-03,\n",
       "             5.0790e-03, 5.0017e-03, 4.8503e-03, 4.7492e-03, 4.7235e-03, 4.3482e-03,\n",
       "             4.0264e-03, 3.3488e-03, 3.2814e-03, 3.2128e-03, 3.1788e-03, 2.9378e-03,\n",
       "             2.6830e-03, 1.9643e-03, 1.5205e-03, 1.2437e-03, 1.1977e-03, 1.1404e-03,\n",
       "             1.0681e-03, 1.0065e-03, 1.0049e-03, 9.1757e-04, 6.1062e-04, 5.7359e-04,\n",
       "             5.5720e-04, 3.9851e-04, 3.6792e-04, 3.4734e-04, 3.4660e-04, 2.7078e-04,\n",
       "             2.6870e-04, 2.6509e-04, 2.0467e-04, 1.9947e-04, 1.6277e-04, 1.5595e-04,\n",
       "             1.3315e-04, 1.2260e-04, 1.0730e-04, 1.0430e-04, 1.0353e-04, 9.9451e-05,\n",
       "             9.8087e-05, 9.6650e-05, 7.6931e-05, 7.4195e-05, 6.3591e-05, 6.0663e-05,\n",
       "             5.0502e-05, 4.4489e-05, 3.9446e-05, 3.6218e-05, 2.8952e-05, 2.6788e-05,\n",
       "             2.5811e-05, 2.5621e-05, 2.3994e-05, 2.3826e-05, 2.3634e-05, 2.2984e-05,\n",
       "             1.9851e-05, 1.9644e-05, 1.7758e-05, 1.6222e-05, 1.4801e-05, 1.4474e-05,\n",
       "             1.1878e-05, 1.1378e-05, 1.0080e-05, 7.2973e-06, 7.0820e-06, 6.5124e-06,\n",
       "             5.5078e-06, 5.0537e-06, 5.0033e-06, 4.8259e-06, 4.7052e-06, 4.6146e-06,\n",
       "             4.4585e-06, 4.3489e-06, 4.1851e-06, 4.0401e-06, 3.5837e-06, 2.8528e-06,\n",
       "             2.4528e-06, 2.2173e-06, 1.9498e-06, 1.8038e-06, 1.7024e-06, 1.6679e-06,\n",
       "             1.3182e-06, 1.3094e-06, 1.2541e-06, 1.1980e-06, 1.1728e-06, 1.1392e-06,\n",
       "             1.1380e-06, 1.0668e-06, 8.3981e-07, 8.0885e-07, 7.6587e-07, 7.2869e-07,\n",
       "             6.6392e-07, 6.0346e-07, 5.8463e-07, 3.7639e-07, 2.9783e-07, 2.7229e-07,\n",
       "             2.6104e-07, 2.0873e-07, 1.9805e-07, 1.8794e-07, 1.0403e-07, 9.8438e-08,\n",
       "             9.8103e-08, 9.4928e-08, 5.7001e-08, 4.1063e-08, 3.6202e-08, 3.1694e-08,\n",
       "             2.7171e-08, 2.2777e-08, 2.0737e-08, 2.0388e-08, 1.5952e-08, 1.5751e-08,\n",
       "             1.5673e-08, 1.4379e-08, 1.2790e-08, 1.0543e-08, 9.8614e-09, 8.8342e-09,\n",
       "             8.7384e-09, 6.5847e-09, 5.6997e-09, 5.0201e-09, 3.3569e-09, 3.3204e-09,\n",
       "             2.3249e-09, 1.8678e-09, 1.7243e-09, 1.6658e-09, 1.5647e-09, 1.5224e-09,\n",
       "             1.4592e-09, 1.3735e-09, 1.2087e-09, 1.1273e-09, 1.1071e-09, 1.0575e-09,\n",
       "             8.7010e-10, 8.0894e-10, 5.6920e-10, 5.4262e-10, 4.9698e-10, 4.1253e-10,\n",
       "             3.9268e-10, 3.8985e-10, 3.4921e-10, 3.0756e-10, 2.6552e-10, 1.6983e-10,\n",
       "             1.4866e-10, 1.1630e-10, 1.0039e-10, 9.5524e-11, 9.3483e-11, 8.2043e-11,\n",
       "             6.4554e-11, 3.4682e-11, 3.0827e-11, 2.7957e-11, 2.4481e-11, 1.7109e-11,\n",
       "             1.5954e-11, 1.2754e-11, 1.2174e-11, 1.1247e-11, 9.3912e-12, 3.8416e-12,\n",
       "             3.3687e-12, 2.4319e-12, 6.5457e-13, 3.4537e-13, 3.3186e-13, 2.8967e-13,\n",
       "             1.2895e-13, 6.5780e-14, 3.3433e-14, 2.1069e-14, 1.9780e-14, 1.6048e-14,\n",
       "             1.0202e-14, 4.5890e-15, 4.2446e-15, 3.6450e-15, 2.1319e-15, 7.0985e-16,\n",
       "             1.3808e-16, 2.7030e-17, 9.6205e-19, 1.1306e-19, 6.7570e-24])}},\n",
       "   {'fpr': np.float64(0.09446254071661238),\n",
       "    'tpr': np.float64(0.9850574712643678),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0033, 0.0033, 0.0033, 0.0033, 0.0065,\n",
       "             0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,\n",
       "             0.0065, 0.0065, 0.0065, 0.0065, 0.0065, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098,\n",
       "             0.0098, 0.0098, 0.0130, 0.0163, 0.0163, 0.0163, 0.0195, 0.0195, 0.0195,\n",
       "             0.0195, 0.0195, 0.0195, 0.0195, 0.0228, 0.0228, 0.0228, 0.0228, 0.0228,\n",
       "             0.0261, 0.0293, 0.0326, 0.0326, 0.0326, 0.0358, 0.0391, 0.0391, 0.0423,\n",
       "             0.0456, 0.0456, 0.0456, 0.0489, 0.0521, 0.0521, 0.0521, 0.0521, 0.0554,\n",
       "             0.0554, 0.0586, 0.0619, 0.0619, 0.0619, 0.0651, 0.0651, 0.0684, 0.0717,\n",
       "             0.0749, 0.0749, 0.0749, 0.0782, 0.0782, 0.0814, 0.0847, 0.0879, 0.0912,\n",
       "             0.0945, 0.0977, 0.0977, 0.1010, 0.1042, 0.1075, 0.1107, 0.1140, 0.1173,\n",
       "             0.1173, 0.1173, 0.1205, 0.1238, 0.1270, 0.1303, 0.1336, 0.1368, 0.1401,\n",
       "             0.1433, 0.1466, 0.1498, 0.1531, 0.1531, 0.1564, 0.1596, 0.1629, 0.1661,\n",
       "             0.1661, 0.1694, 0.1726, 0.1759, 0.1759, 0.1792, 0.1792, 0.1824, 0.1857,\n",
       "             0.1857, 0.1889, 0.1922, 0.1954, 0.1987, 0.2020, 0.2020, 0.2052, 0.2085,\n",
       "             0.2117, 0.2150, 0.2182, 0.2215, 0.2248, 0.2280, 0.2313, 0.2345, 0.2378,\n",
       "             0.2410, 0.2443, 0.2476, 0.2508, 0.2541, 0.2573, 0.2606, 0.2638, 0.2671,\n",
       "             0.2704, 0.2736, 0.2769, 0.2801, 0.2834, 0.2866, 0.2899, 0.2899, 0.2932,\n",
       "             0.2932, 0.2964, 0.2997, 0.3029, 0.3062, 0.3094, 0.3127, 0.3160, 0.3192,\n",
       "             0.3192, 0.3225, 0.3257, 0.3290, 0.3322, 0.3355, 0.3388, 0.3420, 0.3453,\n",
       "             0.3485, 0.3518, 0.3550, 0.3583, 0.3616, 0.3648, 0.3681, 0.3713, 0.3746,\n",
       "             0.3746, 0.3779, 0.3811, 0.3844, 0.3876, 0.3909, 0.3941, 0.3974, 0.4007,\n",
       "             0.4039, 0.4072, 0.4104, 0.4137, 0.4169, 0.4202, 0.4235, 0.4267, 0.4300,\n",
       "             0.4332, 0.4365, 0.4397, 0.4430, 0.4463, 0.4495, 0.4528, 0.4560, 0.4593,\n",
       "             0.4625, 0.4658, 0.4691, 0.4723, 0.4756, 0.4788, 0.4821, 0.4853, 0.4886,\n",
       "             0.4919, 0.4951, 0.4984, 0.5016, 0.5049, 0.5081, 0.5114, 0.5147, 0.5179,\n",
       "             0.5212, 0.5244, 0.5277, 0.5309, 0.5342, 0.5375, 0.5407, 0.5440, 0.5472,\n",
       "             0.5505, 0.5537, 0.5570, 0.5603, 0.5635, 0.5668, 0.5700, 0.5733, 0.5765,\n",
       "             0.5798, 0.5831, 0.5863, 0.5896, 0.5928, 0.5961, 0.5993, 0.6026, 0.6059,\n",
       "             0.6091, 0.6124, 0.6156, 0.6189, 0.6221, 0.6254, 0.6287, 0.6319, 0.6352,\n",
       "             0.6384, 0.6417, 0.6450, 0.6482, 0.6515, 0.6547, 0.6580, 0.6612, 0.6645,\n",
       "             0.6678, 0.6710, 0.6743, 0.6775, 0.6808, 0.6840, 0.6873, 0.6906, 0.6938,\n",
       "             0.6971, 0.7003, 0.7036, 0.7068, 0.7101, 0.7134, 0.7166, 0.7199, 0.7231,\n",
       "             0.7264, 0.7296, 0.7329, 0.7362, 0.7394, 0.7427, 0.7459, 0.7492, 0.7524,\n",
       "             0.7557, 0.7590, 0.7622, 0.7655, 0.7687, 0.7720, 0.7752, 0.7785, 0.7818,\n",
       "             0.7850, 0.7883, 0.7915, 0.7948, 0.7980, 0.8013, 0.8046, 0.8078, 0.8111,\n",
       "             0.8143, 0.8176, 0.8208, 0.8241, 0.8274, 0.8306, 0.8339, 0.8371, 0.8404,\n",
       "             0.8436, 0.8469, 0.8502, 0.8534, 0.8567, 0.8599, 0.8632, 0.8664, 0.8697,\n",
       "             0.8730, 0.8762, 0.8795, 0.8827, 0.8860, 0.8893, 0.8925, 0.8958, 0.8990,\n",
       "             0.9023, 0.9055, 0.9088, 0.9121, 0.9153, 0.9186, 0.9218, 0.9251, 0.9283,\n",
       "             0.9316, 0.9349, 0.9381, 0.9414, 0.9446, 0.9479, 0.9511, 0.9544, 0.9577,\n",
       "             0.9609, 0.9642, 0.9674, 0.9707, 0.9739, 0.9772, 0.9805, 0.9837, 0.9870,\n",
       "             0.9902, 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.7356, 0.7931, 0.8161, 0.8333, 0.8414, 0.8494, 0.8540, 0.8586,\n",
       "             0.8644, 0.8690, 0.8701, 0.8747, 0.8793, 0.8816, 0.8828, 0.8839, 0.8862,\n",
       "             0.8874, 0.8920, 0.8931, 0.8966, 0.8989, 0.9011, 0.9023, 0.9034, 0.9046,\n",
       "             0.9057, 0.9069, 0.9080, 0.9115, 0.9149, 0.9161, 0.9172, 0.9184, 0.9195,\n",
       "             0.9207, 0.9218, 0.9241, 0.9253, 0.9264, 0.9276, 0.9287, 0.9299, 0.9310,\n",
       "             0.9322, 0.9333, 0.9345, 0.9356, 0.9368, 0.9379, 0.9391, 0.9402, 0.9414,\n",
       "             0.9425, 0.9437, 0.9448, 0.9460, 0.9471, 0.9483, 0.9494, 0.9506, 0.9517,\n",
       "             0.9529, 0.9540, 0.9540, 0.9540, 0.9552, 0.9563, 0.9563, 0.9575, 0.9586,\n",
       "             0.9598, 0.9609, 0.9621, 0.9632, 0.9632, 0.9644, 0.9655, 0.9667, 0.9678,\n",
       "             0.9678, 0.9678, 0.9678, 0.9690, 0.9701, 0.9701, 0.9701, 0.9713, 0.9713,\n",
       "             0.9713, 0.9724, 0.9736, 0.9736, 0.9736, 0.9747, 0.9759, 0.9770, 0.9770,\n",
       "             0.9782, 0.9782, 0.9782, 0.9793, 0.9805, 0.9805, 0.9816, 0.9816, 0.9816,\n",
       "             0.9816, 0.9828, 0.9839, 0.9839, 0.9851, 0.9851, 0.9851, 0.9851, 0.9851,\n",
       "             0.9851, 0.9851, 0.9862, 0.9862, 0.9862, 0.9862, 0.9862, 0.9862, 0.9862,\n",
       "             0.9874, 0.9885, 0.9885, 0.9885, 0.9885, 0.9885, 0.9885, 0.9885, 0.9885,\n",
       "             0.9885, 0.9885, 0.9885, 0.9885, 0.9897, 0.9897, 0.9897, 0.9897, 0.9897,\n",
       "             0.9908, 0.9908, 0.9908, 0.9908, 0.9920, 0.9920, 0.9931, 0.9931, 0.9931,\n",
       "             0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9966, 0.9966,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9993e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9987e-01, 9.9985e-01, 9.9985e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9983e-01, 9.9982e-01, 9.9980e-01, 9.9979e-01, 9.9975e-01, 9.9959e-01,\n",
       "             9.9956e-01, 9.9949e-01, 9.9935e-01, 9.9925e-01, 9.9924e-01, 9.9917e-01,\n",
       "             9.9916e-01, 9.9853e-01, 9.9838e-01, 9.9764e-01, 9.9734e-01, 9.9712e-01,\n",
       "             9.9666e-01, 9.9641e-01, 9.9482e-01, 9.9478e-01, 9.9417e-01, 9.9357e-01,\n",
       "             9.9259e-01, 9.9152e-01, 9.8696e-01, 9.8611e-01, 9.8424e-01, 9.8289e-01,\n",
       "             9.8283e-01, 9.8115e-01, 9.5179e-01, 9.5145e-01, 9.4344e-01, 9.4127e-01,\n",
       "             9.2820e-01, 9.1886e-01, 8.9308e-01, 7.9808e-01, 6.2093e-01, 6.1160e-01,\n",
       "             5.6105e-01, 5.5338e-01, 5.2386e-01, 5.1969e-01, 4.3575e-01, 3.1544e-01,\n",
       "             3.0164e-01, 2.6431e-01, 2.2007e-01, 1.8099e-01, 1.6598e-01, 1.4001e-01,\n",
       "             1.2461e-01, 1.0268e-01, 1.0095e-01, 9.1635e-02, 9.0850e-02, 8.2867e-02,\n",
       "             5.5068e-02, 5.4999e-02, 3.0039e-02, 2.7696e-02, 2.2663e-02, 1.0594e-02,\n",
       "             7.3405e-03, 7.2553e-03, 2.8978e-03, 2.5010e-03, 2.1528e-03, 2.1473e-03,\n",
       "             1.2381e-03, 9.7286e-04, 4.7287e-04, 4.0888e-04, 3.7055e-04, 3.0720e-04,\n",
       "             2.4643e-04, 2.1792e-04, 2.1599e-04, 2.0821e-04, 1.9169e-04, 8.7627e-05,\n",
       "             8.3945e-05, 8.2009e-05, 6.0969e-05, 3.2406e-05, 3.0532e-05, 2.9065e-05,\n",
       "             2.0450e-05, 1.5365e-05, 1.5250e-05, 1.3238e-05, 6.1569e-06, 5.8838e-06,\n",
       "             3.7548e-06, 3.7525e-06, 2.7044e-06, 2.6369e-06, 2.1730e-06, 2.0836e-06,\n",
       "             1.4395e-06, 1.4294e-06, 1.3482e-06, 1.2987e-06, 1.2475e-06, 9.9127e-07,\n",
       "             9.1319e-07, 8.1599e-07, 8.0122e-07, 7.2886e-07, 5.9771e-07, 4.8109e-07,\n",
       "             4.1633e-07, 4.1191e-07, 4.0159e-07, 2.2885e-07, 2.1633e-07, 2.0908e-07,\n",
       "             1.8789e-07, 1.8095e-07, 1.4833e-07, 1.4174e-07, 1.4152e-07, 6.6249e-08,\n",
       "             6.2068e-08, 5.5187e-08, 5.1371e-08, 4.9582e-08, 4.7295e-08, 2.9183e-08,\n",
       "             2.6120e-08, 2.4226e-08, 2.2739e-08, 1.9921e-08, 1.7347e-08, 6.5988e-09,\n",
       "             6.3325e-09, 5.4389e-09, 4.1349e-09, 2.9335e-09, 2.6634e-09, 2.3236e-09,\n",
       "             2.1568e-09, 2.0742e-09, 1.8410e-09, 1.8238e-09, 1.3317e-09, 1.2450e-09,\n",
       "             1.1707e-09, 1.1430e-09, 1.1090e-09, 1.0630e-09, 9.7212e-10, 9.1859e-10,\n",
       "             7.0277e-10, 4.1891e-10, 2.8028e-10, 2.6980e-10, 2.5590e-10, 1.8438e-10,\n",
       "             1.1931e-10, 1.0814e-10, 1.0454e-10, 1.0396e-10, 1.0226e-10, 9.8571e-11,\n",
       "             9.1167e-11, 7.3830e-11, 5.9585e-11, 5.0946e-11, 4.7878e-11, 4.0557e-11,\n",
       "             3.3918e-11, 2.9224e-11, 2.7224e-11, 2.5045e-11, 1.9918e-11, 1.6303e-11,\n",
       "             1.5515e-11, 1.5329e-11, 1.2340e-11, 1.1793e-11, 1.0365e-11, 9.7660e-12,\n",
       "             7.7079e-12, 6.2304e-12, 4.8092e-12, 4.6527e-12, 4.4024e-12, 4.3152e-12,\n",
       "             4.1148e-12, 3.9991e-12, 3.4117e-12, 2.9936e-12, 2.3279e-12, 2.1243e-12,\n",
       "             2.0354e-12, 2.0215e-12, 1.7091e-12, 1.7035e-12, 1.4912e-12, 1.3344e-12,\n",
       "             1.2872e-12, 6.3213e-13, 5.1462e-13, 4.8842e-13, 4.4325e-13, 3.7336e-13,\n",
       "             3.2761e-13, 2.9487e-13, 2.5169e-13, 2.3418e-13, 2.1339e-13, 2.0958e-13,\n",
       "             1.6949e-13, 1.6710e-13, 1.6445e-13, 1.2224e-13, 1.0236e-13, 9.1409e-14,\n",
       "             9.0733e-14, 7.7185e-14, 7.1486e-14, 6.7730e-14, 6.6825e-14, 6.4102e-14,\n",
       "             5.6708e-14, 3.2112e-14, 2.7952e-14, 2.6493e-14, 2.3905e-14, 2.3463e-14,\n",
       "             1.9860e-14, 1.8544e-14, 1.7985e-14, 1.5269e-14, 1.0344e-14, 9.2552e-15,\n",
       "             6.5740e-15, 5.6427e-15, 5.5860e-15, 4.8980e-15, 4.4371e-15, 4.4017e-15,\n",
       "             3.2372e-15, 2.9514e-15, 2.6892e-15, 1.3195e-15, 1.1014e-15, 7.9386e-16,\n",
       "             7.6618e-16, 7.3825e-16, 1.7176e-16, 1.2831e-16, 8.7073e-17, 6.7629e-17,\n",
       "             6.2795e-17, 4.2479e-17, 3.1567e-17, 2.5905e-17, 2.1273e-17, 2.0894e-17,\n",
       "             1.6885e-17, 1.5113e-17, 1.3435e-17, 1.1439e-17, 8.0810e-18, 4.7424e-18,\n",
       "             4.2020e-18, 2.4571e-18, 2.1729e-18, 1.9755e-18, 1.6228e-18, 1.5842e-18,\n",
       "             1.5690e-18, 1.3528e-18, 1.0544e-18, 8.3467e-19, 7.7236e-19, 7.2577e-19,\n",
       "             5.4635e-19, 4.9469e-19, 3.1001e-19, 2.4634e-19, 2.0788e-19, 1.3943e-19,\n",
       "             1.1409e-19, 1.0841e-19, 9.3430e-20, 5.1271e-20, 4.0426e-20, 3.5253e-20,\n",
       "             3.2353e-20, 3.1462e-20, 2.7464e-20, 2.6640e-20, 1.8321e-20, 1.5883e-20,\n",
       "             1.3802e-20, 8.0419e-21, 5.5923e-21, 4.0539e-21, 2.0005e-21, 5.2275e-22,\n",
       "             2.6590e-22, 2.1600e-22, 1.7674e-22, 5.1101e-23, 4.3970e-23, 2.8455e-23,\n",
       "             2.8127e-23, 2.5190e-23, 2.1442e-23, 1.7988e-23, 7.5777e-24, 6.1469e-24,\n",
       "             3.3827e-24, 2.8136e-24, 2.2353e-24, 1.8796e-24, 4.3283e-25, 3.3768e-25,\n",
       "             1.5347e-25, 3.5331e-26, 1.3879e-26, 6.3339e-27, 4.2232e-27, 3.1270e-27,\n",
       "             7.3338e-28, 3.4301e-28, 8.3740e-29, 4.9000e-29, 2.5588e-33, 1.8654e-34,\n",
       "             0.0000e+00])}},\n",
       "   {'fpr': np.float64(0.06840390879478828),\n",
       "    'tpr': np.float64(0.9827586206896551),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0065, 0.0065, 0.0065, 0.0065, 0.0065,\n",
       "             0.0065, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0130, 0.0130, 0.0130,\n",
       "             0.0130, 0.0130, 0.0130, 0.0130, 0.0163, 0.0163, 0.0163, 0.0163, 0.0163,\n",
       "             0.0163, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
       "             0.0195, 0.0228, 0.0228, 0.0228, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261,\n",
       "             0.0261, 0.0261, 0.0261, 0.0293, 0.0293, 0.0326, 0.0358, 0.0358, 0.0391,\n",
       "             0.0391, 0.0391, 0.0391, 0.0391, 0.0391, 0.0391, 0.0423, 0.0423, 0.0456,\n",
       "             0.0489, 0.0521, 0.0554, 0.0586, 0.0619, 0.0619, 0.0651, 0.0684, 0.0684,\n",
       "             0.0684, 0.0717, 0.0717, 0.0749, 0.0749, 0.0782, 0.0814, 0.0814, 0.0847,\n",
       "             0.0879, 0.0912, 0.0945, 0.0945, 0.0977, 0.1010, 0.1042, 0.1075, 0.1075,\n",
       "             0.1075, 0.1107, 0.1107, 0.1140, 0.1140, 0.1173, 0.1205, 0.1238, 0.1270,\n",
       "             0.1303, 0.1336, 0.1368, 0.1368, 0.1368, 0.1401, 0.1433, 0.1466, 0.1498,\n",
       "             0.1531, 0.1564, 0.1564, 0.1596, 0.1629, 0.1661, 0.1661, 0.1694, 0.1726,\n",
       "             0.1759, 0.1792, 0.1824, 0.1857, 0.1889, 0.1889, 0.1922, 0.1922, 0.1954,\n",
       "             0.1987, 0.2020, 0.2052, 0.2085, 0.2117, 0.2150, 0.2182, 0.2215, 0.2248,\n",
       "             0.2280, 0.2313, 0.2345, 0.2378, 0.2410, 0.2443, 0.2476, 0.2508, 0.2541,\n",
       "             0.2573, 0.2606, 0.2638, 0.2671, 0.2704, 0.2736, 0.2769, 0.2801, 0.2834,\n",
       "             0.2834, 0.2866, 0.2899, 0.2932, 0.2964, 0.2997, 0.3029, 0.3062, 0.3094,\n",
       "             0.3127, 0.3160, 0.3192, 0.3225, 0.3257, 0.3290, 0.3322, 0.3355, 0.3388,\n",
       "             0.3420, 0.3453, 0.3485, 0.3518, 0.3550, 0.3583, 0.3616, 0.3648, 0.3681,\n",
       "             0.3713, 0.3746, 0.3779, 0.3811, 0.3844, 0.3876, 0.3909, 0.3941, 0.3974,\n",
       "             0.4007, 0.4039, 0.4072, 0.4104, 0.4137, 0.4169, 0.4202, 0.4235, 0.4267,\n",
       "             0.4300, 0.4332, 0.4365, 0.4397, 0.4430, 0.4463, 0.4495, 0.4528, 0.4560,\n",
       "             0.4593, 0.4625, 0.4658, 0.4691, 0.4723, 0.4756, 0.4788, 0.4821, 0.4853,\n",
       "             0.4886, 0.4919, 0.4951, 0.4984, 0.5016, 0.5049, 0.5081, 0.5114, 0.5147,\n",
       "             0.5179, 0.5212, 0.5244, 0.5277, 0.5309, 0.5342, 0.5375, 0.5407, 0.5440,\n",
       "             0.5472, 0.5505, 0.5537, 0.5570, 0.5603, 0.5635, 0.5668, 0.5700, 0.5733,\n",
       "             0.5765, 0.5798, 0.5831, 0.5863, 0.5896, 0.5928, 0.5961, 0.5993, 0.6026,\n",
       "             0.6059, 0.6091, 0.6124, 0.6156, 0.6189, 0.6221, 0.6254, 0.6287, 0.6319,\n",
       "             0.6352, 0.6384, 0.6417, 0.6450, 0.6482, 0.6515, 0.6547, 0.6580, 0.6612,\n",
       "             0.6645, 0.6678, 0.6710, 0.6743, 0.6775, 0.6808, 0.6840, 0.6873, 0.6906,\n",
       "             0.6938, 0.6971, 0.7003, 0.7036, 0.7068, 0.7101, 0.7134, 0.7166, 0.7199,\n",
       "             0.7231, 0.7264, 0.7296, 0.7329, 0.7362, 0.7394, 0.7427, 0.7459, 0.7492,\n",
       "             0.7524, 0.7557, 0.7590, 0.7622, 0.7655, 0.7687, 0.7720, 0.7752, 0.7785,\n",
       "             0.7818, 0.7850, 0.7883, 0.7915, 0.7948, 0.7980, 0.8013, 0.8046, 0.8078,\n",
       "             0.8111, 0.8143, 0.8176, 0.8208, 0.8241, 0.8274, 0.8306, 0.8339, 0.8371,\n",
       "             0.8404, 0.8436, 0.8469, 0.8502, 0.8534, 0.8567, 0.8599, 0.8632, 0.8664,\n",
       "             0.8697, 0.8730, 0.8762, 0.8795, 0.8827, 0.8860, 0.8893, 0.8925, 0.8958,\n",
       "             0.8990, 0.9023, 0.9055, 0.9088, 0.9121, 0.9153, 0.9186, 0.9218, 0.9251,\n",
       "             0.9283, 0.9316, 0.9349, 0.9381, 0.9414, 0.9446, 0.9479, 0.9511, 0.9544,\n",
       "             0.9577, 0.9609, 0.9642, 0.9674, 0.9707, 0.9739, 0.9772, 0.9805, 0.9837,\n",
       "             0.9870, 0.9902, 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.6655, 0.7414, 0.7724, 0.7966, 0.8057, 0.8207, 0.8287, 0.8345,\n",
       "             0.8414, 0.8471, 0.8506, 0.8563, 0.8632, 0.8655, 0.8701, 0.8724, 0.8747,\n",
       "             0.8759, 0.8782, 0.8793, 0.8805, 0.8851, 0.8862, 0.8874, 0.8885, 0.8897,\n",
       "             0.8908, 0.8920, 0.8931, 0.8943, 0.8966, 0.8977, 0.8989, 0.9000, 0.9011,\n",
       "             0.9023, 0.9034, 0.9046, 0.9057, 0.9069, 0.9080, 0.9092, 0.9103, 0.9115,\n",
       "             0.9126, 0.9138, 0.9149, 0.9161, 0.9172, 0.9184, 0.9195, 0.9207, 0.9218,\n",
       "             0.9230, 0.9241, 0.9253, 0.9264, 0.9264, 0.9276, 0.9287, 0.9299, 0.9310,\n",
       "             0.9322, 0.9322, 0.9333, 0.9345, 0.9356, 0.9368, 0.9368, 0.9379, 0.9391,\n",
       "             0.9402, 0.9414, 0.9425, 0.9437, 0.9437, 0.9448, 0.9460, 0.9471, 0.9483,\n",
       "             0.9494, 0.9494, 0.9506, 0.9517, 0.9529, 0.9540, 0.9552, 0.9563, 0.9575,\n",
       "             0.9586, 0.9586, 0.9598, 0.9609, 0.9609, 0.9621, 0.9632, 0.9644, 0.9655,\n",
       "             0.9667, 0.9678, 0.9690, 0.9690, 0.9701, 0.9701, 0.9701, 0.9713, 0.9713,\n",
       "             0.9724, 0.9736, 0.9747, 0.9759, 0.9770, 0.9782, 0.9782, 0.9793, 0.9793,\n",
       "             0.9793, 0.9793, 0.9793, 0.9793, 0.9793, 0.9805, 0.9805, 0.9805, 0.9816,\n",
       "             0.9828, 0.9828, 0.9839, 0.9839, 0.9851, 0.9851, 0.9851, 0.9862, 0.9862,\n",
       "             0.9862, 0.9862, 0.9862, 0.9874, 0.9874, 0.9874, 0.9874, 0.9874, 0.9885,\n",
       "             0.9897, 0.9897, 0.9908, 0.9908, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920,\n",
       "             0.9920, 0.9920, 0.9920, 0.9931, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943,\n",
       "             0.9943, 0.9943, 0.9954, 0.9954, 0.9954, 0.9954, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9977, 0.9977, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9994e-01, 9.9993e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9991e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9989e-01,\n",
       "             9.9986e-01, 9.9984e-01, 9.9984e-01, 9.9983e-01, 9.9982e-01, 9.9979e-01,\n",
       "             9.9979e-01, 9.9978e-01, 9.9976e-01, 9.9968e-01, 9.9957e-01, 9.9955e-01,\n",
       "             9.9930e-01, 9.9890e-01, 9.9871e-01, 9.9864e-01, 9.9842e-01, 9.9840e-01,\n",
       "             9.9785e-01, 9.9767e-01, 9.9733e-01, 9.9695e-01, 9.9616e-01, 9.9612e-01,\n",
       "             9.9598e-01, 9.9483e-01, 9.9428e-01, 9.9407e-01, 9.9358e-01, 9.9289e-01,\n",
       "             9.9013e-01, 9.8932e-01, 9.8921e-01, 9.8820e-01, 9.8745e-01, 9.8638e-01,\n",
       "             9.8583e-01, 9.8538e-01, 9.6129e-01, 9.6004e-01, 9.4788e-01, 9.4302e-01,\n",
       "             9.3932e-01, 9.2895e-01, 9.2776e-01, 9.2110e-01, 9.1496e-01, 8.7573e-01,\n",
       "             8.6701e-01, 8.4449e-01, 8.4260e-01, 8.2154e-01, 7.6653e-01, 7.0869e-01,\n",
       "             7.0329e-01, 6.2059e-01, 5.9791e-01, 5.7379e-01, 5.2947e-01, 5.1992e-01,\n",
       "             5.1456e-01, 3.3774e-01, 2.9821e-01, 2.1233e-01, 1.5439e-01, 1.4770e-01,\n",
       "             1.3627e-01, 1.1635e-01, 1.1124e-01, 6.4294e-02, 5.4337e-02, 5.0501e-02,\n",
       "             3.3851e-02, 2.1637e-02, 2.0141e-02, 1.5159e-02, 1.2776e-02, 1.2122e-02,\n",
       "             1.1488e-02, 1.1167e-02, 6.5232e-03, 6.1918e-03, 3.8769e-03, 3.6271e-03,\n",
       "             3.5168e-03, 3.3544e-03, 3.2552e-03, 2.6778e-03, 2.6074e-03, 2.0163e-03,\n",
       "             5.2843e-04, 4.1341e-04, 4.1072e-04, 3.4129e-04, 2.2735e-04, 2.1528e-04,\n",
       "             2.1471e-04, 1.8346e-04, 1.5900e-04, 1.5055e-04, 1.2163e-04, 9.3927e-05,\n",
       "             8.6921e-05, 7.9783e-05, 6.6019e-05, 4.7074e-05, 4.5113e-05, 4.3993e-05,\n",
       "             3.4666e-05, 2.3408e-05, 1.3425e-05, 1.2318e-05, 9.3917e-06, 9.2275e-06,\n",
       "             8.7014e-06, 8.3585e-06, 7.3356e-06, 7.2509e-06, 5.5478e-06, 3.8667e-06,\n",
       "             3.4837e-06, 2.4438e-06, 2.0464e-06, 2.0311e-06, 1.8528e-06, 1.7409e-06,\n",
       "             1.3811e-06, 1.2344e-06, 1.2248e-06, 1.0384e-06, 6.5072e-07, 6.1570e-07,\n",
       "             5.7847e-07, 4.8344e-07, 3.4989e-07, 2.8710e-07, 1.8488e-07, 1.8320e-07,\n",
       "             1.7959e-07, 1.4572e-07, 1.3850e-07, 1.1931e-07, 1.0074e-07, 8.8557e-08,\n",
       "             7.1705e-08, 6.7372e-08, 5.4024e-08, 3.7527e-08, 3.6577e-08, 2.6859e-08,\n",
       "             2.1959e-08, 2.0383e-08, 1.9938e-08, 1.9460e-08, 1.8361e-08, 1.8298e-08,\n",
       "             1.7579e-08, 1.6302e-08, 9.3292e-09, 8.9891e-09, 7.3778e-09, 6.1539e-09,\n",
       "             5.0324e-09, 4.5596e-09, 4.1034e-09, 3.7560e-09, 3.4965e-09, 3.3299e-09,\n",
       "             3.1235e-09, 3.0079e-09, 3.0004e-09, 2.4804e-09, 2.4243e-09, 2.3877e-09,\n",
       "             2.2522e-09, 2.1100e-09, 2.0058e-09, 1.2313e-09, 1.1983e-09, 1.1494e-09,\n",
       "             1.0114e-09, 8.2670e-10, 7.5450e-10, 6.7028e-10, 5.8021e-10, 4.8983e-10,\n",
       "             4.5678e-10, 4.2670e-10, 3.0805e-10, 2.9643e-10, 2.8812e-10, 2.5987e-10,\n",
       "             2.1532e-10, 1.4824e-10, 1.4509e-10, 1.4428e-10, 1.0511e-10, 9.6492e-11,\n",
       "             9.0594e-11, 8.6170e-11, 7.1940e-11, 4.8938e-11, 4.6528e-11, 4.5179e-11,\n",
       "             4.4847e-11, 3.6926e-11, 3.5897e-11, 3.4540e-11, 3.2873e-11, 3.1008e-11,\n",
       "             2.3286e-11, 2.3035e-11, 2.1290e-11, 2.1219e-11, 1.9232e-11, 1.4501e-11,\n",
       "             1.2512e-11, 1.2248e-11, 1.1830e-11, 1.0997e-11, 1.0057e-11, 9.9713e-12,\n",
       "             9.7737e-12, 8.6813e-12, 5.2808e-12, 5.0710e-12, 4.7520e-12, 3.6144e-12,\n",
       "             3.1001e-12, 2.8417e-12, 2.7444e-12, 2.6992e-12, 2.2741e-12, 1.9977e-12,\n",
       "             1.2731e-12, 1.1400e-12, 1.0980e-12, 7.1180e-13, 6.8278e-13, 6.7797e-13,\n",
       "             5.1015e-13, 4.9449e-13, 4.7292e-13, 4.3120e-13, 4.0441e-13, 3.9146e-13,\n",
       "             3.6110e-13, 3.5790e-13, 3.2694e-13, 2.8417e-13, 2.7784e-13, 2.0879e-13,\n",
       "             1.9323e-13, 1.8742e-13, 1.3672e-13, 1.3370e-13, 1.0026e-13, 7.3266e-14,\n",
       "             7.1593e-14, 5.4078e-14, 4.7845e-14, 4.5167e-14, 4.2258e-14, 4.0426e-14,\n",
       "             4.0425e-14, 2.6634e-14, 2.1248e-14, 1.9981e-14, 1.4711e-14, 1.0989e-14,\n",
       "             1.0830e-14, 9.8509e-15, 8.6221e-15, 8.4930e-15, 8.0727e-15, 5.6963e-15,\n",
       "             5.2460e-15, 5.1935e-15, 4.7994e-15, 4.1154e-15, 2.7451e-15, 2.5113e-15,\n",
       "             2.2105e-15, 2.0769e-15, 2.0383e-15, 1.6802e-15, 1.4845e-15, 1.4255e-15,\n",
       "             1.4183e-15, 9.5505e-16, 9.0747e-16, 8.5272e-16, 7.6340e-16, 6.8301e-16,\n",
       "             5.4103e-16, 5.1624e-16, 5.1155e-16, 4.6368e-16, 4.5151e-16, 4.5089e-16,\n",
       "             4.3956e-16, 4.1056e-16, 3.4599e-16, 3.1967e-16, 1.9382e-16, 1.8607e-16,\n",
       "             1.4825e-16, 1.2409e-16, 1.1870e-16, 1.1023e-16, 8.7174e-17, 8.5597e-17,\n",
       "             7.9766e-17, 5.9819e-17, 5.1963e-17, 4.0572e-17, 3.5978e-17, 2.7378e-17,\n",
       "             2.3210e-17, 1.9177e-17, 1.4316e-17, 1.3378e-17, 1.0371e-17, 9.5646e-18,\n",
       "             7.9559e-18, 6.6291e-18, 5.3607e-18, 5.3301e-18, 4.9016e-18, 4.2437e-18,\n",
       "             2.3061e-18, 1.6202e-18, 6.2383e-19, 3.0402e-19, 2.4660e-19, 1.6475e-19,\n",
       "             1.5095e-19, 1.3178e-19, 8.1108e-20, 7.5320e-20, 6.3488e-20, 3.1774e-20,\n",
       "             2.9888e-20, 2.9109e-20, 2.4416e-20, 1.9905e-20, 1.9738e-20, 1.7946e-20,\n",
       "             7.5062e-21, 7.0796e-21, 6.0626e-21, 2.6736e-21, 7.5894e-22, 3.6925e-23,\n",
       "             1.9091e-23, 7.5897e-24, 5.4552e-24, 1.8391e-24, 4.1704e-27, 3.5881e-27,\n",
       "             2.1941e-27, 1.3004e-34])}},\n",
       "   {'fpr': np.float64(0.15960912052117263),\n",
       "    'tpr': np.float64(0.993103448275862),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0195, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261,\n",
       "             0.0261, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261,\n",
       "             0.0261, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261, 0.0261,\n",
       "             0.0261, 0.0261, 0.0293, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326, 0.0326,\n",
       "             0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358,\n",
       "             0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358, 0.0358,\n",
       "             0.0358, 0.0391, 0.0391, 0.0391, 0.0391, 0.0423, 0.0423, 0.0423, 0.0423,\n",
       "             0.0423, 0.0423, 0.0456, 0.0456, 0.0456, 0.0456, 0.0456, 0.0456, 0.0456,\n",
       "             0.0456, 0.0456, 0.0456, 0.0456, 0.0456, 0.0456, 0.0456, 0.0456, 0.0489,\n",
       "             0.0521, 0.0521, 0.0554, 0.0554, 0.0554, 0.0554, 0.0586, 0.0586, 0.0586,\n",
       "             0.0586, 0.0586, 0.0619, 0.0619, 0.0651, 0.0684, 0.0717, 0.0717, 0.0717,\n",
       "             0.0749, 0.0782, 0.0814, 0.0814, 0.0814, 0.0814, 0.0814, 0.0847, 0.0879,\n",
       "             0.0912, 0.0945, 0.0945, 0.0977, 0.1010, 0.1010, 0.1010, 0.1010, 0.1010,\n",
       "             0.1010, 0.1042, 0.1075, 0.1107, 0.1140, 0.1140, 0.1173, 0.1173, 0.1205,\n",
       "             0.1238, 0.1270, 0.1303, 0.1336, 0.1368, 0.1401, 0.1433, 0.1466, 0.1498,\n",
       "             0.1531, 0.1564, 0.1596, 0.1629, 0.1629, 0.1661, 0.1694, 0.1726, 0.1759,\n",
       "             0.1792, 0.1824, 0.1857, 0.1889, 0.1922, 0.1954, 0.1954, 0.1987, 0.2020,\n",
       "             0.2052, 0.2085, 0.2117, 0.2150, 0.2182, 0.2215, 0.2248, 0.2280, 0.2313,\n",
       "             0.2345, 0.2378, 0.2410, 0.2443, 0.2476, 0.2508, 0.2541, 0.2573, 0.2606,\n",
       "             0.2638, 0.2671, 0.2704, 0.2736, 0.2769, 0.2801, 0.2834, 0.2866, 0.2899,\n",
       "             0.2932, 0.2964, 0.2997, 0.2997, 0.3029, 0.3062, 0.3094, 0.3127, 0.3160,\n",
       "             0.3160, 0.3192, 0.3225, 0.3257, 0.3290, 0.3322, 0.3355, 0.3388, 0.3420,\n",
       "             0.3453, 0.3485, 0.3518, 0.3550, 0.3583, 0.3616, 0.3648, 0.3681, 0.3713,\n",
       "             0.3746, 0.3779, 0.3779, 0.3811, 0.3844, 0.3876, 0.3909, 0.3941, 0.3974,\n",
       "             0.4007, 0.4039, 0.4072, 0.4104, 0.4137, 0.4169, 0.4202, 0.4235, 0.4267,\n",
       "             0.4300, 0.4332, 0.4332, 0.4365, 0.4397, 0.4430, 0.4463, 0.4495, 0.4528,\n",
       "             0.4560, 0.4593, 0.4625, 0.4658, 0.4691, 0.4723, 0.4756, 0.4788, 0.4821,\n",
       "             0.4853, 0.4886, 0.4919, 0.4951, 0.4984, 0.5016, 0.5049, 0.5081, 0.5114,\n",
       "             0.5147, 0.5179, 0.5212, 0.5244, 0.5277, 0.5309, 0.5342, 0.5375, 0.5407,\n",
       "             0.5440, 0.5472, 0.5505, 0.5537, 0.5570, 0.5603, 0.5635, 0.5668, 0.5700,\n",
       "             0.5733, 0.5765, 0.5798, 0.5831, 0.5863, 0.5896, 0.5928, 0.5961, 0.5993,\n",
       "             0.6026, 0.6059, 0.6091, 0.6124, 0.6156, 0.6189, 0.6221, 0.6254, 0.6287,\n",
       "             0.6319, 0.6352, 0.6384, 0.6417, 0.6450, 0.6482, 0.6515, 0.6547, 0.6580,\n",
       "             0.6612, 0.6645, 0.6678, 0.6710, 0.6743, 0.6775, 0.6808, 0.6840, 0.6873,\n",
       "             0.6906, 0.6938, 0.6971, 0.7003, 0.7036, 0.7068, 0.7101, 0.7134, 0.7166,\n",
       "             0.7199, 0.7231, 0.7264, 0.7296, 0.7329, 0.7362, 0.7394, 0.7427, 0.7459,\n",
       "             0.7492, 0.7524, 0.7557, 0.7590, 0.7622, 0.7655, 0.7687, 0.7720, 0.7752,\n",
       "             0.7785, 0.7818, 0.7850, 0.7883, 0.7915, 0.7948, 0.7980, 0.8013, 0.8046,\n",
       "             0.8078, 0.8111, 0.8143, 0.8176, 0.8208, 0.8241, 0.8274, 0.8306, 0.8339,\n",
       "             0.8371, 0.8404, 0.8436, 0.8469, 0.8502, 0.8534, 0.8567, 0.8599, 0.8632,\n",
       "             0.8664, 0.8697, 0.8730, 0.8762, 0.8795, 0.8827, 0.8860, 0.8893, 0.8925,\n",
       "             0.8958, 0.8990, 0.9023, 0.9055, 0.9088, 0.9121, 0.9153, 0.9186, 0.9218,\n",
       "             0.9251, 0.9283, 0.9316, 0.9349, 0.9381, 0.9414, 0.9446, 0.9479, 0.9511,\n",
       "             0.9544, 0.9577, 0.9609, 0.9642, 0.9674, 0.9707, 0.9739, 0.9772, 0.9805,\n",
       "             0.9837, 0.9870, 0.9902, 0.9935, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.7425, 0.7908, 0.8161, 0.8287, 0.8356, 0.8483, 0.8563, 0.8609,\n",
       "             0.8644, 0.8690, 0.8713, 0.8724, 0.8770, 0.8782, 0.8839, 0.8874, 0.8920,\n",
       "             0.8931, 0.8943, 0.8954, 0.8966, 0.8977, 0.8989, 0.9011, 0.9046, 0.9057,\n",
       "             0.9080, 0.9103, 0.9103, 0.9115, 0.9126, 0.9138, 0.9161, 0.9172, 0.9184,\n",
       "             0.9184, 0.9195, 0.9207, 0.9218, 0.9230, 0.9241, 0.9253, 0.9264, 0.9276,\n",
       "             0.9299, 0.9310, 0.9322, 0.9333, 0.9345, 0.9356, 0.9368, 0.9379, 0.9391,\n",
       "             0.9402, 0.9402, 0.9414, 0.9425, 0.9437, 0.9437, 0.9448, 0.9460, 0.9483,\n",
       "             0.9494, 0.9506, 0.9506, 0.9517, 0.9529, 0.9540, 0.9552, 0.9563, 0.9575,\n",
       "             0.9586, 0.9598, 0.9609, 0.9621, 0.9632, 0.9644, 0.9655, 0.9667, 0.9667,\n",
       "             0.9667, 0.9678, 0.9678, 0.9690, 0.9701, 0.9713, 0.9713, 0.9724, 0.9736,\n",
       "             0.9747, 0.9759, 0.9759, 0.9770, 0.9770, 0.9770, 0.9770, 0.9782, 0.9793,\n",
       "             0.9793, 0.9793, 0.9793, 0.9805, 0.9816, 0.9828, 0.9839, 0.9839, 0.9839,\n",
       "             0.9839, 0.9839, 0.9851, 0.9851, 0.9851, 0.9862, 0.9874, 0.9885, 0.9897,\n",
       "             0.9908, 0.9908, 0.9908, 0.9908, 0.9908, 0.9920, 0.9920, 0.9931, 0.9931,\n",
       "             0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931,\n",
       "             0.9931, 0.9931, 0.9931, 0.9931, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943,\n",
       "             0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9992e-01, 9.9991e-01, 9.9991e-01, 9.9985e-01, 9.9982e-01, 9.9980e-01,\n",
       "             9.9977e-01, 9.9976e-01, 9.9974e-01, 9.9970e-01, 9.9968e-01, 9.9964e-01,\n",
       "             9.9953e-01, 9.9935e-01, 9.9925e-01, 9.9924e-01, 9.9922e-01, 9.9921e-01,\n",
       "             9.9918e-01, 9.9914e-01, 9.9908e-01, 9.9908e-01, 9.9895e-01, 9.9892e-01,\n",
       "             9.9879e-01, 9.9867e-01, 9.9847e-01, 9.9846e-01, 9.9805e-01, 9.9779e-01,\n",
       "             9.9779e-01, 9.9577e-01, 9.9441e-01, 9.9414e-01, 9.9337e-01, 9.9253e-01,\n",
       "             9.9169e-01, 9.9010e-01, 9.8885e-01, 9.8869e-01, 9.8795e-01, 9.8507e-01,\n",
       "             9.8384e-01, 9.7328e-01, 9.6303e-01, 9.5997e-01, 9.5856e-01, 9.5572e-01,\n",
       "             9.3265e-01, 8.5692e-01, 8.4325e-01, 8.2899e-01, 8.2545e-01, 7.9275e-01,\n",
       "             7.6400e-01, 7.5707e-01, 7.2108e-01, 7.1102e-01, 7.0883e-01, 6.7651e-01,\n",
       "             6.2695e-01, 6.0817e-01, 5.9350e-01, 5.7084e-01, 5.2183e-01, 5.0496e-01,\n",
       "             4.5393e-01, 3.8462e-01, 2.1205e-01, 1.8964e-01, 1.8762e-01, 1.1832e-01,\n",
       "             1.0680e-01, 6.7432e-02, 6.5909e-02, 6.3582e-02, 4.3201e-02, 3.9536e-02,\n",
       "             3.4225e-02, 3.3987e-02, 2.8810e-02, 2.5951e-02, 2.5095e-02, 2.4362e-02,\n",
       "             2.2662e-02, 2.2653e-02, 2.1948e-02, 9.4462e-03, 8.0601e-03, 7.1898e-03,\n",
       "             6.4778e-03, 4.6582e-03, 3.2193e-03, 3.1534e-03, 2.7494e-03, 2.3411e-03,\n",
       "             1.9837e-03, 1.5752e-03, 1.3174e-03, 1.1768e-03, 1.0687e-03, 9.8491e-04,\n",
       "             9.6335e-04, 5.6580e-04, 3.6130e-04, 3.1098e-04, 2.7902e-04, 2.7454e-04,\n",
       "             2.5719e-04, 2.2809e-04, 1.8952e-04, 1.7546e-04, 1.7001e-04, 1.6285e-04,\n",
       "             1.4447e-04, 1.3710e-04, 1.1860e-04, 9.1754e-05, 8.9395e-05, 8.7689e-05,\n",
       "             8.7185e-05, 8.4823e-05, 7.6336e-05, 7.1234e-05, 5.9460e-05, 5.4121e-05,\n",
       "             5.3539e-05, 4.4529e-05, 2.2845e-05, 2.2134e-05, 2.1774e-05, 1.8545e-05,\n",
       "             1.7888e-05, 1.5043e-05, 1.4775e-05, 1.2480e-05, 1.1340e-05, 1.0923e-05,\n",
       "             8.0282e-06, 7.1642e-06, 5.2478e-06, 4.1648e-06, 2.8990e-06, 2.2091e-06,\n",
       "             2.1258e-06, 1.9839e-06, 1.8253e-06, 1.8086e-06, 1.7536e-06, 1.6707e-06,\n",
       "             1.5561e-06, 1.4569e-06, 1.3938e-06, 1.2972e-06, 1.1090e-06, 1.0759e-06,\n",
       "             1.0436e-06, 8.5320e-07, 5.5240e-07, 5.2340e-07, 4.9782e-07, 3.8149e-07,\n",
       "             3.0043e-07, 2.7923e-07, 2.7690e-07, 2.6282e-07, 2.4495e-07, 1.9411e-07,\n",
       "             1.7465e-07, 1.6987e-07, 1.6394e-07, 1.4021e-07, 1.3958e-07, 1.3048e-07,\n",
       "             1.2994e-07, 9.6303e-08, 9.4302e-08, 8.9192e-08, 8.2356e-08, 7.9686e-08,\n",
       "             7.3251e-08, 6.0910e-08, 5.5149e-08, 4.4391e-08, 4.0560e-08, 4.0204e-08,\n",
       "             2.6459e-08, 2.4966e-08, 2.0831e-08, 1.6668e-08, 1.0609e-08, 1.0360e-08,\n",
       "             6.1072e-09, 5.8135e-09, 5.2381e-09, 5.1125e-09, 4.8441e-09, 4.8154e-09,\n",
       "             4.7863e-09, 3.4848e-09, 3.4602e-09, 3.4253e-09, 2.6125e-09, 2.4310e-09,\n",
       "             2.3434e-09, 1.8947e-09, 1.7804e-09, 1.7501e-09, 1.4000e-09, 1.3502e-09,\n",
       "             1.0932e-09, 1.0903e-09, 9.1380e-10, 9.0544e-10, 8.2607e-10, 7.7347e-10,\n",
       "             5.3994e-10, 5.1653e-10, 4.9575e-10, 4.6881e-10, 4.1377e-10, 3.6720e-10,\n",
       "             3.3597e-10, 2.6479e-10, 2.5414e-10, 2.5260e-10, 2.4447e-10, 2.4293e-10,\n",
       "             1.9787e-10, 1.8508e-10, 1.6813e-10, 1.3958e-10, 1.1860e-10, 9.4427e-11,\n",
       "             7.8205e-11, 7.7415e-11, 6.6333e-11, 6.5492e-11, 6.4304e-11, 6.1665e-11,\n",
       "             5.7720e-11, 4.8596e-11, 4.5117e-11, 3.4806e-11, 2.0648e-11, 1.9983e-11,\n",
       "             1.8525e-11, 1.7647e-11, 1.3070e-11, 1.2019e-11, 1.0430e-11, 8.3160e-12,\n",
       "             5.8564e-12, 5.7655e-12, 5.5720e-12, 4.4204e-12, 4.1323e-12, 4.1215e-12,\n",
       "             3.0328e-12, 2.9104e-12, 2.0840e-12, 1.9771e-12, 1.8563e-12, 1.7485e-12,\n",
       "             1.7022e-12, 1.5755e-12, 1.4707e-12, 9.5939e-13, 9.2879e-13, 8.8693e-13,\n",
       "             3.8595e-13, 3.7112e-13, 2.9221e-13, 2.4889e-13, 2.3442e-13, 2.1113e-13,\n",
       "             2.0448e-13, 1.6805e-13, 7.1670e-14, 6.9970e-14, 5.0736e-14, 3.1179e-14,\n",
       "             2.8935e-14, 2.8915e-14, 2.2269e-14, 1.1759e-14, 9.1897e-15, 8.2944e-15,\n",
       "             8.0583e-15, 7.3183e-15, 5.2710e-15, 1.9841e-15, 1.9160e-15, 1.4322e-15,\n",
       "             1.3398e-15, 1.1168e-15, 1.0929e-15, 9.1189e-16, 8.1115e-16, 7.9751e-16,\n",
       "             6.2058e-16, 5.5254e-16, 5.3329e-16, 3.7211e-16, 3.7116e-16, 8.8680e-17,\n",
       "             8.1609e-17, 7.1219e-17, 6.2794e-17, 5.4551e-17, 1.3357e-17, 1.0555e-17,\n",
       "             7.6948e-18, 1.6830e-18, 3.6178e-19, 2.6185e-19, 1.4097e-19, 6.8708e-20,\n",
       "             3.8379e-20, 3.7367e-20, 1.0676e-20, 9.4013e-21, 6.7412e-21, 5.1275e-21,\n",
       "             1.3166e-21, 7.6582e-22, 9.8185e-23, 4.7800e-23, 1.1491e-31, 5.5580e-32])}},\n",
       "   {'fpr': np.float64(0.40716612377850164),\n",
       "    'tpr': np.float64(0.9942528735632183),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0847, 0.0977, 0.0977, 0.0977, 0.1010, 0.1010, 0.1042, 0.1075,\n",
       "             0.1107, 0.1107, 0.1107, 0.1107, 0.1107, 0.1140, 0.1173, 0.1173, 0.1173,\n",
       "             0.1173, 0.1205, 0.1205, 0.1205, 0.1238, 0.1270, 0.1303, 0.1336, 0.1336,\n",
       "             0.1368, 0.1401, 0.1433, 0.1466, 0.1466, 0.1498, 0.1531, 0.1531, 0.1564,\n",
       "             0.1629, 0.1629, 0.1661, 0.1694, 0.1726, 0.1759, 0.1792, 0.1792, 0.1792,\n",
       "             0.1792, 0.1824, 0.1857, 0.1889, 0.1922, 0.1954, 0.1987, 0.2020, 0.2052,\n",
       "             0.2085, 0.2117, 0.2150, 0.2182, 0.2215, 0.2215, 0.2248, 0.2280, 0.2313,\n",
       "             0.2345, 0.2345, 0.2378, 0.2378, 0.2410, 0.2443, 0.2476, 0.2508, 0.2541,\n",
       "             0.2573, 0.2606, 0.2638, 0.2671, 0.2704, 0.2736, 0.2769, 0.2801, 0.2834,\n",
       "             0.2866, 0.2899, 0.2932, 0.2964, 0.2997, 0.3029, 0.3062, 0.3094, 0.3127,\n",
       "             0.3160, 0.3192, 0.3225, 0.3257, 0.3290, 0.3322, 0.3355, 0.3388, 0.3420,\n",
       "             0.3420, 0.3453, 0.3485, 0.3518, 0.3550, 0.3583, 0.3616, 0.3648, 0.3648,\n",
       "             0.3681, 0.3713, 0.3746, 0.3779, 0.3811, 0.3844, 0.3876, 0.3909, 0.3941,\n",
       "             0.3974, 0.4007, 0.4039, 0.4072, 0.4104, 0.4137, 0.4137, 0.4169, 0.4202,\n",
       "             0.4235, 0.4267, 0.4300, 0.4332, 0.4365, 0.4397, 0.4430, 0.4463, 0.4495,\n",
       "             0.4528, 0.4560, 0.4593, 0.4625, 0.4658, 0.4691, 0.4723, 0.4756, 0.4788,\n",
       "             0.4821, 0.4821, 0.4853, 0.4886, 0.4919, 0.4951, 0.4984, 0.5016, 0.5049,\n",
       "             0.5081, 0.5114, 0.5147, 0.5179, 0.5212, 0.5244, 0.5277, 0.5309, 0.5342,\n",
       "             0.5375, 0.5407, 0.5440, 0.5472, 0.5505, 0.5537, 0.5570, 0.5603, 0.5635,\n",
       "             0.5668, 0.5700, 0.5733, 0.5765, 0.5798, 0.5831, 0.5863, 0.5896, 0.5928,\n",
       "             0.5961, 0.5993, 0.6026, 0.6059, 0.6091, 0.6124, 0.6156, 0.6189, 0.6221,\n",
       "             0.6254, 0.6287, 0.6319, 0.6319, 0.6352, 0.6352, 0.6352, 0.6384, 0.6417,\n",
       "             0.6450, 0.6482, 0.6515, 0.6547, 0.6580, 0.6612, 0.6645, 0.6678, 0.6710,\n",
       "             0.6743, 0.6775, 0.6808, 0.6840, 0.6873, 0.6906, 0.6938, 0.6971, 0.7003,\n",
       "             0.7036, 0.7068, 0.7101, 0.7134, 0.7166, 0.7199, 0.7231, 0.7264, 0.7296,\n",
       "             0.7329, 0.7362, 0.7394, 0.7427, 0.7459, 0.7492, 0.7524, 0.7557, 0.7590,\n",
       "             0.7622, 0.7655, 0.7687, 0.7720, 0.7752, 0.7785, 0.7818, 0.7850, 0.7883,\n",
       "             0.7915, 0.7948, 0.7980, 0.8013, 0.8046, 0.8078, 0.8111, 0.8143, 0.8176,\n",
       "             0.8208, 0.8241, 0.8274, 0.8306, 0.8339, 0.8371, 0.8404, 0.8436, 0.8469,\n",
       "             0.8502, 0.8534, 0.8567, 0.8599, 0.8632, 0.8664, 0.8697, 0.8730, 0.8762,\n",
       "             0.8795, 0.8827, 0.8860, 0.8893, 0.8925, 0.8958, 0.8990, 0.9023, 0.9055,\n",
       "             0.9088, 0.9121, 0.9153, 0.9186, 0.9218, 0.9251, 0.9283, 0.9316, 0.9349,\n",
       "             0.9381, 0.9414, 0.9446, 0.9479, 0.9511, 0.9544, 0.9577, 0.9609, 0.9642,\n",
       "             0.9674, 0.9707, 0.9739, 0.9772, 0.9805, 0.9837, 0.9870, 0.9902, 0.9935,\n",
       "             0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.9437, 0.9552, 0.9598, 0.9609, 0.9632, 0.9667, 0.9678, 0.9678,\n",
       "             0.9701, 0.9713, 0.9724, 0.9736, 0.9747, 0.9747, 0.9747, 0.9759, 0.9770,\n",
       "             0.9782, 0.9782, 0.9793, 0.9805, 0.9805, 0.9805, 0.9805, 0.9805, 0.9816,\n",
       "             0.9816, 0.9816, 0.9816, 0.9816, 0.9828, 0.9828, 0.9828, 0.9839, 0.9839,\n",
       "             0.9839, 0.9851, 0.9851, 0.9851, 0.9851, 0.9851, 0.9851, 0.9862, 0.9874,\n",
       "             0.9885, 0.9885, 0.9885, 0.9885, 0.9885, 0.9885, 0.9885, 0.9885, 0.9885,\n",
       "             0.9885, 0.9885, 0.9885, 0.9885, 0.9885, 0.9897, 0.9897, 0.9897, 0.9897,\n",
       "             0.9897, 0.9908, 0.9908, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920,\n",
       "             0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920,\n",
       "             0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920,\n",
       "             0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920,\n",
       "             0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9943,\n",
       "             0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943,\n",
       "             0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9977, 0.9977, 0.9989, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9994e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9991e-01, 9.9990e-01,\n",
       "             9.9989e-01, 9.9985e-01, 9.9984e-01, 9.9979e-01, 9.9979e-01, 9.9976e-01,\n",
       "             9.9973e-01, 9.9968e-01, 9.9967e-01, 9.9956e-01, 9.9952e-01, 9.9946e-01,\n",
       "             9.9937e-01, 9.9930e-01, 9.9928e-01, 9.9910e-01, 9.9883e-01, 9.9879e-01,\n",
       "             9.9842e-01, 9.9788e-01, 9.9752e-01, 9.9585e-01, 9.9456e-01, 9.9432e-01,\n",
       "             9.9391e-01, 9.9327e-01, 9.9277e-01, 9.9264e-01, 9.9155e-01, 9.9101e-01,\n",
       "             9.9100e-01, 9.9096e-01, 9.8926e-01, 9.8896e-01, 9.8718e-01, 9.8712e-01,\n",
       "             9.8687e-01, 9.8655e-01, 9.8584e-01, 9.8177e-01, 9.7785e-01, 9.7769e-01,\n",
       "             9.7617e-01, 9.7391e-01, 9.6645e-01, 9.6036e-01, 9.5843e-01, 9.5091e-01,\n",
       "             9.4750e-01, 9.4186e-01, 9.3837e-01, 9.3521e-01, 9.3325e-01, 9.2647e-01,\n",
       "             9.1827e-01, 9.1819e-01, 9.1018e-01, 8.7431e-01, 8.4068e-01, 8.3329e-01,\n",
       "             8.1714e-01, 8.0881e-01, 7.9513e-01, 7.8239e-01, 7.8050e-01, 7.3406e-01,\n",
       "             7.2542e-01, 7.2070e-01, 7.1849e-01, 6.6646e-01, 6.5411e-01, 6.3450e-01,\n",
       "             5.2118e-01, 4.8745e-01, 4.8398e-01, 4.7280e-01, 4.1788e-01, 3.7551e-01,\n",
       "             3.5434e-01, 3.4506e-01, 3.2689e-01, 3.1080e-01, 3.0322e-01, 3.0105e-01,\n",
       "             2.9921e-01, 2.4211e-01, 1.5474e-01, 1.5194e-01, 1.1454e-01, 1.1445e-01,\n",
       "             1.1013e-01, 9.4962e-02, 8.8094e-02, 8.3396e-02, 8.0044e-02, 7.3838e-02,\n",
       "             7.0535e-02, 5.8181e-02, 4.0192e-02, 3.1473e-02, 2.7407e-02, 1.2826e-02,\n",
       "             1.2694e-02, 1.1758e-02, 9.7902e-03, 9.4823e-03, 9.2022e-03, 8.7313e-03,\n",
       "             8.2645e-03, 7.3985e-03, 7.3048e-03, 7.1701e-03, 6.8347e-03, 6.6492e-03,\n",
       "             6.0072e-03, 5.2545e-03, 4.9417e-03, 4.2529e-03, 4.0833e-03, 4.0648e-03,\n",
       "             3.9032e-03, 3.7305e-03, 3.4819e-03, 2.9932e-03, 2.5155e-03, 2.4943e-03,\n",
       "             1.9667e-03, 1.2680e-03, 1.2318e-03, 9.9768e-04, 7.4822e-04, 7.4595e-04,\n",
       "             7.2377e-04, 6.5367e-04, 6.2651e-04, 6.0220e-04, 5.6899e-04, 5.3781e-04,\n",
       "             5.0099e-04, 4.2006e-04, 4.0219e-04, 3.7094e-04, 3.2791e-04, 3.1573e-04,\n",
       "             2.2279e-04, 2.0893e-04, 1.7960e-04, 1.6014e-04, 1.4052e-04, 1.3287e-04,\n",
       "             1.2861e-04, 1.2714e-04, 1.2502e-04, 9.9260e-05, 9.2601e-05, 8.5057e-05,\n",
       "             6.6717e-05, 4.8418e-05, 4.7421e-05, 4.2707e-05, 4.0536e-05, 3.8809e-05,\n",
       "             3.6525e-05, 3.3944e-05, 3.2164e-05, 3.1970e-05, 2.5503e-05, 2.4780e-05,\n",
       "             1.9836e-05, 1.7397e-05, 1.5594e-05, 1.1366e-05, 1.1112e-05, 9.4280e-06,\n",
       "             9.2554e-06, 9.1537e-06, 8.9136e-06, 8.1254e-06, 7.4271e-06, 7.2983e-06,\n",
       "             6.9246e-06, 6.8325e-06, 5.8510e-06, 5.6030e-06, 4.7942e-06, 4.5754e-06,\n",
       "             4.3928e-06, 3.8641e-06, 3.2708e-06, 3.0985e-06, 3.0677e-06, 2.3131e-06,\n",
       "             2.1758e-06, 2.1704e-06, 2.1527e-06, 1.5429e-06, 1.4189e-06, 1.3976e-06,\n",
       "             1.3714e-06, 1.3658e-06, 1.1497e-06, 7.2238e-07, 6.8555e-07, 6.5168e-07,\n",
       "             3.6477e-07, 2.1237e-07, 1.9015e-07, 1.6439e-07, 1.1797e-07, 8.9651e-08,\n",
       "             5.9813e-08, 5.3437e-08, 3.8448e-08, 3.7692e-08, 3.7374e-08, 3.1534e-08,\n",
       "             3.1251e-08, 1.3049e-08, 1.2371e-08, 1.2297e-08, 1.1574e-08, 9.2022e-09,\n",
       "             7.5066e-09, 7.3332e-09, 4.4305e-09, 4.0866e-09, 4.0268e-09, 2.5576e-09,\n",
       "             2.3644e-09, 1.2105e-09, 8.9201e-10, 8.7321e-10, 6.7055e-10, 5.9502e-10,\n",
       "             5.1302e-10, 2.6676e-10, 2.3212e-10, 1.9525e-10, 1.0652e-10, 2.2187e-11,\n",
       "             9.2430e-12, 3.7843e-12, 3.6776e-12, 1.5720e-12, 1.4861e-12, 1.3634e-12,\n",
       "             1.0913e-12, 9.7881e-13, 5.7826e-13, 5.0384e-13, 4.9256e-13, 3.3515e-13,\n",
       "             6.2697e-14, 2.5890e-14, 1.8232e-14, 3.2363e-15, 8.9638e-17, 6.3170e-17,\n",
       "             2.9467e-19, 2.9337e-19])}}],\n",
       "  [{'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.0),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0022,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 3.9753e-01, 2.8787e-01,  ..., 2.6765e-11, 1.8997e-11,\n",
       "             1.5550e-11])}},\n",
       "   {'fpr': np.float64(0.0035587188612099642),\n",
       "    'tpr': np.float64(0.71875),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0022,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9122e-01, 9.8924e-01,  ..., 2.3982e-05, 1.1975e-05,\n",
       "             9.1302e-06])}},\n",
       "   {'fpr': np.float64(0.046263345195729534),\n",
       "    'tpr': np.float64(0.9453125),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0022,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9841e-01, 9.9770e-01,  ..., 1.2020e-04, 4.8357e-05,\n",
       "             4.8183e-05])}},\n",
       "   {'fpr': np.float64(0.017793594306049824),\n",
       "    'tpr': np.float64(0.9129464285714286),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0033,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9995e-01, 9.9993e-01,  ..., 1.0187e-07, 1.4640e-08,\n",
       "             5.6864e-09])}},\n",
       "   {'fpr': np.float64(0.028469750889679714),\n",
       "    'tpr': np.float64(0.9631696428571429),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0033, 0.0045,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 9.9999e-01,  ..., 1.0170e-08, 4.7741e-09,\n",
       "             2.5028e-09])}},\n",
       "   {'fpr': np.float64(0.02491103202846975),\n",
       "    'tpr': np.float64(0.9375),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0022,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 4.6949e-11, 1.8428e-11,\n",
       "             2.9440e-12])}},\n",
       "   {'fpr': np.float64(0.028469750889679714),\n",
       "    'tpr': np.float64(0.9665178571428571),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0033,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.0119e-10, 2.8004e-10,\n",
       "             7.8818e-11])}},\n",
       "   {'fpr': np.float64(0.03558718861209965),\n",
       "    'tpr': np.float64(0.9709821428571429),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0033,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.0863e-08, 3.7967e-08,\n",
       "             1.2946e-08])}},\n",
       "   {'fpr': np.float64(0.03558718861209965),\n",
       "    'tpr': np.float64(0.9821428571428571),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0022,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.3752e-08, 7.0870e-09,\n",
       "             4.9858e-09])}},\n",
       "   {'fpr': np.float64(0.021352313167259787),\n",
       "    'tpr': np.float64(0.9609375),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0022,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 7.5283e-11, 6.6510e-11,\n",
       "             2.9411e-11])}},\n",
       "   {'fpr': np.float64(0.0498220640569395),\n",
       "    'tpr': np.float64(0.9776785714285714),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0033, 0.0078,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 7.6604e-10, 7.2220e-10,\n",
       "             3.3287e-10])}},\n",
       "   {'fpr': np.float64(0.05693950177935943),\n",
       "    'tpr': np.float64(0.9899553571428571),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
       "             0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
       "             0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
       "             0.0142, 0.0142, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214,\n",
       "             0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214,\n",
       "             0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0249, 0.0285, 0.0285, 0.0285,\n",
       "             0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
       "             0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
       "             0.0320, 0.0320, 0.0356, 0.0391, 0.0427, 0.0427, 0.0427, 0.0427, 0.0427,\n",
       "             0.0427, 0.0427, 0.0427, 0.0463, 0.0463, 0.0463, 0.0463, 0.0463, 0.0463,\n",
       "             0.0463, 0.0498, 0.0534, 0.0534, 0.0534, 0.0534, 0.0534, 0.0569, 0.0569,\n",
       "             0.0569, 0.0569, 0.0605, 0.0641, 0.0676, 0.0712, 0.0747, 0.0783, 0.0819,\n",
       "             0.0854, 0.0890, 0.0925, 0.0961, 0.0996, 0.0996, 0.1032, 0.1068, 0.1068,\n",
       "             0.1103, 0.1103, 0.1139, 0.1174, 0.1210, 0.1246, 0.1281, 0.1281, 0.1317,\n",
       "             0.1352, 0.1388, 0.1423, 0.1459, 0.1495, 0.1530, 0.1566, 0.1601, 0.1637,\n",
       "             0.1673, 0.1708, 0.1744, 0.1779, 0.1815, 0.1815, 0.1851, 0.1886, 0.1922,\n",
       "             0.1957, 0.1993, 0.2028, 0.2064, 0.2100, 0.2135, 0.2171, 0.2206, 0.2242,\n",
       "             0.2278, 0.2313, 0.2349, 0.2384, 0.2420, 0.2456, 0.2491, 0.2527, 0.2562,\n",
       "             0.2598, 0.2633, 0.2669, 0.2705, 0.2740, 0.2776, 0.2811, 0.2847, 0.2883,\n",
       "             0.2918, 0.2954, 0.2989, 0.3025, 0.3060, 0.3096, 0.3132, 0.3167, 0.3203,\n",
       "             0.3238, 0.3274, 0.3310, 0.3345, 0.3381, 0.3416, 0.3452, 0.3488, 0.3523,\n",
       "             0.3559, 0.3559, 0.3594, 0.3630, 0.3665, 0.3701, 0.3737, 0.3772, 0.3808,\n",
       "             0.3843, 0.3879, 0.3915, 0.3950, 0.3986, 0.4021, 0.4057, 0.4093, 0.4128,\n",
       "             0.4164, 0.4199, 0.4235, 0.4270, 0.4306, 0.4342, 0.4377, 0.4377, 0.4413,\n",
       "             0.4448, 0.4484, 0.4520, 0.4555, 0.4591, 0.4626, 0.4662, 0.4698, 0.4733,\n",
       "             0.4769, 0.4804, 0.4840, 0.4875, 0.4911, 0.4947, 0.4982, 0.5018, 0.5053,\n",
       "             0.5089, 0.5125, 0.5160, 0.5196, 0.5231, 0.5267, 0.5302, 0.5338, 0.5374,\n",
       "             0.5409, 0.5445, 0.5480, 0.5516, 0.5552, 0.5587, 0.5623, 0.5658, 0.5694,\n",
       "             0.5730, 0.5765, 0.5801, 0.5836, 0.5872, 0.5907, 0.5943, 0.5979, 0.6014,\n",
       "             0.6050, 0.6085, 0.6121, 0.6157, 0.6192, 0.6228, 0.6263, 0.6299, 0.6335,\n",
       "             0.6370, 0.6406, 0.6441, 0.6477, 0.6512, 0.6548, 0.6584, 0.6619, 0.6655,\n",
       "             0.6690, 0.6726, 0.6762, 0.6797, 0.6833, 0.6868, 0.6904, 0.6940, 0.6975,\n",
       "             0.7011, 0.7046, 0.7082, 0.7117, 0.7153, 0.7189, 0.7224, 0.7260, 0.7295,\n",
       "             0.7331, 0.7367, 0.7402, 0.7438, 0.7473, 0.7509, 0.7544, 0.7580, 0.7616,\n",
       "             0.7651, 0.7687, 0.7722, 0.7758, 0.7794, 0.7829, 0.7865, 0.7900, 0.7936,\n",
       "             0.7972, 0.8007, 0.8043, 0.8078, 0.8114, 0.8149, 0.8185, 0.8221, 0.8256,\n",
       "             0.8292, 0.8327, 0.8363, 0.8399, 0.8434, 0.8470, 0.8505, 0.8541, 0.8577,\n",
       "             0.8612, 0.8648, 0.8683, 0.8719, 0.8754, 0.8790, 0.8826, 0.8861, 0.8897,\n",
       "             0.8932, 0.8968, 0.9004, 0.9039, 0.9075, 0.9110, 0.9146, 0.9181, 0.9217,\n",
       "             0.9253, 0.9288, 0.9324, 0.9359, 0.9395, 0.9431, 0.9466, 0.9502, 0.9537,\n",
       "             0.9573, 0.9609, 0.9644, 0.9680, 0.9715, 0.9751, 0.9786, 0.9822, 0.9858,\n",
       "             0.9893, 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0446, 0.0792, 0.1049, 0.1295, 0.1462, 0.1618, 0.1730, 0.1819,\n",
       "             0.1853, 0.1897, 0.1964, 0.2076, 0.2109, 0.2188, 0.2310, 0.2388, 0.2444,\n",
       "             0.2511, 0.2545, 0.2589, 0.2701, 0.2779, 0.2812, 0.2835, 0.2846, 0.2913,\n",
       "             0.2935, 0.2969, 0.3013, 0.3047, 0.3092, 0.3136, 0.3147, 0.3170, 0.3181,\n",
       "             0.3214, 0.3225, 0.3248, 0.3259, 0.3304, 0.3348, 0.3382, 0.3415, 0.3438,\n",
       "             0.3449, 0.3471, 0.3504, 0.3538, 0.3560, 0.3605, 0.3616, 0.3638, 0.3661,\n",
       "             0.3672, 0.3683, 0.3694, 0.3717, 0.3750, 0.3761, 0.3772, 0.3783, 0.3795,\n",
       "             0.3806, 0.3828, 0.3850, 0.3873, 0.3884, 0.3917, 0.3929, 0.3940, 0.3951,\n",
       "             0.3962, 0.3984, 0.3996, 0.4007, 0.4018, 0.4029, 0.4051, 0.4062, 0.4096,\n",
       "             0.4118, 0.4129, 0.4141, 0.4163, 0.4185, 0.4230, 0.4252, 0.4263, 0.4286,\n",
       "             0.4297, 0.4308, 0.4342, 0.4375, 0.4420, 0.4442, 0.4475, 0.4487, 0.4498,\n",
       "             0.4509, 0.4520, 0.4542, 0.4554, 0.4609, 0.4621, 0.4654, 0.4665, 0.4676,\n",
       "             0.4688, 0.4699, 0.4710, 0.4732, 0.4754, 0.4766, 0.4788, 0.4810, 0.4821,\n",
       "             0.4833, 0.4855, 0.4866, 0.4888, 0.4911, 0.4922, 0.4933, 0.4944, 0.4955,\n",
       "             0.4978, 0.4989, 0.5000, 0.5011, 0.5033, 0.5045, 0.5056, 0.5067, 0.5078,\n",
       "             0.5089, 0.5100, 0.5123, 0.5134, 0.5145, 0.5156, 0.5167, 0.5190, 0.5201,\n",
       "             0.5212, 0.5223, 0.5246, 0.5257, 0.5268, 0.5279, 0.5290, 0.5301, 0.5312,\n",
       "             0.5324, 0.5335, 0.5346, 0.5357, 0.5368, 0.5379, 0.5391, 0.5402, 0.5413,\n",
       "             0.5424, 0.5435, 0.5446, 0.5458, 0.5469, 0.5480, 0.5513, 0.5525, 0.5536,\n",
       "             0.5558, 0.5569, 0.5580, 0.5592, 0.5603, 0.5625, 0.5636, 0.5647, 0.5658,\n",
       "             0.5670, 0.5681, 0.5703, 0.5714, 0.5725, 0.5737, 0.5748, 0.5759, 0.5770,\n",
       "             0.5781, 0.5792, 0.5804, 0.5815, 0.5826, 0.5837, 0.5848, 0.5859, 0.5871,\n",
       "             0.5882, 0.5893, 0.5904, 0.5915, 0.5938, 0.5949, 0.5960, 0.5971, 0.5982,\n",
       "             0.5993, 0.6004, 0.6038, 0.6049, 0.6060, 0.6071, 0.6083, 0.6094, 0.6105,\n",
       "             0.6116, 0.6127, 0.6138, 0.6150, 0.6194, 0.6205, 0.6217, 0.6228, 0.6239,\n",
       "             0.6250, 0.6261, 0.6272, 0.6283, 0.6295, 0.6306, 0.6317, 0.6328, 0.6339,\n",
       "             0.6350, 0.6362, 0.6373, 0.6384, 0.6395, 0.6406, 0.6417, 0.6429, 0.6440,\n",
       "             0.6451, 0.6462, 0.6473, 0.6496, 0.6518, 0.6529, 0.6540, 0.6551, 0.6562,\n",
       "             0.6574, 0.6585, 0.6596, 0.6607, 0.6618, 0.6629, 0.6641, 0.6652, 0.6663,\n",
       "             0.6674, 0.6685, 0.6708, 0.6719, 0.6730, 0.6741, 0.6752, 0.6763, 0.6775,\n",
       "             0.6786, 0.6797, 0.6808, 0.6819, 0.6830, 0.6842, 0.6853, 0.6864, 0.6875,\n",
       "             0.6886, 0.6897, 0.6908, 0.6920, 0.6931, 0.6942, 0.6953, 0.6964, 0.6975,\n",
       "             0.6987, 0.7009, 0.7020, 0.7031, 0.7042, 0.7065, 0.7076, 0.7087, 0.7098,\n",
       "             0.7109, 0.7121, 0.7132, 0.7143, 0.7154, 0.7165, 0.7176, 0.7188, 0.7199,\n",
       "             0.7210, 0.7221, 0.7232, 0.7254, 0.7266, 0.7277, 0.7288, 0.7299, 0.7310,\n",
       "             0.7321, 0.7333, 0.7344, 0.7355, 0.7366, 0.7377, 0.7388, 0.7411, 0.7422,\n",
       "             0.7433, 0.7444, 0.7455, 0.7467, 0.7478, 0.7489, 0.7500, 0.7511, 0.7522,\n",
       "             0.7533, 0.7556, 0.7567, 0.7578, 0.7589, 0.7600, 0.7612, 0.7623, 0.7634,\n",
       "             0.7645, 0.7656, 0.7667, 0.7679, 0.7690, 0.7701, 0.7712, 0.7723, 0.7734,\n",
       "             0.7746, 0.7757, 0.7768, 0.7779, 0.7790, 0.7801, 0.7812, 0.7824, 0.7835,\n",
       "             0.7846, 0.7857, 0.7868, 0.7879, 0.7891, 0.7902, 0.7913, 0.7924, 0.7935,\n",
       "             0.7946, 0.7958, 0.7969, 0.7980, 0.7991, 0.8002, 0.8013, 0.8025, 0.8036,\n",
       "             0.8047, 0.8058, 0.8069, 0.8069, 0.8080, 0.8092, 0.8103, 0.8114, 0.8125,\n",
       "             0.8136, 0.8147, 0.8147, 0.8158, 0.8170, 0.8181, 0.8192, 0.8203, 0.8214,\n",
       "             0.8225, 0.8237, 0.8248, 0.8259, 0.8270, 0.8281, 0.8292, 0.8304, 0.8315,\n",
       "             0.8326, 0.8337, 0.8348, 0.8359, 0.8371, 0.8382, 0.8393, 0.8404, 0.8415,\n",
       "             0.8426, 0.8438, 0.8438, 0.8449, 0.8460, 0.8471, 0.8482, 0.8493, 0.8504,\n",
       "             0.8516, 0.8527, 0.8538, 0.8549, 0.8560, 0.8571, 0.8583, 0.8594, 0.8605,\n",
       "             0.8616, 0.8627, 0.8638, 0.8650, 0.8661, 0.8672, 0.8683, 0.8694, 0.8705,\n",
       "             0.8717, 0.8728, 0.8739, 0.8750, 0.8761, 0.8772, 0.8783, 0.8795, 0.8806,\n",
       "             0.8817, 0.8828, 0.8839, 0.8850, 0.8862, 0.8873, 0.8884, 0.8895, 0.8906,\n",
       "             0.8917, 0.8929, 0.8940, 0.8962, 0.8973, 0.8984, 0.8996, 0.9007, 0.9018,\n",
       "             0.9029, 0.9040, 0.9051, 0.9062, 0.9074, 0.9085, 0.9096, 0.9107, 0.9118,\n",
       "             0.9129, 0.9141, 0.9152, 0.9163, 0.9174, 0.9185, 0.9196, 0.9208, 0.9219,\n",
       "             0.9219, 0.9230, 0.9241, 0.9252, 0.9263, 0.9275, 0.9286, 0.9297, 0.9308,\n",
       "             0.9319, 0.9330, 0.9342, 0.9353, 0.9364, 0.9375, 0.9386, 0.9397, 0.9408,\n",
       "             0.9420, 0.9431, 0.9442, 0.9453, 0.9464, 0.9464, 0.9464, 0.9475, 0.9487,\n",
       "             0.9487, 0.9498, 0.9509, 0.9520, 0.9531, 0.9542, 0.9554, 0.9565, 0.9576,\n",
       "             0.9587, 0.9598, 0.9609, 0.9621, 0.9632, 0.9643, 0.9654, 0.9665, 0.9676,\n",
       "             0.9688, 0.9699, 0.9699, 0.9699, 0.9699, 0.9710, 0.9721, 0.9732, 0.9743,\n",
       "             0.9754, 0.9766, 0.9777, 0.9777, 0.9788, 0.9799, 0.9810, 0.9821, 0.9833,\n",
       "             0.9844, 0.9844, 0.9844, 0.9855, 0.9866, 0.9877, 0.9888, 0.9888, 0.9900,\n",
       "             0.9911, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "             0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9933, 0.9933, 0.9933, 0.9944,\n",
       "             0.9944, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9967, 0.9967,\n",
       "             0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967,\n",
       "             0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01,\n",
       "             9.9985e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01,\n",
       "             9.9984e-01, 9.9984e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9983e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01,\n",
       "             9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01,\n",
       "             9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9979e-01, 9.9979e-01, 9.9979e-01,\n",
       "             9.9979e-01, 9.9979e-01, 9.9978e-01, 9.9978e-01, 9.9978e-01, 9.9978e-01,\n",
       "             9.9978e-01, 9.9978e-01, 9.9977e-01, 9.9977e-01, 9.9977e-01, 9.9976e-01,\n",
       "             9.9976e-01, 9.9975e-01, 9.9975e-01, 9.9975e-01, 9.9975e-01, 9.9975e-01,\n",
       "             9.9974e-01, 9.9974e-01, 9.9973e-01, 9.9973e-01, 9.9973e-01, 9.9972e-01,\n",
       "             9.9972e-01, 9.9972e-01, 9.9971e-01, 9.9971e-01, 9.9970e-01, 9.9969e-01,\n",
       "             9.9969e-01, 9.9969e-01, 9.9969e-01, 9.9969e-01, 9.9968e-01, 9.9968e-01,\n",
       "             9.9968e-01, 9.9966e-01, 9.9965e-01, 9.9964e-01, 9.9964e-01, 9.9964e-01,\n",
       "             9.9963e-01, 9.9963e-01, 9.9962e-01, 9.9961e-01, 9.9961e-01, 9.9961e-01,\n",
       "             9.9961e-01, 9.9961e-01, 9.9959e-01, 9.9957e-01, 9.9956e-01, 9.9954e-01,\n",
       "             9.9954e-01, 9.9953e-01, 9.9952e-01, 9.9952e-01, 9.9951e-01, 9.9950e-01,\n",
       "             9.9949e-01, 9.9948e-01, 9.9947e-01, 9.9947e-01, 9.9947e-01, 9.9946e-01,\n",
       "             9.9946e-01, 9.9944e-01, 9.9944e-01, 9.9940e-01, 9.9939e-01, 9.9937e-01,\n",
       "             9.9936e-01, 9.9936e-01, 9.9933e-01, 9.9932e-01, 9.9930e-01, 9.9930e-01,\n",
       "             9.9925e-01, 9.9924e-01, 9.9923e-01, 9.9923e-01, 9.9920e-01, 9.9918e-01,\n",
       "             9.9917e-01, 9.9917e-01, 9.9916e-01, 9.9915e-01, 9.9913e-01, 9.9912e-01,\n",
       "             9.9906e-01, 9.9906e-01, 9.9905e-01, 9.9904e-01, 9.9901e-01, 9.9900e-01,\n",
       "             9.9899e-01, 9.9898e-01, 9.9895e-01, 9.9889e-01, 9.9889e-01, 9.9887e-01,\n",
       "             9.9885e-01, 9.9884e-01, 9.9875e-01, 9.9875e-01, 9.9874e-01, 9.9847e-01,\n",
       "             9.9847e-01, 9.9845e-01, 9.9844e-01, 9.9843e-01, 9.9831e-01, 9.9829e-01,\n",
       "             9.9821e-01, 9.9821e-01, 9.9809e-01, 9.9800e-01, 9.9787e-01, 9.9771e-01,\n",
       "             9.9757e-01, 9.9756e-01, 9.9751e-01, 9.9730e-01, 9.9727e-01, 9.9695e-01,\n",
       "             9.9688e-01, 9.9684e-01, 9.9666e-01, 9.9652e-01, 9.9639e-01, 9.9615e-01,\n",
       "             9.9569e-01, 9.9544e-01, 9.9543e-01, 9.9534e-01, 9.9529e-01, 9.9510e-01,\n",
       "             9.9489e-01, 9.9489e-01, 9.9471e-01, 9.9464e-01, 9.9455e-01, 9.9446e-01,\n",
       "             9.9423e-01, 9.9374e-01, 9.9352e-01, 9.9317e-01, 9.9285e-01, 9.9217e-01,\n",
       "             9.9172e-01, 9.9088e-01, 9.8980e-01, 9.8777e-01, 9.8770e-01, 9.8743e-01,\n",
       "             9.8729e-01, 9.8718e-01, 9.8610e-01, 9.8582e-01, 9.8572e-01, 9.8470e-01,\n",
       "             9.8247e-01, 9.8031e-01, 9.7798e-01, 9.7521e-01, 9.7404e-01, 9.7397e-01,\n",
       "             9.7367e-01, 9.7282e-01, 9.7230e-01, 9.7076e-01, 9.6781e-01, 9.6694e-01,\n",
       "             9.6470e-01, 9.6263e-01, 9.5933e-01, 9.5530e-01, 9.5085e-01, 9.4995e-01,\n",
       "             9.4147e-01, 9.3622e-01, 9.2866e-01, 9.2268e-01, 8.9495e-01, 8.8847e-01,\n",
       "             8.5501e-01, 8.5170e-01, 8.5105e-01, 8.3001e-01, 8.2601e-01, 7.8591e-01,\n",
       "             7.3120e-01, 7.3036e-01, 6.3808e-01, 5.9710e-01, 5.9262e-01, 5.6508e-01,\n",
       "             4.9506e-01, 3.5115e-01, 3.0836e-01, 3.0418e-01, 2.2584e-01, 2.0051e-01,\n",
       "             1.7964e-01, 1.7302e-01, 1.6168e-01, 1.5529e-01, 1.2456e-01, 1.2096e-01,\n",
       "             1.2032e-01, 1.1621e-01, 1.1101e-01, 1.0146e-01, 7.1432e-02, 5.9772e-02,\n",
       "             5.8132e-02, 5.7956e-02, 5.7701e-02, 3.3361e-02, 3.0034e-02, 2.7951e-02,\n",
       "             2.7004e-02, 2.5749e-02, 2.1589e-02, 2.1055e-02, 1.8995e-02, 1.8836e-02,\n",
       "             1.7030e-02, 1.6517e-02, 1.6317e-02, 1.5461e-02, 1.5183e-02, 1.3790e-02,\n",
       "             1.2630e-02, 1.2552e-02, 1.2407e-02, 1.2309e-02, 1.0082e-02, 9.1798e-03,\n",
       "             9.1220e-03, 8.0858e-03, 7.6139e-03, 7.2260e-03, 6.9967e-03, 6.6574e-03,\n",
       "             6.2824e-03, 5.6758e-03, 5.5277e-03, 5.4479e-03, 5.1052e-03, 4.9340e-03,\n",
       "             4.7000e-03, 4.6015e-03, 4.5323e-03, 4.4871e-03, 4.3407e-03, 4.1451e-03,\n",
       "             3.9100e-03, 3.5917e-03, 3.4790e-03, 3.3713e-03, 2.6565e-03, 2.5778e-03,\n",
       "             2.4029e-03, 2.3849e-03, 2.2025e-03, 1.7084e-03, 1.6144e-03, 1.4174e-03,\n",
       "             1.3793e-03, 1.2429e-03, 1.2045e-03, 9.8737e-04, 9.2268e-04, 8.9023e-04,\n",
       "             8.8844e-04, 8.4873e-04, 8.4758e-04, 7.0348e-04, 7.0097e-04, 6.2866e-04,\n",
       "             6.1674e-04, 6.1042e-04, 5.8368e-04, 5.8002e-04, 5.7042e-04, 5.5587e-04,\n",
       "             5.4538e-04, 5.4103e-04, 4.8709e-04, 4.8642e-04, 4.4817e-04, 4.4123e-04,\n",
       "             4.3016e-04, 4.0792e-04, 3.9888e-04, 3.9828e-04, 3.8337e-04, 3.7456e-04,\n",
       "             3.6539e-04, 3.4558e-04, 3.4391e-04, 2.8562e-04, 2.7682e-04, 2.6637e-04,\n",
       "             2.6042e-04, 2.5885e-04, 2.5739e-04, 2.0711e-04, 2.0483e-04, 2.0040e-04,\n",
       "             1.8767e-04, 1.8074e-04, 1.7550e-04, 1.6472e-04, 1.6399e-04, 1.5622e-04,\n",
       "             1.5133e-04, 1.4487e-04, 1.3856e-04, 1.2545e-04, 1.0630e-04, 1.0591e-04,\n",
       "             9.0410e-05, 8.9851e-05, 8.1950e-05, 7.7077e-05, 7.3645e-05, 7.0910e-05,\n",
       "             6.4753e-05, 6.4301e-05, 6.4225e-05, 6.0526e-05, 6.0117e-05, 4.6414e-05,\n",
       "             4.5704e-05, 4.4221e-05, 4.4205e-05, 4.2753e-05, 4.1343e-05, 3.9303e-05,\n",
       "             3.7621e-05, 3.4260e-05, 3.3448e-05, 3.1697e-05, 3.0360e-05, 2.8907e-05,\n",
       "             2.5518e-05, 2.4836e-05, 2.4266e-05, 2.3381e-05, 2.3285e-05, 2.2058e-05,\n",
       "             2.1968e-05, 1.8505e-05, 1.7494e-05, 1.6023e-05, 1.5004e-05, 1.1135e-05,\n",
       "             9.6336e-06, 9.4074e-06, 8.0966e-06, 7.2299e-06, 6.4664e-06, 6.4087e-06,\n",
       "             5.4784e-06, 5.4364e-06, 4.8888e-06, 4.6227e-06, 4.5351e-06, 4.3235e-06,\n",
       "             4.2689e-06, 4.2662e-06, 4.1479e-06, 3.9404e-06, 3.3311e-06, 3.2247e-06,\n",
       "             3.2162e-06, 2.8805e-06, 2.8088e-06, 2.3955e-06, 2.3256e-06, 2.1454e-06,\n",
       "             2.1039e-06, 2.0919e-06, 1.9683e-06, 1.9500e-06, 1.8032e-06, 1.7983e-06,\n",
       "             1.6808e-06, 1.6302e-06, 1.5985e-06, 1.5844e-06, 1.5824e-06, 1.5220e-06,\n",
       "             1.4555e-06, 1.4198e-06, 1.3067e-06, 1.2103e-06, 1.1178e-06, 1.1064e-06,\n",
       "             1.0706e-06, 1.0704e-06, 1.0278e-06, 9.4874e-07, 9.1204e-07, 8.8956e-07,\n",
       "             8.3841e-07, 8.3421e-07, 7.7957e-07, 6.6041e-07, 6.0924e-07, 5.4980e-07,\n",
       "             4.9452e-07, 4.8771e-07, 4.4973e-07, 4.4590e-07, 4.1380e-07, 3.8732e-07,\n",
       "             3.7590e-07, 3.4452e-07, 3.2878e-07, 3.2732e-07, 3.2504e-07, 3.1473e-07,\n",
       "             2.9113e-07, 2.2668e-07, 2.2613e-07, 2.0863e-07, 2.0457e-07, 1.8473e-07,\n",
       "             1.8415e-07, 1.7335e-07, 1.6324e-07, 1.5566e-07, 1.5153e-07, 1.3750e-07,\n",
       "             1.3250e-07, 1.3162e-07, 1.2141e-07, 8.4341e-08, 8.1199e-08, 6.8081e-08,\n",
       "             6.2675e-08, 5.4418e-08, 5.3043e-08, 5.1257e-08, 5.0921e-08, 4.7812e-08,\n",
       "             4.7470e-08, 2.7615e-08, 2.3060e-08, 2.1740e-08, 2.0753e-08, 1.4812e-08,\n",
       "             1.0997e-08, 9.7883e-09, 9.5975e-09, 8.0418e-09, 6.2846e-09, 5.0905e-09,\n",
       "             2.5797e-09, 1.6325e-09, 1.3171e-09, 1.2174e-09, 1.2068e-09, 1.2061e-09,\n",
       "             1.0669e-09, 9.7288e-10, 4.9730e-10, 1.6262e-10])}},\n",
       "   {'fpr': np.float64(0.03558718861209965),\n",
       "    'tpr': np.float64(0.9720982142857143),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0056, 0.0100,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 7.3463e-12, 5.5101e-12,\n",
       "             1.6504e-12])}},\n",
       "   {'fpr': np.float64(0.05693950177935943),\n",
       "    'tpr': np.float64(0.9799107142857143),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
       "             0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
       "             0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
       "             0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
       "             0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
       "             0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
       "             0.0142, 0.0142, 0.0142, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0178, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214,\n",
       "             0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0249, 0.0249, 0.0249, 0.0249,\n",
       "             0.0249, 0.0249, 0.0249, 0.0249, 0.0249, 0.0249, 0.0249, 0.0249, 0.0249,\n",
       "             0.0249, 0.0249, 0.0249, 0.0249, 0.0249, 0.0249, 0.0249, 0.0285, 0.0285,\n",
       "             0.0285, 0.0285, 0.0285, 0.0285, 0.0320, 0.0320, 0.0320, 0.0320, 0.0356,\n",
       "             0.0356, 0.0356, 0.0356, 0.0391, 0.0427, 0.0463, 0.0463, 0.0463, 0.0463,\n",
       "             0.0463, 0.0463, 0.0463, 0.0498, 0.0498, 0.0498, 0.0534, 0.0569, 0.0569,\n",
       "             0.0605, 0.0641, 0.0641, 0.0641, 0.0641, 0.0641, 0.0641, 0.0641, 0.0641,\n",
       "             0.0641, 0.0676, 0.0712, 0.0712, 0.0712, 0.0747, 0.0783, 0.0819, 0.0854,\n",
       "             0.0890, 0.0925, 0.0925, 0.0961, 0.0996, 0.1032, 0.1068, 0.1103, 0.1103,\n",
       "             0.1139, 0.1174, 0.1210, 0.1246, 0.1281, 0.1317, 0.1352, 0.1388, 0.1423,\n",
       "             0.1423, 0.1459, 0.1495, 0.1495, 0.1530, 0.1530, 0.1566, 0.1601, 0.1637,\n",
       "             0.1673, 0.1708, 0.1744, 0.1779, 0.1815, 0.1851, 0.1886, 0.1922, 0.1957,\n",
       "             0.1957, 0.1993, 0.2028, 0.2064, 0.2100, 0.2135, 0.2171, 0.2206, 0.2242,\n",
       "             0.2278, 0.2313, 0.2349, 0.2384, 0.2420, 0.2456, 0.2491, 0.2527, 0.2562,\n",
       "             0.2598, 0.2633, 0.2669, 0.2705, 0.2740, 0.2776, 0.2811, 0.2847, 0.2883,\n",
       "             0.2918, 0.2954, 0.2989, 0.3025, 0.3060, 0.3096, 0.3132, 0.3167, 0.3203,\n",
       "             0.3238, 0.3274, 0.3310, 0.3345, 0.3381, 0.3416, 0.3452, 0.3488, 0.3523,\n",
       "             0.3559, 0.3594, 0.3630, 0.3665, 0.3701, 0.3737, 0.3772, 0.3808, 0.3843,\n",
       "             0.3879, 0.3915, 0.3950, 0.3986, 0.4021, 0.4057, 0.4093, 0.4128, 0.4164,\n",
       "             0.4199, 0.4235, 0.4270, 0.4306, 0.4342, 0.4377, 0.4413, 0.4448, 0.4484,\n",
       "             0.4520, 0.4555, 0.4591, 0.4626, 0.4662, 0.4698, 0.4733, 0.4769, 0.4804,\n",
       "             0.4840, 0.4875, 0.4911, 0.4947, 0.4982, 0.5018, 0.5053, 0.5089, 0.5089,\n",
       "             0.5125, 0.5160, 0.5196, 0.5231, 0.5267, 0.5302, 0.5338, 0.5374, 0.5409,\n",
       "             0.5445, 0.5480, 0.5516, 0.5552, 0.5587, 0.5623, 0.5658, 0.5694, 0.5730,\n",
       "             0.5765, 0.5801, 0.5836, 0.5872, 0.5907, 0.5943, 0.5979, 0.6014, 0.6050,\n",
       "             0.6085, 0.6121, 0.6157, 0.6192, 0.6228, 0.6263, 0.6299, 0.6335, 0.6370,\n",
       "             0.6406, 0.6441, 0.6477, 0.6512, 0.6548, 0.6584, 0.6619, 0.6655, 0.6690,\n",
       "             0.6726, 0.6762, 0.6797, 0.6833, 0.6868, 0.6904, 0.6940, 0.6975, 0.7011,\n",
       "             0.7046, 0.7082, 0.7117, 0.7153, 0.7189, 0.7224, 0.7260, 0.7295, 0.7331,\n",
       "             0.7367, 0.7402, 0.7438, 0.7473, 0.7509, 0.7544, 0.7580, 0.7616, 0.7651,\n",
       "             0.7687, 0.7722, 0.7758, 0.7794, 0.7829, 0.7865, 0.7900, 0.7936, 0.7972,\n",
       "             0.8007, 0.8043, 0.8078, 0.8114, 0.8149, 0.8185, 0.8221, 0.8256, 0.8292,\n",
       "             0.8327, 0.8363, 0.8399, 0.8434, 0.8470, 0.8505, 0.8541, 0.8577, 0.8612,\n",
       "             0.8648, 0.8683, 0.8719, 0.8754, 0.8790, 0.8826, 0.8861, 0.8897, 0.8932,\n",
       "             0.8968, 0.9004, 0.9039, 0.9075, 0.9110, 0.9146, 0.9181, 0.9217, 0.9253,\n",
       "             0.9288, 0.9324, 0.9359, 0.9395, 0.9431, 0.9466, 0.9502, 0.9537, 0.9573,\n",
       "             0.9609, 0.9644, 0.9680, 0.9715, 0.9751, 0.9786, 0.9822, 0.9858, 0.9893,\n",
       "             0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0179, 0.0279, 0.0491, 0.0636, 0.0792, 0.0904, 0.0993, 0.1071,\n",
       "             0.1138, 0.1205, 0.1272, 0.1395, 0.1440, 0.1551, 0.1596, 0.1652, 0.1730,\n",
       "             0.1786, 0.1808, 0.1886, 0.1920, 0.1987, 0.2031, 0.2087, 0.2132, 0.2176,\n",
       "             0.2188, 0.2199, 0.2221, 0.2266, 0.2299, 0.2344, 0.2366, 0.2411, 0.2444,\n",
       "             0.2478, 0.2500, 0.2511, 0.2533, 0.2545, 0.2556, 0.2578, 0.2589, 0.2600,\n",
       "             0.2612, 0.2645, 0.2690, 0.2712, 0.2734, 0.2790, 0.2812, 0.2846, 0.2913,\n",
       "             0.2924, 0.2935, 0.2958, 0.2969, 0.3002, 0.3036, 0.3058, 0.3069, 0.3080,\n",
       "             0.3114, 0.3125, 0.3147, 0.3181, 0.3203, 0.3237, 0.3248, 0.3259, 0.3304,\n",
       "             0.3315, 0.3337, 0.3359, 0.3382, 0.3393, 0.3404, 0.3415, 0.3438, 0.3449,\n",
       "             0.3460, 0.3482, 0.3493, 0.3516, 0.3538, 0.3560, 0.3571, 0.3583, 0.3616,\n",
       "             0.3661, 0.3672, 0.3683, 0.3694, 0.3705, 0.3728, 0.3739, 0.3750, 0.3761,\n",
       "             0.3772, 0.3795, 0.3817, 0.3828, 0.3850, 0.3884, 0.3906, 0.3929, 0.3973,\n",
       "             0.4007, 0.4029, 0.4051, 0.4074, 0.4085, 0.4096, 0.4107, 0.4118, 0.4129,\n",
       "             0.4141, 0.4152, 0.4174, 0.4185, 0.4219, 0.4230, 0.4241, 0.4263, 0.4275,\n",
       "             0.4286, 0.4308, 0.4319, 0.4342, 0.4353, 0.4364, 0.4375, 0.4386, 0.4420,\n",
       "             0.4431, 0.4442, 0.4453, 0.4464, 0.4487, 0.4498, 0.4509, 0.4520, 0.4542,\n",
       "             0.4554, 0.4565, 0.4576, 0.4598, 0.4609, 0.4621, 0.4643, 0.4676, 0.4688,\n",
       "             0.4699, 0.4710, 0.4721, 0.4743, 0.4754, 0.4766, 0.4777, 0.4788, 0.4799,\n",
       "             0.4821, 0.4833, 0.4844, 0.4855, 0.4866, 0.4888, 0.4900, 0.4911, 0.4922,\n",
       "             0.4944, 0.4955, 0.4967, 0.4978, 0.4989, 0.5000, 0.5011, 0.5022, 0.5033,\n",
       "             0.5045, 0.5056, 0.5078, 0.5089, 0.5100, 0.5112, 0.5123, 0.5134, 0.5145,\n",
       "             0.5156, 0.5167, 0.5179, 0.5190, 0.5212, 0.5234, 0.5246, 0.5257, 0.5279,\n",
       "             0.5290, 0.5301, 0.5312, 0.5324, 0.5346, 0.5357, 0.5368, 0.5379, 0.5391,\n",
       "             0.5413, 0.5424, 0.5435, 0.5458, 0.5469, 0.5480, 0.5502, 0.5513, 0.5536,\n",
       "             0.5558, 0.5569, 0.5580, 0.5592, 0.5603, 0.5614, 0.5625, 0.5636, 0.5647,\n",
       "             0.5658, 0.5670, 0.5681, 0.5692, 0.5703, 0.5714, 0.5725, 0.5737, 0.5748,\n",
       "             0.5759, 0.5770, 0.5781, 0.5792, 0.5804, 0.5815, 0.5826, 0.5837, 0.5848,\n",
       "             0.5859, 0.5871, 0.5882, 0.5893, 0.5904, 0.5915, 0.5926, 0.5938, 0.5949,\n",
       "             0.5960, 0.5971, 0.5982, 0.5993, 0.6004, 0.6016, 0.6027, 0.6038, 0.6049,\n",
       "             0.6060, 0.6071, 0.6083, 0.6094, 0.6105, 0.6116, 0.6127, 0.6138, 0.6150,\n",
       "             0.6161, 0.6194, 0.6205, 0.6217, 0.6228, 0.6239, 0.6250, 0.6272, 0.6295,\n",
       "             0.6306, 0.6317, 0.6328, 0.6339, 0.6350, 0.6362, 0.6373, 0.6384, 0.6395,\n",
       "             0.6406, 0.6417, 0.6429, 0.6440, 0.6462, 0.6473, 0.6484, 0.6496, 0.6507,\n",
       "             0.6518, 0.6529, 0.6540, 0.6551, 0.6562, 0.6574, 0.6585, 0.6596, 0.6607,\n",
       "             0.6618, 0.6629, 0.6641, 0.6652, 0.6663, 0.6674, 0.6685, 0.6696, 0.6708,\n",
       "             0.6719, 0.6730, 0.6752, 0.6763, 0.6775, 0.6786, 0.6797, 0.6808, 0.6819,\n",
       "             0.6830, 0.6842, 0.6853, 0.6864, 0.6875, 0.6886, 0.6897, 0.6920, 0.6931,\n",
       "             0.6942, 0.6964, 0.6975, 0.6987, 0.6998, 0.7009, 0.7020, 0.7031, 0.7042,\n",
       "             0.7054, 0.7065, 0.7076, 0.7087, 0.7098, 0.7109, 0.7121, 0.7132, 0.7143,\n",
       "             0.7154, 0.7165, 0.7176, 0.7188, 0.7199, 0.7210, 0.7221, 0.7232, 0.7243,\n",
       "             0.7254, 0.7266, 0.7277, 0.7288, 0.7299, 0.7310, 0.7321, 0.7333, 0.7355,\n",
       "             0.7366, 0.7377, 0.7388, 0.7400, 0.7411, 0.7422, 0.7433, 0.7444, 0.7455,\n",
       "             0.7467, 0.7478, 0.7489, 0.7500, 0.7500, 0.7511, 0.7522, 0.7533, 0.7545,\n",
       "             0.7556, 0.7567, 0.7578, 0.7589, 0.7600, 0.7612, 0.7623, 0.7634, 0.7645,\n",
       "             0.7656, 0.7667, 0.7679, 0.7690, 0.7701, 0.7712, 0.7723, 0.7734, 0.7746,\n",
       "             0.7757, 0.7768, 0.7779, 0.7790, 0.7801, 0.7812, 0.7824, 0.7835, 0.7846,\n",
       "             0.7857, 0.7879, 0.7891, 0.7902, 0.7913, 0.7924, 0.7935, 0.7946, 0.7958,\n",
       "             0.7969, 0.7980, 0.7991, 0.8002, 0.8013, 0.8013, 0.8025, 0.8036, 0.8047,\n",
       "             0.8058, 0.8069, 0.8080, 0.8092, 0.8103, 0.8114, 0.8125, 0.8136, 0.8147,\n",
       "             0.8158, 0.8170, 0.8181, 0.8192, 0.8203, 0.8214, 0.8225, 0.8237, 0.8248,\n",
       "             0.8259, 0.8270, 0.8281, 0.8292, 0.8304, 0.8315, 0.8326, 0.8337, 0.8348,\n",
       "             0.8359, 0.8371, 0.8382, 0.8393, 0.8404, 0.8415, 0.8426, 0.8438, 0.8449,\n",
       "             0.8460, 0.8471, 0.8471, 0.8482, 0.8493, 0.8504, 0.8516, 0.8527, 0.8538,\n",
       "             0.8549, 0.8560, 0.8571, 0.8583, 0.8594, 0.8605, 0.8616, 0.8627, 0.8638,\n",
       "             0.8650, 0.8661, 0.8672, 0.8683, 0.8694, 0.8705, 0.8717, 0.8728, 0.8739,\n",
       "             0.8750, 0.8761, 0.8772, 0.8783, 0.8795, 0.8806, 0.8817, 0.8828, 0.8839,\n",
       "             0.8850, 0.8862, 0.8873, 0.8884, 0.8895, 0.8906, 0.8917, 0.8929, 0.8940,\n",
       "             0.8951, 0.8962, 0.8973, 0.8984, 0.8996, 0.9007, 0.9018, 0.9029, 0.9040,\n",
       "             0.9051, 0.9062, 0.9074, 0.9074, 0.9085, 0.9096, 0.9107, 0.9118, 0.9129,\n",
       "             0.9141, 0.9152, 0.9163, 0.9174, 0.9185, 0.9196, 0.9208, 0.9219, 0.9230,\n",
       "             0.9241, 0.9252, 0.9263, 0.9263, 0.9275, 0.9286, 0.9297, 0.9308, 0.9319,\n",
       "             0.9330, 0.9342, 0.9353, 0.9364, 0.9375, 0.9375, 0.9386, 0.9397, 0.9408,\n",
       "             0.9420, 0.9431, 0.9442, 0.9453, 0.9464, 0.9475, 0.9487, 0.9498, 0.9509,\n",
       "             0.9520, 0.9531, 0.9542, 0.9554, 0.9565, 0.9576, 0.9587, 0.9587, 0.9598,\n",
       "             0.9609, 0.9621, 0.9632, 0.9643, 0.9643, 0.9654, 0.9665, 0.9676, 0.9676,\n",
       "             0.9688, 0.9699, 0.9710, 0.9710, 0.9710, 0.9710, 0.9721, 0.9732, 0.9743,\n",
       "             0.9754, 0.9766, 0.9777, 0.9777, 0.9788, 0.9799, 0.9799, 0.9799, 0.9810,\n",
       "             0.9810, 0.9810, 0.9821, 0.9833, 0.9844, 0.9855, 0.9866, 0.9877, 0.9888,\n",
       "             0.9900, 0.9900, 0.9900, 0.9911, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "             0.9922, 0.9922, 0.9933, 0.9933, 0.9933, 0.9933, 0.9933, 0.9933, 0.9944,\n",
       "             0.9944, 0.9944, 0.9944, 0.9944, 0.9944, 0.9944, 0.9944, 0.9944, 0.9944,\n",
       "             0.9955, 0.9955, 0.9955, 0.9967, 0.9967, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9985e-01, 9.9985e-01,\n",
       "             9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9984e-01,\n",
       "             9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9982e-01, 9.9982e-01,\n",
       "             9.9982e-01, 9.9982e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01,\n",
       "             9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9979e-01,\n",
       "             9.9979e-01, 9.9979e-01, 9.9979e-01, 9.9978e-01, 9.9978e-01, 9.9978e-01,\n",
       "             9.9978e-01, 9.9978e-01, 9.9978e-01, 9.9978e-01, 9.9977e-01, 9.9977e-01,\n",
       "             9.9977e-01, 9.9976e-01, 9.9976e-01, 9.9976e-01, 9.9976e-01, 9.9976e-01,\n",
       "             9.9976e-01, 9.9976e-01, 9.9975e-01, 9.9975e-01, 9.9975e-01, 9.9975e-01,\n",
       "             9.9975e-01, 9.9974e-01, 9.9973e-01, 9.9973e-01, 9.9973e-01, 9.9973e-01,\n",
       "             9.9973e-01, 9.9973e-01, 9.9973e-01, 9.9972e-01, 9.9971e-01, 9.9971e-01,\n",
       "             9.9971e-01, 9.9971e-01, 9.9971e-01, 9.9971e-01, 9.9971e-01, 9.9971e-01,\n",
       "             9.9971e-01, 9.9970e-01, 9.9970e-01, 9.9970e-01, 9.9970e-01, 9.9968e-01,\n",
       "             9.9967e-01, 9.9966e-01, 9.9966e-01, 9.9966e-01, 9.9965e-01, 9.9965e-01,\n",
       "             9.9965e-01, 9.9964e-01, 9.9963e-01, 9.9961e-01, 9.9961e-01, 9.9961e-01,\n",
       "             9.9961e-01, 9.9960e-01, 9.9960e-01, 9.9960e-01, 9.9959e-01, 9.9959e-01,\n",
       "             9.9959e-01, 9.9959e-01, 9.9959e-01, 9.9958e-01, 9.9957e-01, 9.9957e-01,\n",
       "             9.9956e-01, 9.9956e-01, 9.9954e-01, 9.9953e-01, 9.9953e-01, 9.9952e-01,\n",
       "             9.9951e-01, 9.9951e-01, 9.9950e-01, 9.9949e-01, 9.9948e-01, 9.9948e-01,\n",
       "             9.9947e-01, 9.9947e-01, 9.9947e-01, 9.9946e-01, 9.9945e-01, 9.9944e-01,\n",
       "             9.9944e-01, 9.9943e-01, 9.9943e-01, 9.9943e-01, 9.9943e-01, 9.9942e-01,\n",
       "             9.9942e-01, 9.9940e-01, 9.9940e-01, 9.9940e-01, 9.9939e-01, 9.9939e-01,\n",
       "             9.9938e-01, 9.9937e-01, 9.9934e-01, 9.9934e-01, 9.9933e-01, 9.9931e-01,\n",
       "             9.9930e-01, 9.9928e-01, 9.9927e-01, 9.9922e-01, 9.9922e-01, 9.9921e-01,\n",
       "             9.9920e-01, 9.9920e-01, 9.9916e-01, 9.9915e-01, 9.9915e-01, 9.9912e-01,\n",
       "             9.9912e-01, 9.9911e-01, 9.9911e-01, 9.9911e-01, 9.9908e-01, 9.9907e-01,\n",
       "             9.9905e-01, 9.9903e-01, 9.9902e-01, 9.9899e-01, 9.9899e-01, 9.9894e-01,\n",
       "             9.9889e-01, 9.9887e-01, 9.9886e-01, 9.9884e-01, 9.9880e-01, 9.9879e-01,\n",
       "             9.9877e-01, 9.9876e-01, 9.9875e-01, 9.9873e-01, 9.9871e-01, 9.9864e-01,\n",
       "             9.9863e-01, 9.9862e-01, 9.9858e-01, 9.9853e-01, 9.9853e-01, 9.9852e-01,\n",
       "             9.9849e-01, 9.9848e-01, 9.9848e-01, 9.9848e-01, 9.9846e-01, 9.9845e-01,\n",
       "             9.9835e-01, 9.9834e-01, 9.9834e-01, 9.9834e-01, 9.9825e-01, 9.9825e-01,\n",
       "             9.9824e-01, 9.9815e-01, 9.9800e-01, 9.9798e-01, 9.9789e-01, 9.9788e-01,\n",
       "             9.9776e-01, 9.9772e-01, 9.9767e-01, 9.9761e-01, 9.9753e-01, 9.9753e-01,\n",
       "             9.9743e-01, 9.9718e-01, 9.9705e-01, 9.9703e-01, 9.9684e-01, 9.9671e-01,\n",
       "             9.9667e-01, 9.9652e-01, 9.9651e-01, 9.9650e-01, 9.9642e-01, 9.9595e-01,\n",
       "             9.9568e-01, 9.9567e-01, 9.9549e-01, 9.9549e-01, 9.9521e-01, 9.9501e-01,\n",
       "             9.9475e-01, 9.9470e-01, 9.9456e-01, 9.9443e-01, 9.9435e-01, 9.9434e-01,\n",
       "             9.9424e-01, 9.9422e-01, 9.9420e-01, 9.9418e-01, 9.9415e-01, 9.9402e-01,\n",
       "             9.9351e-01, 9.9342e-01, 9.9302e-01, 9.9274e-01, 9.9247e-01, 9.9242e-01,\n",
       "             9.9232e-01, 9.9188e-01, 9.9187e-01, 9.9164e-01, 9.9123e-01, 9.9069e-01,\n",
       "             9.9019e-01, 9.8972e-01, 9.8971e-01, 9.8935e-01, 9.8932e-01, 9.8929e-01,\n",
       "             9.8840e-01, 9.8740e-01, 9.8530e-01, 9.8453e-01, 9.8396e-01, 9.8344e-01,\n",
       "             9.8317e-01, 9.8213e-01, 9.7797e-01, 9.7796e-01, 9.7589e-01, 9.7395e-01,\n",
       "             9.7394e-01, 9.6431e-01, 9.6380e-01, 9.6102e-01, 9.5854e-01, 9.5710e-01,\n",
       "             9.5500e-01, 9.4909e-01, 9.4655e-01, 9.4325e-01, 9.4148e-01, 9.3695e-01,\n",
       "             9.2460e-01, 8.9581e-01, 8.8534e-01, 8.7613e-01, 8.4503e-01, 8.3395e-01,\n",
       "             8.2245e-01, 7.6875e-01, 7.5139e-01, 7.4658e-01, 7.4053e-01, 7.3798e-01,\n",
       "             6.9622e-01, 6.0380e-01, 6.0364e-01, 5.9104e-01, 5.8257e-01, 5.7359e-01,\n",
       "             5.5925e-01, 5.3822e-01, 4.8627e-01, 4.8487e-01, 4.1136e-01, 3.8424e-01,\n",
       "             3.4876e-01, 3.4390e-01, 3.1722e-01, 2.6418e-01, 2.3702e-01, 2.0173e-01,\n",
       "             1.3004e-01, 1.2351e-01, 1.2328e-01, 1.1651e-01, 9.4792e-02, 7.0036e-02,\n",
       "             5.2995e-02, 5.2134e-02, 3.6987e-02, 3.4729e-02, 3.1888e-02, 2.7691e-02,\n",
       "             1.7092e-02, 1.4087e-02, 1.3343e-02, 1.2619e-02, 1.1707e-02, 1.1590e-02,\n",
       "             1.0369e-02, 9.5719e-03, 9.3892e-03, 9.2111e-03, 8.7817e-03, 7.6489e-03,\n",
       "             7.2862e-03, 7.2419e-03, 6.9020e-03, 6.8702e-03, 6.7275e-03, 6.5801e-03,\n",
       "             6.4738e-03, 6.2286e-03, 5.3580e-03, 5.0736e-03, 4.8544e-03, 3.8306e-03,\n",
       "             3.2660e-03, 3.2640e-03, 2.9120e-03, 2.7369e-03, 2.4704e-03, 2.4267e-03,\n",
       "             2.1006e-03, 1.7828e-03, 1.6749e-03, 1.6557e-03, 1.5858e-03, 1.5841e-03,\n",
       "             1.4145e-03, 1.3223e-03, 1.2616e-03, 1.1022e-03, 8.0994e-04, 7.8246e-04,\n",
       "             6.8569e-04, 6.6971e-04, 5.7425e-04, 5.2396e-04, 5.1656e-04, 5.1413e-04,\n",
       "             5.1197e-04, 4.9322e-04, 4.9137e-04, 3.5890e-04, 3.2288e-04, 3.0996e-04,\n",
       "             2.7661e-04, 2.6708e-04, 2.5900e-04, 2.5175e-04, 2.3969e-04, 2.3939e-04,\n",
       "             2.3701e-04, 2.3237e-04, 2.0824e-04, 2.0113e-04, 1.4846e-04, 1.4475e-04,\n",
       "             1.3371e-04, 1.0772e-04, 1.0238e-04, 1.0112e-04, 9.3707e-05, 9.3673e-05,\n",
       "             8.9034e-05, 8.8358e-05, 7.9826e-05, 7.6712e-05, 7.4100e-05, 7.0946e-05,\n",
       "             6.5352e-05, 6.0653e-05, 5.9624e-05, 5.9365e-05, 5.7373e-05, 4.7390e-05,\n",
       "             4.4094e-05, 3.7209e-05, 3.1778e-05, 3.1576e-05, 3.1280e-05, 3.0553e-05,\n",
       "             2.7711e-05, 2.6725e-05, 2.2674e-05, 2.0759e-05, 1.9580e-05, 1.9449e-05,\n",
       "             1.8951e-05, 1.8345e-05, 1.8112e-05, 1.7702e-05, 1.7542e-05, 1.7055e-05,\n",
       "             1.5951e-05, 1.4569e-05, 1.4087e-05, 1.3195e-05, 1.2765e-05, 1.1773e-05,\n",
       "             1.0094e-05, 9.9348e-06, 9.5622e-06, 8.5332e-06, 8.3831e-06, 8.1951e-06,\n",
       "             8.1653e-06, 7.6242e-06, 7.4143e-06, 6.7475e-06, 6.1508e-06, 6.1433e-06,\n",
       "             5.3126e-06, 4.7562e-06, 4.5006e-06, 4.1896e-06, 4.0960e-06, 3.9322e-06,\n",
       "             3.7814e-06, 3.4008e-06, 2.8056e-06, 2.8014e-06, 2.5957e-06, 2.4203e-06,\n",
       "             2.0607e-06, 2.0598e-06, 2.0116e-06, 1.9203e-06, 1.8634e-06, 1.7681e-06,\n",
       "             1.5266e-06, 1.5118e-06, 1.4823e-06, 1.4526e-06, 1.3921e-06, 1.2921e-06,\n",
       "             1.1655e-06, 1.1407e-06, 1.0630e-06, 1.0525e-06, 9.9961e-07, 8.9678e-07,\n",
       "             7.8475e-07, 7.3636e-07, 7.2421e-07, 6.7257e-07, 6.4921e-07, 6.0842e-07,\n",
       "             5.7708e-07, 5.5123e-07, 5.2408e-07, 4.8374e-07, 4.0363e-07, 3.9253e-07,\n",
       "             3.9123e-07, 3.8846e-07, 3.8024e-07, 3.4687e-07, 3.4177e-07, 3.3099e-07,\n",
       "             2.7617e-07, 2.3165e-07, 1.9897e-07, 1.9553e-07, 1.7260e-07, 1.6412e-07,\n",
       "             1.5567e-07, 1.5558e-07, 1.4061e-07, 1.3772e-07, 1.3354e-07, 1.1111e-07,\n",
       "             1.0376e-07, 9.6838e-08, 9.3698e-08, 8.8930e-08, 8.7942e-08, 8.7110e-08,\n",
       "             8.2905e-08, 7.6368e-08, 7.6358e-08, 7.0507e-08, 6.9439e-08, 6.6706e-08,\n",
       "             6.4490e-08, 5.7859e-08, 5.3877e-08, 5.0678e-08, 4.9370e-08, 4.1159e-08,\n",
       "             4.0864e-08, 3.8283e-08, 3.6907e-08, 3.5810e-08, 3.5480e-08, 3.4494e-08,\n",
       "             3.3592e-08, 3.2835e-08, 3.1595e-08, 3.1211e-08, 2.3034e-08, 2.2843e-08,\n",
       "             2.1797e-08, 1.8073e-08, 1.5134e-08, 1.4870e-08, 1.4787e-08, 1.3985e-08,\n",
       "             1.2981e-08, 1.2894e-08, 1.2351e-08, 1.2039e-08, 1.2014e-08, 9.4368e-09,\n",
       "             9.4029e-09, 8.2015e-09, 8.1949e-09, 7.8216e-09, 5.6345e-09, 4.2971e-09,\n",
       "             2.8678e-09, 2.7007e-09, 2.6332e-09, 2.5034e-09, 2.1411e-09, 2.0251e-09,\n",
       "             1.9507e-09, 1.9243e-09, 1.4620e-09, 1.1050e-09, 9.9953e-10, 9.9481e-10,\n",
       "             9.3797e-10, 9.0629e-10, 8.9517e-10, 8.8209e-10, 6.4048e-10, 5.7835e-10,\n",
       "             5.3831e-10, 4.8296e-10, 4.7401e-10, 3.7255e-10, 2.1437e-10, 1.8772e-10,\n",
       "             1.4998e-10, 1.2983e-10, 1.2515e-10, 9.8088e-11, 5.5438e-11, 1.3972e-11,\n",
       "             9.4565e-12, 7.9558e-12, 6.9756e-12])}},\n",
       "   {'fpr': np.float64(0.2313167259786477),\n",
       "    'tpr': np.float64(0.9966517857142857),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0142, 0.0178, 0.0178, 0.0178, 0.0178, 0.0214, 0.0214, 0.0214,\n",
       "             0.0214, 0.0214, 0.0214, 0.0214, 0.0249, 0.0249, 0.0285, 0.0285, 0.0285,\n",
       "             0.0285, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
       "             0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
       "             0.0320, 0.0356, 0.0356, 0.0356, 0.0356, 0.0356, 0.0391, 0.0427, 0.0463,\n",
       "             0.0463, 0.0463, 0.0498, 0.0534, 0.0534, 0.0569, 0.0569, 0.0569, 0.0605,\n",
       "             0.0641, 0.0641, 0.0641, 0.0641, 0.0676, 0.0712, 0.0712, 0.0747, 0.0747,\n",
       "             0.0783, 0.0819, 0.0819, 0.0854, 0.0854, 0.0890, 0.0890, 0.0925, 0.0961,\n",
       "             0.0996, 0.1032, 0.1068, 0.1103, 0.1139, 0.1174, 0.1210, 0.1210, 0.1246,\n",
       "             0.1281, 0.1317, 0.1352, 0.1388, 0.1423, 0.1459, 0.1495, 0.1530, 0.1566,\n",
       "             0.1566, 0.1601, 0.1637, 0.1673, 0.1708, 0.1744, 0.1779, 0.1815, 0.1851,\n",
       "             0.1886, 0.1922, 0.1957, 0.1993, 0.2028, 0.2064, 0.2100, 0.2135, 0.2171,\n",
       "             0.2206, 0.2206, 0.2242, 0.2278, 0.2313, 0.2313, 0.2349, 0.2384, 0.2420,\n",
       "             0.2456, 0.2491, 0.2527, 0.2562, 0.2598, 0.2633, 0.2669, 0.2705, 0.2740,\n",
       "             0.2776, 0.2811, 0.2847, 0.2883, 0.2918, 0.2954, 0.2989, 0.3025, 0.3060,\n",
       "             0.3096, 0.3132, 0.3167, 0.3203, 0.3238, 0.3274, 0.3310, 0.3345, 0.3381,\n",
       "             0.3416, 0.3452, 0.3488, 0.3523, 0.3559, 0.3594, 0.3630, 0.3665, 0.3665,\n",
       "             0.3701, 0.3737, 0.3737, 0.3772, 0.3808, 0.3843, 0.3879, 0.3915, 0.3950,\n",
       "             0.3986, 0.4021, 0.4057, 0.4093, 0.4128, 0.4164, 0.4199, 0.4235, 0.4270,\n",
       "             0.4306, 0.4342, 0.4377, 0.4413, 0.4448, 0.4484, 0.4520, 0.4555, 0.4591,\n",
       "             0.4626, 0.4662, 0.4698, 0.4733, 0.4769, 0.4804, 0.4840, 0.4875, 0.4911,\n",
       "             0.4947, 0.4982, 0.5018, 0.5053, 0.5089, 0.5125, 0.5160, 0.5196, 0.5231,\n",
       "             0.5267, 0.5302, 0.5338, 0.5374, 0.5409, 0.5445, 0.5480, 0.5516, 0.5552,\n",
       "             0.5587, 0.5623, 0.5658, 0.5694, 0.5730, 0.5765, 0.5801, 0.5836, 0.5872,\n",
       "             0.5907, 0.5943, 0.5979, 0.6014, 0.6050, 0.6085, 0.6121, 0.6157, 0.6192,\n",
       "             0.6228, 0.6263, 0.6299, 0.6335, 0.6370, 0.6406, 0.6441, 0.6477, 0.6512,\n",
       "             0.6548, 0.6584, 0.6619, 0.6655, 0.6690, 0.6726, 0.6762, 0.6797, 0.6833,\n",
       "             0.6868, 0.6904, 0.6940, 0.6975, 0.7011, 0.7046, 0.7082, 0.7117, 0.7153,\n",
       "             0.7189, 0.7224, 0.7260, 0.7295, 0.7331, 0.7367, 0.7402, 0.7438, 0.7473,\n",
       "             0.7509, 0.7544, 0.7580, 0.7616, 0.7651, 0.7687, 0.7722, 0.7758, 0.7794,\n",
       "             0.7829, 0.7865, 0.7900, 0.7936, 0.7972, 0.8007, 0.8043, 0.8078, 0.8114,\n",
       "             0.8149, 0.8185, 0.8221, 0.8256, 0.8292, 0.8327, 0.8363, 0.8399, 0.8434,\n",
       "             0.8470, 0.8505, 0.8541, 0.8577, 0.8612, 0.8648, 0.8683, 0.8719, 0.8754,\n",
       "             0.8790, 0.8826, 0.8861, 0.8897, 0.8932, 0.8968, 0.9004, 0.9039, 0.9075,\n",
       "             0.9110, 0.9146, 0.9181, 0.9217, 0.9253, 0.9288, 0.9324, 0.9359, 0.9395,\n",
       "             0.9431, 0.9466, 0.9502, 0.9537, 0.9573, 0.9609, 0.9644, 0.9680, 0.9715,\n",
       "             0.9751, 0.9786, 0.9822, 0.9858, 0.9893, 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.8549, 0.8962, 0.9129, 0.9185, 0.9230, 0.9252, 0.9275, 0.9297,\n",
       "             0.9330, 0.9342, 0.9375, 0.9431, 0.9475, 0.9487, 0.9498, 0.9509, 0.9520,\n",
       "             0.9531, 0.9542, 0.9554, 0.9565, 0.9576, 0.9587, 0.9598, 0.9609, 0.9621,\n",
       "             0.9632, 0.9643, 0.9654, 0.9665, 0.9676, 0.9688, 0.9699, 0.9710, 0.9721,\n",
       "             0.9732, 0.9743, 0.9754, 0.9766, 0.9777, 0.9788, 0.9788, 0.9788, 0.9788,\n",
       "             0.9799, 0.9810, 0.9810, 0.9810, 0.9821, 0.9821, 0.9833, 0.9844, 0.9844,\n",
       "             0.9844, 0.9855, 0.9866, 0.9877, 0.9877, 0.9877, 0.9888, 0.9888, 0.9900,\n",
       "             0.9900, 0.9900, 0.9911, 0.9911, 0.9922, 0.9922, 0.9933, 0.9933, 0.9933,\n",
       "             0.9933, 0.9933, 0.9933, 0.9933, 0.9933, 0.9933, 0.9933, 0.9944, 0.9944,\n",
       "             0.9944, 0.9944, 0.9944, 0.9944, 0.9944, 0.9944, 0.9944, 0.9944, 0.9944,\n",
       "             0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955,\n",
       "             0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955,\n",
       "             0.9955, 0.9967, 0.9967, 0.9967, 0.9967, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9989,\n",
       "             0.9989, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9996e-01, 9.9996e-01, 9.9994e-01, 9.9994e-01, 9.9992e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9990e-01, 9.9988e-01, 9.9986e-01, 9.9982e-01,\n",
       "             9.9976e-01, 9.9974e-01, 9.9967e-01, 9.9966e-01, 9.9952e-01, 9.9950e-01,\n",
       "             9.9949e-01, 9.9948e-01, 9.9928e-01, 9.9901e-01, 9.9877e-01, 9.9875e-01,\n",
       "             9.9825e-01, 9.9814e-01, 9.9764e-01, 9.9745e-01, 9.9580e-01, 9.9497e-01,\n",
       "             9.9378e-01, 9.9307e-01, 9.9252e-01, 9.9125e-01, 9.8900e-01, 9.8150e-01,\n",
       "             9.7888e-01, 9.7711e-01, 9.7551e-01, 9.7354e-01, 9.7202e-01, 9.7196e-01,\n",
       "             9.7121e-01, 9.6634e-01, 9.5645e-01, 9.1742e-01, 9.1031e-01, 9.0957e-01,\n",
       "             9.0661e-01, 9.0555e-01, 8.9268e-01, 8.8166e-01, 8.7929e-01, 8.5653e-01,\n",
       "             8.4727e-01, 8.4162e-01, 8.4037e-01, 8.3606e-01, 8.3121e-01, 8.1233e-01,\n",
       "             7.8604e-01, 7.7971e-01, 7.7501e-01, 7.5315e-01, 7.2394e-01, 7.1645e-01,\n",
       "             7.0262e-01, 6.9814e-01, 6.6713e-01, 6.5668e-01, 6.5310e-01, 6.4439e-01,\n",
       "             6.1031e-01, 5.7906e-01, 5.6998e-01, 5.2466e-01, 5.0994e-01, 4.8181e-01,\n",
       "             4.7295e-01, 4.2509e-01, 4.1910e-01, 3.3856e-01, 3.3761e-01, 3.2492e-01,\n",
       "             3.1462e-01, 2.9947e-01, 2.8069e-01, 2.7623e-01, 2.6231e-01, 2.5362e-01,\n",
       "             2.4934e-01, 2.3959e-01, 2.3473e-01, 2.1979e-01, 2.1303e-01, 2.0922e-01,\n",
       "             1.7248e-01, 1.4689e-01, 1.3831e-01, 1.1043e-01, 1.0240e-01, 9.8970e-02,\n",
       "             8.3644e-02, 8.1900e-02, 7.2692e-02, 6.6644e-02, 6.5383e-02, 6.2118e-02,\n",
       "             6.0112e-02, 5.4865e-02, 5.4428e-02, 4.9011e-02, 3.8518e-02, 3.8184e-02,\n",
       "             3.7486e-02, 3.5213e-02, 3.4614e-02, 2.2248e-02, 2.0778e-02, 1.7788e-02,\n",
       "             1.5773e-02, 1.4181e-02, 1.1745e-02, 1.1349e-02, 9.0859e-03, 8.7898e-03,\n",
       "             8.2561e-03, 7.5034e-03, 7.4250e-03, 6.1986e-03, 4.7698e-03, 4.6570e-03,\n",
       "             3.7227e-03, 3.4676e-03, 3.1373e-03, 2.8702e-03, 2.8245e-03, 2.4397e-03,\n",
       "             2.3183e-03, 2.2191e-03, 1.9428e-03, 1.8337e-03, 1.8081e-03, 1.7117e-03,\n",
       "             1.5110e-03, 1.5030e-03, 1.3401e-03, 1.2668e-03, 1.2651e-03, 1.2414e-03,\n",
       "             1.0726e-03, 1.0670e-03, 1.0383e-03, 8.0124e-04, 7.4977e-04, 6.5812e-04,\n",
       "             5.1535e-04, 5.1265e-04, 5.0602e-04, 4.7710e-04, 3.8067e-04, 3.6833e-04,\n",
       "             3.6043e-04, 2.6830e-04, 2.1626e-04, 2.0819e-04, 1.8934e-04, 1.8504e-04,\n",
       "             1.5312e-04, 9.6528e-05, 8.9718e-05, 8.1991e-05, 7.9810e-05, 7.8717e-05,\n",
       "             7.8602e-05, 7.8276e-05, 7.2916e-05, 7.1761e-05, 6.0197e-05, 5.2068e-05,\n",
       "             5.2038e-05, 4.4904e-05, 4.1607e-05, 4.0186e-05, 3.9405e-05, 3.8641e-05,\n",
       "             3.7633e-05, 3.1405e-05, 2.6547e-05, 2.5159e-05, 2.3756e-05, 2.2419e-05,\n",
       "             2.1704e-05, 1.6654e-05, 1.5067e-05, 1.4753e-05, 1.3160e-05, 1.2181e-05,\n",
       "             1.2009e-05, 1.0727e-05, 8.3315e-06, 7.9355e-06, 7.6220e-06, 7.5671e-06,\n",
       "             7.0692e-06, 6.6659e-06, 5.1732e-06, 5.1381e-06, 4.9377e-06, 4.6716e-06,\n",
       "             4.0942e-06, 3.9605e-06, 3.3897e-06, 3.1993e-06, 3.0392e-06, 2.8914e-06,\n",
       "             2.6322e-06, 2.5202e-06, 2.3770e-06, 2.1494e-06, 2.0150e-06, 1.7343e-06,\n",
       "             1.5434e-06, 1.5358e-06, 1.4956e-06, 1.4835e-06, 1.4615e-06, 1.3322e-06,\n",
       "             1.0610e-06, 1.0366e-06, 9.4503e-07, 9.0657e-07, 8.1625e-07, 8.0022e-07,\n",
       "             7.4468e-07, 7.2307e-07, 6.2909e-07, 6.0262e-07, 5.8139e-07, 3.1670e-07,\n",
       "             2.9202e-07, 2.4793e-07, 2.3612e-07, 2.1186e-07, 1.6600e-07, 1.5664e-07,\n",
       "             1.5228e-07, 1.2933e-07, 1.0943e-07, 1.0605e-07, 1.0459e-07, 1.0333e-07,\n",
       "             9.9596e-08, 7.6636e-08, 6.8763e-08, 6.7599e-08, 6.3918e-08, 6.2889e-08,\n",
       "             5.0493e-08, 4.5320e-08, 3.6431e-08, 2.9711e-08, 2.8610e-08, 2.6829e-08,\n",
       "             2.3602e-08, 2.0717e-08, 1.9106e-08, 1.8158e-08, 6.6971e-09, 6.4210e-09,\n",
       "             3.7667e-09, 3.7492e-09, 3.2286e-09, 2.9436e-09, 2.8975e-09, 1.9028e-09,\n",
       "             5.2192e-10, 4.5123e-10, 4.3307e-10, 3.2349e-10, 1.4923e-10, 1.1739e-10,\n",
       "             9.8953e-11, 8.9832e-11, 8.5752e-11, 5.7683e-11, 4.8827e-11, 4.6093e-11,\n",
       "             2.5136e-11, 2.3040e-11, 2.2330e-11, 2.0540e-11, 1.9224e-11, 1.8475e-11,\n",
       "             5.5155e-12, 4.8816e-12])}},\n",
       "   {'fpr': np.float64(0.042704626334519574),\n",
       "    'tpr': np.float64(0.9787946428571429),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0142, 0.0178,\n",
       "             0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214,\n",
       "             0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214,\n",
       "             0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214,\n",
       "             0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214,\n",
       "             0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0249,\n",
       "             0.0285, 0.0285, 0.0285, 0.0285, 0.0320, 0.0320, 0.0320, 0.0320, 0.0320,\n",
       "             0.0320, 0.0320, 0.0356, 0.0356, 0.0356, 0.0356, 0.0391, 0.0391, 0.0391,\n",
       "             0.0427, 0.0427, 0.0463, 0.0463, 0.0498, 0.0534, 0.0534, 0.0534, 0.0534,\n",
       "             0.0534, 0.0534, 0.0534, 0.0534, 0.0569, 0.0569, 0.0605, 0.0641, 0.0676,\n",
       "             0.0712, 0.0747, 0.0783, 0.0819, 0.0819, 0.0854, 0.0854, 0.0890, 0.0890,\n",
       "             0.0925, 0.0961, 0.0996, 0.1032, 0.1068, 0.1103, 0.1139, 0.1174, 0.1210,\n",
       "             0.1246, 0.1246, 0.1281, 0.1317, 0.1352, 0.1352, 0.1388, 0.1423, 0.1459,\n",
       "             0.1495, 0.1530, 0.1566, 0.1601, 0.1601, 0.1637, 0.1673, 0.1708, 0.1744,\n",
       "             0.1779, 0.1815, 0.1851, 0.1886, 0.1922, 0.1922, 0.1957, 0.1993, 0.2028,\n",
       "             0.2064, 0.2100, 0.2135, 0.2171, 0.2206, 0.2242, 0.2278, 0.2313, 0.2349,\n",
       "             0.2384, 0.2420, 0.2456, 0.2491, 0.2527, 0.2562, 0.2598, 0.2633, 0.2669,\n",
       "             0.2705, 0.2740, 0.2776, 0.2811, 0.2847, 0.2883, 0.2918, 0.2954, 0.2989,\n",
       "             0.3025, 0.3060, 0.3096, 0.3132, 0.3167, 0.3203, 0.3238, 0.3274, 0.3310,\n",
       "             0.3345, 0.3381, 0.3416, 0.3452, 0.3488, 0.3523, 0.3559, 0.3594, 0.3630,\n",
       "             0.3665, 0.3701, 0.3737, 0.3772, 0.3808, 0.3843, 0.3879, 0.3915, 0.3950,\n",
       "             0.3986, 0.4021, 0.4057, 0.4093, 0.4128, 0.4164, 0.4199, 0.4235, 0.4270,\n",
       "             0.4306, 0.4342, 0.4342, 0.4377, 0.4413, 0.4448, 0.4448, 0.4484, 0.4520,\n",
       "             0.4555, 0.4591, 0.4626, 0.4662, 0.4698, 0.4733, 0.4769, 0.4804, 0.4840,\n",
       "             0.4875, 0.4911, 0.4947, 0.4982, 0.5018, 0.5053, 0.5089, 0.5125, 0.5160,\n",
       "             0.5196, 0.5231, 0.5267, 0.5302, 0.5338, 0.5374, 0.5409, 0.5445, 0.5480,\n",
       "             0.5516, 0.5552, 0.5587, 0.5623, 0.5658, 0.5694, 0.5730, 0.5765, 0.5801,\n",
       "             0.5836, 0.5872, 0.5907, 0.5943, 0.5979, 0.6014, 0.6050, 0.6085, 0.6121,\n",
       "             0.6157, 0.6192, 0.6228, 0.6263, 0.6299, 0.6335, 0.6370, 0.6406, 0.6441,\n",
       "             0.6477, 0.6512, 0.6548, 0.6584, 0.6619, 0.6655, 0.6690, 0.6726, 0.6762,\n",
       "             0.6797, 0.6833, 0.6868, 0.6904, 0.6940, 0.6975, 0.7011, 0.7046, 0.7082,\n",
       "             0.7117, 0.7153, 0.7189, 0.7224, 0.7260, 0.7295, 0.7331, 0.7367, 0.7402,\n",
       "             0.7438, 0.7473, 0.7509, 0.7544, 0.7580, 0.7616, 0.7651, 0.7687, 0.7722,\n",
       "             0.7758, 0.7794, 0.7829, 0.7865, 0.7900, 0.7936, 0.7972, 0.8007, 0.8043,\n",
       "             0.8078, 0.8114, 0.8149, 0.8185, 0.8221, 0.8256, 0.8292, 0.8327, 0.8363,\n",
       "             0.8399, 0.8434, 0.8470, 0.8505, 0.8541, 0.8577, 0.8612, 0.8648, 0.8683,\n",
       "             0.8719, 0.8754, 0.8790, 0.8826, 0.8861, 0.8897, 0.8932, 0.8968, 0.9004,\n",
       "             0.9039, 0.9075, 0.9110, 0.9146, 0.9181, 0.9217, 0.9253, 0.9288, 0.9324,\n",
       "             0.9359, 0.9395, 0.9431, 0.9466, 0.9502, 0.9537, 0.9573, 0.9609, 0.9644,\n",
       "             0.9680, 0.9715, 0.9751, 0.9786, 0.9822, 0.9858, 0.9893, 0.9929, 0.9964,\n",
       "             1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.3817, 0.4754, 0.5190, 0.5413, 0.5603, 0.5737, 0.5837, 0.5904,\n",
       "             0.6004, 0.6071, 0.6150, 0.6217, 0.6295, 0.6373, 0.6406, 0.6484, 0.6507,\n",
       "             0.6529, 0.6562, 0.6596, 0.6629, 0.6674, 0.6708, 0.6730, 0.6763, 0.6775,\n",
       "             0.6830, 0.6864, 0.6875, 0.6920, 0.6942, 0.6953, 0.6964, 0.6998, 0.7031,\n",
       "             0.7042, 0.7065, 0.7098, 0.7109, 0.7132, 0.7165, 0.7188, 0.7199, 0.7210,\n",
       "             0.7232, 0.7243, 0.7254, 0.7277, 0.7321, 0.7355, 0.7377, 0.7388, 0.7411,\n",
       "             0.7433, 0.7444, 0.7455, 0.7478, 0.7489, 0.7500, 0.7511, 0.7522, 0.7545,\n",
       "             0.7567, 0.7589, 0.7600, 0.7623, 0.7634, 0.7645, 0.7656, 0.7667, 0.7679,\n",
       "             0.7690, 0.7701, 0.7712, 0.7712, 0.7723, 0.7734, 0.7746, 0.7757, 0.7768,\n",
       "             0.7779, 0.7790, 0.7801, 0.7824, 0.7846, 0.7857, 0.7868, 0.7879, 0.7891,\n",
       "             0.7902, 0.7913, 0.7924, 0.7935, 0.7946, 0.7958, 0.7969, 0.7980, 0.7991,\n",
       "             0.8002, 0.8013, 0.8025, 0.8036, 0.8047, 0.8058, 0.8069, 0.8092, 0.8103,\n",
       "             0.8114, 0.8125, 0.8136, 0.8147, 0.8158, 0.8170, 0.8181, 0.8192, 0.8237,\n",
       "             0.8248, 0.8259, 0.8270, 0.8281, 0.8292, 0.8304, 0.8315, 0.8326, 0.8337,\n",
       "             0.8348, 0.8359, 0.8371, 0.8382, 0.8393, 0.8404, 0.8415, 0.8426, 0.8438,\n",
       "             0.8449, 0.8460, 0.8471, 0.8482, 0.8493, 0.8504, 0.8516, 0.8527, 0.8538,\n",
       "             0.8549, 0.8560, 0.8571, 0.8583, 0.8594, 0.8616, 0.8627, 0.8661, 0.8672,\n",
       "             0.8683, 0.8694, 0.8705, 0.8717, 0.8728, 0.8739, 0.8750, 0.8761, 0.8772,\n",
       "             0.8783, 0.8795, 0.8806, 0.8817, 0.8828, 0.8839, 0.8850, 0.8862, 0.8873,\n",
       "             0.8884, 0.8895, 0.8906, 0.8917, 0.8929, 0.8940, 0.8951, 0.8962, 0.8973,\n",
       "             0.8984, 0.8996, 0.9007, 0.9018, 0.9029, 0.9040, 0.9051, 0.9051, 0.9051,\n",
       "             0.9062, 0.9074, 0.9085, 0.9096, 0.9107, 0.9118, 0.9129, 0.9141, 0.9152,\n",
       "             0.9163, 0.9174, 0.9174, 0.9185, 0.9196, 0.9208, 0.9219, 0.9230, 0.9241,\n",
       "             0.9252, 0.9263, 0.9275, 0.9286, 0.9297, 0.9308, 0.9319, 0.9330, 0.9342,\n",
       "             0.9353, 0.9364, 0.9375, 0.9386, 0.9397, 0.9408, 0.9420, 0.9431, 0.9442,\n",
       "             0.9453, 0.9464, 0.9475, 0.9487, 0.9498, 0.9509, 0.9520, 0.9531, 0.9542,\n",
       "             0.9554, 0.9565, 0.9576, 0.9587, 0.9598, 0.9609, 0.9621, 0.9632, 0.9632,\n",
       "             0.9632, 0.9643, 0.9654, 0.9665, 0.9665, 0.9676, 0.9688, 0.9699, 0.9710,\n",
       "             0.9721, 0.9732, 0.9732, 0.9743, 0.9754, 0.9766, 0.9766, 0.9777, 0.9788,\n",
       "             0.9788, 0.9799, 0.9799, 0.9810, 0.9810, 0.9810, 0.9821, 0.9833, 0.9844,\n",
       "             0.9855, 0.9866, 0.9877, 0.9888, 0.9888, 0.9900, 0.9900, 0.9900, 0.9900,\n",
       "             0.9900, 0.9900, 0.9900, 0.9900, 0.9911, 0.9911, 0.9922, 0.9922, 0.9933,\n",
       "             0.9933, 0.9933, 0.9933, 0.9933, 0.9933, 0.9933, 0.9933, 0.9933, 0.9933,\n",
       "             0.9933, 0.9944, 0.9944, 0.9944, 0.9944, 0.9955, 0.9955, 0.9955, 0.9955,\n",
       "             0.9955, 0.9955, 0.9955, 0.9955, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967,\n",
       "             0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9989, 0.9989, 0.9989, 0.9989, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9991e-01, 9.9990e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9984e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9982e-01, 9.9981e-01, 9.9979e-01, 9.9979e-01, 9.9979e-01, 9.9979e-01,\n",
       "             9.9978e-01, 9.9978e-01, 9.9975e-01, 9.9974e-01, 9.9973e-01, 9.9964e-01,\n",
       "             9.9957e-01, 9.9957e-01, 9.9957e-01, 9.9956e-01, 9.9953e-01, 9.9953e-01,\n",
       "             9.9952e-01, 9.9945e-01, 9.9940e-01, 9.9939e-01, 9.9936e-01, 9.9932e-01,\n",
       "             9.9926e-01, 9.9926e-01, 9.9925e-01, 9.9920e-01, 9.9916e-01, 9.9912e-01,\n",
       "             9.9910e-01, 9.9908e-01, 9.9907e-01, 9.9906e-01, 9.9890e-01, 9.9889e-01,\n",
       "             9.9867e-01, 9.9866e-01, 9.9858e-01, 9.9843e-01, 9.9842e-01, 9.9833e-01,\n",
       "             9.9832e-01, 9.9825e-01, 9.9822e-01, 9.9809e-01, 9.9804e-01, 9.9791e-01,\n",
       "             9.9783e-01, 9.9707e-01, 9.9697e-01, 9.9680e-01, 9.9610e-01, 9.9557e-01,\n",
       "             9.9553e-01, 9.9546e-01, 9.9538e-01, 9.9517e-01, 9.9497e-01, 9.9480e-01,\n",
       "             9.9345e-01, 9.9265e-01, 9.9259e-01, 9.9221e-01, 9.9132e-01, 9.9064e-01,\n",
       "             9.9012e-01, 9.8675e-01, 9.8608e-01, 9.8559e-01, 9.8338e-01, 9.7554e-01,\n",
       "             9.7376e-01, 9.6778e-01, 9.6768e-01, 9.6104e-01, 9.6035e-01, 9.5183e-01,\n",
       "             9.4876e-01, 9.4142e-01, 9.3591e-01, 9.2680e-01, 9.2305e-01, 9.2164e-01,\n",
       "             8.8036e-01, 8.7898e-01, 8.5866e-01, 8.5567e-01, 7.6692e-01, 7.1936e-01,\n",
       "             6.4511e-01, 6.3631e-01, 5.7232e-01, 5.4027e-01, 4.1508e-01, 3.2391e-01,\n",
       "             3.0701e-01, 2.5037e-01, 2.4007e-01, 2.3098e-01, 1.2085e-01, 1.1932e-01,\n",
       "             9.1048e-02, 7.2720e-02, 7.1578e-02, 6.7341e-02, 5.4102e-02, 3.0249e-02,\n",
       "             2.8995e-02, 2.7830e-02, 2.7248e-02, 2.6495e-02, 2.5855e-02, 2.2845e-02,\n",
       "             1.8907e-02, 1.7634e-02, 1.7302e-02, 1.5947e-02, 1.3594e-02, 1.3412e-02,\n",
       "             1.2307e-02, 1.1468e-02, 9.9335e-03, 8.3273e-03, 7.3189e-03, 6.2117e-03,\n",
       "             5.7084e-03, 5.6714e-03, 5.4588e-03, 5.3091e-03, 3.2172e-03, 2.1634e-03,\n",
       "             2.1579e-03, 2.1178e-03, 2.1155e-03, 2.0016e-03, 1.9372e-03, 1.9290e-03,\n",
       "             1.9100e-03, 1.8026e-03, 1.3995e-03, 1.3400e-03, 1.1055e-03, 8.4562e-04,\n",
       "             7.4759e-04, 7.3670e-04, 7.0074e-04, 6.9210e-04, 6.6141e-04, 6.0797e-04,\n",
       "             6.0727e-04, 5.5854e-04, 5.5478e-04, 5.1828e-04, 4.1504e-04, 3.8806e-04,\n",
       "             2.4530e-04, 2.3077e-04, 2.3032e-04, 2.0248e-04, 1.9812e-04, 1.7315e-04,\n",
       "             1.6545e-04, 1.6233e-04, 1.2441e-04, 1.2261e-04, 1.1516e-04, 8.7824e-05,\n",
       "             8.3112e-05, 7.9984e-05, 7.2236e-05, 6.5948e-05, 6.1308e-05, 5.8819e-05,\n",
       "             5.8726e-05, 5.2317e-05, 5.0612e-05, 4.9505e-05, 4.3197e-05, 3.6787e-05,\n",
       "             3.6219e-05, 3.6077e-05, 3.3230e-05, 2.7638e-05, 2.7240e-05, 2.4943e-05,\n",
       "             2.4581e-05, 2.3472e-05, 2.1463e-05, 2.1039e-05, 1.6584e-05, 1.2748e-05,\n",
       "             1.2741e-05, 1.2315e-05, 1.1729e-05, 1.0693e-05, 1.0599e-05, 1.0297e-05,\n",
       "             8.6067e-06, 7.7985e-06, 7.6081e-06, 5.9411e-06, 5.8406e-06, 5.2771e-06,\n",
       "             5.0187e-06, 4.0395e-06, 3.9131e-06, 3.7764e-06, 3.4720e-06, 2.3065e-06,\n",
       "             2.2757e-06, 2.2555e-06, 2.0253e-06, 1.9835e-06, 1.8223e-06, 1.7715e-06,\n",
       "             1.4748e-06, 1.3245e-06, 1.3076e-06, 1.1640e-06, 1.1012e-06, 9.6044e-07,\n",
       "             9.5721e-07, 9.2382e-07, 8.9217e-07, 8.8118e-07, 8.1316e-07, 6.0371e-07,\n",
       "             3.9930e-07, 3.9879e-07, 3.5937e-07, 3.5000e-07, 3.4967e-07, 3.3571e-07,\n",
       "             3.2862e-07, 2.8354e-07, 2.5555e-07, 2.5216e-07, 2.4209e-07, 1.8852e-07,\n",
       "             1.6187e-07, 1.5266e-07, 1.4261e-07, 1.3041e-07, 8.7543e-08, 8.5090e-08,\n",
       "             7.8767e-08, 7.5763e-08, 7.2874e-08, 5.9204e-08, 5.6689e-08, 5.3054e-08,\n",
       "             4.2453e-08, 4.0702e-08, 4.0642e-08, 3.9574e-08, 3.8756e-08, 3.5536e-08,\n",
       "             3.4664e-08, 3.0754e-08, 2.2829e-08, 2.2482e-08, 2.0753e-08, 2.0524e-08,\n",
       "             2.0447e-08, 1.9428e-08, 1.9242e-08, 1.8917e-08, 1.7104e-08, 1.6823e-08,\n",
       "             1.6798e-08, 1.5290e-08, 1.5015e-08, 1.4911e-08, 1.4125e-08, 1.3394e-08,\n",
       "             1.2874e-08, 1.1611e-08, 1.0733e-08, 1.0578e-08, 1.0153e-08, 8.5777e-09,\n",
       "             8.1778e-09, 7.9371e-09, 5.8756e-09, 5.7634e-09, 5.7231e-09, 5.4351e-09,\n",
       "             5.3618e-09, 4.7260e-09, 4.6232e-09, 4.1607e-09, 3.3170e-09, 2.5594e-09,\n",
       "             2.4922e-09, 2.1618e-09, 2.1524e-09, 2.1424e-09, 2.0408e-09, 1.9187e-09,\n",
       "             1.7710e-09, 1.7291e-09, 1.4325e-09, 9.9919e-10, 9.8778e-10, 7.8716e-10,\n",
       "             6.8616e-10, 6.1237e-10, 5.4864e-10, 5.0847e-10, 5.0275e-10, 4.7809e-10,\n",
       "             4.5455e-10, 4.5275e-10, 4.2343e-10, 2.8229e-10, 2.3594e-10, 1.9926e-10,\n",
       "             1.8084e-10, 1.4112e-10, 1.3892e-10, 1.3887e-10, 1.1744e-10, 1.1424e-10,\n",
       "             1.1264e-10, 1.0456e-10, 9.3968e-11, 8.0036e-11, 6.6435e-11, 6.3152e-11,\n",
       "             5.4090e-11, 5.3912e-11, 4.9935e-11, 3.9537e-11, 3.6193e-11, 3.4491e-11,\n",
       "             2.7553e-11, 2.5801e-11, 2.1771e-11, 1.6165e-11, 1.3985e-11, 1.3894e-11,\n",
       "             1.2946e-11, 1.0370e-11, 7.3585e-12, 7.3211e-12, 6.9926e-12, 6.5477e-12,\n",
       "             6.4413e-12, 6.0222e-12, 3.8625e-12, 3.3143e-12, 2.5487e-12, 2.1488e-12,\n",
       "             1.7084e-12, 1.6242e-12, 1.5163e-12, 1.4308e-12, 1.2801e-12, 1.2687e-12,\n",
       "             1.2266e-12, 6.3438e-13, 6.0637e-13, 5.9832e-13, 5.5934e-13, 5.5305e-13,\n",
       "             4.9415e-13, 4.6200e-13, 3.5873e-13, 3.5762e-13, 3.4720e-13, 3.0918e-13,\n",
       "             2.1158e-13, 1.4853e-13, 5.3404e-14, 4.7319e-14, 2.6954e-14, 2.5783e-14,\n",
       "             1.9910e-14, 1.1615e-14, 8.0487e-16, 3.8938e-16])}},\n",
       "   {'fpr': np.float64(0.07829181494661921),\n",
       "    'tpr': np.float64(0.9832589285714286),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0142, 0.0142,\n",
       "             0.0142, 0.0178, 0.0214, 0.0214, 0.0214, 0.0214, 0.0249, 0.0249, 0.0249,\n",
       "             0.0249, 0.0285, 0.0285, 0.0285, 0.0285, 0.0285, 0.0285, 0.0285, 0.0320,\n",
       "             0.0356, 0.0356, 0.0356, 0.0391, 0.0391, 0.0391, 0.0391, 0.0427, 0.0463,\n",
       "             0.0498, 0.0534, 0.0534, 0.0534, 0.0569, 0.0569, 0.0569, 0.0569, 0.0605,\n",
       "             0.0605, 0.0605, 0.0641, 0.0641, 0.0641, 0.0676, 0.0676, 0.0676, 0.0676,\n",
       "             0.0676, 0.0676, 0.0712, 0.0747, 0.0783, 0.0819, 0.0819, 0.0854, 0.0890,\n",
       "             0.0890, 0.0890, 0.0925, 0.0961, 0.0961, 0.0961, 0.0961, 0.0996, 0.1032,\n",
       "             0.1068, 0.1103, 0.1139, 0.1174, 0.1210, 0.1210, 0.1246, 0.1281, 0.1281,\n",
       "             0.1317, 0.1352, 0.1388, 0.1423, 0.1459, 0.1495, 0.1530, 0.1566, 0.1601,\n",
       "             0.1637, 0.1673, 0.1708, 0.1708, 0.1744, 0.1779, 0.1815, 0.1851, 0.1886,\n",
       "             0.1922, 0.1957, 0.1993, 0.2028, 0.2064, 0.2100, 0.2100, 0.2135, 0.2135,\n",
       "             0.2135, 0.2171, 0.2206, 0.2242, 0.2278, 0.2313, 0.2349, 0.2384, 0.2420,\n",
       "             0.2456, 0.2491, 0.2527, 0.2527, 0.2562, 0.2598, 0.2633, 0.2669, 0.2705,\n",
       "             0.2740, 0.2776, 0.2811, 0.2847, 0.2883, 0.2883, 0.2918, 0.2954, 0.2989,\n",
       "             0.3025, 0.3060, 0.3096, 0.3132, 0.3167, 0.3203, 0.3238, 0.3274, 0.3310,\n",
       "             0.3345, 0.3381, 0.3416, 0.3452, 0.3488, 0.3523, 0.3559, 0.3594, 0.3630,\n",
       "             0.3665, 0.3701, 0.3737, 0.3772, 0.3808, 0.3843, 0.3879, 0.3915, 0.3950,\n",
       "             0.3986, 0.4021, 0.4057, 0.4093, 0.4128, 0.4164, 0.4199, 0.4235, 0.4270,\n",
       "             0.4306, 0.4342, 0.4377, 0.4413, 0.4448, 0.4484, 0.4520, 0.4555, 0.4591,\n",
       "             0.4626, 0.4662, 0.4698, 0.4733, 0.4769, 0.4804, 0.4840, 0.4875, 0.4911,\n",
       "             0.4947, 0.4982, 0.5018, 0.5053, 0.5089, 0.5125, 0.5160, 0.5196, 0.5231,\n",
       "             0.5267, 0.5302, 0.5338, 0.5338, 0.5374, 0.5409, 0.5445, 0.5480, 0.5516,\n",
       "             0.5552, 0.5587, 0.5623, 0.5658, 0.5694, 0.5730, 0.5765, 0.5801, 0.5836,\n",
       "             0.5872, 0.5907, 0.5943, 0.5979, 0.6014, 0.6050, 0.6085, 0.6121, 0.6157,\n",
       "             0.6192, 0.6228, 0.6263, 0.6299, 0.6335, 0.6370, 0.6406, 0.6441, 0.6477,\n",
       "             0.6512, 0.6548, 0.6584, 0.6619, 0.6655, 0.6690, 0.6726, 0.6762, 0.6797,\n",
       "             0.6833, 0.6868, 0.6904, 0.6940, 0.6975, 0.7011, 0.7046, 0.7082, 0.7117,\n",
       "             0.7153, 0.7189, 0.7224, 0.7260, 0.7295, 0.7331, 0.7367, 0.7402, 0.7438,\n",
       "             0.7473, 0.7509, 0.7544, 0.7580, 0.7616, 0.7651, 0.7687, 0.7722, 0.7758,\n",
       "             0.7794, 0.7829, 0.7865, 0.7900, 0.7936, 0.7972, 0.8007, 0.8043, 0.8078,\n",
       "             0.8114, 0.8149, 0.8185, 0.8221, 0.8256, 0.8292, 0.8327, 0.8363, 0.8399,\n",
       "             0.8434, 0.8470, 0.8505, 0.8541, 0.8577, 0.8612, 0.8648, 0.8683, 0.8719,\n",
       "             0.8754, 0.8790, 0.8826, 0.8861, 0.8897, 0.8932, 0.8968, 0.9004, 0.9039,\n",
       "             0.9075, 0.9110, 0.9146, 0.9181, 0.9217, 0.9253, 0.9288, 0.9324, 0.9359,\n",
       "             0.9395, 0.9431, 0.9466, 0.9502, 0.9537, 0.9573, 0.9609, 0.9644, 0.9680,\n",
       "             0.9715, 0.9751, 0.9786, 0.9822, 0.9858, 0.9893, 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.4141, 0.4833, 0.5223, 0.5513, 0.5647, 0.5837, 0.5926, 0.6049,\n",
       "             0.6150, 0.6239, 0.6339, 0.6417, 0.6484, 0.6529, 0.6551, 0.6585, 0.6652,\n",
       "             0.6696, 0.6708, 0.6752, 0.6775, 0.6808, 0.6842, 0.6853, 0.6864, 0.6886,\n",
       "             0.6897, 0.6908, 0.6953, 0.6987, 0.7009, 0.7020, 0.7054, 0.7065, 0.7087,\n",
       "             0.7109, 0.7121, 0.7143, 0.7154, 0.7176, 0.7199, 0.7232, 0.7254, 0.7266,\n",
       "             0.7299, 0.7310, 0.7321, 0.7333, 0.7344, 0.7355, 0.7388, 0.7400, 0.7411,\n",
       "             0.7433, 0.7455, 0.7467, 0.7478, 0.7489, 0.7511, 0.7522, 0.7533, 0.7545,\n",
       "             0.7556, 0.7567, 0.7589, 0.7600, 0.7612, 0.7623, 0.7634, 0.7645, 0.7656,\n",
       "             0.7679, 0.7690, 0.7701, 0.7712, 0.7723, 0.7734, 0.7746, 0.7757, 0.7768,\n",
       "             0.7790, 0.7801, 0.7812, 0.7824, 0.7835, 0.7857, 0.7868, 0.7879, 0.7891,\n",
       "             0.7902, 0.7913, 0.7924, 0.7935, 0.7946, 0.7980, 0.8002, 0.8025, 0.8036,\n",
       "             0.8047, 0.8058, 0.8069, 0.8080, 0.8092, 0.8103, 0.8114, 0.8125, 0.8136,\n",
       "             0.8147, 0.8158, 0.8170, 0.8181, 0.8192, 0.8203, 0.8214, 0.8237, 0.8248,\n",
       "             0.8259, 0.8270, 0.8281, 0.8304, 0.8315, 0.8326, 0.8337, 0.8348, 0.8359,\n",
       "             0.8371, 0.8382, 0.8393, 0.8404, 0.8415, 0.8426, 0.8449, 0.8460, 0.8471,\n",
       "             0.8482, 0.8493, 0.8504, 0.8516, 0.8527, 0.8527, 0.8538, 0.8549, 0.8560,\n",
       "             0.8583, 0.8594, 0.8605, 0.8616, 0.8627, 0.8638, 0.8650, 0.8661, 0.8672,\n",
       "             0.8683, 0.8694, 0.8717, 0.8728, 0.8739, 0.8750, 0.8761, 0.8772, 0.8783,\n",
       "             0.8795, 0.8806, 0.8817, 0.8828, 0.8839, 0.8850, 0.8862, 0.8873, 0.8884,\n",
       "             0.8895, 0.8906, 0.8917, 0.8929, 0.8940, 0.8951, 0.8962, 0.8973, 0.8996,\n",
       "             0.9007, 0.9018, 0.9029, 0.9040, 0.9051, 0.9062, 0.9074, 0.9085, 0.9096,\n",
       "             0.9107, 0.9118, 0.9129, 0.9141, 0.9152, 0.9163, 0.9174, 0.9185, 0.9196,\n",
       "             0.9208, 0.9219, 0.9230, 0.9241, 0.9252, 0.9263, 0.9275, 0.9286, 0.9297,\n",
       "             0.9308, 0.9319, 0.9330, 0.9342, 0.9353, 0.9364, 0.9364, 0.9375, 0.9386,\n",
       "             0.9397, 0.9408, 0.9420, 0.9431, 0.9442, 0.9453, 0.9464, 0.9464, 0.9475,\n",
       "             0.9487, 0.9487, 0.9487, 0.9498, 0.9509, 0.9520, 0.9520, 0.9531, 0.9542,\n",
       "             0.9554, 0.9554, 0.9565, 0.9576, 0.9587, 0.9598, 0.9609, 0.9621, 0.9621,\n",
       "             0.9621, 0.9632, 0.9643, 0.9643, 0.9654, 0.9665, 0.9676, 0.9676, 0.9676,\n",
       "             0.9676, 0.9676, 0.9688, 0.9699, 0.9699, 0.9710, 0.9721, 0.9732, 0.9732,\n",
       "             0.9743, 0.9754, 0.9754, 0.9766, 0.9777, 0.9777, 0.9788, 0.9799, 0.9810,\n",
       "             0.9821, 0.9833, 0.9833, 0.9833, 0.9833, 0.9833, 0.9844, 0.9844, 0.9844,\n",
       "             0.9855, 0.9866, 0.9866, 0.9866, 0.9877, 0.9888, 0.9900, 0.9900, 0.9900,\n",
       "             0.9900, 0.9900, 0.9900, 0.9900, 0.9900, 0.9911, 0.9911, 0.9911, 0.9922,\n",
       "             0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "             0.9922, 0.9922, 0.9922, 0.9933, 0.9933, 0.9933, 0.9933, 0.9933, 0.9933,\n",
       "             0.9933, 0.9933, 0.9933, 0.9933, 0.9933, 0.9933, 0.9944, 0.9944, 0.9955,\n",
       "             0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967,\n",
       "             0.9967, 0.9967, 0.9967, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9992e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9985e-01, 9.9984e-01,\n",
       "             9.9984e-01, 9.9983e-01, 9.9981e-01, 9.9979e-01, 9.9977e-01, 9.9976e-01,\n",
       "             9.9976e-01, 9.9974e-01, 9.9971e-01, 9.9969e-01, 9.9969e-01, 9.9965e-01,\n",
       "             9.9964e-01, 9.9964e-01, 9.9963e-01, 9.9960e-01, 9.9959e-01, 9.9959e-01,\n",
       "             9.9959e-01, 9.9958e-01, 9.9958e-01, 9.9958e-01, 9.9957e-01, 9.9955e-01,\n",
       "             9.9953e-01, 9.9952e-01, 9.9947e-01, 9.9944e-01, 9.9944e-01, 9.9941e-01,\n",
       "             9.9937e-01, 9.9934e-01, 9.9931e-01, 9.9928e-01, 9.9928e-01, 9.9923e-01,\n",
       "             9.9917e-01, 9.9916e-01, 9.9900e-01, 9.9899e-01, 9.9897e-01, 9.9852e-01,\n",
       "             9.9843e-01, 9.9840e-01, 9.9837e-01, 9.9831e-01, 9.9830e-01, 9.9825e-01,\n",
       "             9.9816e-01, 9.9796e-01, 9.9783e-01, 9.9781e-01, 9.9720e-01, 9.9700e-01,\n",
       "             9.9683e-01, 9.9659e-01, 9.9655e-01, 9.9634e-01, 9.9632e-01, 9.9614e-01,\n",
       "             9.9335e-01, 9.9147e-01, 9.9069e-01, 9.8681e-01, 9.8467e-01, 9.8460e-01,\n",
       "             9.8459e-01, 9.7757e-01, 9.7520e-01, 9.7143e-01, 9.6636e-01, 9.6037e-01,\n",
       "             9.5441e-01, 9.5428e-01, 9.4873e-01, 9.4756e-01, 9.2870e-01, 9.2098e-01,\n",
       "             8.6452e-01, 8.5500e-01, 8.4323e-01, 8.2757e-01, 8.1286e-01, 7.9469e-01,\n",
       "             7.8378e-01, 7.7188e-01, 7.4889e-01, 7.4877e-01, 6.8998e-01, 6.2035e-01,\n",
       "             6.0685e-01, 5.8848e-01, 5.6128e-01, 5.4222e-01, 5.0248e-01, 4.8245e-01,\n",
       "             4.4884e-01, 3.8721e-01, 3.7902e-01, 3.2041e-01, 3.1218e-01, 2.9044e-01,\n",
       "             2.8536e-01, 2.8012e-01, 2.7446e-01, 2.3439e-01, 1.9659e-01, 1.7435e-01,\n",
       "             1.5222e-01, 1.3891e-01, 1.3764e-01, 1.2941e-01, 1.1917e-01, 9.2031e-02,\n",
       "             6.6481e-02, 5.6081e-02, 5.1734e-02, 4.4063e-02, 4.3980e-02, 3.6864e-02,\n",
       "             3.5539e-02, 3.4548e-02, 3.1900e-02, 3.1418e-02, 2.7080e-02, 2.5935e-02,\n",
       "             2.5753e-02, 2.3082e-02, 2.2935e-02, 1.8566e-02, 1.7941e-02, 1.6091e-02,\n",
       "             1.4651e-02, 1.2613e-02, 1.1541e-02, 1.1381e-02, 6.1783e-03, 6.1370e-03,\n",
       "             5.9530e-03, 5.4872e-03, 5.2805e-03, 5.1670e-03, 5.0007e-03, 4.9204e-03,\n",
       "             4.5091e-03, 4.0074e-03, 3.4756e-03, 3.2355e-03, 3.1580e-03, 2.9083e-03,\n",
       "             2.6258e-03, 1.8286e-03, 1.3842e-03, 1.3526e-03, 1.1634e-03, 1.0713e-03,\n",
       "             8.8174e-04, 6.4945e-04, 6.2617e-04, 5.8310e-04, 5.4971e-04, 5.3634e-04,\n",
       "             5.3504e-04, 5.3100e-04, 4.8737e-04, 4.6849e-04, 4.6791e-04, 4.6327e-04,\n",
       "             3.4941e-04, 3.3921e-04, 3.3724e-04, 3.3542e-04, 3.0613e-04, 2.1783e-04,\n",
       "             2.1454e-04, 1.9503e-04, 1.9022e-04, 1.8943e-04, 1.8491e-04, 1.7439e-04,\n",
       "             1.6259e-04, 1.5496e-04, 1.5448e-04, 1.4514e-04, 8.7399e-05, 8.7365e-05,\n",
       "             8.2339e-05, 7.9166e-05, 7.6424e-05, 6.3809e-05, 6.1403e-05, 5.2052e-05,\n",
       "             4.1597e-05, 3.7614e-05, 2.8106e-05, 2.4154e-05, 1.9949e-05, 1.9290e-05,\n",
       "             1.7429e-05, 1.6199e-05, 1.4236e-05, 1.3486e-05, 1.1091e-05, 1.0378e-05,\n",
       "             1.0091e-05, 9.5001e-06, 7.4999e-06, 7.3464e-06, 7.0484e-06, 6.9194e-06,\n",
       "             6.8357e-06, 4.7002e-06, 4.2845e-06, 4.0054e-06, 3.6653e-06, 3.3172e-06,\n",
       "             2.2832e-06, 2.2257e-06, 2.1243e-06, 1.9986e-06, 1.8449e-06, 1.7822e-06,\n",
       "             1.5809e-06, 1.1601e-06, 1.1390e-06, 1.1052e-06, 9.4334e-07, 8.9781e-07,\n",
       "             8.6089e-07, 6.7234e-07, 5.8673e-07, 5.7657e-07, 5.1524e-07, 4.9632e-07,\n",
       "             4.4427e-07, 4.3433e-07, 3.5486e-07, 3.2356e-07, 2.8006e-07, 2.3175e-07,\n",
       "             2.0937e-07, 1.9210e-07, 1.6726e-07, 1.5251e-07, 1.4234e-07, 1.2045e-07,\n",
       "             1.1032e-07, 1.0209e-07, 9.8514e-08, 9.5466e-08, 7.8512e-08, 7.4156e-08,\n",
       "             7.1818e-08, 5.6246e-08, 5.5589e-08, 5.3019e-08, 5.1702e-08, 4.3706e-08,\n",
       "             4.2830e-08, 3.8241e-08, 3.6682e-08, 3.0450e-08, 2.6859e-08, 2.1024e-08,\n",
       "             1.8384e-08, 1.7157e-08, 1.6729e-08, 1.6255e-08, 1.6137e-08, 1.6106e-08,\n",
       "             1.6065e-08, 1.5628e-08, 1.5551e-08, 1.5325e-08, 1.4761e-08, 1.3564e-08,\n",
       "             1.3556e-08, 1.2871e-08, 1.2268e-08, 1.2108e-08, 1.1748e-08, 1.1217e-08,\n",
       "             1.1193e-08, 1.0958e-08, 1.0851e-08, 8.6418e-09, 8.5567e-09, 8.4900e-09,\n",
       "             8.0302e-09, 7.1378e-09, 6.9341e-09, 5.4070e-09, 3.3752e-09, 2.8763e-09,\n",
       "             2.5767e-09, 2.4221e-09, 2.3118e-09, 2.1158e-09, 2.0332e-09, 2.0165e-09,\n",
       "             1.9183e-09, 1.7020e-09, 1.5808e-09, 1.4416e-09, 1.2836e-09, 1.2258e-09,\n",
       "             1.1802e-09, 1.1152e-09, 7.7341e-10, 7.4509e-10, 7.3410e-10, 7.1358e-10,\n",
       "             7.0534e-10, 4.4439e-10, 4.0136e-10, 3.6803e-10, 3.0678e-10, 2.7046e-10,\n",
       "             2.4914e-10, 2.4003e-10, 2.3256e-10, 2.2007e-10, 1.8650e-10, 1.8521e-10,\n",
       "             1.6289e-10, 1.5857e-10, 1.4260e-10, 1.3582e-10, 1.0826e-10, 1.0681e-10,\n",
       "             8.5769e-11, 7.4266e-11, 6.8492e-11, 4.0895e-11, 3.9116e-11, 2.8749e-11,\n",
       "             2.4662e-11, 2.4291e-11, 1.6073e-11, 1.5931e-11, 1.5857e-11, 1.3728e-11,\n",
       "             1.1934e-11, 1.0778e-11, 8.7170e-12, 7.4139e-12, 6.6662e-12, 5.4806e-12,\n",
       "             3.4489e-12, 3.3290e-12, 3.0981e-12, 2.8969e-12, 1.9446e-12, 1.3098e-12,\n",
       "             9.0781e-13, 6.9787e-13, 5.4031e-13, 4.1198e-13, 3.2969e-13, 1.9495e-13,\n",
       "             1.7565e-13, 1.6897e-13, 1.5913e-13, 1.0997e-13, 7.1927e-14, 3.7110e-14,\n",
       "             3.2308e-14, 1.8884e-14, 1.7129e-14])}},\n",
       "   {'fpr': np.float64(0.099644128113879),\n",
       "    'tpr': np.float64(0.9933035714285714),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036, 0.0036,\n",
       "             0.0036, 0.0036, 0.0036, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071, 0.0071,\n",
       "             0.0107, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
       "             0.0142, 0.0142, 0.0142, 0.0142, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0214, 0.0214, 0.0214, 0.0214, 0.0249, 0.0249, 0.0249,\n",
       "             0.0249, 0.0249, 0.0285, 0.0285, 0.0285, 0.0320, 0.0356, 0.0356, 0.0356,\n",
       "             0.0356, 0.0356, 0.0356, 0.0356, 0.0356, 0.0356, 0.0356, 0.0356, 0.0356,\n",
       "             0.0356, 0.0356, 0.0356, 0.0356, 0.0356, 0.0391, 0.0391, 0.0391, 0.0391,\n",
       "             0.0391, 0.0391, 0.0391, 0.0391, 0.0391, 0.0391, 0.0427, 0.0427, 0.0427,\n",
       "             0.0427, 0.0463, 0.0463, 0.0463, 0.0463, 0.0498, 0.0498, 0.0534, 0.0534,\n",
       "             0.0569, 0.0605, 0.0605, 0.0605, 0.0605, 0.0641, 0.0676, 0.0712, 0.0747,\n",
       "             0.0783, 0.0819, 0.0854, 0.0854, 0.0890, 0.0925, 0.0961, 0.0996, 0.1032,\n",
       "             0.1068, 0.1068, 0.1103, 0.1139, 0.1139, 0.1174, 0.1210, 0.1246, 0.1281,\n",
       "             0.1317, 0.1352, 0.1352, 0.1388, 0.1423, 0.1459, 0.1495, 0.1530, 0.1566,\n",
       "             0.1601, 0.1637, 0.1673, 0.1708, 0.1744, 0.1779, 0.1815, 0.1851, 0.1886,\n",
       "             0.1922, 0.1957, 0.1993, 0.2028, 0.2028, 0.2064, 0.2100, 0.2135, 0.2171,\n",
       "             0.2206, 0.2242, 0.2278, 0.2313, 0.2349, 0.2384, 0.2420, 0.2420, 0.2420,\n",
       "             0.2456, 0.2491, 0.2527, 0.2562, 0.2598, 0.2633, 0.2669, 0.2705, 0.2740,\n",
       "             0.2776, 0.2811, 0.2847, 0.2883, 0.2918, 0.2954, 0.2989, 0.3025, 0.3060,\n",
       "             0.3096, 0.3132, 0.3167, 0.3203, 0.3238, 0.3274, 0.3310, 0.3345, 0.3381,\n",
       "             0.3416, 0.3452, 0.3488, 0.3523, 0.3559, 0.3594, 0.3630, 0.3665, 0.3701,\n",
       "             0.3737, 0.3772, 0.3808, 0.3843, 0.3879, 0.3915, 0.3950, 0.3986, 0.4021,\n",
       "             0.4057, 0.4093, 0.4128, 0.4164, 0.4199, 0.4235, 0.4270, 0.4306, 0.4342,\n",
       "             0.4377, 0.4413, 0.4448, 0.4484, 0.4520, 0.4555, 0.4591, 0.4626, 0.4662,\n",
       "             0.4698, 0.4733, 0.4769, 0.4804, 0.4840, 0.4875, 0.4911, 0.4947, 0.4982,\n",
       "             0.5018, 0.5053, 0.5089, 0.5125, 0.5160, 0.5196, 0.5231, 0.5267, 0.5302,\n",
       "             0.5338, 0.5374, 0.5409, 0.5445, 0.5480, 0.5516, 0.5552, 0.5587, 0.5623,\n",
       "             0.5658, 0.5694, 0.5730, 0.5765, 0.5801, 0.5836, 0.5872, 0.5907, 0.5943,\n",
       "             0.5979, 0.6014, 0.6050, 0.6085, 0.6121, 0.6157, 0.6192, 0.6228, 0.6263,\n",
       "             0.6299, 0.6335, 0.6370, 0.6406, 0.6441, 0.6477, 0.6512, 0.6548, 0.6584,\n",
       "             0.6619, 0.6655, 0.6690, 0.6726, 0.6762, 0.6797, 0.6833, 0.6868, 0.6904,\n",
       "             0.6940, 0.6975, 0.7011, 0.7046, 0.7082, 0.7117, 0.7153, 0.7189, 0.7224,\n",
       "             0.7260, 0.7295, 0.7331, 0.7367, 0.7402, 0.7438, 0.7473, 0.7509, 0.7544,\n",
       "             0.7580, 0.7616, 0.7651, 0.7687, 0.7722, 0.7758, 0.7794, 0.7829, 0.7865,\n",
       "             0.7900, 0.7936, 0.7972, 0.8007, 0.8043, 0.8078, 0.8114, 0.8149, 0.8185,\n",
       "             0.8221, 0.8256, 0.8292, 0.8327, 0.8363, 0.8399, 0.8434, 0.8470, 0.8505,\n",
       "             0.8541, 0.8577, 0.8612, 0.8648, 0.8683, 0.8719, 0.8754, 0.8790, 0.8826,\n",
       "             0.8861, 0.8897, 0.8932, 0.8968, 0.9004, 0.9039, 0.9075, 0.9110, 0.9146,\n",
       "             0.9181, 0.9217, 0.9253, 0.9288, 0.9324, 0.9359, 0.9395, 0.9431, 0.9466,\n",
       "             0.9502, 0.9537, 0.9573, 0.9609, 0.9644, 0.9680, 0.9715, 0.9751, 0.9786,\n",
       "             0.9822, 0.9858, 0.9893, 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.7299, 0.7768, 0.8025, 0.8170, 0.8292, 0.8371, 0.8438, 0.8471,\n",
       "             0.8527, 0.8549, 0.8583, 0.8616, 0.8650, 0.8661, 0.8683, 0.8694, 0.8739,\n",
       "             0.8750, 0.8761, 0.8772, 0.8783, 0.8795, 0.8806, 0.8817, 0.8839, 0.8862,\n",
       "             0.8862, 0.8873, 0.8884, 0.8895, 0.8906, 0.8917, 0.8929, 0.8940, 0.8951,\n",
       "             0.8962, 0.8973, 0.8996, 0.9007, 0.9018, 0.9029, 0.9051, 0.9074, 0.9085,\n",
       "             0.9096, 0.9107, 0.9118, 0.9129, 0.9141, 0.9152, 0.9163, 0.9174, 0.9185,\n",
       "             0.9196, 0.9208, 0.9219, 0.9230, 0.9241, 0.9252, 0.9263, 0.9275, 0.9286,\n",
       "             0.9297, 0.9308, 0.9319, 0.9330, 0.9342, 0.9353, 0.9364, 0.9386, 0.9397,\n",
       "             0.9408, 0.9420, 0.9420, 0.9431, 0.9442, 0.9453, 0.9453, 0.9464, 0.9475,\n",
       "             0.9487, 0.9498, 0.9498, 0.9509, 0.9520, 0.9520, 0.9520, 0.9531, 0.9542,\n",
       "             0.9554, 0.9565, 0.9576, 0.9587, 0.9598, 0.9609, 0.9621, 0.9632, 0.9643,\n",
       "             0.9654, 0.9665, 0.9676, 0.9688, 0.9699, 0.9699, 0.9710, 0.9721, 0.9732,\n",
       "             0.9743, 0.9754, 0.9766, 0.9777, 0.9788, 0.9799, 0.9799, 0.9810, 0.9821,\n",
       "             0.9833, 0.9833, 0.9844, 0.9855, 0.9866, 0.9866, 0.9877, 0.9877, 0.9888,\n",
       "             0.9888, 0.9888, 0.9900, 0.9911, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "             0.9922, 0.9922, 0.9922, 0.9933, 0.9933, 0.9933, 0.9933, 0.9933, 0.9933,\n",
       "             0.9933, 0.9944, 0.9944, 0.9944, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955,\n",
       "             0.9955, 0.9955, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967,\n",
       "             0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967,\n",
       "             0.9967, 0.9967, 0.9967, 0.9967, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9989, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9988e-01, 9.9982e-01, 9.9979e-01, 9.9977e-01,\n",
       "             9.9976e-01, 9.9975e-01, 9.9975e-01, 9.9972e-01, 9.9970e-01, 9.9966e-01,\n",
       "             9.9966e-01, 9.9963e-01, 9.9961e-01, 9.9959e-01, 9.9958e-01, 9.9950e-01,\n",
       "             9.9949e-01, 9.9949e-01, 9.9944e-01, 9.9938e-01, 9.9933e-01, 9.9911e-01,\n",
       "             9.9909e-01, 9.9901e-01, 9.9899e-01, 9.9892e-01, 9.9892e-01, 9.9885e-01,\n",
       "             9.9879e-01, 9.9873e-01, 9.9845e-01, 9.9820e-01, 9.9756e-01, 9.9744e-01,\n",
       "             9.9667e-01, 9.9567e-01, 9.9476e-01, 9.9444e-01, 9.9296e-01, 9.9202e-01,\n",
       "             9.8857e-01, 9.8722e-01, 9.8604e-01, 9.7985e-01, 9.7276e-01, 9.5373e-01,\n",
       "             9.5143e-01, 9.1923e-01, 9.0979e-01, 8.9715e-01, 8.6410e-01, 8.4439e-01,\n",
       "             8.3411e-01, 8.2958e-01, 7.9270e-01, 7.6907e-01, 7.5204e-01, 7.5062e-01,\n",
       "             6.8792e-01, 6.8426e-01, 6.0468e-01, 6.0464e-01, 5.7906e-01, 4.7775e-01,\n",
       "             4.4365e-01, 4.1016e-01, 3.9996e-01, 3.8674e-01, 3.2070e-01, 2.9235e-01,\n",
       "             2.5317e-01, 2.4550e-01, 2.2853e-01, 2.1995e-01, 2.0608e-01, 1.6625e-01,\n",
       "             1.5709e-01, 1.5161e-01, 1.3884e-01, 1.3695e-01, 1.3509e-01, 1.3055e-01,\n",
       "             1.1216e-01, 1.1164e-01, 1.1056e-01, 8.5030e-02, 7.3192e-02, 6.7197e-02,\n",
       "             6.6481e-02, 6.2310e-02, 6.1779e-02, 5.9346e-02, 5.8948e-02, 4.5715e-02,\n",
       "             4.0289e-02, 3.6578e-02, 3.0765e-02, 2.9502e-02, 2.1485e-02, 2.0812e-02,\n",
       "             1.5100e-02, 1.4571e-02, 1.4157e-02, 1.3451e-02, 1.1659e-02, 1.0919e-02,\n",
       "             8.3600e-03, 8.0971e-03, 7.8570e-03, 7.1660e-03, 6.0562e-03, 5.6479e-03,\n",
       "             5.3734e-03, 4.5346e-03, 4.1503e-03, 3.9906e-03, 3.7237e-03, 3.5517e-03,\n",
       "             3.5048e-03, 2.9383e-03, 2.9304e-03, 2.8083e-03, 2.5153e-03, 2.5033e-03,\n",
       "             2.5027e-03, 2.4648e-03, 2.2668e-03, 2.2228e-03, 2.0294e-03, 1.5551e-03,\n",
       "             1.5235e-03, 1.4714e-03, 1.4563e-03, 1.3093e-03, 1.1737e-03, 1.0255e-03,\n",
       "             9.3592e-04, 9.1356e-04, 8.1547e-04, 7.9920e-04, 7.3963e-04, 7.3619e-04,\n",
       "             7.1282e-04, 6.8635e-04, 6.8393e-04, 6.2635e-04, 5.9011e-04, 5.8607e-04,\n",
       "             5.8049e-04, 5.5098e-04, 4.9909e-04, 4.7940e-04, 4.4477e-04, 4.1826e-04,\n",
       "             3.8766e-04, 3.7350e-04, 3.4031e-04, 2.8342e-04, 2.6534e-04, 2.4171e-04,\n",
       "             2.3756e-04, 2.2166e-04, 2.1045e-04, 1.8122e-04, 1.7474e-04, 1.7208e-04,\n",
       "             1.4708e-04, 1.3240e-04, 1.1471e-04, 1.1424e-04, 9.8320e-05, 9.6339e-05,\n",
       "             8.0069e-05, 7.8818e-05, 7.7996e-05, 6.7477e-05, 6.4631e-05, 5.8832e-05,\n",
       "             5.2950e-05, 5.1906e-05, 5.0942e-05, 5.0633e-05, 4.9381e-05, 4.7492e-05,\n",
       "             4.4276e-05, 4.3320e-05, 3.7542e-05, 2.7659e-05, 2.4369e-05, 2.4297e-05,\n",
       "             2.2601e-05, 2.1915e-05, 2.1775e-05, 1.8309e-05, 1.7707e-05, 1.5813e-05,\n",
       "             1.4705e-05, 1.4705e-05, 1.4025e-05, 1.2771e-05, 1.2504e-05, 1.2404e-05,\n",
       "             1.2255e-05, 1.1685e-05, 1.0952e-05, 1.0890e-05, 9.6605e-06, 8.8195e-06,\n",
       "             8.2179e-06, 6.3390e-06, 5.3661e-06, 5.3205e-06, 5.0804e-06, 4.7831e-06,\n",
       "             4.3769e-06, 3.1220e-06, 2.7151e-06, 2.6644e-06, 2.2197e-06, 1.9329e-06,\n",
       "             1.8131e-06, 1.5685e-06, 1.5457e-06, 1.4629e-06, 1.3034e-06, 1.1171e-06,\n",
       "             1.1130e-06, 1.0598e-06, 1.0217e-06, 1.0115e-06, 8.9334e-07, 8.6634e-07,\n",
       "             8.4665e-07, 7.8121e-07, 7.6955e-07, 7.4662e-07, 7.4001e-07, 6.1791e-07,\n",
       "             5.5905e-07, 5.4017e-07, 5.0463e-07, 4.7430e-07, 4.3230e-07, 3.8817e-07,\n",
       "             3.7870e-07, 3.6764e-07, 3.2005e-07, 3.0673e-07, 2.9666e-07, 2.7470e-07,\n",
       "             2.4947e-07, 2.4128e-07, 2.3432e-07, 2.0962e-07, 1.7587e-07, 1.7398e-07,\n",
       "             1.6100e-07, 1.3960e-07, 1.3651e-07, 1.3382e-07, 1.1879e-07, 1.0962e-07,\n",
       "             1.0446e-07, 9.1028e-08, 8.9906e-08, 8.6539e-08, 8.1118e-08, 7.7244e-08,\n",
       "             7.6462e-08, 6.4917e-08, 5.5445e-08, 5.3301e-08, 3.6710e-08, 3.1910e-08,\n",
       "             2.8405e-08, 2.7480e-08, 2.7238e-08, 2.6293e-08, 2.4106e-08, 1.7218e-08,\n",
       "             1.3455e-08, 1.2757e-08, 1.2322e-08, 1.2252e-08, 1.1397e-08, 1.1349e-08,\n",
       "             8.6507e-09, 6.9985e-09, 5.1889e-09, 5.1273e-09, 4.6295e-09, 4.5754e-09,\n",
       "             4.2680e-09, 3.3343e-09, 3.2624e-09, 3.2214e-09, 2.9855e-09, 1.8133e-09,\n",
       "             1.3882e-09, 1.3603e-09, 1.1994e-09, 8.4195e-10, 7.4035e-10, 6.0859e-10,\n",
       "             4.8852e-10, 4.5045e-10, 2.2562e-10, 2.1561e-10, 1.5155e-10, 1.4167e-10,\n",
       "             1.2668e-10, 8.1325e-11, 7.1520e-11, 6.4784e-11, 5.9243e-11, 5.4520e-11,\n",
       "             2.8787e-11, 1.2123e-11, 9.5886e-12, 4.1634e-12, 9.9026e-13, 5.4309e-13])}},\n",
       "   {'fpr': np.float64(0.06761565836298933),\n",
       "    'tpr': np.float64(0.9921875),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0071, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
       "             0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0142,\n",
       "             0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142, 0.0142,\n",
       "             0.0142, 0.0142, 0.0142, 0.0142, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178,\n",
       "             0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0178, 0.0214, 0.0214, 0.0214,\n",
       "             0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0249, 0.0249, 0.0249,\n",
       "             0.0249, 0.0249, 0.0249, 0.0249, 0.0249, 0.0249, 0.0249, 0.0249, 0.0249,\n",
       "             0.0249, 0.0285, 0.0320, 0.0320, 0.0320, 0.0356, 0.0356, 0.0356, 0.0356,\n",
       "             0.0356, 0.0356, 0.0356, 0.0356, 0.0356, 0.0356, 0.0356, 0.0391, 0.0391,\n",
       "             0.0427, 0.0427, 0.0427, 0.0427, 0.0427, 0.0463, 0.0463, 0.0463, 0.0463,\n",
       "             0.0463, 0.0463, 0.0498, 0.0534, 0.0534, 0.0534, 0.0534, 0.0569, 0.0569,\n",
       "             0.0605, 0.0641, 0.0676, 0.0676, 0.0712, 0.0712, 0.0747, 0.0783, 0.0783,\n",
       "             0.0819, 0.0854, 0.0890, 0.0890, 0.0925, 0.0961, 0.0996, 0.1032, 0.1068,\n",
       "             0.1103, 0.1139, 0.1174, 0.1210, 0.1246, 0.1281, 0.1317, 0.1352, 0.1388,\n",
       "             0.1423, 0.1459, 0.1495, 0.1530, 0.1566, 0.1601, 0.1637, 0.1673, 0.1708,\n",
       "             0.1744, 0.1779, 0.1815, 0.1815, 0.1851, 0.1886, 0.1922, 0.1957, 0.1993,\n",
       "             0.2028, 0.2064, 0.2100, 0.2135, 0.2171, 0.2206, 0.2242, 0.2278, 0.2313,\n",
       "             0.2349, 0.2384, 0.2420, 0.2456, 0.2456, 0.2491, 0.2527, 0.2562, 0.2598,\n",
       "             0.2633, 0.2669, 0.2705, 0.2740, 0.2776, 0.2811, 0.2847, 0.2883, 0.2918,\n",
       "             0.2918, 0.2954, 0.2989, 0.3025, 0.3060, 0.3096, 0.3132, 0.3167, 0.3203,\n",
       "             0.3238, 0.3274, 0.3310, 0.3345, 0.3381, 0.3416, 0.3452, 0.3488, 0.3523,\n",
       "             0.3559, 0.3594, 0.3630, 0.3665, 0.3701, 0.3737, 0.3772, 0.3808, 0.3843,\n",
       "             0.3879, 0.3915, 0.3950, 0.3986, 0.4021, 0.4057, 0.4093, 0.4128, 0.4164,\n",
       "             0.4199, 0.4235, 0.4270, 0.4306, 0.4342, 0.4377, 0.4413, 0.4448, 0.4484,\n",
       "             0.4520, 0.4555, 0.4591, 0.4626, 0.4662, 0.4698, 0.4733, 0.4769, 0.4804,\n",
       "             0.4840, 0.4875, 0.4911, 0.4947, 0.4982, 0.5018, 0.5053, 0.5089, 0.5125,\n",
       "             0.5160, 0.5196, 0.5231, 0.5267, 0.5302, 0.5338, 0.5374, 0.5409, 0.5445,\n",
       "             0.5480, 0.5516, 0.5552, 0.5587, 0.5623, 0.5658, 0.5694, 0.5730, 0.5765,\n",
       "             0.5801, 0.5836, 0.5872, 0.5907, 0.5943, 0.5979, 0.6014, 0.6050, 0.6085,\n",
       "             0.6121, 0.6157, 0.6192, 0.6228, 0.6263, 0.6299, 0.6335, 0.6370, 0.6406,\n",
       "             0.6441, 0.6477, 0.6512, 0.6548, 0.6584, 0.6619, 0.6655, 0.6690, 0.6726,\n",
       "             0.6762, 0.6797, 0.6833, 0.6868, 0.6904, 0.6940, 0.6975, 0.7011, 0.7046,\n",
       "             0.7082, 0.7117, 0.7153, 0.7189, 0.7224, 0.7260, 0.7295, 0.7331, 0.7367,\n",
       "             0.7402, 0.7438, 0.7473, 0.7509, 0.7544, 0.7580, 0.7616, 0.7651, 0.7687,\n",
       "             0.7722, 0.7758, 0.7794, 0.7829, 0.7865, 0.7900, 0.7936, 0.7972, 0.8007,\n",
       "             0.8043, 0.8078, 0.8114, 0.8149, 0.8185, 0.8221, 0.8256, 0.8292, 0.8327,\n",
       "             0.8363, 0.8399, 0.8434, 0.8470, 0.8505, 0.8541, 0.8577, 0.8612, 0.8648,\n",
       "             0.8683, 0.8719, 0.8754, 0.8790, 0.8826, 0.8861, 0.8897, 0.8932, 0.8968,\n",
       "             0.9004, 0.9039, 0.9075, 0.9110, 0.9146, 0.9181, 0.9217, 0.9253, 0.9288,\n",
       "             0.9324, 0.9359, 0.9395, 0.9431, 0.9466, 0.9502, 0.9537, 0.9573, 0.9609,\n",
       "             0.9644, 0.9680, 0.9715, 0.9751, 0.9786, 0.9822, 0.9858, 0.9893, 0.9929,\n",
       "             0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.8393, 0.8728, 0.8862, 0.8906, 0.8962, 0.8973, 0.9007, 0.9018,\n",
       "             0.9040, 0.9062, 0.9074, 0.9085, 0.9096, 0.9107, 0.9118, 0.9141, 0.9152,\n",
       "             0.9163, 0.9174, 0.9185, 0.9196, 0.9208, 0.9219, 0.9230, 0.9241, 0.9252,\n",
       "             0.9263, 0.9275, 0.9286, 0.9297, 0.9297, 0.9308, 0.9319, 0.9330, 0.9342,\n",
       "             0.9353, 0.9364, 0.9375, 0.9386, 0.9397, 0.9408, 0.9408, 0.9420, 0.9431,\n",
       "             0.9442, 0.9453, 0.9464, 0.9475, 0.9487, 0.9498, 0.9498, 0.9509, 0.9520,\n",
       "             0.9531, 0.9542, 0.9554, 0.9565, 0.9576, 0.9587, 0.9598, 0.9609, 0.9621,\n",
       "             0.9632, 0.9632, 0.9632, 0.9643, 0.9654, 0.9654, 0.9665, 0.9676, 0.9688,\n",
       "             0.9699, 0.9710, 0.9721, 0.9732, 0.9743, 0.9754, 0.9766, 0.9766, 0.9777,\n",
       "             0.9777, 0.9788, 0.9799, 0.9810, 0.9821, 0.9821, 0.9833, 0.9844, 0.9855,\n",
       "             0.9866, 0.9877, 0.9877, 0.9877, 0.9888, 0.9900, 0.9911, 0.9911, 0.9922,\n",
       "             0.9922, 0.9922, 0.9922, 0.9933, 0.9933, 0.9944, 0.9944, 0.9944, 0.9955,\n",
       "             0.9955, 0.9955, 0.9955, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967,\n",
       "             0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967,\n",
       "             0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967, 0.9967,\n",
       "             0.9967, 0.9967, 0.9967, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978,\n",
       "             0.9978, 0.9978, 0.9978, 0.9978, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9988e-01, 9.9985e-01, 9.9984e-01, 9.9981e-01,\n",
       "             9.9979e-01, 9.9979e-01, 9.9976e-01, 9.9973e-01, 9.9966e-01, 9.9965e-01,\n",
       "             9.9964e-01, 9.9961e-01, 9.9960e-01, 9.9948e-01, 9.9929e-01, 9.9889e-01,\n",
       "             9.9885e-01, 9.9834e-01, 9.9819e-01, 9.9759e-01, 9.9741e-01, 9.9739e-01,\n",
       "             9.9721e-01, 9.9705e-01, 9.9588e-01, 9.9584e-01, 9.9554e-01, 9.9513e-01,\n",
       "             9.9225e-01, 9.9210e-01, 9.8872e-01, 9.8803e-01, 9.8750e-01, 9.7528e-01,\n",
       "             9.7506e-01, 9.7446e-01, 9.6800e-01, 9.4797e-01, 9.4611e-01, 9.4354e-01,\n",
       "             8.9899e-01, 8.5323e-01, 8.5167e-01, 8.4835e-01, 8.2074e-01, 7.9407e-01,\n",
       "             7.8106e-01, 7.7790e-01, 7.1565e-01, 5.4377e-01, 5.2941e-01, 5.2747e-01,\n",
       "             4.3850e-01, 4.1524e-01, 4.0947e-01, 3.2049e-01, 2.3114e-01, 2.2235e-01,\n",
       "             2.1034e-01, 1.6445e-01, 1.6245e-01, 1.1131e-01, 7.4833e-02, 6.0509e-02,\n",
       "             5.5004e-02, 5.1802e-02, 5.0628e-02, 3.6660e-02, 3.0725e-02, 2.5452e-02,\n",
       "             2.5215e-02, 1.9891e-02, 1.6463e-02, 1.6101e-02, 1.5892e-02, 1.5175e-02,\n",
       "             1.4758e-02, 1.4467e-02, 1.3644e-02, 1.3564e-02, 1.2880e-02, 1.1131e-02,\n",
       "             7.5194e-03, 6.5584e-03, 6.4919e-03, 6.2146e-03, 4.8574e-03, 4.4371e-03,\n",
       "             4.4352e-03, 3.9441e-03, 3.7191e-03, 3.4653e-03, 3.3733e-03, 2.9925e-03,\n",
       "             2.9619e-03, 2.8318e-03, 2.3956e-03, 2.0231e-03, 1.9463e-03, 1.6526e-03,\n",
       "             1.3242e-03, 1.2655e-03, 1.1367e-03, 9.8847e-04, 9.0283e-04, 8.1680e-04,\n",
       "             8.0307e-04, 7.2512e-04, 6.7601e-04, 5.4176e-04, 5.3934e-04, 5.3739e-04,\n",
       "             5.1690e-04, 4.2794e-04, 3.7047e-04, 3.5008e-04, 3.0009e-04, 2.5774e-04,\n",
       "             2.2687e-04, 2.0474e-04, 2.0237e-04, 1.8650e-04, 1.8626e-04, 1.6888e-04,\n",
       "             1.2769e-04, 1.2090e-04, 9.9388e-05, 9.7242e-05, 7.4821e-05, 6.3476e-05,\n",
       "             5.1957e-05, 4.7976e-05, 4.3549e-05, 4.1425e-05, 4.0384e-05, 3.0159e-05,\n",
       "             2.9774e-05, 2.9701e-05, 2.8575e-05, 2.0429e-05, 1.8226e-05, 1.4261e-05,\n",
       "             1.2823e-05, 1.2707e-05, 1.2161e-05, 1.1264e-05, 1.0659e-05, 9.9420e-06,\n",
       "             9.4895e-06, 8.6675e-06, 8.4280e-06, 7.1343e-06, 6.9322e-06, 6.6454e-06,\n",
       "             6.5162e-06, 5.2423e-06, 5.1697e-06, 4.7835e-06, 3.8524e-06, 3.6878e-06,\n",
       "             3.5237e-06, 3.3502e-06, 3.2563e-06, 3.1516e-06, 3.1382e-06, 2.9479e-06,\n",
       "             2.9471e-06, 2.8600e-06, 2.6746e-06, 2.6603e-06, 2.3931e-06, 2.2948e-06,\n",
       "             2.0041e-06, 1.9936e-06, 1.9136e-06, 1.6292e-06, 1.5271e-06, 1.4803e-06,\n",
       "             1.4288e-06, 1.4094e-06, 1.0438e-06, 9.7109e-07, 9.1782e-07, 8.9236e-07,\n",
       "             6.0549e-07, 5.9324e-07, 4.5640e-07, 4.5183e-07, 4.2574e-07, 4.1962e-07,\n",
       "             4.1101e-07, 3.9242e-07, 3.8545e-07, 3.3410e-07, 3.1601e-07, 2.7726e-07,\n",
       "             2.3709e-07, 2.3402e-07, 2.3242e-07, 2.0674e-07, 2.0316e-07, 2.0165e-07,\n",
       "             2.0119e-07, 1.9809e-07, 1.8969e-07, 1.8790e-07, 1.7199e-07, 1.3100e-07,\n",
       "             1.2751e-07, 1.1691e-07, 1.1312e-07, 1.1102e-07, 9.1275e-08, 8.3158e-08,\n",
       "             8.2134e-08, 7.4629e-08, 7.3570e-08, 7.2013e-08, 5.6697e-08, 5.5657e-08,\n",
       "             3.9180e-08, 3.6141e-08, 3.3463e-08, 3.2793e-08, 3.2035e-08, 3.1234e-08,\n",
       "             3.0768e-08, 3.0135e-08, 2.4744e-08, 2.4255e-08, 2.3933e-08, 2.2975e-08,\n",
       "             2.2357e-08, 2.2141e-08, 2.1316e-08, 1.9431e-08, 1.9425e-08, 1.5908e-08,\n",
       "             1.5820e-08, 1.5367e-08, 1.5348e-08, 1.3131e-08, 1.1375e-08, 1.0727e-08,\n",
       "             9.8369e-09, 9.7120e-09, 8.4718e-09, 7.3659e-09, 7.0932e-09, 7.0474e-09,\n",
       "             6.7790e-09, 5.8151e-09, 5.4428e-09, 5.4244e-09, 4.9645e-09, 4.8525e-09,\n",
       "             3.1498e-09, 2.6880e-09, 2.6060e-09, 2.6040e-09, 2.5949e-09, 2.5597e-09,\n",
       "             2.5338e-09, 2.4959e-09, 2.2729e-09, 2.2151e-09, 2.0504e-09, 1.9414e-09,\n",
       "             1.6868e-09, 1.6052e-09, 1.1015e-09, 9.7773e-10, 8.6945e-10, 8.2059e-10,\n",
       "             7.3824e-10, 7.2438e-10, 5.5949e-10, 4.8434e-10, 4.6159e-10, 4.2842e-10,\n",
       "             4.1002e-10, 2.6979e-10, 2.5551e-10, 2.5050e-10, 2.4430e-10, 2.2022e-10,\n",
       "             2.1302e-10, 1.6927e-10, 1.6095e-10, 1.5002e-10, 1.4421e-10, 1.1266e-10,\n",
       "             9.7093e-11, 9.6175e-11, 7.0201e-11, 4.6668e-11, 4.5933e-11, 3.9893e-11,\n",
       "             3.4936e-11, 3.0265e-11, 2.4582e-11, 2.3553e-11, 1.7789e-11, 1.2356e-11,\n",
       "             8.1497e-12, 7.5343e-12, 6.4765e-12, 4.3964e-12, 4.0174e-12, 2.3911e-12,\n",
       "             1.5034e-12, 1.0568e-12, 6.7893e-13, 6.7487e-13, 5.8081e-13, 3.2341e-13,\n",
       "             2.1888e-13, 1.7376e-13, 1.0976e-13, 3.9428e-14, 2.8520e-16])}},\n",
       "   {'fpr': np.float64(0.3487544483985765),\n",
       "    'tpr': np.float64(0.9988839285714286),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0747, 0.0961, 0.1068, 0.1103, 0.1103, 0.1139, 0.1174, 0.1210,\n",
       "             0.1246, 0.1281, 0.1317, 0.1352, 0.1352, 0.1352, 0.1352, 0.1388, 0.1423,\n",
       "             0.1423, 0.1459, 0.1495, 0.1530, 0.1530, 0.1566, 0.1566, 0.1601, 0.1637,\n",
       "             0.1637, 0.1673, 0.1708, 0.1708, 0.1708, 0.1744, 0.1744, 0.1779, 0.1815,\n",
       "             0.1815, 0.1815, 0.1851, 0.1886, 0.1922, 0.1957, 0.1993, 0.2028, 0.2064,\n",
       "             0.2064, 0.2100, 0.2135, 0.2171, 0.2206, 0.2242, 0.2278, 0.2313, 0.2349,\n",
       "             0.2384, 0.2420, 0.2456, 0.2491, 0.2527, 0.2527, 0.2562, 0.2598, 0.2633,\n",
       "             0.2669, 0.2705, 0.2740, 0.2776, 0.2776, 0.2811, 0.2811, 0.2847, 0.2883,\n",
       "             0.2918, 0.2954, 0.2989, 0.3025, 0.3060, 0.3096, 0.3132, 0.3167, 0.3203,\n",
       "             0.3238, 0.3238, 0.3238, 0.3274, 0.3310, 0.3310, 0.3345, 0.3381, 0.3416,\n",
       "             0.3452, 0.3488, 0.3523, 0.3559, 0.3594, 0.3630, 0.3665, 0.3701, 0.3701,\n",
       "             0.3737, 0.3772, 0.3808, 0.3843, 0.3879, 0.3915, 0.3950, 0.3986, 0.4021,\n",
       "             0.4057, 0.4093, 0.4128, 0.4164, 0.4199, 0.4235, 0.4270, 0.4306, 0.4342,\n",
       "             0.4377, 0.4413, 0.4448, 0.4484, 0.4520, 0.4555, 0.4591, 0.4626, 0.4662,\n",
       "             0.4698, 0.4733, 0.4769, 0.4804, 0.4840, 0.4875, 0.4911, 0.4947, 0.4982,\n",
       "             0.5018, 0.5053, 0.5089, 0.5125, 0.5160, 0.5196, 0.5231, 0.5267, 0.5302,\n",
       "             0.5338, 0.5374, 0.5409, 0.5445, 0.5480, 0.5516, 0.5552, 0.5587, 0.5623,\n",
       "             0.5658, 0.5694, 0.5730, 0.5765, 0.5801, 0.5836, 0.5872, 0.5907, 0.5943,\n",
       "             0.5979, 0.6014, 0.6050, 0.6085, 0.6121, 0.6157, 0.6192, 0.6228, 0.6263,\n",
       "             0.6299, 0.6335, 0.6370, 0.6406, 0.6441, 0.6477, 0.6512, 0.6548, 0.6584,\n",
       "             0.6619, 0.6655, 0.6690, 0.6726, 0.6762, 0.6797, 0.6833, 0.6868, 0.6904,\n",
       "             0.6940, 0.6975, 0.7011, 0.7046, 0.7082, 0.7117, 0.7153, 0.7189, 0.7224,\n",
       "             0.7260, 0.7295, 0.7331, 0.7367, 0.7402, 0.7438, 0.7473, 0.7509, 0.7544,\n",
       "             0.7580, 0.7616, 0.7651, 0.7687, 0.7722, 0.7758, 0.7794, 0.7829, 0.7865,\n",
       "             0.7900, 0.7936, 0.7972, 0.8007, 0.8043, 0.8078, 0.8114, 0.8149, 0.8185,\n",
       "             0.8221, 0.8256, 0.8292, 0.8327, 0.8363, 0.8399, 0.8434, 0.8470, 0.8505,\n",
       "             0.8541, 0.8577, 0.8612, 0.8648, 0.8683, 0.8719, 0.8754, 0.8790, 0.8826,\n",
       "             0.8861, 0.8897, 0.8932, 0.8968, 0.9004, 0.9039, 0.9075, 0.9110, 0.9146,\n",
       "             0.9181, 0.9217, 0.9253, 0.9288, 0.9324, 0.9359, 0.9395, 0.9431, 0.9466,\n",
       "             0.9502, 0.9537, 0.9573, 0.9609, 0.9644, 0.9680, 0.9715, 0.9751, 0.9786,\n",
       "             0.9822, 0.9858, 0.9893, 0.9929, 0.9964, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.9621, 0.9676, 0.9699, 0.9699, 0.9721, 0.9754, 0.9754, 0.9766,\n",
       "             0.9777, 0.9777, 0.9777, 0.9777, 0.9788, 0.9799, 0.9810, 0.9810, 0.9810,\n",
       "             0.9821, 0.9821, 0.9821, 0.9821, 0.9833, 0.9833, 0.9844, 0.9844, 0.9844,\n",
       "             0.9855, 0.9855, 0.9855, 0.9866, 0.9877, 0.9877, 0.9888, 0.9888, 0.9888,\n",
       "             0.9900, 0.9911, 0.9911, 0.9911, 0.9911, 0.9911, 0.9911, 0.9911, 0.9911,\n",
       "             0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "             0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9933, 0.9933, 0.9933, 0.9933,\n",
       "             0.9933, 0.9933, 0.9933, 0.9933, 0.9944, 0.9944, 0.9955, 0.9955, 0.9955,\n",
       "             0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955, 0.9955,\n",
       "             0.9955, 0.9967, 0.9978, 0.9978, 0.9978, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9989e-01, 9.9988e-01, 9.9987e-01,\n",
       "             9.9985e-01, 9.9985e-01, 9.9984e-01, 9.9981e-01, 9.9980e-01, 9.9979e-01,\n",
       "             9.9978e-01, 9.9966e-01, 9.9956e-01, 9.9944e-01, 9.9937e-01, 9.9923e-01,\n",
       "             9.9895e-01, 9.9864e-01, 9.9850e-01, 9.9834e-01, 9.9827e-01, 9.9820e-01,\n",
       "             9.9816e-01, 9.9747e-01, 9.9689e-01, 9.9674e-01, 9.9659e-01, 9.9652e-01,\n",
       "             9.9489e-01, 9.9417e-01, 9.9394e-01, 9.9147e-01, 9.8986e-01, 9.8984e-01,\n",
       "             9.8921e-01, 9.8026e-01, 9.7823e-01, 9.7207e-01, 9.6284e-01, 9.5060e-01,\n",
       "             9.4275e-01, 9.3372e-01, 9.3115e-01, 9.0355e-01, 9.0129e-01, 8.9088e-01,\n",
       "             8.8861e-01, 8.7861e-01, 8.4611e-01, 8.1317e-01, 8.0788e-01, 7.6028e-01,\n",
       "             7.4414e-01, 7.3981e-01, 7.1177e-01, 6.7983e-01, 6.4332e-01, 5.6686e-01,\n",
       "             5.2748e-01, 5.2077e-01, 4.2976e-01, 4.2691e-01, 4.1544e-01, 4.0746e-01,\n",
       "             3.6096e-01, 3.4445e-01, 3.2238e-01, 2.4552e-01, 2.1151e-01, 1.9415e-01,\n",
       "             1.4016e-01, 1.1343e-01, 8.4925e-02, 6.1973e-02, 6.0276e-02, 5.6347e-02,\n",
       "             5.3604e-02, 4.0857e-02, 3.7127e-02, 3.6289e-02, 3.5563e-02, 3.5493e-02,\n",
       "             2.9515e-02, 2.6721e-02, 2.6610e-02, 2.1457e-02, 2.1073e-02, 2.0511e-02,\n",
       "             1.9421e-02, 1.3207e-02, 1.3133e-02, 1.0398e-02, 6.0361e-03, 5.9832e-03,\n",
       "             4.4668e-03, 3.5514e-03, 3.1322e-03, 2.4984e-03, 2.1506e-03, 1.4297e-03,\n",
       "             1.3307e-03, 1.0156e-03, 9.4453e-04, 7.5755e-04, 6.7953e-04, 6.1205e-04,\n",
       "             5.2175e-04, 4.5752e-04, 4.0111e-04, 1.3920e-04, 1.3006e-04, 1.2096e-04,\n",
       "             1.1430e-04, 1.1211e-04, 9.3480e-05, 9.1914e-05, 9.1150e-05, 7.8020e-05,\n",
       "             7.7055e-05, 7.5508e-05, 7.4092e-05, 4.5456e-05, 3.8370e-05, 3.6621e-05,\n",
       "             3.5887e-05, 3.4630e-05, 3.1330e-05, 2.4830e-05, 1.6187e-05, 1.4843e-05,\n",
       "             1.2899e-05, 1.1239e-05, 1.1096e-05, 9.1164e-06, 7.4277e-06, 7.1645e-06,\n",
       "             6.9969e-06, 6.2391e-06, 5.0205e-06, 4.1712e-06, 3.8449e-06, 3.1822e-06,\n",
       "             1.9569e-06, 1.8042e-06, 1.6187e-06, 1.1986e-06, 1.0809e-06, 1.0655e-06,\n",
       "             1.0059e-06, 9.8727e-07, 6.7897e-07, 6.4817e-07, 4.8999e-07, 4.7061e-07,\n",
       "             4.6884e-07, 4.2542e-07, 4.1116e-07, 3.4793e-07, 2.7347e-07, 2.3554e-07,\n",
       "             1.8988e-07, 1.7530e-07, 1.4282e-07, 1.3699e-07, 1.0809e-07, 1.0511e-07,\n",
       "             1.0388e-07, 9.4249e-08, 8.1110e-08, 7.7922e-08, 5.3562e-08, 5.1319e-08,\n",
       "             5.0232e-08, 4.8396e-08, 3.7407e-08, 3.4793e-08, 2.6312e-08, 1.6956e-08,\n",
       "             1.3090e-08, 9.8565e-09, 9.7055e-09, 8.9802e-09, 8.5319e-09, 7.5162e-09,\n",
       "             7.2331e-09, 6.0528e-09, 5.9505e-09, 4.7186e-09, 4.4765e-09, 3.7791e-09,\n",
       "             3.4924e-09, 2.8208e-09, 2.7065e-09, 2.6235e-09, 2.5295e-09, 2.4915e-09,\n",
       "             1.7329e-09, 1.5877e-09, 1.5503e-09, 1.1955e-09, 9.9062e-10, 9.1316e-10,\n",
       "             7.0347e-10, 6.1767e-10, 4.5955e-10, 4.5214e-10, 1.3543e-10, 1.2749e-10,\n",
       "             1.1837e-10, 8.4878e-11, 7.1897e-11, 6.9795e-11, 5.1699e-11, 4.3964e-11,\n",
       "             4.2394e-11, 3.6696e-11, 2.5772e-11, 2.5189e-11, 2.3024e-11, 2.2720e-11,\n",
       "             1.1148e-11, 8.0878e-12, 4.0528e-12, 2.2524e-12, 1.1423e-12, 3.2898e-13,\n",
       "             1.7344e-13, 8.1380e-14, 2.1365e-14, 1.5519e-14, 7.7312e-15, 5.2853e-15,\n",
       "             4.0320e-15, 1.8459e-15, 9.8677e-16, 8.3382e-16, 6.5143e-16, 6.1229e-16,\n",
       "             6.1066e-16, 2.3135e-16, 1.5034e-16, 1.4943e-16, 8.6705e-17, 5.2950e-21])}}],\n",
       "  [{'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.5166093928980527),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9613e-01, 9.9480e-01,  ..., 1.1939e-09, 6.3452e-10,\n",
       "             4.0871e-10])}},\n",
       "   {'fpr': np.float64(0.006578947368421052),\n",
       "    'tpr': np.float64(0.8075601374570447),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9539e-01, 9.9523e-01,  ..., 9.4897e-06, 5.1119e-06,\n",
       "             2.9281e-06])}},\n",
       "   {'fpr': np.float64(0.03618421052631579),\n",
       "    'tpr': np.float64(0.9415807560137457),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9929e-01, 9.9902e-01,  ..., 3.2747e-05, 2.6414e-05,\n",
       "             2.5067e-05])}},\n",
       "   {'fpr': np.float64(0.039473684210526314),\n",
       "    'tpr': np.float64(0.9599083619702177),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9954e-01, 9.9927e-01,  ..., 1.4751e-05, 1.4493e-05,\n",
       "             8.1029e-06])}},\n",
       "   {'fpr': np.float64(0.0),\n",
       "    'tpr': np.float64(0.865979381443299),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9971e-01, 9.9953e-01,  ..., 6.4662e-08, 5.4990e-08,\n",
       "             3.8530e-08])}},\n",
       "   {'fpr': np.float64(0.04276315789473684),\n",
       "    'tpr': np.float64(0.97709049255441),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9911e-01, 9.9910e-01,  ..., 3.2590e-05, 2.0359e-05,\n",
       "             1.8481e-05])}},\n",
       "   {'fpr': np.float64(0.003289473684210526),\n",
       "    'tpr': np.float64(0.9392898052691867),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.7436e-09, 1.7701e-09,\n",
       "             9.2837e-10])}},\n",
       "   {'fpr': np.float64(0.06578947368421052),\n",
       "    'tpr': np.float64(0.9873997709049256),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9997e-01, 9.9996e-01,  ..., 7.5083e-07, 6.3422e-07,\n",
       "             4.0186e-07])}},\n",
       "   {'fpr': np.float64(0.12171052631578948),\n",
       "    'tpr': np.float64(0.9965635738831615),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.1348e-06, 8.1142e-07,\n",
       "             2.3587e-07])}},\n",
       "   {'fpr': np.float64(0.006578947368421052),\n",
       "    'tpr': np.float64(0.9656357388316151),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 9.9998e-01, 9.9998e-01,  ..., 4.4753e-08, 9.5980e-09,\n",
       "             2.2391e-09])}},\n",
       "   {'fpr': np.float64(0.046052631578947366),\n",
       "    'tpr': np.float64(0.97709049255441),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000,  ..., 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0011, 0.0023,  ..., 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 2.3811e-10, 5.3819e-11,\n",
       "             2.1742e-11])}},\n",
       "   {'fpr': np.float64(0.06907894736842106),\n",
       "    'tpr': np.float64(0.9885452462772051),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0066, 0.0066, 0.0066, 0.0066, 0.0099,\n",
       "             0.0099, 0.0099, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132,\n",
       "             0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0164, 0.0164, 0.0164,\n",
       "             0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164,\n",
       "             0.0164, 0.0164, 0.0197, 0.0230, 0.0263, 0.0263, 0.0263, 0.0263, 0.0296,\n",
       "             0.0329, 0.0362, 0.0395, 0.0428, 0.0428, 0.0428, 0.0461, 0.0461, 0.0461,\n",
       "             0.0493, 0.0493, 0.0526, 0.0559, 0.0592, 0.0625, 0.0658, 0.0658, 0.0658,\n",
       "             0.0691, 0.0691, 0.0724, 0.0724, 0.0724, 0.0757, 0.0789, 0.0789, 0.0789,\n",
       "             0.0822, 0.0855, 0.0888, 0.0921, 0.0954, 0.0987, 0.1020, 0.1053, 0.1086,\n",
       "             0.1086, 0.1086, 0.1118, 0.1151, 0.1184, 0.1217, 0.1250, 0.1283, 0.1316,\n",
       "             0.1316, 0.1349, 0.1382, 0.1414, 0.1447, 0.1480, 0.1513, 0.1546, 0.1546,\n",
       "             0.1579, 0.1612, 0.1645, 0.1678, 0.1711, 0.1743, 0.1776, 0.1809, 0.1842,\n",
       "             0.1875, 0.1908, 0.1941, 0.1974, 0.2007, 0.2039, 0.2072, 0.2105, 0.2138,\n",
       "             0.2138, 0.2171, 0.2204, 0.2237, 0.2270, 0.2303, 0.2336, 0.2368, 0.2401,\n",
       "             0.2434, 0.2467, 0.2500, 0.2533, 0.2566, 0.2599, 0.2632, 0.2664, 0.2697,\n",
       "             0.2730, 0.2763, 0.2796, 0.2829, 0.2862, 0.2895, 0.2928, 0.2961, 0.2993,\n",
       "             0.3026, 0.3059, 0.3092, 0.3125, 0.3158, 0.3191, 0.3224, 0.3257, 0.3289,\n",
       "             0.3322, 0.3355, 0.3388, 0.3421, 0.3454, 0.3487, 0.3520, 0.3553, 0.3586,\n",
       "             0.3618, 0.3651, 0.3684, 0.3717, 0.3750, 0.3783, 0.3783, 0.3816, 0.3849,\n",
       "             0.3882, 0.3914, 0.3947, 0.3980, 0.4013, 0.4046, 0.4079, 0.4112, 0.4145,\n",
       "             0.4178, 0.4211, 0.4243, 0.4276, 0.4309, 0.4342, 0.4375, 0.4408, 0.4441,\n",
       "             0.4474, 0.4507, 0.4539, 0.4572, 0.4605, 0.4638, 0.4671, 0.4704, 0.4737,\n",
       "             0.4770, 0.4803, 0.4836, 0.4868, 0.4901, 0.4934, 0.4967, 0.5000, 0.5033,\n",
       "             0.5066, 0.5099, 0.5132, 0.5164, 0.5197, 0.5230, 0.5263, 0.5296, 0.5329,\n",
       "             0.5362, 0.5395, 0.5428, 0.5461, 0.5493, 0.5526, 0.5559, 0.5592, 0.5625,\n",
       "             0.5658, 0.5691, 0.5724, 0.5757, 0.5789, 0.5822, 0.5855, 0.5888, 0.5921,\n",
       "             0.5954, 0.5987, 0.6020, 0.6053, 0.6086, 0.6118, 0.6151, 0.6184, 0.6217,\n",
       "             0.6250, 0.6283, 0.6316, 0.6349, 0.6382, 0.6414, 0.6447, 0.6480, 0.6513,\n",
       "             0.6546, 0.6579, 0.6612, 0.6645, 0.6678, 0.6711, 0.6743, 0.6776, 0.6809,\n",
       "             0.6842, 0.6875, 0.6908, 0.6941, 0.6974, 0.7007, 0.7039, 0.7072, 0.7105,\n",
       "             0.7138, 0.7171, 0.7204, 0.7237, 0.7270, 0.7303, 0.7336, 0.7368, 0.7401,\n",
       "             0.7434, 0.7467, 0.7500, 0.7533, 0.7566, 0.7599, 0.7632, 0.7664, 0.7697,\n",
       "             0.7730, 0.7763, 0.7796, 0.7829, 0.7862, 0.7895, 0.7928, 0.7961, 0.7993,\n",
       "             0.8026, 0.8059, 0.8092, 0.8125, 0.8158, 0.8191, 0.8224, 0.8257, 0.8289,\n",
       "             0.8322, 0.8355, 0.8388, 0.8421, 0.8454, 0.8487, 0.8520, 0.8553, 0.8586,\n",
       "             0.8618, 0.8651, 0.8684, 0.8717, 0.8750, 0.8783, 0.8816, 0.8849, 0.8882,\n",
       "             0.8914, 0.8947, 0.8980, 0.9013, 0.9046, 0.9079, 0.9112, 0.9145, 0.9178,\n",
       "             0.9211, 0.9243, 0.9276, 0.9309, 0.9342, 0.9375, 0.9408, 0.9441, 0.9474,\n",
       "             0.9507, 0.9539, 0.9572, 0.9605, 0.9638, 0.9671, 0.9704, 0.9737, 0.9770,\n",
       "             0.9803, 0.9836, 0.9868, 0.9901, 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0069, 0.0229, 0.0367, 0.0504, 0.0641, 0.0733, 0.0848, 0.0905,\n",
       "             0.0951, 0.0974, 0.1100, 0.1134, 0.1191, 0.1271, 0.1363, 0.1409, 0.1455,\n",
       "             0.1512, 0.1569, 0.1592, 0.1638, 0.1661, 0.1707, 0.1730, 0.1821, 0.1856,\n",
       "             0.1936, 0.1982, 0.2027, 0.2050, 0.2096, 0.2131, 0.2188, 0.2199, 0.2245,\n",
       "             0.2257, 0.2279, 0.2314, 0.2325, 0.2348, 0.2383, 0.2417, 0.2440, 0.2463,\n",
       "             0.2509, 0.2532, 0.2554, 0.2612, 0.2646, 0.2658, 0.2680, 0.2692, 0.2703,\n",
       "             0.2726, 0.2761, 0.2795, 0.2818, 0.2841, 0.2864, 0.2875, 0.2887, 0.2910,\n",
       "             0.2932, 0.2944, 0.2967, 0.2978, 0.3013, 0.3024, 0.3036, 0.3058, 0.3081,\n",
       "             0.3093, 0.3104, 0.3127, 0.3139, 0.3150, 0.3173, 0.3196, 0.3219, 0.3230,\n",
       "             0.3242, 0.3253, 0.3288, 0.3310, 0.3345, 0.3368, 0.3379, 0.3402, 0.3414,\n",
       "             0.3448, 0.3459, 0.3471, 0.3482, 0.3494, 0.3517, 0.3528, 0.3551, 0.3574,\n",
       "             0.3608, 0.3620, 0.3631, 0.3654, 0.3677, 0.3688, 0.3711, 0.3723, 0.3734,\n",
       "             0.3757, 0.3780, 0.3792, 0.3803, 0.3837, 0.3860, 0.3872, 0.3883, 0.3895,\n",
       "             0.3906, 0.3918, 0.3952, 0.3963, 0.3986, 0.3998, 0.4009, 0.4021, 0.4032,\n",
       "             0.4055, 0.4066, 0.4078, 0.4112, 0.4124, 0.4135, 0.4147, 0.4158, 0.4181,\n",
       "             0.4204, 0.4227, 0.4238, 0.4261, 0.4284, 0.4296, 0.4307, 0.4318, 0.4330,\n",
       "             0.4341, 0.4353, 0.4364, 0.4387, 0.4399, 0.4410, 0.4433, 0.4456, 0.4467,\n",
       "             0.4479, 0.4490, 0.4502, 0.4513, 0.4525, 0.4536, 0.4559, 0.4570, 0.4605,\n",
       "             0.4616, 0.4639, 0.4651, 0.4662, 0.4685, 0.4696, 0.4719, 0.4731, 0.4742,\n",
       "             0.4777, 0.4788, 0.4800, 0.4811, 0.4822, 0.4834, 0.4845, 0.4857, 0.4868,\n",
       "             0.4880, 0.4891, 0.4903, 0.4914, 0.4926, 0.4937, 0.4960, 0.4971, 0.4994,\n",
       "             0.5006, 0.5017, 0.5040, 0.5052, 0.5074, 0.5097, 0.5109, 0.5120, 0.5132,\n",
       "             0.5143, 0.5166, 0.5189, 0.5200, 0.5212, 0.5223, 0.5235, 0.5246, 0.5258,\n",
       "             0.5269, 0.5281, 0.5292, 0.5304, 0.5315, 0.5326, 0.5338, 0.5349, 0.5361,\n",
       "             0.5384, 0.5395, 0.5407, 0.5418, 0.5430, 0.5441, 0.5452, 0.5464, 0.5475,\n",
       "             0.5487, 0.5498, 0.5510, 0.5521, 0.5533, 0.5544, 0.5567, 0.5578, 0.5590,\n",
       "             0.5601, 0.5613, 0.5624, 0.5636, 0.5647, 0.5659, 0.5670, 0.5682, 0.5693,\n",
       "             0.5704, 0.5716, 0.5727, 0.5739, 0.5750, 0.5762, 0.5773, 0.5785, 0.5796,\n",
       "             0.5808, 0.5819, 0.5830, 0.5842, 0.5853, 0.5865, 0.5876, 0.5888, 0.5899,\n",
       "             0.5911, 0.5922, 0.5934, 0.5945, 0.5956, 0.5968, 0.5979, 0.5991, 0.6002,\n",
       "             0.6014, 0.6025, 0.6037, 0.6048, 0.6060, 0.6071, 0.6082, 0.6094, 0.6105,\n",
       "             0.6117, 0.6128, 0.6140, 0.6151, 0.6163, 0.6174, 0.6186, 0.6197, 0.6208,\n",
       "             0.6220, 0.6243, 0.6254, 0.6266, 0.6277, 0.6289, 0.6300, 0.6312, 0.6323,\n",
       "             0.6334, 0.6346, 0.6357, 0.6369, 0.6380, 0.6392, 0.6403, 0.6415, 0.6438,\n",
       "             0.6449, 0.6460, 0.6472, 0.6483, 0.6495, 0.6506, 0.6529, 0.6541, 0.6552,\n",
       "             0.6575, 0.6586, 0.6598, 0.6609, 0.6621, 0.6632, 0.6644, 0.6667, 0.6678,\n",
       "             0.6690, 0.6701, 0.6712, 0.6724, 0.6735, 0.6747, 0.6758, 0.6770, 0.6781,\n",
       "             0.6793, 0.6804, 0.6816, 0.6827, 0.6838, 0.6850, 0.6861, 0.6873, 0.6884,\n",
       "             0.6896, 0.6907, 0.6919, 0.6930, 0.6942, 0.6953, 0.6964, 0.6976, 0.6987,\n",
       "             0.6999, 0.7010, 0.7022, 0.7033, 0.7045, 0.7056, 0.7068, 0.7079, 0.7090,\n",
       "             0.7102, 0.7113, 0.7125, 0.7136, 0.7148, 0.7159, 0.7171, 0.7182, 0.7194,\n",
       "             0.7205, 0.7216, 0.7228, 0.7239, 0.7251, 0.7262, 0.7274, 0.7285, 0.7297,\n",
       "             0.7308, 0.7320, 0.7331, 0.7342, 0.7354, 0.7365, 0.7377, 0.7388, 0.7400,\n",
       "             0.7411, 0.7423, 0.7434, 0.7446, 0.7457, 0.7468, 0.7480, 0.7491, 0.7503,\n",
       "             0.7514, 0.7526, 0.7537, 0.7549, 0.7560, 0.7572, 0.7583, 0.7595, 0.7606,\n",
       "             0.7617, 0.7629, 0.7640, 0.7652, 0.7663, 0.7675, 0.7686, 0.7698, 0.7709,\n",
       "             0.7721, 0.7732, 0.7743, 0.7755, 0.7766, 0.7778, 0.7789, 0.7801, 0.7812,\n",
       "             0.7824, 0.7835, 0.7847, 0.7858, 0.7869, 0.7881, 0.7892, 0.7904, 0.7915,\n",
       "             0.7927, 0.7938, 0.7950, 0.7961, 0.7973, 0.7984, 0.7995, 0.8007, 0.8018,\n",
       "             0.8030, 0.8041, 0.8053, 0.8076, 0.8087, 0.8099, 0.8110, 0.8121, 0.8133,\n",
       "             0.8144, 0.8156, 0.8167, 0.8179, 0.8190, 0.8202, 0.8213, 0.8225, 0.8236,\n",
       "             0.8247, 0.8259, 0.8270, 0.8282, 0.8293, 0.8305, 0.8316, 0.8328, 0.8339,\n",
       "             0.8351, 0.8362, 0.8373, 0.8385, 0.8396, 0.8408, 0.8419, 0.8431, 0.8442,\n",
       "             0.8454, 0.8465, 0.8477, 0.8488, 0.8499, 0.8511, 0.8522, 0.8534, 0.8545,\n",
       "             0.8557, 0.8568, 0.8580, 0.8591, 0.8603, 0.8614, 0.8625, 0.8637, 0.8648,\n",
       "             0.8660, 0.8671, 0.8683, 0.8694, 0.8706, 0.8717, 0.8729, 0.8740, 0.8751,\n",
       "             0.8763, 0.8774, 0.8786, 0.8797, 0.8809, 0.8820, 0.8832, 0.8843, 0.8855,\n",
       "             0.8866, 0.8877, 0.8889, 0.8900, 0.8912, 0.8923, 0.8935, 0.8946, 0.8946,\n",
       "             0.8958, 0.8969, 0.8992, 0.9003, 0.9015, 0.9026, 0.9038, 0.9049, 0.9061,\n",
       "             0.9072, 0.9084, 0.9095, 0.9107, 0.9118, 0.9129, 0.9141, 0.9152, 0.9164,\n",
       "             0.9175, 0.9187, 0.9198, 0.9210, 0.9221, 0.9233, 0.9244, 0.9255, 0.9267,\n",
       "             0.9278, 0.9290, 0.9301, 0.9313, 0.9324, 0.9336, 0.9347, 0.9359, 0.9370,\n",
       "             0.9381, 0.9393, 0.9404, 0.9416, 0.9416, 0.9427, 0.9439, 0.9450, 0.9450,\n",
       "             0.9462, 0.9473, 0.9473, 0.9485, 0.9496, 0.9507, 0.9519, 0.9530, 0.9542,\n",
       "             0.9553, 0.9565, 0.9576, 0.9588, 0.9599, 0.9611, 0.9611, 0.9622, 0.9633,\n",
       "             0.9645, 0.9656, 0.9668, 0.9679, 0.9691, 0.9702, 0.9714, 0.9725, 0.9737,\n",
       "             0.9748, 0.9759, 0.9759, 0.9759, 0.9759, 0.9771, 0.9782, 0.9794, 0.9794,\n",
       "             0.9794, 0.9794, 0.9794, 0.9794, 0.9805, 0.9817, 0.9817, 0.9828, 0.9840,\n",
       "             0.9840, 0.9851, 0.9851, 0.9851, 0.9851, 0.9851, 0.9851, 0.9863, 0.9874,\n",
       "             0.9874, 0.9885, 0.9885, 0.9897, 0.9908, 0.9908, 0.9908, 0.9920, 0.9931,\n",
       "             0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931,\n",
       "             0.9943, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9986e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01,\n",
       "             9.9986e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01,\n",
       "             9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9983e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01,\n",
       "             9.9982e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01, 9.9980e-01, 9.9980e-01,\n",
       "             9.9980e-01, 9.9979e-01, 9.9979e-01, 9.9979e-01, 9.9978e-01, 9.9978e-01,\n",
       "             9.9978e-01, 9.9978e-01, 9.9977e-01, 9.9977e-01, 9.9977e-01, 9.9976e-01,\n",
       "             9.9976e-01, 9.9976e-01, 9.9976e-01, 9.9976e-01, 9.9975e-01, 9.9975e-01,\n",
       "             9.9975e-01, 9.9975e-01, 9.9974e-01, 9.9974e-01, 9.9974e-01, 9.9974e-01,\n",
       "             9.9973e-01, 9.9973e-01, 9.9973e-01, 9.9972e-01, 9.9972e-01, 9.9972e-01,\n",
       "             9.9972e-01, 9.9971e-01, 9.9971e-01, 9.9971e-01, 9.9970e-01, 9.9970e-01,\n",
       "             9.9969e-01, 9.9969e-01, 9.9969e-01, 9.9966e-01, 9.9966e-01, 9.9966e-01,\n",
       "             9.9966e-01, 9.9966e-01, 9.9966e-01, 9.9965e-01, 9.9964e-01, 9.9963e-01,\n",
       "             9.9963e-01, 9.9963e-01, 9.9962e-01, 9.9962e-01, 9.9962e-01, 9.9961e-01,\n",
       "             9.9961e-01, 9.9961e-01, 9.9961e-01, 9.9959e-01, 9.9959e-01, 9.9959e-01,\n",
       "             9.9959e-01, 9.9959e-01, 9.9959e-01, 9.9958e-01, 9.9957e-01, 9.9957e-01,\n",
       "             9.9955e-01, 9.9954e-01, 9.9954e-01, 9.9954e-01, 9.9954e-01, 9.9953e-01,\n",
       "             9.9953e-01, 9.9952e-01, 9.9951e-01, 9.9951e-01, 9.9948e-01, 9.9948e-01,\n",
       "             9.9946e-01, 9.9946e-01, 9.9943e-01, 9.9939e-01, 9.9939e-01, 9.9938e-01,\n",
       "             9.9938e-01, 9.9937e-01, 9.9936e-01, 9.9934e-01, 9.9933e-01, 9.9933e-01,\n",
       "             9.9926e-01, 9.9926e-01, 9.9926e-01, 9.9924e-01, 9.9921e-01, 9.9920e-01,\n",
       "             9.9920e-01, 9.9919e-01, 9.9918e-01, 9.9913e-01, 9.9911e-01, 9.9910e-01,\n",
       "             9.9909e-01, 9.9908e-01, 9.9908e-01, 9.9907e-01, 9.9905e-01, 9.9903e-01,\n",
       "             9.9896e-01, 9.9894e-01, 9.9892e-01, 9.9890e-01, 9.9889e-01, 9.9885e-01,\n",
       "             9.9884e-01, 9.9883e-01, 9.9882e-01, 9.9877e-01, 9.9875e-01, 9.9873e-01,\n",
       "             9.9870e-01, 9.9862e-01, 9.9862e-01, 9.9860e-01, 9.9858e-01, 9.9856e-01,\n",
       "             9.9856e-01, 9.9849e-01, 9.9849e-01, 9.9848e-01, 9.9845e-01, 9.9842e-01,\n",
       "             9.9840e-01, 9.9835e-01, 9.9834e-01, 9.9834e-01, 9.9828e-01, 9.9827e-01,\n",
       "             9.9827e-01, 9.9825e-01, 9.9815e-01, 9.9807e-01, 9.9797e-01, 9.9789e-01,\n",
       "             9.9787e-01, 9.9785e-01, 9.9783e-01, 9.9778e-01, 9.9774e-01, 9.9749e-01,\n",
       "             9.9747e-01, 9.9745e-01, 9.9742e-01, 9.9738e-01, 9.9729e-01, 9.9725e-01,\n",
       "             9.9721e-01, 9.9719e-01, 9.9712e-01, 9.9709e-01, 9.9689e-01, 9.9683e-01,\n",
       "             9.9665e-01, 9.9651e-01, 9.9647e-01, 9.9647e-01, 9.9645e-01, 9.9634e-01,\n",
       "             9.9630e-01, 9.9622e-01, 9.9614e-01, 9.9564e-01, 9.9552e-01, 9.9530e-01,\n",
       "             9.9524e-01, 9.9521e-01, 9.9520e-01, 9.9495e-01, 9.9491e-01, 9.9487e-01,\n",
       "             9.9484e-01, 9.9396e-01, 9.9361e-01, 9.9359e-01, 9.9359e-01, 9.9333e-01,\n",
       "             9.9287e-01, 9.9232e-01, 9.9223e-01, 9.9204e-01, 9.9201e-01, 9.9147e-01,\n",
       "             9.9088e-01, 9.9073e-01, 9.9004e-01, 9.8988e-01, 9.8964e-01, 9.8938e-01,\n",
       "             9.8897e-01, 9.8877e-01, 9.8820e-01, 9.8689e-01, 9.8663e-01, 9.8657e-01,\n",
       "             9.8547e-01, 9.8507e-01, 9.8319e-01, 9.8318e-01, 9.8317e-01, 9.8243e-01,\n",
       "             9.8094e-01, 9.7775e-01, 9.7642e-01, 9.7535e-01, 9.7521e-01, 9.7327e-01,\n",
       "             9.7178e-01, 9.6797e-01, 9.6648e-01, 9.6486e-01, 9.6328e-01, 9.6283e-01,\n",
       "             9.6026e-01, 9.5978e-01, 9.5957e-01, 9.5807e-01, 9.4911e-01, 9.4264e-01,\n",
       "             9.4168e-01, 9.3170e-01, 9.2405e-01, 8.9711e-01, 8.9490e-01, 8.7687e-01,\n",
       "             8.7508e-01, 8.3980e-01, 8.2747e-01, 7.8543e-01, 7.8521e-01, 7.8188e-01,\n",
       "             7.8133e-01, 7.7481e-01, 7.7140e-01, 7.4328e-01, 7.3345e-01, 7.2804e-01,\n",
       "             7.2746e-01, 7.2559e-01, 6.9863e-01, 6.8947e-01, 6.6287e-01, 6.4442e-01,\n",
       "             6.3965e-01, 6.1435e-01, 5.7295e-01, 5.4386e-01, 5.2212e-01, 4.9323e-01,\n",
       "             4.5311e-01, 4.4312e-01, 3.8432e-01, 2.9583e-01, 2.9255e-01, 2.7722e-01,\n",
       "             2.6071e-01, 2.4245e-01, 1.9914e-01, 1.9064e-01, 1.4612e-01, 1.4573e-01,\n",
       "             1.3007e-01, 1.2331e-01, 1.1158e-01, 1.1068e-01, 7.9803e-02, 7.8859e-02,\n",
       "             7.8376e-02, 7.4642e-02, 6.8343e-02, 6.5441e-02, 6.4254e-02, 5.4179e-02,\n",
       "             5.1158e-02, 5.0219e-02, 4.5704e-02, 4.4529e-02, 4.1932e-02, 4.1320e-02,\n",
       "             3.9651e-02, 3.6182e-02, 3.2276e-02, 3.2165e-02, 3.1022e-02, 2.6524e-02,\n",
       "             2.5364e-02, 2.4172e-02, 1.9421e-02, 1.9400e-02, 1.9149e-02, 1.8994e-02,\n",
       "             1.8690e-02, 1.7845e-02, 1.6922e-02, 1.6316e-02, 1.5419e-02, 1.4806e-02,\n",
       "             1.3832e-02, 1.2909e-02, 1.2828e-02, 1.2773e-02, 1.2313e-02, 1.2241e-02,\n",
       "             9.7571e-03, 7.9543e-03, 7.8635e-03, 7.1079e-03, 6.7822e-03, 6.6166e-03,\n",
       "             6.3433e-03, 6.1058e-03, 5.7953e-03, 5.7443e-03, 5.7155e-03, 5.5428e-03,\n",
       "             5.5338e-03, 5.4749e-03, 5.3267e-03, 5.1172e-03, 4.7432e-03, 4.4948e-03,\n",
       "             4.4403e-03, 4.0044e-03, 3.8266e-03, 3.7742e-03, 3.7351e-03, 3.5498e-03,\n",
       "             3.3085e-03, 3.2899e-03, 3.2213e-03, 3.2151e-03, 3.1355e-03, 2.7991e-03,\n",
       "             2.7095e-03, 2.5321e-03, 2.4869e-03, 2.4611e-03, 2.2439e-03, 2.2157e-03,\n",
       "             2.1640e-03, 2.0976e-03, 2.0791e-03, 2.0515e-03, 2.0475e-03, 1.8702e-03,\n",
       "             1.8008e-03, 1.5186e-03, 1.5114e-03, 1.4978e-03, 1.4525e-03, 1.2441e-03,\n",
       "             1.2439e-03, 1.1461e-03, 1.1278e-03, 1.1248e-03, 1.0957e-03, 1.0442e-03,\n",
       "             1.0265e-03, 9.9555e-04, 8.3854e-04, 7.9560e-04, 6.2250e-04, 6.2226e-04,\n",
       "             5.9866e-04, 5.8874e-04, 5.7844e-04, 5.6126e-04, 5.3311e-04, 5.1989e-04,\n",
       "             4.6351e-04, 4.3084e-04, 4.2004e-04, 3.8069e-04, 3.8056e-04, 3.7269e-04,\n",
       "             3.6283e-04, 3.4353e-04, 2.8376e-04, 2.5799e-04, 2.2871e-04, 2.2786e-04,\n",
       "             2.2334e-04, 2.2260e-04, 2.1962e-04, 2.1782e-04, 2.0829e-04, 2.0642e-04,\n",
       "             2.0078e-04, 1.9875e-04, 1.9137e-04, 1.8321e-04, 1.7770e-04, 1.6899e-04,\n",
       "             1.6619e-04, 1.5862e-04, 1.4721e-04, 1.4327e-04, 1.3405e-04, 1.0692e-04,\n",
       "             1.0383e-04, 9.1328e-05, 8.6115e-05, 7.9680e-05, 7.6850e-05, 7.4613e-05,\n",
       "             7.1281e-05, 6.8412e-05, 6.6844e-05, 6.5533e-05, 6.4643e-05, 6.3582e-05,\n",
       "             6.3295e-05, 6.2300e-05, 6.2229e-05, 6.0678e-05, 5.8061e-05, 5.6323e-05,\n",
       "             5.5378e-05, 5.3648e-05, 5.3376e-05, 5.2235e-05, 5.1645e-05, 4.3321e-05,\n",
       "             4.2587e-05, 3.9726e-05, 3.8821e-05, 3.8756e-05, 3.8258e-05, 3.7332e-05,\n",
       "             3.6614e-05, 3.5466e-05, 2.9816e-05, 2.9723e-05, 2.9259e-05, 2.9114e-05,\n",
       "             2.7997e-05, 2.7399e-05, 2.6628e-05, 2.6261e-05, 2.6253e-05, 2.4901e-05,\n",
       "             2.3749e-05, 2.3020e-05, 2.0848e-05, 2.0476e-05, 2.0334e-05, 1.9316e-05,\n",
       "             1.8216e-05, 1.5373e-05, 1.5051e-05, 1.4994e-05, 1.3936e-05, 1.3032e-05,\n",
       "             1.2935e-05, 1.2639e-05, 1.1402e-05, 1.1287e-05, 1.0302e-05, 1.0218e-05,\n",
       "             8.8336e-06, 8.7398e-06, 8.7053e-06, 8.2012e-06, 8.1368e-06, 7.7428e-06,\n",
       "             7.4454e-06, 6.7392e-06, 6.4426e-06, 6.2439e-06, 5.6845e-06, 5.0643e-06,\n",
       "             4.8473e-06, 4.2525e-06, 4.2139e-06, 4.2073e-06, 3.9802e-06, 3.7324e-06,\n",
       "             3.4514e-06, 3.2606e-06, 3.1674e-06, 3.1206e-06, 3.0645e-06, 2.9240e-06,\n",
       "             2.6053e-06, 2.5455e-06, 2.4104e-06, 2.2027e-06, 2.1172e-06, 2.0984e-06,\n",
       "             1.9502e-06, 1.7999e-06, 1.5928e-06, 1.2226e-06, 1.1045e-06, 1.0522e-06,\n",
       "             1.0288e-06, 9.8380e-07, 8.4461e-07, 7.7413e-07, 7.7195e-07, 6.5044e-07,\n",
       "             6.4220e-07, 6.1785e-07, 6.1424e-07, 5.7765e-07, 5.7072e-07, 5.2319e-07,\n",
       "             4.6906e-07, 4.4940e-07, 4.4753e-07, 4.2360e-07, 3.9055e-07, 3.7973e-07,\n",
       "             3.6209e-07, 3.5923e-07, 2.1635e-07, 1.8441e-07, 1.7259e-07, 1.3369e-07,\n",
       "             1.0980e-07, 5.7502e-08, 4.5071e-08, 4.1612e-08, 4.0214e-08, 3.3063e-08,\n",
       "             3.0197e-08, 2.9940e-08, 2.1662e-08, 1.8913e-08, 1.7388e-08, 1.5393e-08,\n",
       "             1.3987e-08, 1.1156e-08, 2.9825e-09, 2.8368e-09, 2.1659e-09, 1.1309e-09,\n",
       "             4.9948e-10, 4.2765e-10, 3.4285e-10, 3.5979e-11])}},\n",
       "   {'fpr': np.float64(0.0756578947368421),\n",
       "    'tpr': np.float64(0.9885452462772051),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066,\n",
       "             0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066,\n",
       "             0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066,\n",
       "             0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066,\n",
       "             0.0066, 0.0066, 0.0099, 0.0099, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132,\n",
       "             0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132,\n",
       "             0.0132, 0.0132, 0.0132, 0.0164, 0.0164, 0.0164, 0.0197, 0.0197, 0.0197,\n",
       "             0.0197, 0.0197, 0.0197, 0.0197, 0.0230, 0.0263, 0.0296, 0.0329, 0.0329,\n",
       "             0.0362, 0.0362, 0.0395, 0.0428, 0.0428, 0.0461, 0.0493, 0.0526, 0.0559,\n",
       "             0.0559, 0.0559, 0.0559, 0.0592, 0.0625, 0.0625, 0.0625, 0.0658, 0.0691,\n",
       "             0.0724, 0.0757, 0.0789, 0.0822, 0.0855, 0.0888, 0.0888, 0.0921, 0.0954,\n",
       "             0.0987, 0.1020, 0.1053, 0.1086, 0.1086, 0.1118, 0.1151, 0.1184, 0.1184,\n",
       "             0.1217, 0.1250, 0.1250, 0.1283, 0.1316, 0.1349, 0.1382, 0.1414, 0.1414,\n",
       "             0.1414, 0.1447, 0.1480, 0.1513, 0.1546, 0.1579, 0.1612, 0.1645, 0.1678,\n",
       "             0.1678, 0.1711, 0.1711, 0.1743, 0.1776, 0.1809, 0.1842, 0.1875, 0.1908,\n",
       "             0.1941, 0.1974, 0.2007, 0.2039, 0.2072, 0.2105, 0.2138, 0.2171, 0.2204,\n",
       "             0.2237, 0.2270, 0.2303, 0.2336, 0.2368, 0.2401, 0.2434, 0.2467, 0.2500,\n",
       "             0.2500, 0.2533, 0.2566, 0.2566, 0.2599, 0.2632, 0.2664, 0.2697, 0.2730,\n",
       "             0.2763, 0.2796, 0.2829, 0.2862, 0.2895, 0.2928, 0.2961, 0.2993, 0.3026,\n",
       "             0.3059, 0.3092, 0.3125, 0.3158, 0.3191, 0.3224, 0.3257, 0.3289, 0.3322,\n",
       "             0.3355, 0.3388, 0.3421, 0.3454, 0.3487, 0.3520, 0.3553, 0.3586, 0.3618,\n",
       "             0.3651, 0.3684, 0.3717, 0.3750, 0.3783, 0.3816, 0.3849, 0.3882, 0.3914,\n",
       "             0.3947, 0.3980, 0.4013, 0.4046, 0.4079, 0.4112, 0.4145, 0.4178, 0.4211,\n",
       "             0.4243, 0.4276, 0.4309, 0.4342, 0.4375, 0.4408, 0.4441, 0.4474, 0.4507,\n",
       "             0.4539, 0.4572, 0.4605, 0.4638, 0.4671, 0.4704, 0.4737, 0.4770, 0.4803,\n",
       "             0.4836, 0.4868, 0.4901, 0.4934, 0.4967, 0.5000, 0.5033, 0.5066, 0.5099,\n",
       "             0.5132, 0.5164, 0.5197, 0.5230, 0.5263, 0.5296, 0.5329, 0.5362, 0.5395,\n",
       "             0.5428, 0.5461, 0.5493, 0.5526, 0.5559, 0.5592, 0.5625, 0.5658, 0.5691,\n",
       "             0.5724, 0.5757, 0.5789, 0.5822, 0.5855, 0.5888, 0.5921, 0.5954, 0.5987,\n",
       "             0.6020, 0.6053, 0.6086, 0.6118, 0.6151, 0.6184, 0.6217, 0.6250, 0.6283,\n",
       "             0.6316, 0.6349, 0.6382, 0.6414, 0.6447, 0.6480, 0.6513, 0.6546, 0.6579,\n",
       "             0.6612, 0.6645, 0.6678, 0.6711, 0.6743, 0.6776, 0.6809, 0.6842, 0.6875,\n",
       "             0.6908, 0.6941, 0.6974, 0.7007, 0.7039, 0.7072, 0.7105, 0.7138, 0.7171,\n",
       "             0.7204, 0.7237, 0.7270, 0.7303, 0.7336, 0.7368, 0.7401, 0.7434, 0.7467,\n",
       "             0.7500, 0.7533, 0.7566, 0.7599, 0.7632, 0.7664, 0.7697, 0.7730, 0.7763,\n",
       "             0.7796, 0.7829, 0.7862, 0.7895, 0.7928, 0.7961, 0.7993, 0.8026, 0.8059,\n",
       "             0.8092, 0.8125, 0.8158, 0.8191, 0.8224, 0.8257, 0.8289, 0.8322, 0.8355,\n",
       "             0.8388, 0.8421, 0.8454, 0.8487, 0.8520, 0.8553, 0.8586, 0.8618, 0.8651,\n",
       "             0.8684, 0.8717, 0.8750, 0.8783, 0.8816, 0.8849, 0.8882, 0.8914, 0.8947,\n",
       "             0.8980, 0.9013, 0.9046, 0.9079, 0.9112, 0.9145, 0.9178, 0.9211, 0.9243,\n",
       "             0.9276, 0.9309, 0.9342, 0.9375, 0.9408, 0.9441, 0.9474, 0.9507, 0.9539,\n",
       "             0.9572, 0.9605, 0.9638, 0.9671, 0.9704, 0.9737, 0.9770, 0.9803, 0.9836,\n",
       "             0.9868, 0.9901, 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0034, 0.0092, 0.0160, 0.0206, 0.0263, 0.0298, 0.0355, 0.0435,\n",
       "             0.0481, 0.0550, 0.0584, 0.0619, 0.0722, 0.0779, 0.0825, 0.0859, 0.0905,\n",
       "             0.0916, 0.0928, 0.0997, 0.1054, 0.1111, 0.1157, 0.1168, 0.1191, 0.1203,\n",
       "             0.1226, 0.1260, 0.1271, 0.1283, 0.1294, 0.1317, 0.1352, 0.1397, 0.1432,\n",
       "             0.1501, 0.1558, 0.1569, 0.1604, 0.1615, 0.1627, 0.1638, 0.1672, 0.1695,\n",
       "             0.1707, 0.1753, 0.1775, 0.1798, 0.1821, 0.1833, 0.1856, 0.1879, 0.1901,\n",
       "             0.1936, 0.1970, 0.1993, 0.2005, 0.2016, 0.2027, 0.2062, 0.2073, 0.2085,\n",
       "             0.2108, 0.2131, 0.2142, 0.2153, 0.2176, 0.2199, 0.2222, 0.2257, 0.2279,\n",
       "             0.2302, 0.2314, 0.2325, 0.2348, 0.2360, 0.2383, 0.2394, 0.2405, 0.2417,\n",
       "             0.2428, 0.2440, 0.2451, 0.2474, 0.2486, 0.2509, 0.2532, 0.2543, 0.2554,\n",
       "             0.2566, 0.2577, 0.2612, 0.2635, 0.2658, 0.2669, 0.2680, 0.2692, 0.2703,\n",
       "             0.2715, 0.2738, 0.2772, 0.2795, 0.2806, 0.2818, 0.2829, 0.2841, 0.2864,\n",
       "             0.2887, 0.2898, 0.2910, 0.2921, 0.2932, 0.2944, 0.2967, 0.2990, 0.3001,\n",
       "             0.3013, 0.3024, 0.3058, 0.3081, 0.3093, 0.3116, 0.3127, 0.3162, 0.3173,\n",
       "             0.3184, 0.3196, 0.3207, 0.3230, 0.3242, 0.3253, 0.3265, 0.3288, 0.3310,\n",
       "             0.3322, 0.3333, 0.3345, 0.3356, 0.3368, 0.3379, 0.3391, 0.3402, 0.3414,\n",
       "             0.3425, 0.3436, 0.3471, 0.3494, 0.3517, 0.3528, 0.3562, 0.3574, 0.3585,\n",
       "             0.3608, 0.3631, 0.3643, 0.3654, 0.3666, 0.3688, 0.3700, 0.3734, 0.3757,\n",
       "             0.3769, 0.3780, 0.3792, 0.3803, 0.3814, 0.3826, 0.3837, 0.3849, 0.3860,\n",
       "             0.3872, 0.3883, 0.3906, 0.3929, 0.3952, 0.3963, 0.3975, 0.4009, 0.4021,\n",
       "             0.4032, 0.4044, 0.4055, 0.4066, 0.4078, 0.4089, 0.4101, 0.4112, 0.4124,\n",
       "             0.4147, 0.4158, 0.4181, 0.4192, 0.4215, 0.4227, 0.4238, 0.4250, 0.4261,\n",
       "             0.4273, 0.4284, 0.4296, 0.4318, 0.4330, 0.4341, 0.4353, 0.4364, 0.4376,\n",
       "             0.4387, 0.4399, 0.4410, 0.4422, 0.4433, 0.4444, 0.4456, 0.4467, 0.4490,\n",
       "             0.4502, 0.4525, 0.4536, 0.4548, 0.4559, 0.4570, 0.4582, 0.4593, 0.4605,\n",
       "             0.4616, 0.4628, 0.4639, 0.4651, 0.4662, 0.4674, 0.4696, 0.4708, 0.4719,\n",
       "             0.4742, 0.4754, 0.4777, 0.4788, 0.4800, 0.4811, 0.4822, 0.4834, 0.4845,\n",
       "             0.4857, 0.4868, 0.4880, 0.4891, 0.4903, 0.4914, 0.4926, 0.4937, 0.4948,\n",
       "             0.4960, 0.4971, 0.4983, 0.4994, 0.5006, 0.5029, 0.5040, 0.5052, 0.5063,\n",
       "             0.5074, 0.5086, 0.5097, 0.5109, 0.5120, 0.5132, 0.5143, 0.5155, 0.5166,\n",
       "             0.5178, 0.5189, 0.5200, 0.5212, 0.5223, 0.5258, 0.5269, 0.5281, 0.5292,\n",
       "             0.5304, 0.5326, 0.5338, 0.5349, 0.5361, 0.5372, 0.5395, 0.5407, 0.5418,\n",
       "             0.5430, 0.5441, 0.5464, 0.5475, 0.5487, 0.5498, 0.5510, 0.5521, 0.5544,\n",
       "             0.5556, 0.5567, 0.5578, 0.5590, 0.5601, 0.5613, 0.5624, 0.5636, 0.5647,\n",
       "             0.5659, 0.5670, 0.5682, 0.5693, 0.5704, 0.5716, 0.5727, 0.5739, 0.5750,\n",
       "             0.5762, 0.5773, 0.5785, 0.5796, 0.5808, 0.5819, 0.5830, 0.5842, 0.5853,\n",
       "             0.5865, 0.5876, 0.5888, 0.5899, 0.5911, 0.5922, 0.5934, 0.5945, 0.5956,\n",
       "             0.5968, 0.5979, 0.5991, 0.6002, 0.6014, 0.6025, 0.6037, 0.6048, 0.6060,\n",
       "             0.6071, 0.6082, 0.6094, 0.6105, 0.6117, 0.6128, 0.6140, 0.6151, 0.6163,\n",
       "             0.6174, 0.6186, 0.6197, 0.6208, 0.6220, 0.6231, 0.6243, 0.6254, 0.6266,\n",
       "             0.6277, 0.6289, 0.6300, 0.6312, 0.6323, 0.6334, 0.6346, 0.6357, 0.6369,\n",
       "             0.6380, 0.6392, 0.6403, 0.6415, 0.6426, 0.6438, 0.6449, 0.6460, 0.6483,\n",
       "             0.6495, 0.6506, 0.6518, 0.6529, 0.6541, 0.6552, 0.6564, 0.6575, 0.6586,\n",
       "             0.6598, 0.6609, 0.6621, 0.6632, 0.6644, 0.6655, 0.6667, 0.6678, 0.6690,\n",
       "             0.6701, 0.6712, 0.6724, 0.6735, 0.6747, 0.6758, 0.6770, 0.6781, 0.6793,\n",
       "             0.6804, 0.6816, 0.6827, 0.6838, 0.6850, 0.6861, 0.6873, 0.6884, 0.6896,\n",
       "             0.6907, 0.6919, 0.6930, 0.6942, 0.6953, 0.6964, 0.6976, 0.6987, 0.6999,\n",
       "             0.7022, 0.7045, 0.7056, 0.7068, 0.7079, 0.7090, 0.7102, 0.7113, 0.7125,\n",
       "             0.7136, 0.7148, 0.7159, 0.7171, 0.7182, 0.7194, 0.7205, 0.7216, 0.7228,\n",
       "             0.7239, 0.7251, 0.7262, 0.7274, 0.7285, 0.7297, 0.7308, 0.7320, 0.7331,\n",
       "             0.7342, 0.7365, 0.7377, 0.7388, 0.7400, 0.7411, 0.7411, 0.7423, 0.7434,\n",
       "             0.7446, 0.7457, 0.7468, 0.7480, 0.7491, 0.7503, 0.7514, 0.7526, 0.7537,\n",
       "             0.7549, 0.7560, 0.7572, 0.7583, 0.7595, 0.7606, 0.7617, 0.7629, 0.7640,\n",
       "             0.7652, 0.7663, 0.7675, 0.7686, 0.7698, 0.7709, 0.7721, 0.7732, 0.7743,\n",
       "             0.7755, 0.7766, 0.7778, 0.7789, 0.7801, 0.7812, 0.7824, 0.7835, 0.7847,\n",
       "             0.7858, 0.7869, 0.7881, 0.7892, 0.7904, 0.7915, 0.7927, 0.7938, 0.7950,\n",
       "             0.7961, 0.7973, 0.7984, 0.7995, 0.8007, 0.8018, 0.8030, 0.8041, 0.8053,\n",
       "             0.8064, 0.8076, 0.8087, 0.8099, 0.8110, 0.8121, 0.8133, 0.8144, 0.8156,\n",
       "             0.8167, 0.8179, 0.8190, 0.8202, 0.8213, 0.8225, 0.8236, 0.8247, 0.8259,\n",
       "             0.8270, 0.8282, 0.8293, 0.8305, 0.8316, 0.8328, 0.8339, 0.8351, 0.8362,\n",
       "             0.8373, 0.8385, 0.8396, 0.8408, 0.8419, 0.8431, 0.8442, 0.8454, 0.8465,\n",
       "             0.8477, 0.8488, 0.8499, 0.8511, 0.8522, 0.8534, 0.8545, 0.8557, 0.8568,\n",
       "             0.8580, 0.8591, 0.8603, 0.8614, 0.8625, 0.8637, 0.8648, 0.8660, 0.8671,\n",
       "             0.8683, 0.8694, 0.8706, 0.8717, 0.8729, 0.8740, 0.8751, 0.8763, 0.8774,\n",
       "             0.8786, 0.8797, 0.8809, 0.8820, 0.8832, 0.8843, 0.8855, 0.8866, 0.8877,\n",
       "             0.8889, 0.8900, 0.8912, 0.8923, 0.8935, 0.8946, 0.8958, 0.8969, 0.8981,\n",
       "             0.8992, 0.9003, 0.9015, 0.9026, 0.9038, 0.9049, 0.9061, 0.9072, 0.9084,\n",
       "             0.9095, 0.9107, 0.9107, 0.9118, 0.9129, 0.9141, 0.9152, 0.9164, 0.9175,\n",
       "             0.9187, 0.9198, 0.9210, 0.9221, 0.9233, 0.9244, 0.9255, 0.9267, 0.9278,\n",
       "             0.9290, 0.9301, 0.9313, 0.9324, 0.9336, 0.9347, 0.9359, 0.9370, 0.9381,\n",
       "             0.9393, 0.9404, 0.9416, 0.9427, 0.9439, 0.9450, 0.9462, 0.9473, 0.9485,\n",
       "             0.9496, 0.9507, 0.9507, 0.9519, 0.9519, 0.9530, 0.9542, 0.9553, 0.9565,\n",
       "             0.9576, 0.9588, 0.9599, 0.9611, 0.9622, 0.9633, 0.9645, 0.9656, 0.9668,\n",
       "             0.9679, 0.9691, 0.9702, 0.9702, 0.9714, 0.9725, 0.9725, 0.9737, 0.9748,\n",
       "             0.9759, 0.9771, 0.9782, 0.9794, 0.9794, 0.9794, 0.9794, 0.9794, 0.9805,\n",
       "             0.9805, 0.9817, 0.9817, 0.9817, 0.9828, 0.9828, 0.9828, 0.9828, 0.9828,\n",
       "             0.9840, 0.9851, 0.9863, 0.9863, 0.9863, 0.9874, 0.9885, 0.9885, 0.9885,\n",
       "             0.9885, 0.9885, 0.9885, 0.9885, 0.9885, 0.9885, 0.9897, 0.9897, 0.9897,\n",
       "             0.9897, 0.9897, 0.9897, 0.9897, 0.9908, 0.9908, 0.9908, 0.9908, 0.9920,\n",
       "             0.9920, 0.9920, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9943,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9966, 0.9966, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9989, 0.9989, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01,\n",
       "             9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01,\n",
       "             9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01,\n",
       "             9.9984e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9983e-01, 9.9983e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01,\n",
       "             9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01,\n",
       "             9.9982e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01,\n",
       "             9.9981e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01, 9.9981e-01, 9.9980e-01,\n",
       "             9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9979e-01,\n",
       "             9.9979e-01, 9.9979e-01, 9.9979e-01, 9.9979e-01, 9.9978e-01, 9.9978e-01,\n",
       "             9.9978e-01, 9.9978e-01, 9.9977e-01, 9.9977e-01, 9.9976e-01, 9.9976e-01,\n",
       "             9.9976e-01, 9.9976e-01, 9.9975e-01, 9.9975e-01, 9.9975e-01, 9.9975e-01,\n",
       "             9.9974e-01, 9.9974e-01, 9.9973e-01, 9.9973e-01, 9.9973e-01, 9.9973e-01,\n",
       "             9.9972e-01, 9.9972e-01, 9.9972e-01, 9.9972e-01, 9.9972e-01, 9.9971e-01,\n",
       "             9.9971e-01, 9.9971e-01, 9.9971e-01, 9.9971e-01, 9.9971e-01, 9.9970e-01,\n",
       "             9.9969e-01, 9.9969e-01, 9.9968e-01, 9.9968e-01, 9.9968e-01, 9.9968e-01,\n",
       "             9.9968e-01, 9.9968e-01, 9.9967e-01, 9.9967e-01, 9.9967e-01, 9.9967e-01,\n",
       "             9.9967e-01, 9.9967e-01, 9.9967e-01, 9.9966e-01, 9.9966e-01, 9.9966e-01,\n",
       "             9.9965e-01, 9.9963e-01, 9.9962e-01, 9.9962e-01, 9.9961e-01, 9.9961e-01,\n",
       "             9.9958e-01, 9.9958e-01, 9.9958e-01, 9.9958e-01, 9.9957e-01, 9.9957e-01,\n",
       "             9.9957e-01, 9.9957e-01, 9.9956e-01, 9.9955e-01, 9.9955e-01, 9.9955e-01,\n",
       "             9.9955e-01, 9.9955e-01, 9.9954e-01, 9.9953e-01, 9.9952e-01, 9.9952e-01,\n",
       "             9.9952e-01, 9.9948e-01, 9.9948e-01, 9.9948e-01, 9.9947e-01, 9.9944e-01,\n",
       "             9.9944e-01, 9.9944e-01, 9.9944e-01, 9.9944e-01, 9.9944e-01, 9.9943e-01,\n",
       "             9.9942e-01, 9.9941e-01, 9.9941e-01, 9.9938e-01, 9.9938e-01, 9.9937e-01,\n",
       "             9.9937e-01, 9.9935e-01, 9.9935e-01, 9.9934e-01, 9.9934e-01, 9.9934e-01,\n",
       "             9.9932e-01, 9.9932e-01, 9.9930e-01, 9.9930e-01, 9.9927e-01, 9.9926e-01,\n",
       "             9.9926e-01, 9.9925e-01, 9.9924e-01, 9.9923e-01, 9.9923e-01, 9.9921e-01,\n",
       "             9.9919e-01, 9.9919e-01, 9.9917e-01, 9.9917e-01, 9.9916e-01, 9.9916e-01,\n",
       "             9.9916e-01, 9.9916e-01, 9.9915e-01, 9.9913e-01, 9.9910e-01, 9.9910e-01,\n",
       "             9.9908e-01, 9.9908e-01, 9.9906e-01, 9.9905e-01, 9.9904e-01, 9.9900e-01,\n",
       "             9.9900e-01, 9.9898e-01, 9.9898e-01, 9.9896e-01, 9.9895e-01, 9.9893e-01,\n",
       "             9.9892e-01, 9.9884e-01, 9.9881e-01, 9.9881e-01, 9.9880e-01, 9.9876e-01,\n",
       "             9.9873e-01, 9.9873e-01, 9.9872e-01, 9.9871e-01, 9.9870e-01, 9.9868e-01,\n",
       "             9.9865e-01, 9.9864e-01, 9.9862e-01, 9.9857e-01, 9.9856e-01, 9.9853e-01,\n",
       "             9.9853e-01, 9.9853e-01, 9.9850e-01, 9.9848e-01, 9.9843e-01, 9.9843e-01,\n",
       "             9.9842e-01, 9.9842e-01, 9.9838e-01, 9.9838e-01, 9.9834e-01, 9.9834e-01,\n",
       "             9.9831e-01, 9.9829e-01, 9.9824e-01, 9.9823e-01, 9.9820e-01, 9.9817e-01,\n",
       "             9.9817e-01, 9.9817e-01, 9.9816e-01, 9.9810e-01, 9.9803e-01, 9.9798e-01,\n",
       "             9.9798e-01, 9.9797e-01, 9.9793e-01, 9.9788e-01, 9.9785e-01, 9.9783e-01,\n",
       "             9.9778e-01, 9.9778e-01, 9.9778e-01, 9.9774e-01, 9.9773e-01, 9.9773e-01,\n",
       "             9.9772e-01, 9.9764e-01, 9.9745e-01, 9.9744e-01, 9.9738e-01, 9.9735e-01,\n",
       "             9.9730e-01, 9.9727e-01, 9.9679e-01, 9.9679e-01, 9.9667e-01, 9.9655e-01,\n",
       "             9.9646e-01, 9.9636e-01, 9.9633e-01, 9.9593e-01, 9.9591e-01, 9.9590e-01,\n",
       "             9.9566e-01, 9.9537e-01, 9.9518e-01, 9.9516e-01, 9.9514e-01, 9.9493e-01,\n",
       "             9.9488e-01, 9.9478e-01, 9.9443e-01, 9.9425e-01, 9.9406e-01, 9.9386e-01,\n",
       "             9.9364e-01, 9.9347e-01, 9.9340e-01, 9.9307e-01, 9.9293e-01, 9.9277e-01,\n",
       "             9.9276e-01, 9.9162e-01, 9.9141e-01, 9.9128e-01, 9.9113e-01, 9.9108e-01,\n",
       "             9.9100e-01, 9.9058e-01, 9.9054e-01, 9.8871e-01, 9.8828e-01, 9.8784e-01,\n",
       "             9.8740e-01, 9.8561e-01, 9.8354e-01, 9.8333e-01, 9.8268e-01, 9.8249e-01,\n",
       "             9.8169e-01, 9.7927e-01, 9.7628e-01, 9.7128e-01, 9.6721e-01, 9.6683e-01,\n",
       "             9.6505e-01, 9.6261e-01, 9.6075e-01, 9.5993e-01, 9.5769e-01, 9.5653e-01,\n",
       "             9.5544e-01, 9.5506e-01, 9.5449e-01, 9.5163e-01, 9.5041e-01, 9.4819e-01,\n",
       "             9.4627e-01, 9.4543e-01, 9.4502e-01, 9.4441e-01, 9.4132e-01, 9.3877e-01,\n",
       "             9.3612e-01, 9.2813e-01, 9.1363e-01, 9.0942e-01, 9.0591e-01, 8.9901e-01,\n",
       "             8.9643e-01, 8.9259e-01, 8.8322e-01, 8.8067e-01, 8.7687e-01, 8.5220e-01,\n",
       "             8.4678e-01, 8.4455e-01, 8.3252e-01, 8.2329e-01, 8.2216e-01, 8.1959e-01,\n",
       "             8.1889e-01, 8.0920e-01, 7.8950e-01, 7.8103e-01, 7.3829e-01, 7.3735e-01,\n",
       "             7.2703e-01, 7.0247e-01, 6.9002e-01, 5.9925e-01, 5.0087e-01, 4.4741e-01,\n",
       "             4.4641e-01, 4.3707e-01, 4.2658e-01, 3.8659e-01, 3.8251e-01, 3.4542e-01,\n",
       "             3.4488e-01, 3.1040e-01, 2.8407e-01, 2.1414e-01, 1.9727e-01, 1.9181e-01,\n",
       "             1.8754e-01, 1.8480e-01, 1.7794e-01, 1.7297e-01, 1.6540e-01, 1.6465e-01,\n",
       "             1.3688e-01, 1.3023e-01, 1.2266e-01, 1.2144e-01, 1.0831e-01, 1.0829e-01,\n",
       "             1.0066e-01, 1.0002e-01, 9.7849e-02, 9.1787e-02, 8.7234e-02, 8.4198e-02,\n",
       "             8.1685e-02, 7.8333e-02, 6.9576e-02, 6.7585e-02, 6.3788e-02, 6.0175e-02,\n",
       "             5.4506e-02, 5.4072e-02, 5.3733e-02, 5.3046e-02, 5.0182e-02, 5.0017e-02,\n",
       "             4.4648e-02, 4.2984e-02, 4.2268e-02, 3.8757e-02, 3.8554e-02, 3.4950e-02,\n",
       "             3.3015e-02, 3.2502e-02, 2.4192e-02, 2.3039e-02, 2.1245e-02, 1.7077e-02,\n",
       "             1.6549e-02, 1.3021e-02, 1.2969e-02, 1.2707e-02, 1.2696e-02, 1.2547e-02,\n",
       "             1.2530e-02, 1.2147e-02, 1.1164e-02, 9.3260e-03, 8.7908e-03, 8.5821e-03,\n",
       "             8.3293e-03, 8.2250e-03, 7.9162e-03, 6.7349e-03, 6.5002e-03, 6.4062e-03,\n",
       "             6.2558e-03, 5.7851e-03, 4.3222e-03, 3.9839e-03, 3.9476e-03, 3.7782e-03,\n",
       "             3.6185e-03, 3.4812e-03, 3.4742e-03, 3.4561e-03, 3.3989e-03, 3.3915e-03,\n",
       "             3.0189e-03, 2.7354e-03, 2.7329e-03, 2.7255e-03, 2.6855e-03, 2.3266e-03,\n",
       "             2.2664e-03, 2.1492e-03, 2.1126e-03, 2.0983e-03, 2.0908e-03, 2.0527e-03,\n",
       "             2.0354e-03, 1.9300e-03, 1.7097e-03, 1.5319e-03, 1.4727e-03, 1.4690e-03,\n",
       "             1.2069e-03, 1.1002e-03, 1.0028e-03, 8.2583e-04, 8.0942e-04, 8.0139e-04,\n",
       "             7.6732e-04, 7.5439e-04, 7.0459e-04, 6.3387e-04, 6.2621e-04, 6.1586e-04,\n",
       "             5.9989e-04, 5.9955e-04, 5.6116e-04, 5.5396e-04, 5.4854e-04, 5.4584e-04,\n",
       "             5.2289e-04, 5.1343e-04, 4.9699e-04, 4.5865e-04, 4.1337e-04, 4.0783e-04,\n",
       "             3.9763e-04, 3.6771e-04, 3.4736e-04, 3.4406e-04, 3.2177e-04, 2.9119e-04,\n",
       "             2.5550e-04, 2.4847e-04, 2.2670e-04, 1.9610e-04, 1.8402e-04, 1.7418e-04,\n",
       "             1.5390e-04, 1.2928e-04, 1.2743e-04, 1.2039e-04, 1.1517e-04, 1.0461e-04,\n",
       "             1.0265e-04, 9.3433e-05, 7.6179e-05, 7.5775e-05, 7.2162e-05, 6.8055e-05,\n",
       "             6.6720e-05, 6.4426e-05, 6.3914e-05, 6.2899e-05, 6.1659e-05, 5.9742e-05,\n",
       "             5.7830e-05, 5.7666e-05, 5.5740e-05, 5.4529e-05, 5.4078e-05, 5.3887e-05,\n",
       "             5.1506e-05, 5.0589e-05, 5.0369e-05, 4.9422e-05, 4.5250e-05, 4.4499e-05,\n",
       "             4.3885e-05, 4.3575e-05, 4.2608e-05, 4.0517e-05, 3.6961e-05, 3.6186e-05,\n",
       "             3.5464e-05, 3.5433e-05, 2.7854e-05, 2.7726e-05, 2.6156e-05, 2.5685e-05,\n",
       "             2.4607e-05, 2.3508e-05, 2.1863e-05, 2.1697e-05, 2.1227e-05, 2.0769e-05,\n",
       "             2.0514e-05, 1.9925e-05, 1.8772e-05, 1.8562e-05, 1.7184e-05, 1.6708e-05,\n",
       "             1.6334e-05, 1.5941e-05, 1.5543e-05, 1.3510e-05, 1.3453e-05, 1.2961e-05,\n",
       "             1.1690e-05, 1.1280e-05, 1.0545e-05, 9.4593e-06, 8.2024e-06, 8.1712e-06,\n",
       "             7.6349e-06, 7.1514e-06, 6.6396e-06, 6.2620e-06, 5.2105e-06, 5.1551e-06,\n",
       "             5.1451e-06, 5.0419e-06, 4.6538e-06, 4.3477e-06, 4.2924e-06, 4.0031e-06,\n",
       "             3.5308e-06, 3.4885e-06, 3.3502e-06, 3.2549e-06, 3.2181e-06, 2.9062e-06,\n",
       "             2.4250e-06, 2.4191e-06, 2.3987e-06, 2.3335e-06, 2.1850e-06, 2.1820e-06,\n",
       "             2.0395e-06, 1.9305e-06, 1.8508e-06, 1.7212e-06, 1.6770e-06, 1.5436e-06,\n",
       "             1.5289e-06, 1.4532e-06, 1.3192e-06, 1.0909e-06, 1.0740e-06, 9.4223e-07,\n",
       "             8.2203e-07, 8.0272e-07, 7.0777e-07, 6.7663e-07, 6.5870e-07, 5.9748e-07,\n",
       "             4.3699e-07, 4.3565e-07, 4.2319e-07, 4.1971e-07, 3.7315e-07, 3.7075e-07,\n",
       "             3.6501e-07, 3.0923e-07, 2.9375e-07, 2.7710e-07, 2.5875e-07, 2.3380e-07,\n",
       "             2.0817e-07, 1.8307e-07, 1.4645e-07, 1.2867e-07, 1.0938e-07, 1.0104e-07,\n",
       "             7.6695e-08, 5.7352e-08, 3.5388e-08, 3.4265e-08, 3.2773e-08, 3.1812e-08,\n",
       "             2.5705e-08, 2.4316e-08, 2.0855e-08, 1.8554e-08, 1.5984e-08, 1.5111e-08,\n",
       "             1.2905e-08, 8.5651e-09, 7.9152e-09, 6.1324e-09, 6.0513e-09, 5.4353e-09,\n",
       "             2.3807e-09, 1.4317e-09, 9.2194e-10, 9.2015e-10, 5.7000e-10, 4.7494e-11,\n",
       "             7.3970e-12, 3.0041e-12])}},\n",
       "   {'fpr': np.float64(0.10526315789473684),\n",
       "    'tpr': np.float64(0.9919816723940436),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0066, 0.0066, 0.0066, 0.0066, 0.0099,\n",
       "             0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
       "             0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0132, 0.0164,\n",
       "             0.0164, 0.0164, 0.0164, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197,\n",
       "             0.0197, 0.0197, 0.0197, 0.0197, 0.0230, 0.0230, 0.0230, 0.0263, 0.0296,\n",
       "             0.0296, 0.0329, 0.0329, 0.0329, 0.0329, 0.0329, 0.0362, 0.0362, 0.0362,\n",
       "             0.0395, 0.0428, 0.0461, 0.0493, 0.0493, 0.0493, 0.0526, 0.0526, 0.0559,\n",
       "             0.0592, 0.0625, 0.0658, 0.0691, 0.0724, 0.0757, 0.0789, 0.0822, 0.0855,\n",
       "             0.0855, 0.0855, 0.0855, 0.0888, 0.0888, 0.0921, 0.0954, 0.0954, 0.0987,\n",
       "             0.1020, 0.1053, 0.1053, 0.1053, 0.1086, 0.1118, 0.1151, 0.1151, 0.1184,\n",
       "             0.1217, 0.1250, 0.1283, 0.1283, 0.1316, 0.1316, 0.1349, 0.1382, 0.1414,\n",
       "             0.1447, 0.1480, 0.1513, 0.1546, 0.1546, 0.1579, 0.1612, 0.1645, 0.1678,\n",
       "             0.1711, 0.1743, 0.1776, 0.1809, 0.1842, 0.1875, 0.1908, 0.1941, 0.1974,\n",
       "             0.1974, 0.2007, 0.2039, 0.2072, 0.2105, 0.2138, 0.2171, 0.2204, 0.2237,\n",
       "             0.2270, 0.2303, 0.2336, 0.2368, 0.2401, 0.2434, 0.2467, 0.2467, 0.2500,\n",
       "             0.2533, 0.2566, 0.2566, 0.2599, 0.2632, 0.2664, 0.2697, 0.2730, 0.2763,\n",
       "             0.2796, 0.2829, 0.2862, 0.2895, 0.2928, 0.2961, 0.2993, 0.3026, 0.3059,\n",
       "             0.3092, 0.3125, 0.3158, 0.3191, 0.3224, 0.3257, 0.3289, 0.3322, 0.3355,\n",
       "             0.3388, 0.3421, 0.3454, 0.3487, 0.3520, 0.3553, 0.3586, 0.3618, 0.3651,\n",
       "             0.3684, 0.3717, 0.3750, 0.3783, 0.3816, 0.3849, 0.3882, 0.3914, 0.3947,\n",
       "             0.3980, 0.4013, 0.4046, 0.4079, 0.4112, 0.4145, 0.4178, 0.4211, 0.4243,\n",
       "             0.4276, 0.4309, 0.4342, 0.4375, 0.4408, 0.4441, 0.4474, 0.4507, 0.4539,\n",
       "             0.4572, 0.4605, 0.4638, 0.4671, 0.4704, 0.4737, 0.4770, 0.4803, 0.4836,\n",
       "             0.4868, 0.4901, 0.4934, 0.4967, 0.5000, 0.5033, 0.5066, 0.5099, 0.5132,\n",
       "             0.5164, 0.5197, 0.5230, 0.5263, 0.5296, 0.5329, 0.5362, 0.5395, 0.5428,\n",
       "             0.5461, 0.5493, 0.5526, 0.5559, 0.5592, 0.5625, 0.5658, 0.5691, 0.5724,\n",
       "             0.5757, 0.5789, 0.5822, 0.5855, 0.5888, 0.5921, 0.5954, 0.5987, 0.6020,\n",
       "             0.6053, 0.6086, 0.6118, 0.6151, 0.6184, 0.6217, 0.6250, 0.6283, 0.6316,\n",
       "             0.6349, 0.6382, 0.6414, 0.6447, 0.6480, 0.6513, 0.6546, 0.6579, 0.6612,\n",
       "             0.6645, 0.6678, 0.6711, 0.6743, 0.6776, 0.6809, 0.6842, 0.6875, 0.6908,\n",
       "             0.6941, 0.6974, 0.7007, 0.7039, 0.7072, 0.7105, 0.7138, 0.7171, 0.7204,\n",
       "             0.7237, 0.7270, 0.7303, 0.7336, 0.7368, 0.7401, 0.7434, 0.7467, 0.7500,\n",
       "             0.7533, 0.7566, 0.7599, 0.7632, 0.7664, 0.7697, 0.7730, 0.7763, 0.7796,\n",
       "             0.7829, 0.7862, 0.7895, 0.7928, 0.7961, 0.7993, 0.8026, 0.8059, 0.8092,\n",
       "             0.8125, 0.8158, 0.8191, 0.8224, 0.8257, 0.8289, 0.8322, 0.8355, 0.8388,\n",
       "             0.8421, 0.8454, 0.8487, 0.8520, 0.8553, 0.8586, 0.8618, 0.8651, 0.8684,\n",
       "             0.8717, 0.8750, 0.8783, 0.8816, 0.8849, 0.8882, 0.8914, 0.8947, 0.8980,\n",
       "             0.9013, 0.9046, 0.9079, 0.9112, 0.9145, 0.9178, 0.9211, 0.9243, 0.9276,\n",
       "             0.9309, 0.9342, 0.9375, 0.9408, 0.9441, 0.9474, 0.9507, 0.9539, 0.9572,\n",
       "             0.9605, 0.9638, 0.9671, 0.9704, 0.9737, 0.9770, 0.9803, 0.9836, 0.9868,\n",
       "             0.9901, 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.2497, 0.3711, 0.4101, 0.4502, 0.4777, 0.4983, 0.5155, 0.5292,\n",
       "             0.5407, 0.5487, 0.5578, 0.5682, 0.5808, 0.5899, 0.5968, 0.6002, 0.6025,\n",
       "             0.6071, 0.6140, 0.6197, 0.6231, 0.6312, 0.6403, 0.6426, 0.6460, 0.6483,\n",
       "             0.6495, 0.6529, 0.6564, 0.6598, 0.6632, 0.6701, 0.6747, 0.6781, 0.6804,\n",
       "             0.6816, 0.6827, 0.6838, 0.6873, 0.6907, 0.6942, 0.6964, 0.6987, 0.6999,\n",
       "             0.7022, 0.7068, 0.7102, 0.7113, 0.7136, 0.7148, 0.7205, 0.7216, 0.7228,\n",
       "             0.7239, 0.7251, 0.7262, 0.7274, 0.7285, 0.7297, 0.7320, 0.7365, 0.7377,\n",
       "             0.7400, 0.7411, 0.7423, 0.7434, 0.7446, 0.7457, 0.7491, 0.7514, 0.7526,\n",
       "             0.7537, 0.7560, 0.7572, 0.7583, 0.7595, 0.7606, 0.7617, 0.7629, 0.7640,\n",
       "             0.7652, 0.7663, 0.7675, 0.7686, 0.7698, 0.7709, 0.7721, 0.7743, 0.7755,\n",
       "             0.7766, 0.7789, 0.7801, 0.7812, 0.7824, 0.7835, 0.7847, 0.7881, 0.7892,\n",
       "             0.7904, 0.7915, 0.7915, 0.7927, 0.7938, 0.7961, 0.7973, 0.7984, 0.7995,\n",
       "             0.8007, 0.8018, 0.8030, 0.8041, 0.8053, 0.8064, 0.8076, 0.8087, 0.8099,\n",
       "             0.8121, 0.8133, 0.8144, 0.8156, 0.8179, 0.8190, 0.8202, 0.8213, 0.8225,\n",
       "             0.8236, 0.8247, 0.8259, 0.8270, 0.8282, 0.8305, 0.8316, 0.8328, 0.8339,\n",
       "             0.8351, 0.8362, 0.8373, 0.8396, 0.8408, 0.8419, 0.8431, 0.8442, 0.8454,\n",
       "             0.8465, 0.8477, 0.8488, 0.8499, 0.8511, 0.8522, 0.8534, 0.8557, 0.8568,\n",
       "             0.8580, 0.8591, 0.8614, 0.8625, 0.8637, 0.8648, 0.8660, 0.8671, 0.8683,\n",
       "             0.8694, 0.8706, 0.8717, 0.8729, 0.8740, 0.8751, 0.8763, 0.8774, 0.8786,\n",
       "             0.8797, 0.8809, 0.8820, 0.8832, 0.8843, 0.8855, 0.8866, 0.8877, 0.8889,\n",
       "             0.8900, 0.8912, 0.8923, 0.8935, 0.8946, 0.8958, 0.8969, 0.8981, 0.8992,\n",
       "             0.9003, 0.9015, 0.9026, 0.9038, 0.9049, 0.9061, 0.9072, 0.9084, 0.9095,\n",
       "             0.9107, 0.9118, 0.9129, 0.9141, 0.9152, 0.9164, 0.9175, 0.9187, 0.9198,\n",
       "             0.9210, 0.9221, 0.9233, 0.9244, 0.9255, 0.9267, 0.9278, 0.9290, 0.9301,\n",
       "             0.9313, 0.9324, 0.9336, 0.9347, 0.9347, 0.9359, 0.9370, 0.9381, 0.9381,\n",
       "             0.9393, 0.9404, 0.9416, 0.9427, 0.9439, 0.9450, 0.9462, 0.9473, 0.9485,\n",
       "             0.9496, 0.9507, 0.9519, 0.9530, 0.9542, 0.9553, 0.9565, 0.9565, 0.9565,\n",
       "             0.9576, 0.9588, 0.9599, 0.9599, 0.9611, 0.9622, 0.9633, 0.9645, 0.9656,\n",
       "             0.9668, 0.9679, 0.9691, 0.9702, 0.9702, 0.9714, 0.9725, 0.9725, 0.9725,\n",
       "             0.9737, 0.9737, 0.9748, 0.9759, 0.9771, 0.9782, 0.9782, 0.9794, 0.9805,\n",
       "             0.9805, 0.9805, 0.9805, 0.9805, 0.9817, 0.9828, 0.9828, 0.9840, 0.9840,\n",
       "             0.9840, 0.9840, 0.9840, 0.9840, 0.9840, 0.9840, 0.9840, 0.9840, 0.9840,\n",
       "             0.9851, 0.9863, 0.9874, 0.9874, 0.9885, 0.9885, 0.9885, 0.9897, 0.9897,\n",
       "             0.9897, 0.9897, 0.9908, 0.9920, 0.9920, 0.9920, 0.9920, 0.9931, 0.9931,\n",
       "             0.9931, 0.9931, 0.9931, 0.9943, 0.9943, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9990e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9987e-01, 9.9986e-01, 9.9985e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01,\n",
       "             9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9981e-01, 9.9981e-01,\n",
       "             9.9980e-01, 9.9980e-01, 9.9979e-01, 9.9978e-01, 9.9978e-01, 9.9977e-01,\n",
       "             9.9977e-01, 9.9977e-01, 9.9977e-01, 9.9976e-01, 9.9976e-01, 9.9974e-01,\n",
       "             9.9973e-01, 9.9972e-01, 9.9972e-01, 9.9966e-01, 9.9965e-01, 9.9962e-01,\n",
       "             9.9961e-01, 9.9961e-01, 9.9960e-01, 9.9957e-01, 9.9955e-01, 9.9955e-01,\n",
       "             9.9955e-01, 9.9952e-01, 9.9945e-01, 9.9942e-01, 9.9936e-01, 9.9935e-01,\n",
       "             9.9933e-01, 9.9930e-01, 9.9919e-01, 9.9906e-01, 9.9904e-01, 9.9896e-01,\n",
       "             9.9892e-01, 9.9889e-01, 9.9882e-01, 9.9877e-01, 9.9864e-01, 9.9862e-01,\n",
       "             9.9859e-01, 9.9851e-01, 9.9848e-01, 9.9831e-01, 9.9819e-01, 9.9814e-01,\n",
       "             9.9795e-01, 9.9791e-01, 9.9755e-01, 9.9746e-01, 9.9730e-01, 9.9719e-01,\n",
       "             9.9717e-01, 9.9707e-01, 9.9706e-01, 9.9655e-01, 9.9617e-01, 9.9599e-01,\n",
       "             9.9475e-01, 9.9459e-01, 9.9438e-01, 9.9388e-01, 9.9353e-01, 9.9346e-01,\n",
       "             9.9228e-01, 9.9142e-01, 9.9122e-01, 9.9045e-01, 9.8882e-01, 9.8600e-01,\n",
       "             9.8552e-01, 9.8285e-01, 9.8256e-01, 9.8189e-01, 9.8101e-01, 9.8017e-01,\n",
       "             9.7700e-01, 9.7368e-01, 9.6804e-01, 9.6353e-01, 9.6261e-01, 9.6092e-01,\n",
       "             9.5720e-01, 9.5233e-01, 9.4528e-01, 9.2755e-01, 9.1185e-01, 9.0641e-01,\n",
       "             9.0525e-01, 8.9906e-01, 8.3950e-01, 8.3220e-01, 8.3074e-01, 8.1675e-01,\n",
       "             8.1652e-01, 8.1080e-01, 7.9984e-01, 7.9771e-01, 7.5717e-01, 7.5503e-01,\n",
       "             7.3565e-01, 6.9259e-01, 6.8831e-01, 6.3797e-01, 6.3651e-01, 6.3087e-01,\n",
       "             5.1717e-01, 4.8424e-01, 4.5465e-01, 4.5158e-01, 4.4263e-01, 4.1548e-01,\n",
       "             3.2289e-01, 3.1626e-01, 3.0371e-01, 2.7897e-01, 2.6159e-01, 2.5678e-01,\n",
       "             1.6482e-01, 1.5742e-01, 1.2019e-01, 1.1969e-01, 1.1379e-01, 1.1202e-01,\n",
       "             9.2865e-02, 8.8185e-02, 8.6287e-02, 8.0619e-02, 7.7396e-02, 7.5477e-02,\n",
       "             7.0966e-02, 7.0065e-02, 6.7434e-02, 6.6578e-02, 6.3319e-02, 6.3145e-02,\n",
       "             5.6688e-02, 5.5543e-02, 5.3653e-02, 5.2371e-02, 5.1577e-02, 5.1318e-02,\n",
       "             5.1137e-02, 4.0743e-02, 3.8210e-02, 3.6985e-02, 3.3629e-02, 3.3186e-02,\n",
       "             3.2244e-02, 3.1828e-02, 3.0611e-02, 2.7223e-02, 2.3797e-02, 2.3328e-02,\n",
       "             2.1163e-02, 1.9164e-02, 1.7072e-02, 1.6697e-02, 1.6659e-02, 1.6522e-02,\n",
       "             1.4949e-02, 1.4488e-02, 9.0709e-03, 8.2386e-03, 8.0792e-03, 7.8448e-03,\n",
       "             6.3775e-03, 5.5260e-03, 5.4137e-03, 4.1751e-03, 4.0317e-03, 3.8583e-03,\n",
       "             3.7409e-03, 3.5942e-03, 3.3777e-03, 3.2559e-03, 3.0674e-03, 2.8009e-03,\n",
       "             2.6485e-03, 2.3649e-03, 2.1509e-03, 1.9388e-03, 1.8398e-03, 1.7598e-03,\n",
       "             1.6536e-03, 1.5923e-03, 1.5240e-03, 1.4706e-03, 1.4136e-03, 1.2905e-03,\n",
       "             1.2635e-03, 1.2501e-03, 1.2479e-03, 1.0189e-03, 9.9103e-04, 9.8113e-04,\n",
       "             7.7206e-04, 7.5995e-04, 7.4145e-04, 7.1789e-04, 6.9258e-04, 6.8750e-04,\n",
       "             6.7387e-04, 5.7518e-04, 5.6328e-04, 5.5004e-04, 5.2346e-04, 5.1098e-04,\n",
       "             5.1052e-04, 3.8693e-04, 3.3347e-04, 2.8470e-04, 2.5672e-04, 2.5597e-04,\n",
       "             2.4221e-04, 2.3132e-04, 2.2657e-04, 2.0620e-04, 1.9478e-04, 1.9254e-04,\n",
       "             1.8869e-04, 1.8088e-04, 1.3726e-04, 1.3359e-04, 1.1874e-04, 1.1857e-04,\n",
       "             1.0829e-04, 1.0563e-04, 8.5611e-05, 8.3532e-05, 8.1967e-05, 8.0567e-05,\n",
       "             7.1625e-05, 6.6461e-05, 6.3024e-05, 5.3616e-05, 5.2677e-05, 4.8883e-05,\n",
       "             4.2477e-05, 4.1771e-05, 4.1470e-05, 3.8923e-05, 3.7439e-05, 3.3015e-05,\n",
       "             3.2922e-05, 3.2206e-05, 2.8504e-05, 2.5858e-05, 2.5260e-05, 2.4763e-05,\n",
       "             2.2553e-05, 2.0970e-05, 1.7501e-05, 1.7489e-05, 1.5867e-05, 1.5182e-05,\n",
       "             1.5114e-05, 1.4411e-05, 1.4205e-05, 1.3722e-05, 1.3465e-05, 1.1323e-05,\n",
       "             1.1124e-05, 1.0391e-05, 9.8176e-06, 9.0025e-06, 8.9602e-06, 8.9176e-06,\n",
       "             8.8805e-06, 8.0085e-06, 7.9860e-06, 7.7319e-06, 6.4408e-06, 6.1480e-06,\n",
       "             5.3839e-06, 5.1910e-06, 4.3956e-06, 4.0332e-06, 3.9955e-06, 3.3405e-06,\n",
       "             3.2848e-06, 3.0437e-06, 2.8860e-06, 2.8415e-06, 2.5824e-06, 2.5091e-06,\n",
       "             2.4740e-06, 2.3874e-06, 2.3201e-06, 2.1793e-06, 2.0887e-06, 2.0623e-06,\n",
       "             1.7740e-06, 1.6775e-06, 1.6551e-06, 1.5460e-06, 1.5053e-06, 1.4424e-06,\n",
       "             1.3070e-06, 1.2564e-06, 1.2185e-06, 1.0556e-06, 8.5242e-07, 7.1337e-07,\n",
       "             6.3953e-07, 6.1347e-07, 5.9839e-07, 4.5876e-07, 4.2885e-07, 4.2113e-07,\n",
       "             4.1808e-07, 4.0314e-07, 3.7698e-07, 3.5898e-07, 3.5028e-07, 2.3492e-07,\n",
       "             2.3092e-07, 2.2953e-07, 2.2108e-07, 2.1330e-07, 2.1194e-07, 2.0788e-07,\n",
       "             1.8224e-07, 1.7703e-07, 1.7618e-07, 1.7375e-07, 1.6701e-07, 1.6320e-07,\n",
       "             1.5863e-07, 1.0521e-07, 1.0041e-07, 7.7449e-08, 6.1182e-08, 5.7356e-08,\n",
       "             5.7076e-08, 4.6657e-08, 4.2617e-08, 4.1327e-08, 3.6651e-08, 3.4400e-08,\n",
       "             3.3158e-08, 3.2577e-08, 3.0370e-08, 2.6239e-08, 2.4744e-08, 1.8493e-08,\n",
       "             1.6279e-08, 1.1791e-08, 8.9203e-09, 8.8781e-09, 7.5771e-09, 7.0958e-09,\n",
       "             6.7694e-09, 5.4109e-09, 5.0627e-09, 4.3012e-09, 3.6560e-09, 3.2895e-09,\n",
       "             2.9830e-09, 2.3060e-09, 1.7889e-09, 1.3455e-09, 1.1781e-09, 1.0263e-09,\n",
       "             8.7538e-10, 5.1188e-10, 4.7239e-10, 4.0932e-10, 3.8569e-10, 3.2266e-10,\n",
       "             1.6512e-10, 9.7684e-11, 8.3809e-11, 8.1484e-11, 7.8272e-11, 3.5224e-11,\n",
       "             2.3285e-11, 1.5775e-11, 1.1052e-11, 1.0411e-11, 6.8361e-12, 9.8251e-13,\n",
       "             9.5887e-13, 5.1288e-14, 1.7178e-14, 1.6255e-14])}},\n",
       "   {'fpr': np.float64(0.049342105263157895),\n",
       "    'tpr': np.float64(0.981672394043528),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0066, 0.0066, 0.0066,\n",
       "             0.0099, 0.0099, 0.0099, 0.0099, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132,\n",
       "             0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132,\n",
       "             0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0164, 0.0164, 0.0164,\n",
       "             0.0164, 0.0197, 0.0197, 0.0197, 0.0197, 0.0230, 0.0230, 0.0263, 0.0263,\n",
       "             0.0296, 0.0296, 0.0329, 0.0362, 0.0395, 0.0428, 0.0461, 0.0461, 0.0461,\n",
       "             0.0461, 0.0493, 0.0493, 0.0526, 0.0559, 0.0559, 0.0559, 0.0592, 0.0592,\n",
       "             0.0625, 0.0625, 0.0658, 0.0658, 0.0691, 0.0691, 0.0724, 0.0724, 0.0724,\n",
       "             0.0757, 0.0789, 0.0789, 0.0822, 0.0855, 0.0888, 0.0921, 0.0954, 0.0987,\n",
       "             0.1020, 0.1053, 0.1086, 0.1118, 0.1151, 0.1184, 0.1217, 0.1250, 0.1283,\n",
       "             0.1316, 0.1349, 0.1382, 0.1414, 0.1414, 0.1447, 0.1480, 0.1513, 0.1513,\n",
       "             0.1546, 0.1546, 0.1579, 0.1612, 0.1645, 0.1678, 0.1711, 0.1743, 0.1776,\n",
       "             0.1809, 0.1842, 0.1875, 0.1908, 0.1941, 0.1974, 0.2007, 0.2039, 0.2072,\n",
       "             0.2072, 0.2105, 0.2138, 0.2171, 0.2204, 0.2237, 0.2270, 0.2303, 0.2336,\n",
       "             0.2336, 0.2368, 0.2401, 0.2434, 0.2467, 0.2500, 0.2533, 0.2566, 0.2599,\n",
       "             0.2599, 0.2632, 0.2664, 0.2697, 0.2697, 0.2730, 0.2763, 0.2796, 0.2829,\n",
       "             0.2862, 0.2895, 0.2928, 0.2961, 0.2993, 0.3026, 0.3059, 0.3092, 0.3125,\n",
       "             0.3158, 0.3191, 0.3224, 0.3257, 0.3289, 0.3322, 0.3355, 0.3388, 0.3421,\n",
       "             0.3454, 0.3487, 0.3520, 0.3553, 0.3586, 0.3618, 0.3651, 0.3684, 0.3717,\n",
       "             0.3750, 0.3783, 0.3816, 0.3849, 0.3882, 0.3914, 0.3947, 0.3980, 0.4013,\n",
       "             0.4046, 0.4079, 0.4112, 0.4145, 0.4178, 0.4211, 0.4243, 0.4276, 0.4309,\n",
       "             0.4342, 0.4375, 0.4408, 0.4441, 0.4474, 0.4507, 0.4539, 0.4572, 0.4605,\n",
       "             0.4638, 0.4671, 0.4704, 0.4737, 0.4770, 0.4803, 0.4836, 0.4868, 0.4901,\n",
       "             0.4934, 0.4967, 0.5000, 0.5033, 0.5066, 0.5099, 0.5132, 0.5164, 0.5197,\n",
       "             0.5230, 0.5263, 0.5296, 0.5329, 0.5362, 0.5395, 0.5428, 0.5461, 0.5493,\n",
       "             0.5526, 0.5559, 0.5592, 0.5625, 0.5658, 0.5691, 0.5724, 0.5757, 0.5789,\n",
       "             0.5822, 0.5855, 0.5888, 0.5921, 0.5954, 0.5987, 0.6020, 0.6053, 0.6086,\n",
       "             0.6118, 0.6151, 0.6184, 0.6217, 0.6250, 0.6283, 0.6316, 0.6349, 0.6382,\n",
       "             0.6414, 0.6447, 0.6480, 0.6513, 0.6546, 0.6579, 0.6612, 0.6645, 0.6678,\n",
       "             0.6711, 0.6743, 0.6776, 0.6809, 0.6842, 0.6875, 0.6908, 0.6941, 0.6974,\n",
       "             0.7007, 0.7039, 0.7072, 0.7105, 0.7138, 0.7171, 0.7204, 0.7237, 0.7270,\n",
       "             0.7303, 0.7336, 0.7368, 0.7401, 0.7434, 0.7467, 0.7500, 0.7533, 0.7566,\n",
       "             0.7599, 0.7632, 0.7664, 0.7697, 0.7730, 0.7763, 0.7796, 0.7829, 0.7862,\n",
       "             0.7895, 0.7928, 0.7961, 0.7993, 0.8026, 0.8059, 0.8092, 0.8125, 0.8158,\n",
       "             0.8191, 0.8224, 0.8257, 0.8289, 0.8322, 0.8355, 0.8388, 0.8421, 0.8454,\n",
       "             0.8487, 0.8520, 0.8553, 0.8586, 0.8618, 0.8651, 0.8684, 0.8717, 0.8750,\n",
       "             0.8783, 0.8816, 0.8849, 0.8882, 0.8914, 0.8947, 0.8980, 0.9013, 0.9046,\n",
       "             0.9079, 0.9112, 0.9145, 0.9178, 0.9211, 0.9243, 0.9276, 0.9309, 0.9342,\n",
       "             0.9375, 0.9408, 0.9441, 0.9474, 0.9507, 0.9539, 0.9572, 0.9605, 0.9638,\n",
       "             0.9671, 0.9704, 0.9737, 0.9770, 0.9803, 0.9836, 0.9868, 0.9901, 0.9934,\n",
       "             0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.1077, 0.1856, 0.2199, 0.2417, 0.2623, 0.2806, 0.3070, 0.3265,\n",
       "             0.3322, 0.3414, 0.3436, 0.3608, 0.3666, 0.3746, 0.3803, 0.3872, 0.3895,\n",
       "             0.3918, 0.3986, 0.4009, 0.4032, 0.4101, 0.4147, 0.4181, 0.4204, 0.4238,\n",
       "             0.4318, 0.4341, 0.4422, 0.4456, 0.4490, 0.4513, 0.4548, 0.4570, 0.4616,\n",
       "             0.4639, 0.4662, 0.4685, 0.4731, 0.4742, 0.4788, 0.4800, 0.4822, 0.4834,\n",
       "             0.4857, 0.4868, 0.4880, 0.4914, 0.4937, 0.4983, 0.5006, 0.5040, 0.5063,\n",
       "             0.5074, 0.5097, 0.5109, 0.5132, 0.5189, 0.5200, 0.5212, 0.5246, 0.5269,\n",
       "             0.5292, 0.5304, 0.5338, 0.5372, 0.5395, 0.5407, 0.5418, 0.5475, 0.5487,\n",
       "             0.5510, 0.5533, 0.5544, 0.5556, 0.5590, 0.5601, 0.5624, 0.5636, 0.5647,\n",
       "             0.5659, 0.5682, 0.5693, 0.5704, 0.5716, 0.5727, 0.5750, 0.5762, 0.5785,\n",
       "             0.5796, 0.5808, 0.5830, 0.5842, 0.5853, 0.5865, 0.5876, 0.5888, 0.5911,\n",
       "             0.5922, 0.5945, 0.5956, 0.5979, 0.5991, 0.6002, 0.6025, 0.6037, 0.6060,\n",
       "             0.6071, 0.6082, 0.6094, 0.6105, 0.6117, 0.6128, 0.6140, 0.6151, 0.6174,\n",
       "             0.6186, 0.6197, 0.6208, 0.6231, 0.6254, 0.6266, 0.6277, 0.6300, 0.6312,\n",
       "             0.6323, 0.6334, 0.6357, 0.6369, 0.6380, 0.6392, 0.6403, 0.6415, 0.6426,\n",
       "             0.6438, 0.6449, 0.6460, 0.6472, 0.6483, 0.6495, 0.6506, 0.6518, 0.6529,\n",
       "             0.6541, 0.6552, 0.6564, 0.6575, 0.6586, 0.6598, 0.6609, 0.6621, 0.6632,\n",
       "             0.6644, 0.6655, 0.6667, 0.6678, 0.6690, 0.6701, 0.6712, 0.6724, 0.6747,\n",
       "             0.6758, 0.6770, 0.6781, 0.6793, 0.6804, 0.6816, 0.6827, 0.6838, 0.6850,\n",
       "             0.6861, 0.6873, 0.6884, 0.6896, 0.6907, 0.6919, 0.6930, 0.6942, 0.6953,\n",
       "             0.6964, 0.6976, 0.6987, 0.6999, 0.7010, 0.7022, 0.7033, 0.7045, 0.7068,\n",
       "             0.7079, 0.7090, 0.7102, 0.7113, 0.7125, 0.7136, 0.7148, 0.7159, 0.7171,\n",
       "             0.7182, 0.7194, 0.7205, 0.7216, 0.7228, 0.7239, 0.7251, 0.7262, 0.7274,\n",
       "             0.7285, 0.7297, 0.7308, 0.7320, 0.7331, 0.7342, 0.7354, 0.7365, 0.7377,\n",
       "             0.7388, 0.7400, 0.7411, 0.7423, 0.7434, 0.7446, 0.7457, 0.7468, 0.7480,\n",
       "             0.7491, 0.7503, 0.7514, 0.7526, 0.7537, 0.7549, 0.7560, 0.7572, 0.7583,\n",
       "             0.7595, 0.7606, 0.7617, 0.7629, 0.7640, 0.7652, 0.7663, 0.7675, 0.7686,\n",
       "             0.7698, 0.7709, 0.7721, 0.7732, 0.7743, 0.7755, 0.7766, 0.7778, 0.7789,\n",
       "             0.7801, 0.7812, 0.7824, 0.7835, 0.7847, 0.7858, 0.7869, 0.7881, 0.7892,\n",
       "             0.7904, 0.7915, 0.7927, 0.7938, 0.7950, 0.7961, 0.7973, 0.7984, 0.7995,\n",
       "             0.8007, 0.8018, 0.8030, 0.8041, 0.8053, 0.8064, 0.8076, 0.8087, 0.8099,\n",
       "             0.8110, 0.8121, 0.8133, 0.8144, 0.8156, 0.8167, 0.8179, 0.8190, 0.8202,\n",
       "             0.8213, 0.8225, 0.8236, 0.8247, 0.8259, 0.8270, 0.8282, 0.8293, 0.8305,\n",
       "             0.8316, 0.8328, 0.8339, 0.8351, 0.8362, 0.8373, 0.8385, 0.8396, 0.8408,\n",
       "             0.8419, 0.8431, 0.8442, 0.8454, 0.8465, 0.8477, 0.8488, 0.8499, 0.8499,\n",
       "             0.8511, 0.8522, 0.8534, 0.8545, 0.8557, 0.8568, 0.8580, 0.8591, 0.8603,\n",
       "             0.8614, 0.8625, 0.8637, 0.8648, 0.8660, 0.8671, 0.8683, 0.8694, 0.8706,\n",
       "             0.8717, 0.8729, 0.8740, 0.8751, 0.8763, 0.8774, 0.8786, 0.8797, 0.8809,\n",
       "             0.8820, 0.8832, 0.8843, 0.8855, 0.8866, 0.8877, 0.8889, 0.8900, 0.8912,\n",
       "             0.8923, 0.8935, 0.8946, 0.8958, 0.8969, 0.8981, 0.8992, 0.9003, 0.9015,\n",
       "             0.9026, 0.9038, 0.9049, 0.9061, 0.9072, 0.9084, 0.9095, 0.9107, 0.9118,\n",
       "             0.9129, 0.9141, 0.9152, 0.9164, 0.9175, 0.9187, 0.9198, 0.9210, 0.9221,\n",
       "             0.9233, 0.9244, 0.9255, 0.9267, 0.9278, 0.9290, 0.9301, 0.9313, 0.9324,\n",
       "             0.9336, 0.9347, 0.9359, 0.9370, 0.9381, 0.9393, 0.9393, 0.9404, 0.9416,\n",
       "             0.9416, 0.9427, 0.9439, 0.9450, 0.9450, 0.9462, 0.9473, 0.9485, 0.9496,\n",
       "             0.9507, 0.9519, 0.9530, 0.9542, 0.9553, 0.9565, 0.9576, 0.9588, 0.9599,\n",
       "             0.9611, 0.9622, 0.9633, 0.9645, 0.9656, 0.9668, 0.9668, 0.9679, 0.9691,\n",
       "             0.9702, 0.9702, 0.9714, 0.9725, 0.9737, 0.9737, 0.9748, 0.9748, 0.9759,\n",
       "             0.9759, 0.9771, 0.9771, 0.9771, 0.9771, 0.9771, 0.9771, 0.9782, 0.9794,\n",
       "             0.9805, 0.9805, 0.9817, 0.9817, 0.9817, 0.9828, 0.9840, 0.9840, 0.9851,\n",
       "             0.9851, 0.9863, 0.9863, 0.9874, 0.9874, 0.9885, 0.9885, 0.9897, 0.9908,\n",
       "             0.9908, 0.9908, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920,\n",
       "             0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920,\n",
       "             0.9920, 0.9920, 0.9920, 0.9920, 0.9931, 0.9931, 0.9931, 0.9931, 0.9943,\n",
       "             0.9943, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9985e-01,\n",
       "             9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9984e-01, 9.9984e-01,\n",
       "             9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9983e-01, 9.9983e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01,\n",
       "             9.9982e-01, 9.9982e-01, 9.9981e-01, 9.9981e-01, 9.9980e-01, 9.9980e-01,\n",
       "             9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9979e-01, 9.9979e-01, 9.9979e-01,\n",
       "             9.9979e-01, 9.9978e-01, 9.9978e-01, 9.9977e-01, 9.9977e-01, 9.9976e-01,\n",
       "             9.9976e-01, 9.9976e-01, 9.9973e-01, 9.9973e-01, 9.9973e-01, 9.9972e-01,\n",
       "             9.9972e-01, 9.9971e-01, 9.9970e-01, 9.9970e-01, 9.9969e-01, 9.9968e-01,\n",
       "             9.9968e-01, 9.9966e-01, 9.9966e-01, 9.9965e-01, 9.9964e-01, 9.9963e-01,\n",
       "             9.9962e-01, 9.9961e-01, 9.9960e-01, 9.9960e-01, 9.9960e-01, 9.9959e-01,\n",
       "             9.9959e-01, 9.9955e-01, 9.9955e-01, 9.9953e-01, 9.9951e-01, 9.9949e-01,\n",
       "             9.9948e-01, 9.9946e-01, 9.9945e-01, 9.9944e-01, 9.9942e-01, 9.9941e-01,\n",
       "             9.9940e-01, 9.9937e-01, 9.9934e-01, 9.9933e-01, 9.9932e-01, 9.9931e-01,\n",
       "             9.9931e-01, 9.9930e-01, 9.9930e-01, 9.9929e-01, 9.9929e-01, 9.9928e-01,\n",
       "             9.9927e-01, 9.9926e-01, 9.9925e-01, 9.9925e-01, 9.9924e-01, 9.9920e-01,\n",
       "             9.9919e-01, 9.9918e-01, 9.9916e-01, 9.9912e-01, 9.9906e-01, 9.9898e-01,\n",
       "             9.9891e-01, 9.9888e-01, 9.9886e-01, 9.9879e-01, 9.9877e-01, 9.9875e-01,\n",
       "             9.9869e-01, 9.9869e-01, 9.9860e-01, 9.9859e-01, 9.9859e-01, 9.9856e-01,\n",
       "             9.9855e-01, 9.9851e-01, 9.9843e-01, 9.9834e-01, 9.9833e-01, 9.9832e-01,\n",
       "             9.9830e-01, 9.9825e-01, 9.9818e-01, 9.9814e-01, 9.9813e-01, 9.9813e-01,\n",
       "             9.9811e-01, 9.9806e-01, 9.9802e-01, 9.9774e-01, 9.9720e-01, 9.9709e-01,\n",
       "             9.9690e-01, 9.9687e-01, 9.9670e-01, 9.9662e-01, 9.9653e-01, 9.9618e-01,\n",
       "             9.9597e-01, 9.9574e-01, 9.9572e-01, 9.9563e-01, 9.9528e-01, 9.9507e-01,\n",
       "             9.9493e-01, 9.9478e-01, 9.9439e-01, 9.9363e-01, 9.9362e-01, 9.9340e-01,\n",
       "             9.9287e-01, 9.9275e-01, 9.9268e-01, 9.9206e-01, 9.9200e-01, 9.9154e-01,\n",
       "             9.9072e-01, 9.9044e-01, 9.8752e-01, 9.8705e-01, 9.8664e-01, 9.8510e-01,\n",
       "             9.8140e-01, 9.8088e-01, 9.8084e-01, 9.7988e-01, 9.7820e-01, 9.7766e-01,\n",
       "             9.7528e-01, 9.7121e-01, 9.7025e-01, 9.6982e-01, 9.6899e-01, 9.6866e-01,\n",
       "             9.6717e-01, 9.6247e-01, 9.5439e-01, 9.5298e-01, 9.5221e-01, 9.4905e-01,\n",
       "             9.4518e-01, 9.3821e-01, 9.2837e-01, 9.2810e-01, 9.0525e-01, 8.8398e-01,\n",
       "             8.8369e-01, 8.7534e-01, 8.7155e-01, 8.6867e-01, 8.6481e-01, 8.6463e-01,\n",
       "             8.5655e-01, 8.5206e-01, 8.3221e-01, 8.2422e-01, 8.0415e-01, 7.9699e-01,\n",
       "             7.6636e-01, 7.6464e-01, 7.4188e-01, 7.3786e-01, 7.1352e-01, 7.0603e-01,\n",
       "             6.6563e-01, 6.6370e-01, 6.4747e-01, 6.0317e-01, 6.0216e-01, 5.0151e-01,\n",
       "             4.6140e-01, 3.8589e-01, 3.6710e-01, 3.5735e-01, 3.2599e-01, 3.2330e-01,\n",
       "             3.1150e-01, 2.7950e-01, 2.6481e-01, 2.2524e-01, 2.1402e-01, 2.1233e-01,\n",
       "             1.9197e-01, 1.7803e-01, 1.7642e-01, 1.0791e-01, 1.0719e-01, 1.0712e-01,\n",
       "             1.0610e-01, 1.0258e-01, 8.3002e-02, 7.6448e-02, 6.9508e-02, 5.4249e-02,\n",
       "             4.5557e-02, 4.0340e-02, 3.7628e-02, 3.7401e-02, 2.8668e-02, 2.3868e-02,\n",
       "             2.3317e-02, 2.0493e-02, 1.8973e-02, 1.6644e-02, 1.1236e-02, 1.0455e-02,\n",
       "             8.6985e-03, 8.4549e-03, 7.5070e-03, 6.6889e-03, 5.9801e-03, 5.2941e-03,\n",
       "             4.8270e-03, 4.7555e-03, 4.4074e-03, 4.2275e-03, 4.2018e-03, 3.9321e-03,\n",
       "             3.8443e-03, 3.5746e-03, 3.5504e-03, 2.7064e-03, 2.3896e-03, 2.2051e-03,\n",
       "             1.9132e-03, 1.8103e-03, 1.3004e-03, 1.0812e-03, 1.0190e-03, 9.0102e-04,\n",
       "             7.9684e-04, 7.6610e-04, 6.6773e-04, 6.6279e-04, 5.9287e-04, 5.5542e-04,\n",
       "             5.1379e-04, 4.9782e-04, 4.5318e-04, 4.4945e-04, 4.2479e-04, 4.0313e-04,\n",
       "             3.0259e-04, 2.9518e-04, 2.9192e-04, 2.8600e-04, 2.6364e-04, 2.4559e-04,\n",
       "             2.1914e-04, 2.1604e-04, 2.0115e-04, 1.9420e-04, 1.6080e-04, 1.4650e-04,\n",
       "             1.3416e-04, 1.2986e-04, 9.2047e-05, 7.8536e-05, 6.4052e-05, 5.0863e-05,\n",
       "             4.7513e-05, 4.6049e-05, 3.8774e-05, 3.7749e-05, 3.6635e-05, 3.3727e-05,\n",
       "             2.7488e-05, 2.6769e-05, 2.6319e-05, 2.5770e-05, 2.2360e-05, 2.0696e-05,\n",
       "             1.9488e-05, 1.6409e-05, 1.4595e-05, 1.3269e-05, 1.3034e-05, 1.1069e-05,\n",
       "             8.6189e-06, 8.0111e-06, 7.7792e-06, 7.5838e-06, 7.3957e-06, 7.0149e-06,\n",
       "             6.7846e-06, 6.2461e-06, 6.2127e-06, 6.0534e-06, 5.9439e-06, 5.7609e-06,\n",
       "             5.4422e-06, 5.0328e-06, 5.0067e-06, 4.4186e-06, 4.4121e-06, 4.4102e-06,\n",
       "             4.2901e-06, 4.0472e-06, 3.8927e-06, 3.4570e-06, 3.4041e-06, 2.9949e-06,\n",
       "             2.9637e-06, 2.7276e-06, 2.6525e-06, 2.4433e-06, 2.1427e-06, 2.1258e-06,\n",
       "             2.1208e-06, 2.0026e-06, 1.6887e-06, 1.6251e-06, 1.5281e-06, 1.4530e-06,\n",
       "             1.2268e-06, 1.2180e-06, 1.0843e-06, 1.0841e-06, 9.4386e-07, 8.7102e-07,\n",
       "             8.5610e-07, 8.5566e-07, 8.3575e-07, 7.0523e-07, 6.7483e-07, 6.3803e-07,\n",
       "             6.2043e-07, 6.2034e-07, 5.3296e-07, 5.1005e-07, 5.0249e-07, 4.9057e-07,\n",
       "             4.1375e-07, 3.9659e-07, 3.8164e-07, 3.6717e-07, 3.2694e-07, 2.9255e-07,\n",
       "             2.8720e-07, 2.8140e-07, 2.0966e-07, 2.0957e-07, 1.9789e-07, 1.9477e-07,\n",
       "             1.8306e-07, 1.7435e-07, 1.6946e-07, 1.6678e-07, 1.6484e-07, 1.5485e-07,\n",
       "             1.4964e-07, 1.2582e-07, 1.1550e-07, 1.1383e-07, 1.0716e-07, 9.8929e-08,\n",
       "             8.2843e-08, 7.5974e-08, 7.1185e-08, 7.0672e-08, 6.9270e-08, 5.3432e-08,\n",
       "             5.1814e-08, 4.8543e-08, 4.8513e-08, 4.3989e-08, 4.2732e-08, 3.9492e-08,\n",
       "             3.7963e-08, 3.6951e-08, 3.0730e-08, 2.7589e-08, 2.6982e-08, 2.6253e-08,\n",
       "             2.4798e-08, 1.7557e-08, 1.7335e-08, 1.5875e-08, 1.5145e-08, 1.3645e-08,\n",
       "             1.3215e-08, 1.2218e-08, 1.1356e-08, 1.0182e-08, 7.3953e-09, 7.2848e-09,\n",
       "             7.2715e-09, 6.7532e-09, 6.6545e-09, 6.0561e-09, 5.9527e-09, 5.7739e-09,\n",
       "             4.8553e-09, 4.7879e-09, 2.9944e-09, 2.9934e-09, 2.7888e-09, 2.5106e-09,\n",
       "             2.3904e-09, 1.8635e-09, 1.6982e-09, 1.5383e-09, 1.5290e-09, 1.4046e-09,\n",
       "             1.1390e-09, 1.1239e-09, 1.0089e-09, 6.6397e-10, 5.2450e-10, 4.9098e-10,\n",
       "             4.2537e-10, 4.1661e-10, 3.7274e-10, 3.4807e-10, 3.2385e-10, 2.9861e-10,\n",
       "             2.9855e-10, 2.9087e-10, 2.3921e-10, 1.9887e-10, 1.9804e-10, 1.4786e-10,\n",
       "             1.4746e-10, 1.4709e-10, 1.2961e-10, 8.3088e-11, 7.7755e-11, 7.5289e-11,\n",
       "             5.8596e-11, 5.0007e-11, 4.5757e-11, 4.2918e-11, 4.1637e-11, 3.3148e-11,\n",
       "             2.9717e-11, 2.9503e-11, 2.1619e-11, 2.0539e-11, 1.8607e-11, 1.7061e-11,\n",
       "             1.4158e-11, 1.2694e-11, 8.9376e-12, 7.4927e-12, 5.7324e-12, 4.7303e-12,\n",
       "             4.3949e-12, 4.0012e-12, 3.9319e-12, 3.7803e-12, 2.6589e-12, 2.5035e-12,\n",
       "             2.1480e-12, 2.1030e-12, 1.7713e-12, 1.0771e-12, 7.6127e-13, 7.4178e-13,\n",
       "             7.0571e-13, 7.0514e-13, 3.3256e-13, 2.9313e-13, 9.8435e-14, 8.2988e-14,\n",
       "             7.4610e-14, 6.7413e-14, 6.1653e-14, 5.8183e-14, 2.8348e-14, 1.4037e-14,\n",
       "             8.9286e-16, 1.5281e-16, 1.2609e-16, 7.7686e-17, 1.8496e-17])}},\n",
       "   {'fpr': np.float64(0.03618421052631579),\n",
       "    'tpr': np.float64(0.9564719358533792),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0066, 0.0066,\n",
       "             0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066,\n",
       "             0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066,\n",
       "             0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0099, 0.0099, 0.0099,\n",
       "             0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
       "             0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
       "             0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
       "             0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
       "             0.0099, 0.0132, 0.0132, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164,\n",
       "             0.0164, 0.0164, 0.0197, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
       "             0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0263, 0.0263,\n",
       "             0.0263, 0.0263, 0.0263, 0.0296, 0.0296, 0.0296, 0.0296, 0.0296, 0.0296,\n",
       "             0.0296, 0.0296, 0.0296, 0.0296, 0.0296, 0.0296, 0.0296, 0.0296, 0.0296,\n",
       "             0.0296, 0.0296, 0.0296, 0.0296, 0.0296, 0.0329, 0.0329, 0.0362, 0.0362,\n",
       "             0.0362, 0.0362, 0.0362, 0.0362, 0.0362, 0.0362, 0.0362, 0.0362, 0.0362,\n",
       "             0.0362, 0.0362, 0.0395, 0.0428, 0.0428, 0.0461, 0.0461, 0.0461, 0.0461,\n",
       "             0.0461, 0.0461, 0.0493, 0.0493, 0.0493, 0.0526, 0.0559, 0.0592, 0.0625,\n",
       "             0.0625, 0.0625, 0.0658, 0.0658, 0.0658, 0.0658, 0.0658, 0.0658, 0.0691,\n",
       "             0.0724, 0.0757, 0.0789, 0.0822, 0.0855, 0.0855, 0.0855, 0.0888, 0.0888,\n",
       "             0.0921, 0.0954, 0.0987, 0.1020, 0.1020, 0.1053, 0.1086, 0.1118, 0.1151,\n",
       "             0.1151, 0.1184, 0.1217, 0.1250, 0.1283, 0.1316, 0.1349, 0.1382, 0.1414,\n",
       "             0.1447, 0.1480, 0.1513, 0.1513, 0.1546, 0.1546, 0.1579, 0.1612, 0.1645,\n",
       "             0.1678, 0.1711, 0.1743, 0.1776, 0.1776, 0.1809, 0.1842, 0.1875, 0.1908,\n",
       "             0.1941, 0.1974, 0.2007, 0.2039, 0.2072, 0.2105, 0.2138, 0.2171, 0.2204,\n",
       "             0.2237, 0.2270, 0.2303, 0.2336, 0.2368, 0.2401, 0.2434, 0.2467, 0.2500,\n",
       "             0.2533, 0.2566, 0.2599, 0.2632, 0.2664, 0.2697, 0.2730, 0.2763, 0.2796,\n",
       "             0.2829, 0.2829, 0.2862, 0.2895, 0.2928, 0.2961, 0.2993, 0.3026, 0.3059,\n",
       "             0.3092, 0.3125, 0.3158, 0.3191, 0.3224, 0.3257, 0.3257, 0.3289, 0.3322,\n",
       "             0.3355, 0.3388, 0.3421, 0.3454, 0.3487, 0.3520, 0.3553, 0.3586, 0.3618,\n",
       "             0.3651, 0.3684, 0.3717, 0.3750, 0.3783, 0.3816, 0.3849, 0.3882, 0.3914,\n",
       "             0.3947, 0.3980, 0.4013, 0.4046, 0.4079, 0.4112, 0.4145, 0.4178, 0.4211,\n",
       "             0.4243, 0.4276, 0.4309, 0.4342, 0.4375, 0.4408, 0.4441, 0.4474, 0.4507,\n",
       "             0.4539, 0.4572, 0.4605, 0.4605, 0.4638, 0.4671, 0.4704, 0.4737, 0.4770,\n",
       "             0.4803, 0.4836, 0.4868, 0.4901, 0.4934, 0.4967, 0.5000, 0.5033, 0.5066,\n",
       "             0.5099, 0.5132, 0.5164, 0.5197, 0.5230, 0.5263, 0.5296, 0.5329, 0.5362,\n",
       "             0.5395, 0.5428, 0.5461, 0.5493, 0.5526, 0.5559, 0.5592, 0.5625, 0.5658,\n",
       "             0.5691, 0.5724, 0.5757, 0.5789, 0.5822, 0.5855, 0.5888, 0.5921, 0.5954,\n",
       "             0.5987, 0.6020, 0.6053, 0.6086, 0.6118, 0.6151, 0.6184, 0.6217, 0.6250,\n",
       "             0.6283, 0.6316, 0.6349, 0.6382, 0.6414, 0.6447, 0.6480, 0.6513, 0.6546,\n",
       "             0.6579, 0.6612, 0.6645, 0.6678, 0.6711, 0.6743, 0.6776, 0.6809, 0.6842,\n",
       "             0.6875, 0.6908, 0.6941, 0.6974, 0.7007, 0.7039, 0.7072, 0.7105, 0.7138,\n",
       "             0.7171, 0.7204, 0.7237, 0.7270, 0.7303, 0.7336, 0.7368, 0.7401, 0.7434,\n",
       "             0.7467, 0.7500, 0.7533, 0.7566, 0.7599, 0.7632, 0.7664, 0.7697, 0.7730,\n",
       "             0.7763, 0.7796, 0.7829, 0.7862, 0.7895, 0.7928, 0.7961, 0.7993, 0.8026,\n",
       "             0.8059, 0.8092, 0.8125, 0.8158, 0.8191, 0.8224, 0.8257, 0.8289, 0.8322,\n",
       "             0.8355, 0.8388, 0.8421, 0.8454, 0.8487, 0.8520, 0.8553, 0.8586, 0.8618,\n",
       "             0.8651, 0.8684, 0.8717, 0.8750, 0.8783, 0.8816, 0.8849, 0.8882, 0.8914,\n",
       "             0.8947, 0.8980, 0.9013, 0.9046, 0.9079, 0.9112, 0.9145, 0.9178, 0.9211,\n",
       "             0.9243, 0.9276, 0.9309, 0.9342, 0.9375, 0.9408, 0.9441, 0.9474, 0.9507,\n",
       "             0.9539, 0.9572, 0.9605, 0.9638, 0.9671, 0.9704, 0.9737, 0.9770, 0.9803,\n",
       "             0.9836, 0.9868, 0.9901, 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.0309, 0.0527, 0.0836, 0.0905, 0.1008, 0.1157, 0.1260, 0.1317,\n",
       "             0.1397, 0.1466, 0.1535, 0.1615, 0.1707, 0.1741, 0.1775, 0.1833, 0.1844,\n",
       "             0.1879, 0.1947, 0.1970, 0.1993, 0.2005, 0.2039, 0.2085, 0.2119, 0.2176,\n",
       "             0.2199, 0.2211, 0.2245, 0.2257, 0.2291, 0.2348, 0.2371, 0.2383, 0.2394,\n",
       "             0.2440, 0.2463, 0.2486, 0.2543, 0.2577, 0.2612, 0.2623, 0.2646, 0.2658,\n",
       "             0.2669, 0.2692, 0.2715, 0.2738, 0.2772, 0.2795, 0.2841, 0.2864, 0.2887,\n",
       "             0.2921, 0.2955, 0.2990, 0.3013, 0.3036, 0.3058, 0.3081, 0.3093, 0.3127,\n",
       "             0.3162, 0.3173, 0.3184, 0.3196, 0.3230, 0.3253, 0.3265, 0.3276, 0.3288,\n",
       "             0.3299, 0.3310, 0.3322, 0.3333, 0.3345, 0.3368, 0.3391, 0.3414, 0.3448,\n",
       "             0.3459, 0.3471, 0.3505, 0.3517, 0.3540, 0.3562, 0.3597, 0.3608, 0.3631,\n",
       "             0.3654, 0.3666, 0.3677, 0.3688, 0.3700, 0.3711, 0.3723, 0.3746, 0.3757,\n",
       "             0.3780, 0.3814, 0.3826, 0.3849, 0.3860, 0.3883, 0.3895, 0.3906, 0.3918,\n",
       "             0.3929, 0.3952, 0.3975, 0.3986, 0.4009, 0.4021, 0.4032, 0.4044, 0.4055,\n",
       "             0.4066, 0.4078, 0.4101, 0.4112, 0.4124, 0.4158, 0.4170, 0.4181, 0.4192,\n",
       "             0.4204, 0.4215, 0.4227, 0.4238, 0.4250, 0.4261, 0.4273, 0.4284, 0.4296,\n",
       "             0.4307, 0.4318, 0.4330, 0.4353, 0.4376, 0.4387, 0.4399, 0.4410, 0.4422,\n",
       "             0.4433, 0.4444, 0.4456, 0.4467, 0.4479, 0.4490, 0.4502, 0.4525, 0.4536,\n",
       "             0.4548, 0.4559, 0.4582, 0.4593, 0.4605, 0.4616, 0.4628, 0.4639, 0.4651,\n",
       "             0.4662, 0.4674, 0.4685, 0.4696, 0.4708, 0.4719, 0.4731, 0.4742, 0.4754,\n",
       "             0.4765, 0.4777, 0.4788, 0.4811, 0.4822, 0.4834, 0.4845, 0.4857, 0.4868,\n",
       "             0.4880, 0.4903, 0.4914, 0.4926, 0.4937, 0.4948, 0.4960, 0.4971, 0.4983,\n",
       "             0.4994, 0.5006, 0.5017, 0.5029, 0.5040, 0.5052, 0.5063, 0.5074, 0.5086,\n",
       "             0.5097, 0.5109, 0.5120, 0.5132, 0.5155, 0.5166, 0.5178, 0.5200, 0.5212,\n",
       "             0.5223, 0.5235, 0.5246, 0.5258, 0.5269, 0.5281, 0.5292, 0.5315, 0.5326,\n",
       "             0.5349, 0.5372, 0.5384, 0.5395, 0.5407, 0.5418, 0.5464, 0.5475, 0.5487,\n",
       "             0.5510, 0.5521, 0.5533, 0.5544, 0.5556, 0.5567, 0.5578, 0.5590, 0.5601,\n",
       "             0.5613, 0.5636, 0.5647, 0.5659, 0.5670, 0.5682, 0.5693, 0.5716, 0.5727,\n",
       "             0.5739, 0.5750, 0.5762, 0.5773, 0.5785, 0.5796, 0.5808, 0.5819, 0.5830,\n",
       "             0.5842, 0.5853, 0.5865, 0.5876, 0.5888, 0.5899, 0.5911, 0.5934, 0.5945,\n",
       "             0.5956, 0.5968, 0.5979, 0.5991, 0.6002, 0.6014, 0.6025, 0.6037, 0.6048,\n",
       "             0.6060, 0.6071, 0.6082, 0.6094, 0.6105, 0.6117, 0.6128, 0.6140, 0.6151,\n",
       "             0.6163, 0.6174, 0.6186, 0.6197, 0.6208, 0.6220, 0.6231, 0.6243, 0.6254,\n",
       "             0.6266, 0.6277, 0.6289, 0.6300, 0.6312, 0.6323, 0.6334, 0.6346, 0.6357,\n",
       "             0.6369, 0.6380, 0.6392, 0.6403, 0.6415, 0.6426, 0.6438, 0.6449, 0.6460,\n",
       "             0.6472, 0.6483, 0.6495, 0.6506, 0.6518, 0.6529, 0.6541, 0.6552, 0.6564,\n",
       "             0.6575, 0.6586, 0.6598, 0.6609, 0.6621, 0.6632, 0.6644, 0.6655, 0.6667,\n",
       "             0.6678, 0.6690, 0.6701, 0.6712, 0.6724, 0.6735, 0.6747, 0.6758, 0.6770,\n",
       "             0.6781, 0.6793, 0.6804, 0.6816, 0.6827, 0.6838, 0.6850, 0.6861, 0.6873,\n",
       "             0.6884, 0.6896, 0.6907, 0.6919, 0.6942, 0.6953, 0.6964, 0.6976, 0.6987,\n",
       "             0.6999, 0.7010, 0.7022, 0.7033, 0.7056, 0.7068, 0.7079, 0.7090, 0.7102,\n",
       "             0.7113, 0.7125, 0.7136, 0.7148, 0.7159, 0.7171, 0.7182, 0.7194, 0.7205,\n",
       "             0.7216, 0.7228, 0.7239, 0.7251, 0.7262, 0.7274, 0.7285, 0.7297, 0.7308,\n",
       "             0.7320, 0.7331, 0.7342, 0.7354, 0.7365, 0.7377, 0.7388, 0.7400, 0.7411,\n",
       "             0.7423, 0.7446, 0.7457, 0.7468, 0.7480, 0.7491, 0.7503, 0.7514, 0.7526,\n",
       "             0.7537, 0.7549, 0.7560, 0.7572, 0.7583, 0.7595, 0.7606, 0.7617, 0.7629,\n",
       "             0.7640, 0.7652, 0.7663, 0.7675, 0.7686, 0.7698, 0.7709, 0.7721, 0.7732,\n",
       "             0.7743, 0.7766, 0.7778, 0.7789, 0.7801, 0.7812, 0.7824, 0.7835, 0.7847,\n",
       "             0.7858, 0.7869, 0.7881, 0.7892, 0.7904, 0.7915, 0.7927, 0.7938, 0.7950,\n",
       "             0.7961, 0.7973, 0.7984, 0.7995, 0.8007, 0.8018, 0.8030, 0.8041, 0.8053,\n",
       "             0.8064, 0.8076, 0.8087, 0.8099, 0.8110, 0.8121, 0.8133, 0.8144, 0.8156,\n",
       "             0.8167, 0.8179, 0.8190, 0.8202, 0.8202, 0.8213, 0.8225, 0.8236, 0.8247,\n",
       "             0.8259, 0.8270, 0.8282, 0.8293, 0.8305, 0.8316, 0.8328, 0.8328, 0.8339,\n",
       "             0.8351, 0.8362, 0.8373, 0.8385, 0.8396, 0.8408, 0.8419, 0.8431, 0.8442,\n",
       "             0.8454, 0.8465, 0.8477, 0.8488, 0.8499, 0.8511, 0.8522, 0.8534, 0.8545,\n",
       "             0.8557, 0.8568, 0.8580, 0.8591, 0.8603, 0.8614, 0.8614, 0.8625, 0.8637,\n",
       "             0.8648, 0.8660, 0.8671, 0.8683, 0.8694, 0.8706, 0.8717, 0.8729, 0.8740,\n",
       "             0.8751, 0.8763, 0.8774, 0.8786, 0.8797, 0.8809, 0.8820, 0.8832, 0.8843,\n",
       "             0.8855, 0.8866, 0.8877, 0.8889, 0.8900, 0.8912, 0.8923, 0.8935, 0.8946,\n",
       "             0.8958, 0.8969, 0.8981, 0.8992, 0.9003, 0.9015, 0.9026, 0.9038, 0.9049,\n",
       "             0.9061, 0.9061, 0.9072, 0.9072, 0.9084, 0.9095, 0.9107, 0.9118, 0.9129,\n",
       "             0.9141, 0.9152, 0.9152, 0.9152, 0.9164, 0.9175, 0.9187, 0.9198, 0.9210,\n",
       "             0.9221, 0.9233, 0.9244, 0.9255, 0.9267, 0.9278, 0.9290, 0.9290, 0.9301,\n",
       "             0.9313, 0.9324, 0.9336, 0.9336, 0.9347, 0.9359, 0.9370, 0.9381, 0.9393,\n",
       "             0.9404, 0.9416, 0.9427, 0.9439, 0.9450, 0.9462, 0.9473, 0.9485, 0.9496,\n",
       "             0.9507, 0.9519, 0.9530, 0.9542, 0.9553, 0.9553, 0.9565, 0.9565, 0.9576,\n",
       "             0.9588, 0.9599, 0.9611, 0.9622, 0.9633, 0.9645, 0.9656, 0.9668, 0.9679,\n",
       "             0.9691, 0.9702, 0.9702, 0.9702, 0.9714, 0.9714, 0.9725, 0.9737, 0.9748,\n",
       "             0.9759, 0.9771, 0.9771, 0.9782, 0.9794, 0.9794, 0.9794, 0.9794, 0.9794,\n",
       "             0.9805, 0.9817, 0.9817, 0.9828, 0.9840, 0.9851, 0.9863, 0.9874, 0.9874,\n",
       "             0.9874, 0.9874, 0.9874, 0.9874, 0.9874, 0.9885, 0.9897, 0.9897, 0.9908,\n",
       "             0.9908, 0.9908, 0.9908, 0.9908, 0.9920, 0.9920, 0.9920, 0.9920, 0.9920,\n",
       "             0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931,\n",
       "             0.9931, 0.9931, 0.9931, 0.9943, 0.9943, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9986e-01, 9.9986e-01,\n",
       "             9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9985e-01,\n",
       "             9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9984e-01,\n",
       "             9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9984e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9983e-01, 9.9983e-01, 9.9983e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01,\n",
       "             9.9981e-01, 9.9981e-01, 9.9980e-01, 9.9980e-01, 9.9980e-01, 9.9980e-01,\n",
       "             9.9980e-01, 9.9979e-01, 9.9979e-01, 9.9979e-01, 9.9979e-01, 9.9979e-01,\n",
       "             9.9979e-01, 9.9978e-01, 9.9978e-01, 9.9978e-01, 9.9978e-01, 9.9978e-01,\n",
       "             9.9977e-01, 9.9977e-01, 9.9976e-01, 9.9976e-01, 9.9976e-01, 9.9975e-01,\n",
       "             9.9975e-01, 9.9975e-01, 9.9974e-01, 9.9974e-01, 9.9973e-01, 9.9973e-01,\n",
       "             9.9973e-01, 9.9972e-01, 9.9972e-01, 9.9972e-01, 9.9972e-01, 9.9972e-01,\n",
       "             9.9972e-01, 9.9971e-01, 9.9971e-01, 9.9970e-01, 9.9970e-01, 9.9970e-01,\n",
       "             9.9969e-01, 9.9969e-01, 9.9969e-01, 9.9968e-01, 9.9968e-01, 9.9968e-01,\n",
       "             9.9967e-01, 9.9967e-01, 9.9966e-01, 9.9965e-01, 9.9964e-01, 9.9964e-01,\n",
       "             9.9964e-01, 9.9962e-01, 9.9961e-01, 9.9961e-01, 9.9960e-01, 9.9959e-01,\n",
       "             9.9959e-01, 9.9958e-01, 9.9958e-01, 9.9957e-01, 9.9957e-01, 9.9957e-01,\n",
       "             9.9956e-01, 9.9956e-01, 9.9955e-01, 9.9955e-01, 9.9954e-01, 9.9953e-01,\n",
       "             9.9952e-01, 9.9951e-01, 9.9951e-01, 9.9950e-01, 9.9949e-01, 9.9948e-01,\n",
       "             9.9946e-01, 9.9946e-01, 9.9946e-01, 9.9945e-01, 9.9944e-01, 9.9941e-01,\n",
       "             9.9940e-01, 9.9939e-01, 9.9939e-01, 9.9939e-01, 9.9931e-01, 9.9931e-01,\n",
       "             9.9928e-01, 9.9928e-01, 9.9927e-01, 9.9927e-01, 9.9926e-01, 9.9925e-01,\n",
       "             9.9925e-01, 9.9925e-01, 9.9925e-01, 9.9924e-01, 9.9924e-01, 9.9922e-01,\n",
       "             9.9922e-01, 9.9919e-01, 9.9918e-01, 9.9918e-01, 9.9918e-01, 9.9914e-01,\n",
       "             9.9913e-01, 9.9911e-01, 9.9907e-01, 9.9901e-01, 9.9901e-01, 9.9897e-01,\n",
       "             9.9896e-01, 9.9896e-01, 9.9895e-01, 9.9893e-01, 9.9891e-01, 9.9888e-01,\n",
       "             9.9887e-01, 9.9879e-01, 9.9876e-01, 9.9871e-01, 9.9866e-01, 9.9862e-01,\n",
       "             9.9861e-01, 9.9861e-01, 9.9859e-01, 9.9857e-01, 9.9857e-01, 9.9854e-01,\n",
       "             9.9854e-01, 9.9849e-01, 9.9842e-01, 9.9841e-01, 9.9837e-01, 9.9830e-01,\n",
       "             9.9824e-01, 9.9818e-01, 9.9818e-01, 9.9815e-01, 9.9815e-01, 9.9810e-01,\n",
       "             9.9803e-01, 9.9802e-01, 9.9797e-01, 9.9793e-01, 9.9792e-01, 9.9792e-01,\n",
       "             9.9784e-01, 9.9783e-01, 9.9782e-01, 9.9776e-01, 9.9771e-01, 9.9754e-01,\n",
       "             9.9748e-01, 9.9745e-01, 9.9743e-01, 9.9737e-01, 9.9727e-01, 9.9721e-01,\n",
       "             9.9718e-01, 9.9715e-01, 9.9712e-01, 9.9708e-01, 9.9703e-01, 9.9683e-01,\n",
       "             9.9682e-01, 9.9680e-01, 9.9680e-01, 9.9677e-01, 9.9673e-01, 9.9657e-01,\n",
       "             9.9654e-01, 9.9647e-01, 9.9604e-01, 9.9602e-01, 9.9596e-01, 9.9594e-01,\n",
       "             9.9590e-01, 9.9570e-01, 9.9546e-01, 9.9534e-01, 9.9516e-01, 9.9515e-01,\n",
       "             9.9507e-01, 9.9506e-01, 9.9505e-01, 9.9503e-01, 9.9491e-01, 9.9474e-01,\n",
       "             9.9466e-01, 9.9459e-01, 9.9436e-01, 9.9429e-01, 9.9426e-01, 9.9416e-01,\n",
       "             9.9371e-01, 9.9357e-01, 9.9310e-01, 9.9299e-01, 9.9294e-01, 9.9293e-01,\n",
       "             9.9230e-01, 9.9226e-01, 9.9203e-01, 9.9146e-01, 9.9106e-01, 9.9080e-01,\n",
       "             9.9006e-01, 9.9005e-01, 9.8983e-01, 9.8919e-01, 9.8882e-01, 9.8854e-01,\n",
       "             9.8828e-01, 9.8820e-01, 9.8786e-01, 9.8766e-01, 9.8754e-01, 9.8676e-01,\n",
       "             9.8589e-01, 9.8561e-01, 9.8544e-01, 9.8335e-01, 9.8312e-01, 9.7876e-01,\n",
       "             9.7830e-01, 9.7728e-01, 9.7673e-01, 9.7665e-01, 9.7621e-01, 9.7610e-01,\n",
       "             9.7610e-01, 9.7598e-01, 9.7163e-01, 9.6974e-01, 9.6583e-01, 9.6431e-01,\n",
       "             9.6419e-01, 9.6193e-01, 9.5557e-01, 9.5480e-01, 9.5371e-01, 9.5308e-01,\n",
       "             9.4610e-01, 9.4387e-01, 9.4381e-01, 9.4007e-01, 9.3896e-01, 9.3383e-01,\n",
       "             9.3283e-01, 9.3229e-01, 9.2235e-01, 9.2164e-01, 9.1803e-01, 9.1489e-01,\n",
       "             9.1421e-01, 9.0872e-01, 9.0469e-01, 9.0322e-01, 9.0076e-01, 8.9617e-01,\n",
       "             8.8800e-01, 8.7857e-01, 8.7772e-01, 8.7355e-01, 8.7160e-01, 8.6294e-01,\n",
       "             8.6016e-01, 8.5858e-01, 8.5274e-01, 8.5089e-01, 8.4457e-01, 8.4295e-01,\n",
       "             8.3280e-01, 8.0424e-01, 7.9656e-01, 7.8992e-01, 7.8588e-01, 7.7981e-01,\n",
       "             7.7943e-01, 7.4586e-01, 7.3795e-01, 7.3361e-01, 7.2153e-01, 7.1139e-01,\n",
       "             6.9803e-01, 6.8810e-01, 6.5645e-01, 6.5161e-01, 6.2381e-01, 6.0512e-01,\n",
       "             5.3345e-01, 5.3146e-01, 4.6645e-01, 4.6333e-01, 4.5199e-01, 4.3762e-01,\n",
       "             4.2507e-01, 4.0605e-01, 3.8075e-01, 3.5866e-01, 3.5536e-01, 3.3503e-01,\n",
       "             3.2924e-01, 3.1695e-01, 2.8631e-01, 2.8271e-01, 2.3662e-01, 1.9457e-01,\n",
       "             1.7278e-01, 1.6295e-01, 1.5324e-01, 1.4338e-01, 1.2822e-01, 1.0145e-01,\n",
       "             9.7433e-02, 9.4173e-02, 8.6957e-02, 8.5922e-02, 7.8949e-02, 5.0562e-02,\n",
       "             4.6784e-02, 4.4337e-02, 4.0589e-02, 3.7886e-02, 2.7994e-02, 2.3795e-02,\n",
       "             2.2988e-02, 2.0790e-02, 1.9983e-02, 1.6375e-02, 1.6030e-02, 1.5837e-02,\n",
       "             1.5643e-02, 1.4171e-02, 1.4142e-02, 1.4126e-02, 1.0632e-02, 1.0128e-02,\n",
       "             9.0810e-03, 5.9239e-03, 5.6874e-03, 5.4128e-03, 5.2093e-03, 4.7632e-03,\n",
       "             4.4102e-03, 4.3252e-03, 3.6165e-03, 3.2196e-03, 3.1896e-03, 2.7557e-03,\n",
       "             2.1838e-03, 1.9480e-03, 1.3849e-03, 1.3549e-03, 1.3204e-03, 1.1300e-03,\n",
       "             8.6812e-04, 7.9779e-04, 7.7377e-04, 7.5459e-04, 7.3081e-04, 5.6027e-04,\n",
       "             5.0734e-04, 4.9630e-04, 4.2553e-04, 4.1818e-04, 4.1802e-04, 3.9452e-04,\n",
       "             3.7640e-04, 3.5529e-04, 3.0110e-04, 2.8152e-04, 2.7303e-04, 2.5332e-04,\n",
       "             2.4363e-04, 2.1365e-04, 2.0676e-04, 1.9696e-04, 1.9645e-04, 1.9445e-04,\n",
       "             1.5851e-04, 1.0732e-04, 9.1700e-05, 8.0627e-05, 7.8550e-05, 7.2854e-05,\n",
       "             6.7743e-05, 6.6559e-05, 6.5662e-05, 6.2714e-05, 5.7026e-05, 5.6540e-05,\n",
       "             5.4416e-05, 5.1764e-05, 5.1653e-05, 4.3822e-05, 4.3217e-05, 4.0282e-05,\n",
       "             4.0143e-05, 3.8705e-05, 3.6185e-05, 3.1860e-05, 3.0776e-05, 3.0768e-05,\n",
       "             2.6746e-05, 2.1386e-05, 2.1255e-05, 2.0725e-05, 1.5908e-05, 1.4885e-05,\n",
       "             1.1998e-05, 1.1450e-05, 8.7671e-06, 8.6473e-06, 6.9632e-06, 6.8846e-06,\n",
       "             5.7867e-06, 5.7728e-06, 5.3317e-06, 5.2324e-06, 4.6447e-06, 4.3743e-06,\n",
       "             4.2061e-06, 3.7276e-06, 3.5916e-06, 3.3356e-06, 2.8338e-06, 2.7356e-06,\n",
       "             2.0827e-06, 1.8387e-06, 1.6847e-06, 1.6846e-06, 1.5657e-06, 1.5022e-06,\n",
       "             1.3334e-06, 1.2212e-06, 1.1947e-06, 1.1558e-06, 1.0486e-06, 9.9898e-07,\n",
       "             9.4153e-07, 9.3008e-07, 8.3481e-07, 7.3618e-07, 6.4906e-07, 6.3542e-07,\n",
       "             6.0591e-07, 5.2360e-07, 5.1652e-07, 4.8154e-07, 4.0920e-07, 4.0815e-07,\n",
       "             4.0514e-07, 3.9651e-07, 3.7816e-07, 3.3580e-07, 3.2345e-07, 3.2084e-07,\n",
       "             3.0854e-07, 2.7202e-07, 2.4675e-07, 2.4296e-07, 2.1445e-07, 1.9242e-07,\n",
       "             1.8537e-07, 1.6447e-07, 1.4704e-07, 1.4120e-07, 1.2955e-07, 1.2601e-07,\n",
       "             1.2180e-07, 1.0937e-07, 1.0585e-07, 1.0079e-07, 1.0048e-07, 9.3812e-08,\n",
       "             8.5364e-08, 7.7547e-08, 5.8413e-08, 5.4521e-08, 4.6256e-08, 3.8808e-08,\n",
       "             3.6594e-08, 3.4644e-08, 3.3455e-08, 3.1882e-08, 3.1260e-08, 3.1251e-08,\n",
       "             3.0263e-08, 3.0035e-08, 2.9449e-08, 2.8257e-08, 2.5788e-08, 2.5019e-08,\n",
       "             2.2414e-08, 2.1940e-08, 2.1867e-08, 2.0251e-08, 1.9904e-08, 1.8338e-08,\n",
       "             1.7426e-08, 1.7074e-08, 1.6412e-08, 1.5933e-08, 1.4704e-08, 1.4669e-08,\n",
       "             1.4173e-08, 1.3487e-08, 1.3397e-08, 1.3062e-08, 1.2247e-08, 1.2188e-08,\n",
       "             1.1746e-08, 1.1588e-08, 8.5660e-09, 8.3193e-09, 7.8164e-09, 7.7013e-09,\n",
       "             7.2282e-09, 6.7770e-09, 6.0327e-09, 5.8922e-09, 5.7412e-09, 5.5671e-09,\n",
       "             4.5926e-09, 4.2086e-09, 4.0125e-09, 3.9902e-09, 3.9638e-09, 3.4346e-09,\n",
       "             2.6997e-09, 1.9250e-09, 1.8942e-09, 1.7919e-09, 1.5926e-09, 1.4977e-09,\n",
       "             1.4702e-09, 1.4224e-09, 1.3019e-09, 1.2616e-09, 1.2028e-09, 1.0601e-09,\n",
       "             9.7472e-10, 7.8834e-10, 6.0645e-10, 5.2016e-10, 5.0030e-10, 4.8243e-10,\n",
       "             4.8171e-10, 4.4065e-10, 3.8819e-10, 3.8728e-10, 3.4059e-10, 3.3160e-10,\n",
       "             3.1075e-10, 2.7066e-10, 2.2307e-10, 2.1464e-10, 2.0366e-10, 1.9908e-10,\n",
       "             1.8234e-10, 1.6848e-10, 1.6340e-10, 1.5712e-10, 1.5250e-10, 1.3773e-10,\n",
       "             1.2210e-10, 6.3110e-11, 5.7505e-11, 5.0799e-11, 4.5405e-11, 4.2957e-11,\n",
       "             3.8216e-11, 3.1046e-11, 2.9229e-11, 2.2810e-11, 1.9484e-11, 1.6525e-11,\n",
       "             1.5679e-11, 1.5246e-11, 1.4071e-11, 1.3862e-11, 1.3837e-11, 1.3290e-11,\n",
       "             1.2849e-11, 1.0046e-11, 8.0215e-12, 6.1473e-12, 5.3988e-12, 4.9760e-12,\n",
       "             4.5201e-12, 3.7011e-12, 3.4819e-12, 2.8136e-12, 1.4772e-12, 1.3611e-12,\n",
       "             1.1941e-12, 1.1344e-12, 9.2561e-13, 8.8814e-13, 7.4492e-13, 5.3608e-13,\n",
       "             4.8168e-13, 4.2222e-13, 3.6857e-13, 2.5131e-13, 2.3343e-13, 2.2263e-13,\n",
       "             2.0654e-13, 1.9867e-13, 1.7982e-13, 1.2747e-13, 1.1565e-13, 9.7425e-14,\n",
       "             8.6041e-14, 6.2443e-14, 2.6796e-14, 2.2198e-14, 5.9215e-15, 1.9099e-15,\n",
       "             4.6763e-16, 2.0310e-16, 7.5636e-19])}},\n",
       "   {'fpr': np.float64(0.05921052631578947),\n",
       "    'tpr': np.float64(0.983963344788087),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066,\n",
       "             0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066,\n",
       "             0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066,\n",
       "             0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0099,\n",
       "             0.0099, 0.0099, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132,\n",
       "             0.0132, 0.0132, 0.0132, 0.0132, 0.0132, 0.0164, 0.0164, 0.0164, 0.0197,\n",
       "             0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230, 0.0230,\n",
       "             0.0230, 0.0263, 0.0263, 0.0296, 0.0329, 0.0362, 0.0362, 0.0362, 0.0395,\n",
       "             0.0428, 0.0428, 0.0428, 0.0428, 0.0428, 0.0428, 0.0428, 0.0461, 0.0493,\n",
       "             0.0493, 0.0526, 0.0559, 0.0592, 0.0592, 0.0592, 0.0592, 0.0592, 0.0592,\n",
       "             0.0592, 0.0625, 0.0625, 0.0658, 0.0658, 0.0658, 0.0691, 0.0724, 0.0724,\n",
       "             0.0724, 0.0757, 0.0789, 0.0822, 0.0855, 0.0888, 0.0921, 0.0954, 0.0987,\n",
       "             0.1020, 0.1053, 0.1086, 0.1118, 0.1151, 0.1184, 0.1217, 0.1250, 0.1283,\n",
       "             0.1283, 0.1316, 0.1349, 0.1382, 0.1414, 0.1447, 0.1480, 0.1513, 0.1546,\n",
       "             0.1579, 0.1612, 0.1645, 0.1678, 0.1711, 0.1743, 0.1776, 0.1809, 0.1842,\n",
       "             0.1875, 0.1908, 0.1941, 0.1974, 0.2007, 0.2039, 0.2072, 0.2105, 0.2138,\n",
       "             0.2171, 0.2204, 0.2237, 0.2270, 0.2303, 0.2336, 0.2368, 0.2401, 0.2401,\n",
       "             0.2434, 0.2467, 0.2467, 0.2500, 0.2533, 0.2566, 0.2599, 0.2599, 0.2632,\n",
       "             0.2664, 0.2697, 0.2730, 0.2763, 0.2796, 0.2829, 0.2862, 0.2895, 0.2928,\n",
       "             0.2961, 0.2993, 0.3026, 0.3059, 0.3092, 0.3125, 0.3158, 0.3191, 0.3224,\n",
       "             0.3257, 0.3257, 0.3289, 0.3322, 0.3355, 0.3355, 0.3388, 0.3421, 0.3454,\n",
       "             0.3487, 0.3520, 0.3553, 0.3586, 0.3618, 0.3651, 0.3684, 0.3717, 0.3750,\n",
       "             0.3783, 0.3816, 0.3849, 0.3882, 0.3914, 0.3947, 0.3980, 0.4013, 0.4046,\n",
       "             0.4079, 0.4112, 0.4145, 0.4178, 0.4211, 0.4243, 0.4276, 0.4309, 0.4342,\n",
       "             0.4375, 0.4408, 0.4441, 0.4474, 0.4507, 0.4539, 0.4572, 0.4605, 0.4638,\n",
       "             0.4671, 0.4704, 0.4737, 0.4770, 0.4803, 0.4836, 0.4868, 0.4901, 0.4934,\n",
       "             0.4967, 0.5000, 0.5033, 0.5066, 0.5099, 0.5132, 0.5164, 0.5197, 0.5230,\n",
       "             0.5263, 0.5296, 0.5329, 0.5362, 0.5395, 0.5428, 0.5461, 0.5493, 0.5526,\n",
       "             0.5559, 0.5592, 0.5625, 0.5658, 0.5691, 0.5724, 0.5757, 0.5789, 0.5822,\n",
       "             0.5855, 0.5888, 0.5921, 0.5954, 0.5987, 0.6020, 0.6053, 0.6086, 0.6118,\n",
       "             0.6151, 0.6184, 0.6217, 0.6250, 0.6283, 0.6316, 0.6349, 0.6382, 0.6414,\n",
       "             0.6447, 0.6480, 0.6513, 0.6546, 0.6579, 0.6612, 0.6645, 0.6678, 0.6711,\n",
       "             0.6743, 0.6776, 0.6809, 0.6842, 0.6875, 0.6908, 0.6941, 0.6974, 0.7007,\n",
       "             0.7039, 0.7072, 0.7105, 0.7138, 0.7171, 0.7204, 0.7237, 0.7270, 0.7303,\n",
       "             0.7336, 0.7368, 0.7401, 0.7434, 0.7467, 0.7500, 0.7533, 0.7566, 0.7599,\n",
       "             0.7632, 0.7664, 0.7697, 0.7730, 0.7763, 0.7796, 0.7829, 0.7862, 0.7895,\n",
       "             0.7928, 0.7961, 0.7993, 0.8026, 0.8059, 0.8092, 0.8125, 0.8158, 0.8191,\n",
       "             0.8224, 0.8257, 0.8289, 0.8322, 0.8355, 0.8388, 0.8421, 0.8454, 0.8487,\n",
       "             0.8520, 0.8553, 0.8586, 0.8618, 0.8651, 0.8684, 0.8717, 0.8750, 0.8783,\n",
       "             0.8816, 0.8849, 0.8882, 0.8914, 0.8947, 0.8980, 0.9013, 0.9046, 0.9079,\n",
       "             0.9112, 0.9145, 0.9178, 0.9211, 0.9243, 0.9276, 0.9309, 0.9342, 0.9375,\n",
       "             0.9408, 0.9441, 0.9474, 0.9507, 0.9539, 0.9572, 0.9605, 0.9638, 0.9671,\n",
       "             0.9704, 0.9737, 0.9770, 0.9803, 0.9836, 0.9868, 0.9901, 0.9934, 0.9967,\n",
       "             1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.2360, 0.3242, 0.3688, 0.3998, 0.4147, 0.4307, 0.4467, 0.4605,\n",
       "             0.4742, 0.4822, 0.4948, 0.4994, 0.5052, 0.5109, 0.5166, 0.5200, 0.5246,\n",
       "             0.5315, 0.5361, 0.5395, 0.5418, 0.5441, 0.5487, 0.5521, 0.5533, 0.5601,\n",
       "             0.5624, 0.5659, 0.5670, 0.5727, 0.5739, 0.5750, 0.5762, 0.5773, 0.5796,\n",
       "             0.5842, 0.5853, 0.5865, 0.5876, 0.5888, 0.5899, 0.5945, 0.5979, 0.6037,\n",
       "             0.6060, 0.6071, 0.6082, 0.6117, 0.6140, 0.6151, 0.6174, 0.6186, 0.6208,\n",
       "             0.6220, 0.6243, 0.6254, 0.6266, 0.6277, 0.6289, 0.6300, 0.6312, 0.6323,\n",
       "             0.6346, 0.6357, 0.6380, 0.6403, 0.6415, 0.6426, 0.6438, 0.6460, 0.6472,\n",
       "             0.6495, 0.6506, 0.6518, 0.6541, 0.6552, 0.6564, 0.6575, 0.6586, 0.6598,\n",
       "             0.6609, 0.6621, 0.6632, 0.6644, 0.6655, 0.6667, 0.6678, 0.6690, 0.6701,\n",
       "             0.6712, 0.6724, 0.6735, 0.6747, 0.6758, 0.6770, 0.6793, 0.6804, 0.6816,\n",
       "             0.6827, 0.6850, 0.6861, 0.6873, 0.6884, 0.6907, 0.6919, 0.6930, 0.6964,\n",
       "             0.6976, 0.6987, 0.6999, 0.7010, 0.7022, 0.7033, 0.7045, 0.7056, 0.7068,\n",
       "             0.7079, 0.7090, 0.7102, 0.7113, 0.7125, 0.7136, 0.7148, 0.7159, 0.7171,\n",
       "             0.7182, 0.7194, 0.7205, 0.7216, 0.7228, 0.7239, 0.7251, 0.7262, 0.7274,\n",
       "             0.7285, 0.7297, 0.7308, 0.7320, 0.7331, 0.7342, 0.7354, 0.7365, 0.7377,\n",
       "             0.7388, 0.7400, 0.7411, 0.7423, 0.7434, 0.7446, 0.7457, 0.7468, 0.7480,\n",
       "             0.7491, 0.7503, 0.7514, 0.7526, 0.7537, 0.7549, 0.7560, 0.7572, 0.7583,\n",
       "             0.7595, 0.7606, 0.7617, 0.7629, 0.7640, 0.7652, 0.7663, 0.7675, 0.7686,\n",
       "             0.7698, 0.7709, 0.7721, 0.7732, 0.7743, 0.7755, 0.7766, 0.7778, 0.7789,\n",
       "             0.7801, 0.7812, 0.7824, 0.7835, 0.7847, 0.7858, 0.7858, 0.7869, 0.7881,\n",
       "             0.7892, 0.7904, 0.7915, 0.7927, 0.7938, 0.7950, 0.7961, 0.7973, 0.7984,\n",
       "             0.7995, 0.8007, 0.8018, 0.8030, 0.8041, 0.8053, 0.8064, 0.8076, 0.8087,\n",
       "             0.8099, 0.8110, 0.8121, 0.8133, 0.8144, 0.8167, 0.8179, 0.8190, 0.8202,\n",
       "             0.8213, 0.8225, 0.8236, 0.8247, 0.8259, 0.8270, 0.8282, 0.8293, 0.8305,\n",
       "             0.8316, 0.8328, 0.8339, 0.8351, 0.8362, 0.8373, 0.8385, 0.8396, 0.8408,\n",
       "             0.8419, 0.8431, 0.8442, 0.8454, 0.8465, 0.8477, 0.8488, 0.8499, 0.8511,\n",
       "             0.8522, 0.8534, 0.8545, 0.8557, 0.8568, 0.8580, 0.8591, 0.8603, 0.8614,\n",
       "             0.8625, 0.8637, 0.8648, 0.8660, 0.8671, 0.8683, 0.8694, 0.8706, 0.8717,\n",
       "             0.8729, 0.8740, 0.8751, 0.8763, 0.8774, 0.8786, 0.8797, 0.8809, 0.8820,\n",
       "             0.8832, 0.8843, 0.8855, 0.8866, 0.8877, 0.8889, 0.8900, 0.8912, 0.8923,\n",
       "             0.8935, 0.8946, 0.8958, 0.8969, 0.8981, 0.8992, 0.9003, 0.9015, 0.9026,\n",
       "             0.9038, 0.9049, 0.9061, 0.9072, 0.9072, 0.9084, 0.9095, 0.9107, 0.9118,\n",
       "             0.9129, 0.9141, 0.9152, 0.9164, 0.9175, 0.9187, 0.9198, 0.9210, 0.9221,\n",
       "             0.9233, 0.9244, 0.9255, 0.9267, 0.9278, 0.9290, 0.9301, 0.9313, 0.9324,\n",
       "             0.9336, 0.9347, 0.9359, 0.9370, 0.9381, 0.9393, 0.9404, 0.9416, 0.9416,\n",
       "             0.9427, 0.9439, 0.9439, 0.9450, 0.9462, 0.9473, 0.9485, 0.9496, 0.9507,\n",
       "             0.9519, 0.9530, 0.9542, 0.9553, 0.9565, 0.9565, 0.9576, 0.9588, 0.9588,\n",
       "             0.9588, 0.9599, 0.9611, 0.9622, 0.9633, 0.9645, 0.9656, 0.9668, 0.9679,\n",
       "             0.9691, 0.9691, 0.9702, 0.9702, 0.9702, 0.9702, 0.9714, 0.9725, 0.9725,\n",
       "             0.9725, 0.9737, 0.9748, 0.9759, 0.9771, 0.9782, 0.9794, 0.9794, 0.9794,\n",
       "             0.9805, 0.9805, 0.9805, 0.9805, 0.9817, 0.9828, 0.9840, 0.9851, 0.9863,\n",
       "             0.9874, 0.9874, 0.9885, 0.9885, 0.9897, 0.9908, 0.9908, 0.9908, 0.9920,\n",
       "             0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931,\n",
       "             0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931,\n",
       "             0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943,\n",
       "             0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943,\n",
       "             0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943,\n",
       "             0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9954,\n",
       "             0.9954, 0.9954, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9989, 0.9989, 0.9989, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9996e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9992e-01,\n",
       "             9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01,\n",
       "             9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01, 9.9991e-01,\n",
       "             9.9991e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9990e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9990e-01, 9.9989e-01, 9.9989e-01, 9.9989e-01,\n",
       "             9.9989e-01, 9.9989e-01, 9.9989e-01, 9.9988e-01, 9.9988e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9988e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01, 9.9987e-01,\n",
       "             9.9987e-01, 9.9987e-01, 9.9986e-01, 9.9986e-01, 9.9986e-01, 9.9985e-01,\n",
       "             9.9985e-01, 9.9984e-01, 9.9984e-01, 9.9983e-01, 9.9983e-01, 9.9983e-01,\n",
       "             9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9982e-01, 9.9981e-01, 9.9981e-01,\n",
       "             9.9979e-01, 9.9979e-01, 9.9978e-01, 9.9977e-01, 9.9977e-01, 9.9977e-01,\n",
       "             9.9975e-01, 9.9973e-01, 9.9971e-01, 9.9970e-01, 9.9969e-01, 9.9969e-01,\n",
       "             9.9967e-01, 9.9963e-01, 9.9962e-01, 9.9962e-01, 9.9961e-01, 9.9960e-01,\n",
       "             9.9960e-01, 9.9960e-01, 9.9959e-01, 9.9959e-01, 9.9959e-01, 9.9958e-01,\n",
       "             9.9958e-01, 9.9957e-01, 9.9956e-01, 9.9955e-01, 9.9955e-01, 9.9954e-01,\n",
       "             9.9953e-01, 9.9947e-01, 9.9945e-01, 9.9944e-01, 9.9943e-01, 9.9943e-01,\n",
       "             9.9938e-01, 9.9937e-01, 9.9935e-01, 9.9933e-01, 9.9932e-01, 9.9930e-01,\n",
       "             9.9929e-01, 9.9927e-01, 9.9927e-01, 9.9920e-01, 9.9917e-01, 9.9917e-01,\n",
       "             9.9916e-01, 9.9909e-01, 9.9904e-01, 9.9896e-01, 9.9886e-01, 9.9872e-01,\n",
       "             9.9870e-01, 9.9869e-01, 9.9858e-01, 9.9850e-01, 9.9849e-01, 9.9844e-01,\n",
       "             9.9843e-01, 9.9842e-01, 9.9836e-01, 9.9828e-01, 9.9828e-01, 9.9828e-01,\n",
       "             9.9807e-01, 9.9791e-01, 9.9785e-01, 9.9780e-01, 9.9752e-01, 9.9748e-01,\n",
       "             9.9737e-01, 9.9725e-01, 9.9687e-01, 9.9684e-01, 9.9621e-01, 9.9607e-01,\n",
       "             9.9578e-01, 9.9572e-01, 9.9556e-01, 9.9550e-01, 9.9499e-01, 9.9470e-01,\n",
       "             9.9463e-01, 9.9450e-01, 9.9412e-01, 9.9403e-01, 9.9325e-01, 9.9271e-01,\n",
       "             9.9187e-01, 9.9171e-01, 9.9046e-01, 9.8971e-01, 9.8921e-01, 9.8668e-01,\n",
       "             9.8597e-01, 9.8315e-01, 9.8125e-01, 9.8025e-01, 9.7916e-01, 9.7827e-01,\n",
       "             9.7665e-01, 9.7531e-01, 9.7489e-01, 9.7112e-01, 9.7070e-01, 9.6940e-01,\n",
       "             9.6566e-01, 9.6247e-01, 9.6227e-01, 9.6084e-01, 9.5897e-01, 9.5707e-01,\n",
       "             9.4645e-01, 9.4608e-01, 9.3581e-01, 9.3006e-01, 9.2517e-01, 9.1069e-01,\n",
       "             9.0388e-01, 8.9452e-01, 8.9276e-01, 8.8220e-01, 8.7619e-01, 8.6546e-01,\n",
       "             8.6052e-01, 8.3821e-01, 8.3480e-01, 8.1681e-01, 7.9201e-01, 7.3492e-01,\n",
       "             7.1196e-01, 6.5833e-01, 6.5746e-01, 6.5190e-01, 6.1924e-01, 5.9635e-01,\n",
       "             5.3256e-01, 5.0160e-01, 5.0084e-01, 5.0003e-01, 4.9893e-01, 4.9005e-01,\n",
       "             4.7971e-01, 4.7782e-01, 4.6317e-01, 4.5157e-01, 3.5226e-01, 2.5127e-01,\n",
       "             2.4789e-01, 2.3625e-01, 1.7506e-01, 1.6516e-01, 1.6182e-01, 1.2735e-01,\n",
       "             1.1565e-01, 1.1514e-01, 1.1144e-01, 8.8570e-02, 7.9579e-02, 7.4363e-02,\n",
       "             6.4933e-02, 6.2796e-02, 5.9519e-02, 5.6016e-02, 5.0828e-02, 4.5854e-02,\n",
       "             4.2999e-02, 4.2122e-02, 4.1954e-02, 3.9727e-02, 3.8677e-02, 3.7560e-02,\n",
       "             3.6349e-02, 2.9827e-02, 2.2701e-02, 2.1597e-02, 2.1433e-02, 2.0716e-02,\n",
       "             1.8205e-02, 1.7681e-02, 1.4652e-02, 1.4383e-02, 1.3926e-02, 1.3689e-02,\n",
       "             1.3380e-02, 1.2492e-02, 1.2055e-02, 9.5773e-03, 8.6885e-03, 7.3943e-03,\n",
       "             6.8251e-03, 5.9153e-03, 5.8718e-03, 4.7451e-03, 4.5839e-03, 4.4682e-03,\n",
       "             4.2955e-03, 3.7166e-03, 2.9871e-03, 2.8405e-03, 2.6581e-03, 2.2919e-03,\n",
       "             2.2261e-03, 1.9477e-03, 1.6877e-03, 1.6641e-03, 1.3879e-03, 1.0746e-03,\n",
       "             1.0581e-03, 1.0082e-03, 9.6571e-04, 9.6040e-04, 7.6030e-04, 7.5373e-04,\n",
       "             7.3473e-04, 7.2279e-04, 6.7790e-04, 6.0765e-04, 5.0008e-04, 4.9608e-04,\n",
       "             3.2592e-04, 3.0470e-04, 2.9243e-04, 2.5713e-04, 2.3429e-04, 2.2750e-04,\n",
       "             1.9729e-04, 1.9297e-04, 1.7808e-04, 1.6145e-04, 1.4855e-04, 1.3590e-04,\n",
       "             1.2585e-04, 1.0611e-04, 1.0187e-04, 6.2303e-05, 5.6543e-05, 5.5891e-05,\n",
       "             5.4893e-05, 4.7838e-05, 4.7387e-05, 4.1708e-05, 3.9505e-05, 3.7716e-05,\n",
       "             3.7668e-05, 3.7280e-05, 3.6860e-05, 3.5279e-05, 3.3799e-05, 3.1570e-05,\n",
       "             3.1468e-05, 2.5427e-05, 2.5389e-05, 2.3811e-05, 2.0394e-05, 1.9678e-05,\n",
       "             1.8837e-05, 1.5251e-05, 1.5183e-05, 1.2800e-05, 1.2405e-05, 1.2171e-05,\n",
       "             1.0602e-05, 1.0317e-05, 9.9718e-06, 9.9672e-06, 9.6241e-06, 9.2730e-06,\n",
       "             8.6842e-06, 8.3247e-06, 8.2703e-06, 8.0856e-06, 6.7341e-06, 6.6518e-06,\n",
       "             6.6345e-06, 6.5716e-06, 6.3593e-06, 6.2648e-06, 5.9867e-06, 5.8363e-06,\n",
       "             5.4465e-06, 4.9838e-06, 4.9042e-06, 4.6100e-06, 4.5266e-06, 3.5231e-06,\n",
       "             3.1941e-06, 3.0782e-06, 2.9079e-06, 2.7403e-06, 2.5611e-06, 2.5136e-06,\n",
       "             2.5091e-06, 2.2554e-06, 2.2174e-06, 1.8663e-06, 1.8152e-06, 1.8047e-06,\n",
       "             1.7207e-06, 1.6995e-06, 1.5385e-06, 1.4259e-06, 1.3301e-06, 1.2852e-06,\n",
       "             1.1326e-06, 9.6685e-07, 8.6824e-07, 7.2698e-07, 6.8295e-07, 6.2947e-07,\n",
       "             5.6224e-07, 5.0684e-07, 4.9416e-07, 4.9299e-07, 4.8941e-07, 4.8762e-07,\n",
       "             3.9055e-07, 3.3427e-07, 3.2868e-07, 3.1100e-07, 2.6795e-07, 2.5452e-07,\n",
       "             2.2294e-07, 2.2153e-07, 1.9314e-07, 1.6427e-07, 1.5416e-07, 1.4673e-07,\n",
       "             1.4209e-07, 1.3085e-07, 1.2305e-07, 1.1030e-07, 1.1019e-07, 9.9458e-08,\n",
       "             8.6880e-08, 7.7733e-08, 7.7374e-08, 5.6347e-08, 5.6337e-08, 4.8381e-08,\n",
       "             4.6587e-08, 4.4023e-08, 4.0838e-08, 4.0355e-08, 3.9290e-08, 3.8665e-08,\n",
       "             3.8310e-08, 3.1931e-08, 2.2106e-08, 2.1744e-08, 2.1678e-08, 2.1004e-08,\n",
       "             1.8506e-08, 1.5613e-08, 1.3810e-08, 1.0046e-08, 9.4018e-09, 9.0396e-09,\n",
       "             8.0778e-09, 7.9612e-09, 5.9543e-09, 4.8740e-09, 4.5500e-09, 4.1817e-09,\n",
       "             3.5493e-09, 3.3467e-09, 3.3405e-09, 2.7731e-09, 2.4205e-09, 2.3752e-09,\n",
       "             2.3087e-09, 1.7363e-09, 1.1839e-09, 1.1556e-09, 1.1051e-09, 1.0298e-09,\n",
       "             7.4833e-10, 6.9390e-10, 5.3526e-10, 4.3625e-10, 4.0805e-10, 3.1073e-10,\n",
       "             3.0146e-10, 2.8699e-10, 2.8692e-10, 2.0208e-10, 1.5592e-10, 1.4076e-10,\n",
       "             1.4059e-10, 1.1696e-10, 1.1466e-10, 1.0570e-10, 1.0009e-10, 8.8120e-11,\n",
       "             6.5045e-11, 5.8678e-11, 5.4898e-11, 5.3409e-11, 4.8837e-11, 4.0286e-11,\n",
       "             3.8155e-11, 2.9495e-11, 2.3820e-11, 2.0933e-11, 1.8918e-11, 1.7547e-11,\n",
       "             1.6541e-11, 9.3959e-12, 8.2467e-12, 3.2920e-12, 2.6369e-12, 2.5194e-12,\n",
       "             2.3893e-12, 2.3136e-12, 2.0601e-12, 1.5210e-12, 7.2334e-13, 6.9275e-13,\n",
       "             6.4818e-13, 5.0680e-13, 4.6295e-13, 4.3799e-13, 4.3565e-13, 2.8098e-13,\n",
       "             2.3741e-13, 2.3487e-13, 1.9022e-13, 7.5560e-14, 3.9188e-14, 1.1966e-14,\n",
       "             1.0215e-14, 7.2041e-15, 2.9108e-15, 2.8382e-15, 9.9976e-16, 4.2557e-16,\n",
       "             3.2816e-16, 8.0560e-17, 8.5218e-18, 3.1177e-18])}},\n",
       "   {'fpr': np.float64(0.17763157894736842),\n",
       "    'tpr': np.float64(0.995418098510882),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0033, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0132, 0.0132,\n",
       "             0.0132, 0.0132, 0.0132, 0.0132, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164,\n",
       "             0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164,\n",
       "             0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0197,\n",
       "             0.0197, 0.0197, 0.0230, 0.0230, 0.0263, 0.0296, 0.0296, 0.0296, 0.0296,\n",
       "             0.0296, 0.0296, 0.0296, 0.0296, 0.0296, 0.0296, 0.0296, 0.0296, 0.0296,\n",
       "             0.0296, 0.0296, 0.0296, 0.0296, 0.0296, 0.0296, 0.0296, 0.0296, 0.0329,\n",
       "             0.0329, 0.0329, 0.0329, 0.0329, 0.0329, 0.0329, 0.0329, 0.0329, 0.0329,\n",
       "             0.0329, 0.0362, 0.0362, 0.0362, 0.0362, 0.0362, 0.0362, 0.0362, 0.0362,\n",
       "             0.0362, 0.0362, 0.0362, 0.0395, 0.0395, 0.0395, 0.0395, 0.0395, 0.0428,\n",
       "             0.0428, 0.0461, 0.0461, 0.0461, 0.0461, 0.0493, 0.0526, 0.0526, 0.0559,\n",
       "             0.0592, 0.0592, 0.0625, 0.0625, 0.0658, 0.0658, 0.0658, 0.0658, 0.0691,\n",
       "             0.0691, 0.0691, 0.0691, 0.0724, 0.0757, 0.0789, 0.0822, 0.0855, 0.0888,\n",
       "             0.0888, 0.0921, 0.0921, 0.0954, 0.0954, 0.0954, 0.0987, 0.1020, 0.1053,\n",
       "             0.1053, 0.1053, 0.1086, 0.1118, 0.1151, 0.1151, 0.1184, 0.1217, 0.1250,\n",
       "             0.1283, 0.1316, 0.1349, 0.1349, 0.1382, 0.1414, 0.1447, 0.1480, 0.1513,\n",
       "             0.1546, 0.1579, 0.1612, 0.1645, 0.1678, 0.1711, 0.1743, 0.1743, 0.1776,\n",
       "             0.1809, 0.1842, 0.1875, 0.1908, 0.1941, 0.1974, 0.2007, 0.2039, 0.2072,\n",
       "             0.2105, 0.2138, 0.2171, 0.2204, 0.2237, 0.2270, 0.2270, 0.2303, 0.2336,\n",
       "             0.2368, 0.2401, 0.2434, 0.2467, 0.2500, 0.2533, 0.2566, 0.2599, 0.2632,\n",
       "             0.2664, 0.2697, 0.2730, 0.2763, 0.2796, 0.2829, 0.2862, 0.2895, 0.2928,\n",
       "             0.2961, 0.2993, 0.3026, 0.3059, 0.3092, 0.3092, 0.3125, 0.3158, 0.3191,\n",
       "             0.3224, 0.3257, 0.3289, 0.3322, 0.3355, 0.3388, 0.3421, 0.3454, 0.3487,\n",
       "             0.3520, 0.3553, 0.3586, 0.3618, 0.3651, 0.3684, 0.3717, 0.3750, 0.3783,\n",
       "             0.3816, 0.3849, 0.3882, 0.3914, 0.3947, 0.3947, 0.3980, 0.4013, 0.4046,\n",
       "             0.4079, 0.4112, 0.4145, 0.4178, 0.4211, 0.4243, 0.4276, 0.4309, 0.4342,\n",
       "             0.4375, 0.4408, 0.4441, 0.4474, 0.4507, 0.4539, 0.4572, 0.4605, 0.4638,\n",
       "             0.4671, 0.4671, 0.4704, 0.4737, 0.4770, 0.4803, 0.4836, 0.4868, 0.4901,\n",
       "             0.4934, 0.4967, 0.5000, 0.5033, 0.5066, 0.5099, 0.5132, 0.5164, 0.5197,\n",
       "             0.5230, 0.5263, 0.5296, 0.5329, 0.5362, 0.5395, 0.5428, 0.5461, 0.5493,\n",
       "             0.5526, 0.5559, 0.5592, 0.5625, 0.5658, 0.5691, 0.5724, 0.5757, 0.5789,\n",
       "             0.5822, 0.5855, 0.5888, 0.5921, 0.5954, 0.5987, 0.6020, 0.6053, 0.6086,\n",
       "             0.6118, 0.6151, 0.6184, 0.6217, 0.6250, 0.6283, 0.6316, 0.6349, 0.6382,\n",
       "             0.6414, 0.6447, 0.6480, 0.6513, 0.6546, 0.6579, 0.6612, 0.6645, 0.6678,\n",
       "             0.6711, 0.6743, 0.6776, 0.6809, 0.6842, 0.6875, 0.6908, 0.6941, 0.6974,\n",
       "             0.7007, 0.7039, 0.7072, 0.7105, 0.7138, 0.7171, 0.7204, 0.7237, 0.7270,\n",
       "             0.7303, 0.7336, 0.7368, 0.7401, 0.7434, 0.7467, 0.7500, 0.7533, 0.7566,\n",
       "             0.7599, 0.7632, 0.7664, 0.7697, 0.7730, 0.7763, 0.7796, 0.7829, 0.7862,\n",
       "             0.7895, 0.7928, 0.7961, 0.7993, 0.8026, 0.8059, 0.8092, 0.8125, 0.8158,\n",
       "             0.8191, 0.8224, 0.8257, 0.8289, 0.8322, 0.8355, 0.8388, 0.8421, 0.8454,\n",
       "             0.8487, 0.8520, 0.8553, 0.8586, 0.8618, 0.8651, 0.8684, 0.8717, 0.8750,\n",
       "             0.8783, 0.8816, 0.8849, 0.8882, 0.8914, 0.8947, 0.8980, 0.9013, 0.9046,\n",
       "             0.9079, 0.9112, 0.9145, 0.9178, 0.9211, 0.9243, 0.9276, 0.9309, 0.9342,\n",
       "             0.9375, 0.9408, 0.9441, 0.9474, 0.9507, 0.9539, 0.9572, 0.9605, 0.9638,\n",
       "             0.9671, 0.9704, 0.9737, 0.9770, 0.9803, 0.9836, 0.9868, 0.9901, 0.9934,\n",
       "             0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.6976, 0.7709, 0.7984, 0.8190, 0.8351, 0.8419, 0.8545, 0.8580,\n",
       "             0.8648, 0.8694, 0.8751, 0.8774, 0.8809, 0.8820, 0.8843, 0.8866, 0.8877,\n",
       "             0.8889, 0.8900, 0.8923, 0.8935, 0.8946, 0.8958, 0.8969, 0.8981, 0.8992,\n",
       "             0.9015, 0.9038, 0.9049, 0.9061, 0.9072, 0.9084, 0.9095, 0.9118, 0.9118,\n",
       "             0.9129, 0.9152, 0.9164, 0.9175, 0.9187, 0.9187, 0.9198, 0.9221, 0.9233,\n",
       "             0.9244, 0.9255, 0.9267, 0.9278, 0.9290, 0.9301, 0.9313, 0.9324, 0.9336,\n",
       "             0.9347, 0.9359, 0.9370, 0.9381, 0.9393, 0.9404, 0.9416, 0.9427, 0.9427,\n",
       "             0.9439, 0.9450, 0.9462, 0.9473, 0.9485, 0.9496, 0.9507, 0.9519, 0.9530,\n",
       "             0.9542, 0.9542, 0.9553, 0.9565, 0.9576, 0.9588, 0.9599, 0.9611, 0.9622,\n",
       "             0.9633, 0.9645, 0.9656, 0.9656, 0.9668, 0.9679, 0.9691, 0.9702, 0.9702,\n",
       "             0.9714, 0.9714, 0.9725, 0.9737, 0.9748, 0.9748, 0.9748, 0.9759, 0.9759,\n",
       "             0.9759, 0.9771, 0.9771, 0.9782, 0.9782, 0.9794, 0.9805, 0.9817, 0.9817,\n",
       "             0.9828, 0.9840, 0.9851, 0.9851, 0.9851, 0.9851, 0.9851, 0.9851, 0.9851,\n",
       "             0.9863, 0.9863, 0.9874, 0.9874, 0.9885, 0.9897, 0.9897, 0.9897, 0.9897,\n",
       "             0.9908, 0.9920, 0.9920, 0.9920, 0.9920, 0.9931, 0.9931, 0.9931, 0.9931,\n",
       "             0.9931, 0.9931, 0.9931, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943,\n",
       "             0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01, 9.9997e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9995e-01,\n",
       "             9.9995e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9992e-01, 9.9991e-01,\n",
       "             9.9990e-01, 9.9990e-01, 9.9989e-01, 9.9987e-01, 9.9987e-01, 9.9986e-01,\n",
       "             9.9982e-01, 9.9977e-01, 9.9976e-01, 9.9964e-01, 9.9961e-01, 9.9959e-01,\n",
       "             9.9959e-01, 9.9957e-01, 9.9954e-01, 9.9948e-01, 9.9947e-01, 9.9944e-01,\n",
       "             9.9934e-01, 9.9932e-01, 9.9917e-01, 9.9909e-01, 9.9909e-01, 9.9896e-01,\n",
       "             9.9894e-01, 9.9893e-01, 9.9885e-01, 9.9880e-01, 9.9864e-01, 9.9844e-01,\n",
       "             9.9826e-01, 9.9817e-01, 9.9798e-01, 9.9765e-01, 9.9721e-01, 9.9691e-01,\n",
       "             9.9578e-01, 9.9569e-01, 9.9409e-01, 9.9367e-01, 9.9283e-01, 9.9182e-01,\n",
       "             9.9160e-01, 9.8883e-01, 9.8622e-01, 9.8500e-01, 9.8168e-01, 9.7575e-01,\n",
       "             9.7484e-01, 9.7146e-01, 9.7013e-01, 9.6977e-01, 9.6651e-01, 9.6627e-01,\n",
       "             9.5161e-01, 9.3841e-01, 9.3549e-01, 9.2404e-01, 8.8920e-01, 8.7282e-01,\n",
       "             8.6762e-01, 8.4946e-01, 8.1768e-01, 7.9154e-01, 6.7849e-01, 6.7836e-01,\n",
       "             6.7544e-01, 6.6965e-01, 6.3907e-01, 6.3793e-01, 6.3178e-01, 6.0931e-01,\n",
       "             5.6452e-01, 5.2369e-01, 5.1456e-01, 3.6444e-01, 2.7300e-01, 2.2936e-01,\n",
       "             2.1551e-01, 1.9631e-01, 1.6401e-01, 1.6240e-01, 1.5754e-01, 1.5373e-01,\n",
       "             1.4891e-01, 1.4305e-01, 1.3626e-01, 1.2417e-01, 1.1138e-01, 1.0466e-01,\n",
       "             1.0132e-01, 8.4525e-02, 7.7086e-02, 7.3245e-02, 7.0051e-02, 5.5668e-02,\n",
       "             4.3810e-02, 4.0063e-02, 4.0026e-02, 3.5353e-02, 2.9336e-02, 2.8931e-02,\n",
       "             2.7630e-02, 2.6995e-02, 2.6353e-02, 2.1657e-02, 2.1613e-02, 2.0801e-02,\n",
       "             1.8661e-02, 1.4554e-02, 1.2250e-02, 1.1615e-02, 1.0772e-02, 1.0470e-02,\n",
       "             9.1324e-03, 8.6019e-03, 7.4008e-03, 5.9201e-03, 5.5595e-03, 5.4560e-03,\n",
       "             5.1302e-03, 3.8553e-03, 3.3107e-03, 3.0854e-03, 2.9916e-03, 2.3762e-03,\n",
       "             2.1386e-03, 2.0350e-03, 1.9745e-03, 1.9638e-03, 1.7847e-03, 1.2395e-03,\n",
       "             1.1996e-03, 9.1967e-04, 9.0755e-04, 8.5835e-04, 8.5585e-04, 7.2024e-04,\n",
       "             6.6341e-04, 6.2517e-04, 6.2282e-04, 5.9627e-04, 5.1199e-04, 4.9121e-04,\n",
       "             4.8410e-04, 4.2461e-04, 4.1513e-04, 4.1136e-04, 4.0817e-04, 4.0380e-04,\n",
       "             3.6554e-04, 2.8119e-04, 2.5048e-04, 2.4316e-04, 1.9898e-04, 1.7218e-04,\n",
       "             1.4106e-04, 1.3682e-04, 1.2167e-04, 1.1666e-04, 1.1217e-04, 8.5247e-05,\n",
       "             7.5743e-05, 6.7267e-05, 5.6394e-05, 5.3400e-05, 4.3567e-05, 3.8956e-05,\n",
       "             3.8225e-05, 3.8156e-05, 3.6494e-05, 3.6192e-05, 3.3967e-05, 3.1056e-05,\n",
       "             2.9470e-05, 2.3413e-05, 2.2875e-05, 2.2448e-05, 2.1889e-05, 2.0838e-05,\n",
       "             2.0727e-05, 1.9019e-05, 1.7213e-05, 1.6679e-05, 1.4648e-05, 1.4597e-05,\n",
       "             1.3537e-05, 1.3464e-05, 1.1701e-05, 1.1236e-05, 1.0813e-05, 1.0502e-05,\n",
       "             9.0898e-06, 8.8345e-06, 7.1619e-06, 5.7696e-06, 5.6213e-06, 5.1020e-06,\n",
       "             4.4070e-06, 4.1961e-06, 4.1686e-06, 3.5947e-06, 3.4242e-06, 2.9045e-06,\n",
       "             2.8752e-06, 2.7840e-06, 2.7233e-06, 2.6858e-06, 2.5552e-06, 2.2109e-06,\n",
       "             2.1371e-06, 2.0015e-06, 1.7796e-06, 1.7335e-06, 1.5868e-06, 1.5083e-06,\n",
       "             1.4604e-06, 1.3229e-06, 1.1445e-06, 1.1409e-06, 1.0957e-06, 1.0242e-06,\n",
       "             8.0613e-07, 7.1527e-07, 7.0778e-07, 6.1398e-07, 5.7409e-07, 5.6036e-07,\n",
       "             4.4428e-07, 3.1682e-07, 2.7270e-07, 1.3086e-07, 1.1890e-07, 9.0668e-08,\n",
       "             8.3845e-08, 8.3323e-08, 7.6464e-08, 7.3348e-08, 6.6068e-08, 6.4276e-08,\n",
       "             5.2150e-08, 5.0825e-08, 4.7216e-08, 4.6207e-08, 4.5815e-08, 4.4705e-08,\n",
       "             3.9971e-08, 3.8692e-08, 2.7682e-08, 2.2107e-08, 1.9312e-08, 1.8963e-08,\n",
       "             1.7567e-08, 1.4953e-08, 1.4002e-08, 8.7553e-09, 8.0542e-09, 7.6910e-09,\n",
       "             6.8148e-09, 3.4485e-09, 3.3473e-09, 2.8710e-09, 2.5653e-09, 2.2644e-09,\n",
       "             2.0469e-09, 1.8982e-09, 1.7965e-09, 1.2992e-09, 1.1736e-09, 9.0156e-10,\n",
       "             8.5375e-10, 7.7809e-10, 7.6770e-10, 5.5510e-10, 5.0530e-10, 5.0210e-10,\n",
       "             3.9234e-10, 3.6347e-10, 3.4144e-10, 2.7172e-10, 2.5942e-10, 2.5756e-10,\n",
       "             2.3960e-10, 1.3474e-10, 1.2373e-10, 1.0025e-10, 6.1434e-11, 5.4665e-11,\n",
       "             4.8749e-11, 4.3882e-11, 4.1858e-11, 3.9763e-11, 3.8400e-11, 3.1821e-11,\n",
       "             2.7596e-11, 2.4727e-11, 2.1759e-11, 2.1354e-11, 1.5169e-11, 5.3018e-12,\n",
       "             4.8904e-12, 3.6403e-12, 3.5952e-12, 1.9553e-12, 1.6336e-12, 1.4189e-12,\n",
       "             1.0418e-12, 7.4736e-13, 5.7341e-13, 4.0922e-13, 3.4555e-13, 3.0602e-13,\n",
       "             1.6929e-13, 1.4972e-13, 1.0869e-13, 1.0820e-13, 1.0252e-13, 3.1188e-14,\n",
       "             3.0694e-14, 2.7041e-14, 1.0342e-14, 9.1505e-15, 1.9945e-15, 5.2114e-16,\n",
       "             2.8243e-16, 9.2959e-17, 4.4538e-17, 2.3259e-17, 3.1942e-21])}},\n",
       "   {'fpr': np.float64(0.13157894736842105),\n",
       "    'tpr': np.float64(0.993127147766323),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0099, 0.0099, 0.0099, 0.0132, 0.0164, 0.0164, 0.0164, 0.0164,\n",
       "             0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164, 0.0164,\n",
       "             0.0164, 0.0164, 0.0164, 0.0164, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197,\n",
       "             0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197,\n",
       "             0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197,\n",
       "             0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197, 0.0197,\n",
       "             0.0197, 0.0230, 0.0230, 0.0230, 0.0263, 0.0263, 0.0263, 0.0296, 0.0329,\n",
       "             0.0329, 0.0362, 0.0362, 0.0362, 0.0395, 0.0395, 0.0395, 0.0428, 0.0428,\n",
       "             0.0428, 0.0461, 0.0461, 0.0461, 0.0461, 0.0461, 0.0461, 0.0461, 0.0461,\n",
       "             0.0461, 0.0461, 0.0461, 0.0461, 0.0493, 0.0526, 0.0526, 0.0526, 0.0559,\n",
       "             0.0559, 0.0559, 0.0592, 0.0625, 0.0625, 0.0625, 0.0658, 0.0658, 0.0658,\n",
       "             0.0691, 0.0691, 0.0724, 0.0757, 0.0757, 0.0757, 0.0757, 0.0789, 0.0789,\n",
       "             0.0822, 0.0822, 0.0822, 0.0855, 0.0888, 0.0888, 0.0888, 0.0888, 0.0921,\n",
       "             0.0954, 0.0987, 0.1020, 0.1020, 0.1053, 0.1086, 0.1118, 0.1151, 0.1184,\n",
       "             0.1217, 0.1250, 0.1283, 0.1316, 0.1349, 0.1382, 0.1414, 0.1447, 0.1480,\n",
       "             0.1513, 0.1546, 0.1579, 0.1612, 0.1645, 0.1678, 0.1711, 0.1743, 0.1776,\n",
       "             0.1809, 0.1809, 0.1842, 0.1875, 0.1908, 0.1941, 0.1941, 0.1974, 0.2007,\n",
       "             0.2039, 0.2072, 0.2105, 0.2138, 0.2171, 0.2204, 0.2237, 0.2237, 0.2270,\n",
       "             0.2303, 0.2336, 0.2368, 0.2401, 0.2434, 0.2467, 0.2500, 0.2533, 0.2566,\n",
       "             0.2599, 0.2632, 0.2632, 0.2664, 0.2664, 0.2697, 0.2730, 0.2763, 0.2796,\n",
       "             0.2829, 0.2862, 0.2895, 0.2928, 0.2961, 0.2961, 0.2993, 0.3026, 0.3059,\n",
       "             0.3092, 0.3125, 0.3158, 0.3191, 0.3224, 0.3257, 0.3289, 0.3322, 0.3355,\n",
       "             0.3388, 0.3421, 0.3454, 0.3487, 0.3520, 0.3553, 0.3586, 0.3618, 0.3651,\n",
       "             0.3684, 0.3717, 0.3750, 0.3783, 0.3816, 0.3849, 0.3882, 0.3914, 0.3947,\n",
       "             0.3980, 0.4013, 0.4046, 0.4079, 0.4112, 0.4145, 0.4178, 0.4211, 0.4243,\n",
       "             0.4276, 0.4309, 0.4342, 0.4375, 0.4408, 0.4441, 0.4474, 0.4507, 0.4539,\n",
       "             0.4572, 0.4605, 0.4638, 0.4671, 0.4704, 0.4737, 0.4770, 0.4803, 0.4836,\n",
       "             0.4868, 0.4901, 0.4934, 0.4967, 0.5000, 0.5033, 0.5066, 0.5099, 0.5132,\n",
       "             0.5164, 0.5197, 0.5230, 0.5263, 0.5296, 0.5329, 0.5362, 0.5395, 0.5428,\n",
       "             0.5461, 0.5493, 0.5526, 0.5559, 0.5592, 0.5625, 0.5658, 0.5691, 0.5724,\n",
       "             0.5757, 0.5789, 0.5822, 0.5855, 0.5888, 0.5921, 0.5954, 0.5987, 0.6020,\n",
       "             0.6053, 0.6086, 0.6118, 0.6151, 0.6184, 0.6217, 0.6250, 0.6283, 0.6316,\n",
       "             0.6349, 0.6382, 0.6414, 0.6447, 0.6480, 0.6513, 0.6546, 0.6579, 0.6612,\n",
       "             0.6645, 0.6678, 0.6711, 0.6743, 0.6776, 0.6809, 0.6842, 0.6875, 0.6908,\n",
       "             0.6941, 0.6974, 0.7007, 0.7039, 0.7072, 0.7105, 0.7138, 0.7171, 0.7204,\n",
       "             0.7237, 0.7270, 0.7303, 0.7336, 0.7368, 0.7401, 0.7434, 0.7467, 0.7500,\n",
       "             0.7533, 0.7566, 0.7599, 0.7632, 0.7664, 0.7697, 0.7730, 0.7763, 0.7796,\n",
       "             0.7829, 0.7862, 0.7895, 0.7928, 0.7961, 0.7993, 0.8026, 0.8059, 0.8092,\n",
       "             0.8125, 0.8158, 0.8191, 0.8224, 0.8257, 0.8289, 0.8322, 0.8355, 0.8388,\n",
       "             0.8421, 0.8454, 0.8487, 0.8520, 0.8553, 0.8586, 0.8618, 0.8651, 0.8684,\n",
       "             0.8717, 0.8750, 0.8783, 0.8816, 0.8849, 0.8882, 0.8914, 0.8947, 0.8980,\n",
       "             0.9013, 0.9046, 0.9079, 0.9112, 0.9145, 0.9178, 0.9211, 0.9243, 0.9276,\n",
       "             0.9309, 0.9342, 0.9375, 0.9408, 0.9441, 0.9474, 0.9507, 0.9539, 0.9572,\n",
       "             0.9605, 0.9638, 0.9671, 0.9704, 0.9737, 0.9770, 0.9803, 0.9836, 0.9868,\n",
       "             0.9901, 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.7950, 0.8282, 0.8373, 0.8499, 0.8580, 0.8648, 0.8683, 0.8729,\n",
       "             0.8763, 0.8797, 0.8832, 0.8843, 0.8855, 0.8866, 0.8900, 0.8923, 0.8935,\n",
       "             0.8958, 0.8981, 0.8992, 0.9015, 0.9061, 0.9084, 0.9095, 0.9118, 0.9129,\n",
       "             0.9141, 0.9152, 0.9164, 0.9175, 0.9187, 0.9198, 0.9210, 0.9221, 0.9233,\n",
       "             0.9244, 0.9255, 0.9267, 0.9278, 0.9290, 0.9301, 0.9313, 0.9324, 0.9336,\n",
       "             0.9347, 0.9359, 0.9370, 0.9381, 0.9393, 0.9404, 0.9416, 0.9427, 0.9439,\n",
       "             0.9450, 0.9450, 0.9462, 0.9473, 0.9473, 0.9485, 0.9496, 0.9507, 0.9507,\n",
       "             0.9519, 0.9519, 0.9530, 0.9542, 0.9542, 0.9553, 0.9565, 0.9565, 0.9576,\n",
       "             0.9588, 0.9588, 0.9599, 0.9611, 0.9622, 0.9633, 0.9645, 0.9656, 0.9668,\n",
       "             0.9679, 0.9691, 0.9702, 0.9714, 0.9714, 0.9714, 0.9725, 0.9737, 0.9737,\n",
       "             0.9748, 0.9759, 0.9759, 0.9759, 0.9771, 0.9782, 0.9782, 0.9794, 0.9805,\n",
       "             0.9805, 0.9817, 0.9817, 0.9817, 0.9828, 0.9840, 0.9851, 0.9851, 0.9863,\n",
       "             0.9863, 0.9874, 0.9885, 0.9885, 0.9885, 0.9897, 0.9908, 0.9920, 0.9920,\n",
       "             0.9920, 0.9920, 0.9920, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931,\n",
       "             0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931,\n",
       "             0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931,\n",
       "             0.9931, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9954, 0.9954, 0.9954,\n",
       "             0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9954, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9977, 0.9977, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01, 9.9996e-01,\n",
       "             9.9996e-01, 9.9996e-01, 9.9996e-01, 9.9995e-01, 9.9994e-01, 9.9993e-01,\n",
       "             9.9993e-01, 9.9993e-01, 9.9993e-01, 9.9991e-01, 9.9989e-01, 9.9988e-01,\n",
       "             9.9988e-01, 9.9987e-01, 9.9986e-01, 9.9982e-01, 9.9977e-01, 9.9976e-01,\n",
       "             9.9975e-01, 9.9974e-01, 9.9967e-01, 9.9966e-01, 9.9964e-01, 9.9950e-01,\n",
       "             9.9949e-01, 9.9944e-01, 9.9919e-01, 9.9916e-01, 9.9902e-01, 9.9874e-01,\n",
       "             9.9852e-01, 9.9831e-01, 9.9830e-01, 9.9781e-01, 9.9735e-01, 9.9702e-01,\n",
       "             9.9694e-01, 9.9676e-01, 9.9634e-01, 9.9609e-01, 9.9406e-01, 9.9389e-01,\n",
       "             9.9335e-01, 9.9309e-01, 9.9234e-01, 9.9131e-01, 9.9098e-01, 9.8872e-01,\n",
       "             9.8518e-01, 9.8264e-01, 9.7291e-01, 9.5423e-01, 9.5342e-01, 9.5060e-01,\n",
       "             9.4909e-01, 9.4882e-01, 9.4556e-01, 9.4061e-01, 9.3727e-01, 9.1842e-01,\n",
       "             9.0650e-01, 8.8941e-01, 8.7347e-01, 8.6123e-01, 8.6108e-01, 8.5113e-01,\n",
       "             7.7457e-01, 7.3035e-01, 6.6470e-01, 6.6446e-01, 6.2278e-01, 5.7795e-01,\n",
       "             5.6275e-01, 5.5854e-01, 5.2411e-01, 5.0130e-01, 4.5169e-01, 4.3158e-01,\n",
       "             3.6414e-01, 2.1954e-01, 1.9185e-01, 1.4197e-01, 1.3954e-01, 1.3597e-01,\n",
       "             9.6032e-02, 8.4016e-02, 5.2165e-02, 4.8580e-02, 4.5914e-02, 2.8372e-02,\n",
       "             2.5319e-02, 1.8770e-02, 1.8338e-02, 1.7950e-02, 1.4605e-02, 1.4549e-02,\n",
       "             1.3584e-02, 1.1691e-02, 1.0098e-02, 9.7631e-03, 8.8883e-03, 7.8653e-03,\n",
       "             7.0442e-03, 5.2857e-03, 4.5150e-03, 3.6618e-03, 2.6304e-03, 2.2645e-03,\n",
       "             1.8807e-03, 1.4082e-03, 9.3250e-04, 9.0116e-04, 8.2317e-04, 7.7757e-04,\n",
       "             5.1538e-04, 4.1842e-04, 3.8197e-04, 3.5731e-04, 2.5923e-04, 2.5755e-04,\n",
       "             1.2145e-04, 1.1065e-04, 1.0940e-04, 8.7445e-05, 7.9692e-05, 7.0703e-05,\n",
       "             4.8156e-05, 3.9831e-05, 3.7507e-05, 3.7225e-05, 2.3282e-05, 2.2304e-05,\n",
       "             2.1540e-05, 2.1371e-05, 2.0706e-05, 1.9575e-05, 1.8770e-05, 1.6750e-05,\n",
       "             1.5349e-05, 1.3825e-05, 1.0113e-05, 9.2036e-06, 8.5331e-06, 7.7266e-06,\n",
       "             7.1806e-06, 5.8582e-06, 5.4885e-06, 5.1387e-06, 4.8250e-06, 4.0289e-06,\n",
       "             3.1569e-06, 3.1511e-06, 2.8240e-06, 2.6724e-06, 2.5671e-06, 2.1737e-06,\n",
       "             1.7429e-06, 9.9936e-07, 8.1196e-07, 8.0434e-07, 6.4418e-07, 5.8661e-07,\n",
       "             5.7933e-07, 5.7566e-07, 5.4391e-07, 5.3248e-07, 5.0547e-07, 4.6375e-07,\n",
       "             4.2435e-07, 3.6169e-07, 3.3805e-07, 3.3455e-07, 3.3277e-07, 3.0262e-07,\n",
       "             2.8188e-07, 2.3830e-07, 2.0680e-07, 1.9049e-07, 1.6427e-07, 1.2594e-07,\n",
       "             1.1840e-07, 8.0713e-08, 7.8793e-08, 7.8782e-08, 5.7112e-08, 5.3930e-08,\n",
       "             3.6286e-08, 3.4501e-08, 3.2654e-08, 2.5635e-08, 2.2616e-08, 2.0641e-08,\n",
       "             1.9872e-08, 1.8969e-08, 1.8116e-08, 1.6682e-08, 1.6558e-08, 1.5859e-08,\n",
       "             1.5312e-08, 1.1135e-08, 1.1021e-08, 1.0730e-08, 8.9364e-09, 8.4541e-09,\n",
       "             7.8123e-09, 7.3091e-09, 7.1136e-09, 6.2477e-09, 6.1086e-09, 5.9087e-09,\n",
       "             5.8897e-09, 5.5949e-09, 5.0585e-09, 4.7929e-09, 4.4455e-09, 3.9121e-09,\n",
       "             3.3342e-09, 3.2197e-09, 2.8984e-09, 2.8250e-09, 2.7219e-09, 1.7912e-09,\n",
       "             1.5696e-09, 1.3134e-09, 1.1925e-09, 1.1780e-09, 1.0732e-09, 9.8221e-10,\n",
       "             9.6175e-10, 8.2748e-10, 7.9363e-10, 6.0986e-10, 5.9861e-10, 5.7320e-10,\n",
       "             4.1987e-10, 3.6584e-10, 2.9200e-10, 2.5496e-10, 2.4972e-10, 2.2540e-10,\n",
       "             1.5285e-10, 1.3122e-10, 1.2483e-10, 1.1313e-10, 9.6272e-11, 7.7510e-11,\n",
       "             7.3713e-11, 6.4173e-11, 5.8209e-11, 5.7305e-11, 5.0626e-11, 4.4844e-11,\n",
       "             4.2383e-11, 4.0488e-11, 4.0139e-11, 3.4055e-11, 2.7292e-11, 2.5550e-11,\n",
       "             2.4468e-11, 2.2829e-11, 1.5903e-11, 1.3712e-11, 1.2224e-11, 1.1257e-11,\n",
       "             9.6460e-12, 7.7197e-12, 5.6371e-12, 4.5658e-12, 3.2727e-12, 3.2019e-12,\n",
       "             2.7752e-12, 2.5617e-12, 1.7159e-12, 1.5845e-12, 1.5565e-12, 1.4828e-12,\n",
       "             1.1418e-12, 1.0255e-12, 9.2246e-13, 8.3785e-13, 7.7438e-13, 7.1671e-13,\n",
       "             6.5876e-13, 6.5564e-13, 5.7458e-13, 5.6083e-13, 4.9392e-13, 4.4118e-13,\n",
       "             4.1608e-13, 3.8826e-13, 3.4182e-13, 3.2735e-13, 2.9248e-13, 2.4837e-13,\n",
       "             2.0433e-13, 1.8641e-13, 1.4622e-13, 7.7741e-14, 7.3269e-14, 7.2671e-14,\n",
       "             7.1698e-14, 6.9794e-14, 6.6237e-14, 6.5352e-14, 4.4759e-14, 3.9862e-14,\n",
       "             2.4474e-14, 2.0791e-14, 1.7938e-14, 1.5844e-14, 6.2983e-15, 5.6475e-15,\n",
       "             3.6196e-15, 3.3536e-15, 2.6120e-15, 2.1364e-15, 1.3300e-15, 1.2471e-15,\n",
       "             1.2438e-15, 1.2341e-15, 1.0267e-15, 1.0108e-15, 8.4275e-16, 5.8087e-16,\n",
       "             5.4593e-16, 1.5754e-16, 1.4745e-16, 9.9001e-17, 5.6980e-17, 5.5530e-17,\n",
       "             2.6460e-17, 1.6027e-17, 1.5665e-17, 9.0270e-18, 4.0013e-18, 1.6302e-18,\n",
       "             1.1097e-18, 9.5623e-19, 4.6432e-19, 2.4010e-19, 1.1908e-19, 3.6979e-21,\n",
       "             1.3850e-22, 1.4794e-23, 1.2177e-23, 3.2834e-24])}},\n",
       "   {'fpr': np.float64(0.05592105263157895),\n",
       "    'tpr': np.float64(0.9782359679266895),\n",
       "    'model': LitSimpleCNN(\n",
       "      (model): SimpleCNN(\n",
       "        (features): Sequential(\n",
       "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): ReLU()\n",
       "          (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): ReLU()\n",
       "          (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): ReLU()\n",
       "          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "        (relu_fc): ReLU()\n",
       "        (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "      )\n",
       "      (criterion): BCEWithLogitsLoss()\n",
       "      (train_accuracy): BinaryAccuracy()\n",
       "      (val_accuracy): BinaryAccuracy()\n",
       "      (val_auc): BinaryAUROC()\n",
       "      (test_accuracy): BinaryAccuracy()\n",
       "      (test_auc): BinaryAUROC()\n",
       "      (test_precision): BinaryPrecision()\n",
       "      (test_recall): BinaryRecall()\n",
       "      (test_f1): BinaryF1Score()\n",
       "    ),\n",
       "    'threshold': 0.5,\n",
       "    'full_roc': {'fpr': tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "             0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033,\n",
       "             0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0033, 0.0066, 0.0066, 0.0066,\n",
       "             0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066,\n",
       "             0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0066, 0.0099,\n",
       "             0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
       "             0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
       "             0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
       "             0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099,\n",
       "             0.0099, 0.0099, 0.0099, 0.0099, 0.0132, 0.0132, 0.0132, 0.0132, 0.0132,\n",
       "             0.0132, 0.0132, 0.0132, 0.0164, 0.0164, 0.0197, 0.0197, 0.0197, 0.0197,\n",
       "             0.0197, 0.0230, 0.0230, 0.0230, 0.0263, 0.0263, 0.0263, 0.0263, 0.0296,\n",
       "             0.0329, 0.0362, 0.0362, 0.0362, 0.0362, 0.0362, 0.0362, 0.0395, 0.0428,\n",
       "             0.0428, 0.0461, 0.0493, 0.0526, 0.0559, 0.0559, 0.0592, 0.0592, 0.0592,\n",
       "             0.0625, 0.0625, 0.0658, 0.0658, 0.0658, 0.0658, 0.0691, 0.0724, 0.0757,\n",
       "             0.0789, 0.0789, 0.0789, 0.0789, 0.0789, 0.0822, 0.0855, 0.0855, 0.0888,\n",
       "             0.0921, 0.0954, 0.0954, 0.0987, 0.1020, 0.1020, 0.1053, 0.1053, 0.1086,\n",
       "             0.1118, 0.1151, 0.1184, 0.1217, 0.1250, 0.1283, 0.1316, 0.1349, 0.1382,\n",
       "             0.1382, 0.1414, 0.1414, 0.1447, 0.1480, 0.1513, 0.1546, 0.1579, 0.1612,\n",
       "             0.1645, 0.1678, 0.1711, 0.1743, 0.1776, 0.1809, 0.1809, 0.1842, 0.1875,\n",
       "             0.1908, 0.1941, 0.1974, 0.2007, 0.2039, 0.2072, 0.2105, 0.2138, 0.2171,\n",
       "             0.2204, 0.2237, 0.2270, 0.2303, 0.2336, 0.2368, 0.2401, 0.2434, 0.2467,\n",
       "             0.2500, 0.2533, 0.2566, 0.2599, 0.2632, 0.2664, 0.2697, 0.2730, 0.2763,\n",
       "             0.2796, 0.2796, 0.2829, 0.2862, 0.2895, 0.2928, 0.2961, 0.2993, 0.3026,\n",
       "             0.3059, 0.3092, 0.3125, 0.3158, 0.3191, 0.3224, 0.3257, 0.3289, 0.3322,\n",
       "             0.3355, 0.3388, 0.3421, 0.3454, 0.3487, 0.3520, 0.3553, 0.3586, 0.3618,\n",
       "             0.3651, 0.3684, 0.3717, 0.3750, 0.3750, 0.3783, 0.3816, 0.3849, 0.3882,\n",
       "             0.3914, 0.3947, 0.3980, 0.4013, 0.4046, 0.4079, 0.4112, 0.4145, 0.4178,\n",
       "             0.4211, 0.4243, 0.4276, 0.4309, 0.4342, 0.4375, 0.4408, 0.4441, 0.4474,\n",
       "             0.4507, 0.4539, 0.4572, 0.4605, 0.4638, 0.4671, 0.4704, 0.4737, 0.4770,\n",
       "             0.4803, 0.4836, 0.4868, 0.4901, 0.4934, 0.4967, 0.5000, 0.5033, 0.5066,\n",
       "             0.5099, 0.5132, 0.5164, 0.5197, 0.5230, 0.5263, 0.5296, 0.5329, 0.5362,\n",
       "             0.5395, 0.5428, 0.5461, 0.5493, 0.5526, 0.5559, 0.5592, 0.5625, 0.5658,\n",
       "             0.5691, 0.5724, 0.5757, 0.5789, 0.5822, 0.5855, 0.5888, 0.5921, 0.5954,\n",
       "             0.5987, 0.6020, 0.6053, 0.6086, 0.6118, 0.6151, 0.6184, 0.6217, 0.6250,\n",
       "             0.6283, 0.6316, 0.6349, 0.6382, 0.6414, 0.6447, 0.6480, 0.6513, 0.6546,\n",
       "             0.6579, 0.6612, 0.6645, 0.6678, 0.6711, 0.6743, 0.6776, 0.6809, 0.6842,\n",
       "             0.6875, 0.6908, 0.6941, 0.6974, 0.7007, 0.7039, 0.7072, 0.7105, 0.7138,\n",
       "             0.7171, 0.7204, 0.7237, 0.7270, 0.7303, 0.7336, 0.7368, 0.7401, 0.7434,\n",
       "             0.7467, 0.7500, 0.7533, 0.7566, 0.7599, 0.7632, 0.7664, 0.7697, 0.7730,\n",
       "             0.7763, 0.7796, 0.7829, 0.7862, 0.7895, 0.7928, 0.7961, 0.7993, 0.8026,\n",
       "             0.8059, 0.8092, 0.8125, 0.8158, 0.8191, 0.8224, 0.8257, 0.8289, 0.8322,\n",
       "             0.8355, 0.8388, 0.8421, 0.8454, 0.8487, 0.8520, 0.8553, 0.8586, 0.8618,\n",
       "             0.8651, 0.8684, 0.8717, 0.8750, 0.8783, 0.8816, 0.8849, 0.8882, 0.8914,\n",
       "             0.8947, 0.8980, 0.9013, 0.9046, 0.9079, 0.9112, 0.9145, 0.9178, 0.9211,\n",
       "             0.9243, 0.9276, 0.9309, 0.9342, 0.9375, 0.9408, 0.9441, 0.9474, 0.9507,\n",
       "             0.9539, 0.9572, 0.9605, 0.9638, 0.9671, 0.9704, 0.9737, 0.9770, 0.9803,\n",
       "             0.9836, 0.9868, 0.9901, 0.9934, 0.9967, 1.0000]),\n",
       "     'tpr': tensor([0.0000, 0.7801, 0.8087, 0.8236, 0.8259, 0.8316, 0.8362, 0.8419, 0.8465,\n",
       "             0.8499, 0.8511, 0.8522, 0.8534, 0.8557, 0.8580, 0.8603, 0.8603, 0.8614,\n",
       "             0.8625, 0.8637, 0.8648, 0.8660, 0.8683, 0.8706, 0.8717, 0.8729, 0.8740,\n",
       "             0.8751, 0.8763, 0.8786, 0.8797, 0.8809, 0.8820, 0.8820, 0.8832, 0.8843,\n",
       "             0.8855, 0.8866, 0.8877, 0.8889, 0.8912, 0.8923, 0.8935, 0.8946, 0.8958,\n",
       "             0.8969, 0.8981, 0.8992, 0.9003, 0.9015, 0.9026, 0.9038, 0.9049, 0.9049,\n",
       "             0.9061, 0.9072, 0.9084, 0.9095, 0.9107, 0.9118, 0.9129, 0.9141, 0.9152,\n",
       "             0.9164, 0.9175, 0.9187, 0.9198, 0.9210, 0.9221, 0.9233, 0.9244, 0.9255,\n",
       "             0.9267, 0.9278, 0.9290, 0.9301, 0.9313, 0.9324, 0.9336, 0.9347, 0.9359,\n",
       "             0.9370, 0.9381, 0.9393, 0.9404, 0.9416, 0.9427, 0.9439, 0.9450, 0.9462,\n",
       "             0.9473, 0.9485, 0.9496, 0.9507, 0.9507, 0.9519, 0.9530, 0.9542, 0.9553,\n",
       "             0.9565, 0.9576, 0.9588, 0.9588, 0.9599, 0.9599, 0.9611, 0.9622, 0.9633,\n",
       "             0.9645, 0.9645, 0.9656, 0.9668, 0.9668, 0.9679, 0.9691, 0.9702, 0.9702,\n",
       "             0.9702, 0.9702, 0.9714, 0.9725, 0.9737, 0.9748, 0.9759, 0.9759, 0.9759,\n",
       "             0.9771, 0.9771, 0.9771, 0.9771, 0.9771, 0.9782, 0.9782, 0.9794, 0.9805,\n",
       "             0.9805, 0.9817, 0.9817, 0.9828, 0.9840, 0.9851, 0.9851, 0.9851, 0.9851,\n",
       "             0.9851, 0.9863, 0.9874, 0.9885, 0.9897, 0.9897, 0.9897, 0.9908, 0.9908,\n",
       "             0.9908, 0.9908, 0.9920, 0.9920, 0.9920, 0.9931, 0.9931, 0.9943, 0.9943,\n",
       "             0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943, 0.9943,\n",
       "             0.9954, 0.9954, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966,\n",
       "             0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9966, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977, 0.9977,\n",
       "             0.9977, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "             0.9989, 0.9989, 0.9989, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "             1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "     'thresholds': tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "             1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01, 9.9999e-01,\n",
       "             9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9998e-01, 9.9997e-01,\n",
       "             9.9997e-01, 9.9997e-01, 9.9996e-01, 9.9995e-01, 9.9995e-01, 9.9994e-01,\n",
       "             9.9994e-01, 9.9994e-01, 9.9993e-01, 9.9992e-01, 9.9991e-01, 9.9990e-01,\n",
       "             9.9989e-01, 9.9985e-01, 9.9985e-01, 9.9985e-01, 9.9984e-01, 9.9981e-01,\n",
       "             9.9980e-01, 9.9979e-01, 9.9978e-01, 9.9976e-01, 9.9976e-01, 9.9974e-01,\n",
       "             9.9965e-01, 9.9964e-01, 9.9963e-01, 9.9963e-01, 9.9963e-01, 9.9962e-01,\n",
       "             9.9955e-01, 9.9948e-01, 9.9938e-01, 9.9936e-01, 9.9931e-01, 9.9918e-01,\n",
       "             9.9909e-01, 9.9865e-01, 9.9833e-01, 9.9775e-01, 9.9763e-01, 9.9697e-01,\n",
       "             9.9688e-01, 9.9652e-01, 9.9639e-01, 9.9530e-01, 9.9518e-01, 9.9497e-01,\n",
       "             9.9479e-01, 9.9463e-01, 9.9459e-01, 9.9410e-01, 9.9409e-01, 9.9329e-01,\n",
       "             9.9284e-01, 9.9264e-01, 9.9261e-01, 9.9172e-01, 9.9024e-01, 9.8904e-01,\n",
       "             9.8416e-01, 9.8398e-01, 9.8391e-01, 9.7604e-01, 9.7567e-01, 9.7433e-01,\n",
       "             9.7411e-01, 9.7227e-01, 9.7196e-01, 9.6967e-01, 9.6310e-01, 9.5781e-01,\n",
       "             9.5628e-01, 9.5200e-01, 9.4686e-01, 9.4650e-01, 9.4070e-01, 9.2112e-01,\n",
       "             9.1821e-01, 8.9795e-01, 8.9766e-01, 8.7184e-01, 8.6806e-01, 8.6769e-01,\n",
       "             8.6021e-01, 7.6720e-01, 7.0475e-01, 6.8686e-01, 6.2231e-01, 5.7857e-01,\n",
       "             3.9709e-01, 3.2676e-01, 3.0241e-01, 2.9333e-01, 2.0963e-01, 1.5054e-01,\n",
       "             1.4476e-01, 1.4173e-01, 1.3058e-01, 8.5378e-02, 7.9462e-02, 3.8723e-02,\n",
       "             3.6934e-02, 2.8715e-02, 2.8198e-02, 1.7384e-02, 1.7369e-02, 8.9205e-03,\n",
       "             7.0605e-03, 3.9990e-03, 2.6726e-03, 1.7290e-03, 1.4921e-03, 9.4835e-04,\n",
       "             8.6367e-04, 7.5790e-04, 5.3087e-04, 5.1943e-04, 4.2687e-04, 3.4470e-04,\n",
       "             1.7904e-04, 1.6877e-04, 1.4132e-04, 1.1914e-04, 9.8637e-05, 8.9513e-05,\n",
       "             8.6545e-05, 6.9600e-05, 6.2527e-05, 6.0310e-05, 2.6988e-05, 2.2882e-05,\n",
       "             2.2272e-05, 1.9570e-05, 1.6078e-05, 1.4407e-05, 1.3017e-05, 7.1417e-06,\n",
       "             4.6072e-06, 2.1109e-06, 1.0926e-06, 9.6170e-07, 9.3919e-07, 7.8920e-07,\n",
       "             4.7735e-07, 4.6905e-07, 4.1466e-07, 3.4436e-07, 3.4264e-07, 3.1507e-07,\n",
       "             2.9750e-07, 2.9715e-07, 2.8353e-07, 2.7946e-07, 1.8027e-07, 1.7115e-07,\n",
       "             1.3285e-07, 1.0440e-07, 8.6431e-08, 7.7255e-08, 5.2340e-08, 4.0141e-08,\n",
       "             2.9723e-08, 2.1754e-08, 1.7415e-08, 1.6314e-08, 1.5192e-08, 1.0983e-08,\n",
       "             6.8954e-09, 5.8400e-09, 5.7724e-09, 3.8409e-09, 3.4806e-09, 3.4059e-09,\n",
       "             2.9491e-09, 2.7990e-09, 2.7227e-09, 2.3597e-09, 2.3477e-09, 2.2509e-09,\n",
       "             1.7261e-09, 1.3116e-09, 1.2724e-09, 1.2621e-09, 1.0407e-09, 9.8080e-10,\n",
       "             6.0515e-10, 5.3904e-10, 5.3397e-10, 5.1410e-10, 5.0718e-10, 4.3403e-10,\n",
       "             4.2179e-10, 4.0485e-10, 3.9125e-10, 3.5307e-10, 3.4842e-10, 3.1009e-10,\n",
       "             2.9597e-10, 2.6320e-10, 2.2231e-10, 1.2995e-10, 7.0321e-11, 6.2436e-11,\n",
       "             6.2319e-11, 6.0762e-11, 6.0435e-11, 5.5361e-11, 5.3550e-11, 4.6332e-11,\n",
       "             3.7187e-11, 2.7731e-11, 2.5191e-11, 2.4558e-11, 2.4493e-11, 2.4479e-11,\n",
       "             2.2311e-11, 1.5546e-11, 1.5147e-11, 1.2765e-11, 1.0986e-11, 1.0282e-11,\n",
       "             1.0236e-11, 1.0169e-11, 7.8837e-12, 6.9329e-12, 6.2287e-12, 6.0182e-12,\n",
       "             5.2228e-12, 4.6890e-12, 3.7130e-12, 2.6920e-12, 2.0165e-12, 1.2999e-12,\n",
       "             1.1915e-12, 8.6548e-13, 7.8341e-13, 7.4957e-13, 7.3163e-13, 6.5100e-13,\n",
       "             5.4638e-13, 3.2502e-13, 2.9503e-13, 2.5495e-13, 1.7923e-13, 1.5603e-13,\n",
       "             1.2555e-13, 1.0282e-13, 5.0474e-14, 4.6205e-14, 2.5839e-14, 1.9891e-14,\n",
       "             1.9184e-14, 1.7409e-14, 1.5447e-14, 1.5329e-14, 1.2466e-14, 1.2024e-14,\n",
       "             1.0160e-14, 1.0101e-14, 8.6405e-15, 8.5331e-15, 4.4710e-15, 4.4622e-15,\n",
       "             4.2292e-15, 4.2190e-15, 3.8142e-15, 3.7275e-15, 3.4074e-15, 3.0326e-15,\n",
       "             2.7170e-15, 2.3550e-15, 2.2612e-15, 1.8260e-15, 1.2404e-15, 1.0730e-15,\n",
       "             9.1413e-16, 9.0923e-16, 8.6207e-16, 8.3795e-16, 7.6821e-16, 7.3214e-16,\n",
       "             7.2846e-16, 6.7984e-16, 5.9535e-16, 5.9358e-16, 4.8837e-16, 4.4510e-16,\n",
       "             3.6368e-16, 3.5848e-16, 3.0656e-16, 2.7301e-16, 2.4867e-16, 2.4135e-16,\n",
       "             1.8515e-16, 1.8011e-16, 1.5361e-16, 1.2985e-16, 1.0588e-16, 9.4896e-17,\n",
       "             7.7639e-17, 7.1235e-17, 6.4968e-17, 5.8188e-17, 4.9143e-17, 4.7618e-17,\n",
       "             4.2758e-17, 3.9464e-17, 3.4049e-17, 3.0811e-17, 2.2151e-17, 1.9834e-17,\n",
       "             1.8522e-17, 1.6347e-17, 1.1987e-17, 1.1379e-17, 1.0964e-17, 1.0082e-17,\n",
       "             9.3393e-18, 7.3540e-18, 5.4252e-18, 4.6941e-18, 4.5822e-18, 4.0521e-18,\n",
       "             3.6058e-18, 3.5278e-18, 2.1278e-18, 1.9591e-18, 1.6842e-18, 1.4964e-18,\n",
       "             1.3369e-18, 1.1036e-18, 9.2863e-19, 9.0231e-19, 8.6086e-19, 8.3988e-19,\n",
       "             7.3995e-19, 6.8766e-19, 5.6539e-19, 4.4663e-19, 4.0895e-19, 4.0132e-19,\n",
       "             3.9078e-19, 3.8575e-19, 2.9082e-19, 2.6984e-19, 2.6691e-19, 1.9478e-19,\n",
       "             1.6975e-19, 1.5867e-19, 1.2293e-19, 7.3191e-20, 6.2268e-20, 5.5952e-20,\n",
       "             5.1220e-20, 4.0869e-20, 3.6580e-20, 9.6597e-21, 5.3104e-21, 2.1943e-21,\n",
       "             1.8005e-21, 1.7627e-21, 1.7251e-21, 1.4454e-21, 1.1475e-21, 8.5215e-22,\n",
       "             7.4256e-22, 7.2293e-22, 6.8830e-22, 6.5427e-22, 3.5722e-22, 2.8469e-22,\n",
       "             2.7477e-22, 2.5860e-22, 1.2840e-22, 1.1152e-22, 8.1854e-23, 3.7000e-23,\n",
       "             1.5634e-23, 6.0398e-24, 5.9221e-24, 5.4105e-24, 5.1001e-24, 4.3057e-24,\n",
       "             3.4070e-24, 2.8045e-24, 9.2160e-25, 7.9068e-25, 1.5910e-25, 1.5539e-25,\n",
       "             3.3493e-26, 1.5164e-26, 4.1168e-28, 8.8454e-30, 4.8627e-31, 2.1256e-32])}}]],\n",
       " 'roc_results': {'fpr': tensor([0.0000, 0.0043, 0.0043, 0.0043, 0.0043, 0.0085, 0.0085, 0.0085, 0.0085,\n",
       "          0.0085, 0.0085, 0.0085, 0.0085, 0.0128, 0.0128, 0.0128, 0.0128, 0.0128,\n",
       "          0.0128, 0.0128, 0.0128, 0.0171, 0.0171, 0.0171, 0.0171, 0.0214, 0.0214,\n",
       "          0.0256, 0.0256, 0.0256, 0.0256, 0.0256, 0.0256, 0.0299, 0.0299, 0.0299,\n",
       "          0.0299, 0.0299, 0.0299, 0.0299, 0.0299, 0.0299, 0.0299, 0.0342, 0.0342,\n",
       "          0.0342, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0427, 0.0427, 0.0427,\n",
       "          0.0427, 0.0427, 0.0427, 0.0427, 0.0427, 0.0427, 0.0427, 0.0427, 0.0470,\n",
       "          0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0470, 0.0513, 0.0513,\n",
       "          0.0513, 0.0513, 0.0513, 0.0513, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556,\n",
       "          0.0556, 0.0598, 0.0598, 0.0598, 0.0598, 0.0641, 0.0641, 0.0641, 0.0641,\n",
       "          0.0641, 0.0641, 0.0641, 0.0641, 0.0641, 0.0641, 0.0641, 0.0641, 0.0641,\n",
       "          0.0641, 0.0684, 0.0684, 0.0684, 0.0684, 0.0684, 0.0684, 0.0684, 0.0684,\n",
       "          0.0684, 0.0684, 0.0684, 0.0684, 0.0684, 0.0726, 0.0726, 0.0726, 0.0726,\n",
       "          0.0726, 0.0726, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0812,\n",
       "          0.0812, 0.0812, 0.0812, 0.0855, 0.0940, 0.0940, 0.0940, 0.0940, 0.0940,\n",
       "          0.0983, 0.0983, 0.1026, 0.1026, 0.1026, 0.1026, 0.1026, 0.1026, 0.1026,\n",
       "          0.1026, 0.1068, 0.1068, 0.1068, 0.1068, 0.1154, 0.1154, 0.1154, 0.1154,\n",
       "          0.1154, 0.1154, 0.1154, 0.1154, 0.1197, 0.1197, 0.1197, 0.1197, 0.1197,\n",
       "          0.1197, 0.1197, 0.1197, 0.1197, 0.1197, 0.1197, 0.1239, 0.1239, 0.1239,\n",
       "          0.1282, 0.1282, 0.1282, 0.1282, 0.1282, 0.1282, 0.1282, 0.1282, 0.1282,\n",
       "          0.1325, 0.1368, 0.1368, 0.1368, 0.1368, 0.1368, 0.1410, 0.1410, 0.1410,\n",
       "          0.1453, 0.1496, 0.1496, 0.1496, 0.1496, 0.1538, 0.1538, 0.1581, 0.1624,\n",
       "          0.1624, 0.1667, 0.1667, 0.1709, 0.1752, 0.1795, 0.1838, 0.1838, 0.1838,\n",
       "          0.1880, 0.1880, 0.1923, 0.1923, 0.1923, 0.1966, 0.2009, 0.2009, 0.2051,\n",
       "          0.2051, 0.2051, 0.2051, 0.2051, 0.2051, 0.2094, 0.2094, 0.2094, 0.2179,\n",
       "          0.2179, 0.2179, 0.2179, 0.2222, 0.2265, 0.2308, 0.2350, 0.2393, 0.2393,\n",
       "          0.2436, 0.2479, 0.2479, 0.2521, 0.2521, 0.2521, 0.2521, 0.2564, 0.2607,\n",
       "          0.2650, 0.2735, 0.2778, 0.2778, 0.2778, 0.2821, 0.2863, 0.2906, 0.2949,\n",
       "          0.2991, 0.3034, 0.3034, 0.3077, 0.3077, 0.3077, 0.3120, 0.3162, 0.3162,\n",
       "          0.3205, 0.3248, 0.3291, 0.3333, 0.3376, 0.3419, 0.3462, 0.3504, 0.3547,\n",
       "          0.3590, 0.3632, 0.3675, 0.3718, 0.3761, 0.3803, 0.3846, 0.3846, 0.3889,\n",
       "          0.3932, 0.3932, 0.3974, 0.3974, 0.3974, 0.4017, 0.4060, 0.4103, 0.4145,\n",
       "          0.4188, 0.4231, 0.4274, 0.4316, 0.4359, 0.4359, 0.4359, 0.4402, 0.4402,\n",
       "          0.4444, 0.4487, 0.4530, 0.4573, 0.4573, 0.4615, 0.4658, 0.4701, 0.4744,\n",
       "          0.4744, 0.4786, 0.4829, 0.4872, 0.4957, 0.5000, 0.5000, 0.5043, 0.5043,\n",
       "          0.5085, 0.5128, 0.5171, 0.5214, 0.5256, 0.5299, 0.5299, 0.5342, 0.5385,\n",
       "          0.5427, 0.5470, 0.5513, 0.5556, 0.5598, 0.5641, 0.5684, 0.5726, 0.5769,\n",
       "          0.5812, 0.5855, 0.5897, 0.5897, 0.5940, 0.5983, 0.6026, 0.6068, 0.6111,\n",
       "          0.6154, 0.6197, 0.6239, 0.6282, 0.6325, 0.6368, 0.6410, 0.6453, 0.6496,\n",
       "          0.6496, 0.6538, 0.6581, 0.6624, 0.6667, 0.6709, 0.6752, 0.6838, 0.6880,\n",
       "          0.6923, 0.6966, 0.7009, 0.7051, 0.7094, 0.7137, 0.7222, 0.7265, 0.7308,\n",
       "          0.7350, 0.7393, 0.7436, 0.7479, 0.7521, 0.7564, 0.7607, 0.7650, 0.7692,\n",
       "          0.7735, 0.7778, 0.7821, 0.7863, 0.7949, 0.7991, 0.8034, 0.8120, 0.8162,\n",
       "          0.8205, 0.8248, 0.8291, 0.8333, 0.8376, 0.8419, 0.8462, 0.8504, 0.8547,\n",
       "          0.8590, 0.8632, 0.8675, 0.8718, 0.8761, 0.8803, 0.8846, 0.8889, 0.8932,\n",
       "          0.8974, 0.9017, 0.9060, 0.9103, 0.9145, 0.9188, 0.9231, 0.9274, 0.9316,\n",
       "          0.9359, 0.9402, 0.9444, 0.9487, 0.9530, 0.9573, 0.9615, 0.9658, 0.9701,\n",
       "          0.9744, 0.9786, 0.9829, 0.9872, 0.9915, 0.9957, 1.0000]),\n",
       "  'tpr': tensor([0.0000, 0.0000, 0.0026, 0.0077, 0.0179, 0.0282, 0.0462, 0.0615, 0.0846,\n",
       "          0.1051, 0.1282, 0.1436, 0.1615, 0.1846, 0.2051, 0.2103, 0.2205, 0.2282,\n",
       "          0.2462, 0.2538, 0.2692, 0.2744, 0.2821, 0.2897, 0.2974, 0.3026, 0.3154,\n",
       "          0.3205, 0.3282, 0.3385, 0.3410, 0.3462, 0.3538, 0.3564, 0.3667, 0.3769,\n",
       "          0.3795, 0.3821, 0.3923, 0.4000, 0.4051, 0.4128, 0.4179, 0.4308, 0.4333,\n",
       "          0.4359, 0.4410, 0.4487, 0.4564, 0.4590, 0.4692, 0.4744, 0.4821, 0.4872,\n",
       "          0.4897, 0.4949, 0.4974, 0.5026, 0.5051, 0.5077, 0.5154, 0.5231, 0.5282,\n",
       "          0.5333, 0.5359, 0.5385, 0.5436, 0.5462, 0.5487, 0.5538, 0.5564, 0.5590,\n",
       "          0.5615, 0.5692, 0.5718, 0.5744, 0.5795, 0.5821, 0.5846, 0.5872, 0.5897,\n",
       "          0.5949, 0.5949, 0.5974, 0.6000, 0.6026, 0.6026, 0.6051, 0.6077, 0.6103,\n",
       "          0.6128, 0.6154, 0.6179, 0.6205, 0.6231, 0.6282, 0.6308, 0.6359, 0.6385,\n",
       "          0.6410, 0.6436, 0.6462, 0.6487, 0.6513, 0.6538, 0.6564, 0.6615, 0.6641,\n",
       "          0.6692, 0.6718, 0.6744, 0.6769, 0.6795, 0.6795, 0.6821, 0.6846, 0.6872,\n",
       "          0.6923, 0.6949, 0.6949, 0.7000, 0.7051, 0.7077, 0.7103, 0.7128, 0.7154,\n",
       "          0.7179, 0.7205, 0.7231, 0.7256, 0.7282, 0.7308, 0.7333, 0.7359, 0.7385,\n",
       "          0.7436, 0.7462, 0.7462, 0.7487, 0.7513, 0.7538, 0.7590, 0.7615, 0.7641,\n",
       "          0.7667, 0.7667, 0.7692, 0.7718, 0.7744, 0.7744, 0.7769, 0.7795, 0.7821,\n",
       "          0.7872, 0.7897, 0.7949, 0.7974, 0.7974, 0.8000, 0.8026, 0.8051, 0.8077,\n",
       "          0.8103, 0.8128, 0.8154, 0.8179, 0.8205, 0.8231, 0.8231, 0.8256, 0.8282,\n",
       "          0.8282, 0.8308, 0.8333, 0.8359, 0.8385, 0.8410, 0.8436, 0.8462, 0.8487,\n",
       "          0.8487, 0.8487, 0.8513, 0.8538, 0.8564, 0.8590, 0.8590, 0.8615, 0.8667,\n",
       "          0.8667, 0.8667, 0.8692, 0.8718, 0.8744, 0.8744, 0.8769, 0.8769, 0.8769,\n",
       "          0.8821, 0.8821, 0.8872, 0.8872, 0.8872, 0.8872, 0.8872, 0.8897, 0.8923,\n",
       "          0.8923, 0.8949, 0.8949, 0.8974, 0.9000, 0.9000, 0.9000, 0.9026, 0.9026,\n",
       "          0.9051, 0.9077, 0.9103, 0.9128, 0.9154, 0.9154, 0.9179, 0.9205, 0.9205,\n",
       "          0.9231, 0.9256, 0.9282, 0.9282, 0.9282, 0.9282, 0.9282, 0.9282, 0.9308,\n",
       "          0.9308, 0.9308, 0.9333, 0.9333, 0.9359, 0.9385, 0.9436, 0.9436, 0.9436,\n",
       "          0.9436, 0.9436, 0.9436, 0.9462, 0.9487, 0.9487, 0.9487, 0.9487, 0.9487,\n",
       "          0.9487, 0.9487, 0.9513, 0.9513, 0.9538, 0.9564, 0.9564, 0.9564, 0.9590,\n",
       "          0.9590, 0.9590, 0.9590, 0.9590, 0.9590, 0.9590, 0.9590, 0.9615, 0.9615,\n",
       "          0.9615, 0.9615, 0.9615, 0.9615, 0.9615, 0.9615, 0.9615, 0.9641, 0.9641,\n",
       "          0.9641, 0.9667, 0.9667, 0.9692, 0.9718, 0.9718, 0.9718, 0.9718, 0.9718,\n",
       "          0.9718, 0.9718, 0.9718, 0.9718, 0.9718, 0.9744, 0.9769, 0.9769, 0.9795,\n",
       "          0.9795, 0.9795, 0.9795, 0.9795, 0.9821, 0.9821, 0.9821, 0.9846, 0.9846,\n",
       "          0.9872, 0.9872, 0.9872, 0.9872, 0.9872, 0.9872, 0.9897, 0.9897, 0.9923,\n",
       "          0.9923, 0.9923, 0.9923, 0.9923, 0.9923, 0.9923, 0.9949, 0.9949, 0.9949,\n",
       "          0.9949, 0.9949, 0.9949, 0.9949, 0.9949, 0.9949, 0.9949, 0.9949, 0.9949,\n",
       "          0.9949, 0.9949, 0.9949, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974,\n",
       "          0.9974, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974, 0.9974,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]),\n",
       "  'thresholds': tensor([1.0000, 1.0000, 0.9995, 0.9990, 0.9985, 0.9980, 0.9976, 0.9971, 0.9966,\n",
       "          0.9961, 0.9956, 0.9951, 0.9946, 0.9941, 0.9937, 0.9932, 0.9927, 0.9922,\n",
       "          0.9917, 0.9912, 0.9907, 0.9902, 0.9897, 0.9893, 0.9888, 0.9883, 0.9878,\n",
       "          0.9873, 0.9868, 0.9863, 0.9858, 0.9854, 0.9849, 0.9844, 0.9839, 0.9829,\n",
       "          0.9824, 0.9819, 0.9814, 0.9810, 0.9805, 0.9800, 0.9795, 0.9790, 0.9785,\n",
       "          0.9775, 0.9771, 0.9766, 0.9761, 0.9756, 0.9751, 0.9746, 0.9741, 0.9731,\n",
       "          0.9727, 0.9722, 0.9717, 0.9712, 0.9702, 0.9697, 0.9692, 0.9688, 0.9683,\n",
       "          0.9678, 0.9663, 0.9653, 0.9639, 0.9619, 0.9614, 0.9609, 0.9595, 0.9585,\n",
       "          0.9580, 0.9570, 0.9565, 0.9556, 0.9551, 0.9546, 0.9531, 0.9521, 0.9507,\n",
       "          0.9497, 0.9492, 0.9478, 0.9463, 0.9458, 0.9448, 0.9438, 0.9424, 0.9419,\n",
       "          0.9399, 0.9395, 0.9370, 0.9365, 0.9360, 0.9326, 0.9316, 0.9292, 0.9277,\n",
       "          0.9272, 0.9248, 0.9243, 0.9233, 0.9229, 0.9219, 0.9199, 0.9194, 0.9160,\n",
       "          0.9146, 0.9116, 0.9092, 0.9048, 0.9028, 0.8989, 0.8965, 0.8940, 0.8931,\n",
       "          0.8901, 0.8877, 0.8872, 0.8862, 0.8848, 0.8818, 0.8813, 0.8809, 0.8804,\n",
       "          0.8784, 0.8760, 0.8745, 0.8730, 0.8726, 0.8711, 0.8696, 0.8691, 0.8667,\n",
       "          0.8662, 0.8628, 0.8618, 0.8579, 0.8521, 0.8516, 0.8511, 0.8506, 0.8501,\n",
       "          0.8486, 0.8442, 0.8423, 0.8398, 0.8394, 0.8345, 0.8325, 0.8276, 0.8262,\n",
       "          0.8247, 0.8237, 0.8208, 0.8198, 0.8159, 0.8154, 0.8120, 0.8110, 0.8081,\n",
       "          0.8066, 0.8022, 0.7988, 0.7983, 0.7959, 0.7939, 0.7925, 0.7915, 0.7900,\n",
       "          0.7886, 0.7856, 0.7817, 0.7803, 0.7720, 0.7695, 0.7690, 0.7661, 0.7642,\n",
       "          0.7627, 0.7598, 0.7588, 0.7573, 0.7559, 0.7510, 0.7441, 0.7417, 0.7383,\n",
       "          0.7368, 0.7363, 0.7344, 0.7271, 0.7241, 0.7231, 0.7217, 0.7173, 0.7158,\n",
       "          0.7095, 0.7051, 0.7046, 0.7031, 0.7026, 0.6982, 0.6953, 0.6943, 0.6826,\n",
       "          0.6738, 0.6719, 0.6636, 0.6631, 0.6621, 0.6582, 0.6572, 0.6558, 0.6523,\n",
       "          0.6509, 0.6494, 0.6470, 0.6392, 0.6387, 0.6353, 0.6333, 0.6274, 0.6270,\n",
       "          0.6216, 0.6191, 0.6187, 0.6084, 0.6079, 0.6074, 0.5981, 0.5889, 0.5854,\n",
       "          0.5825, 0.5742, 0.5737, 0.5630, 0.5625, 0.5610, 0.5591, 0.5356, 0.5342,\n",
       "          0.5332, 0.5278, 0.5220, 0.5171, 0.5098, 0.5068, 0.5039, 0.5010, 0.4976,\n",
       "          0.4890, 0.4822, 0.4746, 0.4709, 0.4543, 0.4487, 0.4429, 0.4397, 0.4353,\n",
       "          0.4351, 0.4304, 0.4258, 0.4143, 0.3970, 0.3955, 0.3906, 0.3887, 0.3855,\n",
       "          0.3816, 0.3772, 0.3696, 0.3662, 0.3616, 0.3606, 0.3555, 0.3538, 0.3481,\n",
       "          0.3462, 0.3384, 0.3374, 0.3372, 0.3357, 0.3342, 0.3269, 0.3262, 0.3252,\n",
       "          0.3235, 0.3228, 0.3210, 0.3191, 0.3164, 0.3000, 0.2842, 0.2834, 0.2830,\n",
       "          0.2712, 0.2668, 0.2661, 0.2651, 0.2637, 0.2607, 0.2603, 0.2487, 0.2424,\n",
       "          0.2343, 0.2339, 0.2311, 0.2307, 0.2203, 0.2200, 0.2152, 0.2148, 0.2129,\n",
       "          0.2069, 0.2006, 0.2004, 0.1965, 0.1901, 0.1853, 0.1844, 0.1772, 0.1587,\n",
       "          0.1564, 0.1481, 0.1451, 0.1400, 0.1392, 0.1355, 0.1328, 0.1322, 0.1317,\n",
       "          0.1310, 0.1300, 0.1295, 0.1255, 0.1246, 0.1242, 0.1180, 0.1172, 0.1160,\n",
       "          0.1142, 0.1122, 0.1108, 0.1099, 0.1097, 0.1089, 0.1084, 0.1072, 0.1067,\n",
       "          0.1047, 0.1034, 0.1021, 0.1014, 0.1000, 0.0997, 0.0953, 0.0939, 0.0937,\n",
       "          0.0903, 0.0896, 0.0891, 0.0885, 0.0865, 0.0847, 0.0830, 0.0812, 0.0797,\n",
       "          0.0789, 0.0770, 0.0768, 0.0765, 0.0754, 0.0753, 0.0740, 0.0729, 0.0725,\n",
       "          0.0720, 0.0712, 0.0690, 0.0679, 0.0636, 0.0621, 0.0608, 0.0604, 0.0588,\n",
       "          0.0582, 0.0574, 0.0568, 0.0561, 0.0555, 0.0530, 0.0503, 0.0500, 0.0474,\n",
       "          0.0473, 0.0453, 0.0448, 0.0433, 0.0429, 0.0426, 0.0423, 0.0414, 0.0399,\n",
       "          0.0394, 0.0388, 0.0380, 0.0365, 0.0350, 0.0348, 0.0336, 0.0317, 0.0296,\n",
       "          0.0295, 0.0273, 0.0263, 0.0261, 0.0245, 0.0241, 0.0240, 0.0237, 0.0228,\n",
       "          0.0208, 0.0207, 0.0206, 0.0199, 0.0193, 0.0169, 0.0133],\n",
       "         dtype=torch.float16),\n",
       "  'name': 'Original NN PneumoniaMNIST',\n",
       "  'auc': tensor(0.9215, device='cuda:0'),\n",
       "  'model': LitSimpleCNN(\n",
       "    (model): SimpleCNN(\n",
       "      (features): Sequential(\n",
       "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): ReLU()\n",
       "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): ReLU()\n",
       "        (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (10): ReLU()\n",
       "        (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "      (relu_fc): ReLU()\n",
       "      (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "    (criterion): BCEWithLogitsLoss()\n",
       "    (train_accuracy): BinaryAccuracy()\n",
       "    (val_accuracy): BinaryAccuracy()\n",
       "    (val_auc): BinaryAUROC()\n",
       "    (test_accuracy): BinaryAccuracy()\n",
       "    (test_auc): BinaryAUROC()\n",
       "    (test_precision): BinaryPrecision()\n",
       "    (test_recall): BinaryRecall()\n",
       "    (test_f1): BinaryF1Score()\n",
       "  )},\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x76c683faa840>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Save the data\n",
    "save_to_pickle(list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader, filename='pickle/medMNIST_weighted.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576d29cb",
   "metadata": {},
   "source": [
    "# Load pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974bbf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from predict_ensemble_and_evaluate import save_to_pickle, load_from_pickle\n",
    "from predict_ensemble_and_evaluate import predict_ensemble_and_evaluate\n",
    "from predict_ensemble_and_evaluate import plot_roc_comparison\n",
    "from predict_ensemble_and_evaluate import make_curve_monotonic\n",
    "\n",
    "# Load the data\n",
    "list_folds_best_models, list_folds_weighted_clfs, results_original_roc, test_loader = load_from_pickle(filename='pickle/medMNIST_weighted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2787fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28a49e4",
   "metadata": {},
   "source": [
    "### Ensemble prediction using voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d77ee047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a single ensemble from 93 models across all folds.\n",
      "Extracting full dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions from all models...\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n",
      "Warning: Skipping model of unsupported type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Loop through all the FPR values to generate the ensemble ROC curve ---\n",
    "\n",
    "\n",
    "\n",
    "results_tuple = predict_ensemble_and_evaluate(list_folds_best_models=list_folds_best_models,\n",
    "    test_loader=test_loader)\n",
    "\n",
    "ensemble_results_soft = results_tuple['soft_voting']\n",
    "ensemble_results_hard = results_tuple['hard_voting']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49ac634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Plotting all ROC curves for comparison ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x1100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the best classifiers of all folds\n",
    "results_lists = []\n",
    "results_lists.extend(list_folds_best_models)\n",
    "results_lists.extend(list_folds_weighted_clfs)\n",
    "results_lists.append(ensemble_results_soft)\n",
    "results_lists.append(ensemble_results_hard)\n",
    "\n",
    "\n",
    "# --- Plot the final comparison ---\n",
    "print(\"\\n--- Plotting all ROC curves for comparison ---\")\n",
    "plot_roc_comparison(\n",
    "    results_lists=results_lists,\n",
    "    names=[\"Fold 1\", \"Fold 2\", \"Fold 3\", \"Fold 4\", \"Weighted1\", \"Weighted2\", \"Weighted3\", \"Weighted4\", \"Ensemble_voting_soft\", \"Ensemble_voting_hard\"],\n",
    "    results_original_roc=results_original_roc\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLlabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
